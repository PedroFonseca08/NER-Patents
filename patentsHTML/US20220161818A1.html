<!DOCTYPE html>
<html lang="en">
  <head>
    <title>US20220161818A1 - Method and system for supporting autonomous driving of an autonomous vehicle 
        - Google Patents</title>

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta charset="UTF-8">
    <meta name="referrer" content="origin-when-crossorigin">
    <link rel="canonical" href="https://patents.google.com/patent/US20220161818A1/en">
    <meta name="description" content="
     A method for supporting autonomous driving of an autonomous vehicle includes detecting, by an in-vehicle internet-of-things (IoT) platform of the autonomous vehicle, a vulnerable road user (VRU) having a mobile device in a vicinity of the autonomous vehicle. A mobility application runs on the mobile device of the VRU and sends VRU-specific data to the in-vehicle IoT platform of the autonomous vehicle. The VRU is detected based on the VRU-specific data and/or in-vehicle sensor data of the autonomous vehicle. The method further includes determining, by the in-vehicle IoT platform, a movement intention prediction based on the VRU-specific data. The movement intention prediction is computed by use of a machine learning model. The VRU-specific data of the mobile device are provided as input data for the machine learning model. In addition, the method includes performing an autonomous driving decision for the autonomous vehicle based on the movement intention prediction. 
   
   ">
    <meta name="DC.type" content="patent">
    <meta name="DC.title" content="Method and system for supporting autonomous driving of an autonomous vehicle 
       ">
    <meta name="DC.date" content="2019-12-06" scheme="dateSubmitted">
    <meta name="DC.description" content="
     A method for supporting autonomous driving of an autonomous vehicle includes detecting, by an in-vehicle internet-of-things (IoT) platform of the autonomous vehicle, a vulnerable road user (VRU) having a mobile device in a vicinity of the autonomous vehicle. A mobility application runs on the mobile device of the VRU and sends VRU-specific data to the in-vehicle IoT platform of the autonomous vehicle. The VRU is detected based on the VRU-specific data and/or in-vehicle sensor data of the autonomous vehicle. The method further includes determining, by the in-vehicle IoT platform, a movement intention prediction based on the VRU-specific data. The movement intention prediction is computed by use of a machine learning model. The VRU-specific data of the mobile device are provided as input data for the machine learning model. In addition, the method includes performing an autonomous driving decision for the autonomous vehicle based on the movement intention prediction. 
   
   ">
    <meta name="citation_patent_application_number" content="US:17/599,595">
    <meta name="citation_pdf_url" content="https://patentimages.storage.googleapis.com/47/99/4a/cc180e6469f48b/US20220161818A1.pdf">
    <meta name="citation_patent_publication_number" content="US:20220161818:A1">
    <meta name="DC.date" content="2022-05-26">
    <meta name="DC.contributor" content="GÃ¼rkan SOLMAZ" scheme="inventor">
    <meta name="DC.contributor" content="Everton Luis BERZ" scheme="inventor">
    <meta name="DC.contributor" content="Jonathan Fuerst" scheme="inventor">
    <meta name="DC.contributor" content="Bin Cheng" scheme="inventor">
    <meta name="DC.contributor" content="Mauricio Fadel Argerich" scheme="inventor">
    <meta name="DC.contributor" content="NEC Laboratories Europe GmbH" scheme="assignee">
    <meta name="DC.relation" content="US:20050073438:A1" scheme="references">
    <meta name="DC.relation" content="US:20180136651:A1" scheme="references">
    <meta name="DC.relation" content="US:11119477" scheme="references">
    <meta name="DC.relation" content="US:20190039570:A1" scheme="references">
    <meta name="DC.relation" content="US:20200026283:A1" scheme="references">
    <meta name="DC.relation" content="US:20190171988:A1" scheme="references">
    <meta name="DC.relation" content="US:20200241545:A1" scheme="references">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:400,400italic,500,500italic,700">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Product+Sans">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Google+Sans:wght@400;500;700">

    <style>
      body { transition: none; }
    </style>

    <script>
      window.version = 'patent-search.search_20240108_RC01';

      function sendFeedback() {
        userfeedback.api.startFeedback({
          'productId': '713680',
          'bucket': 'patent-search-web',
          'productVersion': window.version,
        });
      }

      window.experiments = {};
      window.experiments.patentCountries = "ae,ag,al,am,ao,ap,ar,at,au,aw,az,ba,bb,bd,be,bf,bg,bh,bj,bn,bo,br,bw,bx,by,bz,ca,cf,cg,ch,ci,cl,cm,cn,co,cr,cs,cu,cy,cz,dd,de,dj,dk,dm,do,dz,ea,ec,ee,eg,em,ep,es,fi,fr,ga,gb,gc,gd,ge,gh,gm,gn,gq,gr,gt,gw,hk,hn,hr,hu,ib,id,ie,il,in,ir,is,it,jo,jp,ke,kg,kh,km,kn,kp,kr,kw,kz,la,lc,li,lk,lr,ls,lt,lu,lv,ly,ma,mc,md,me,mg,mk,ml,mn,mo,mr,mt,mw,mx,my,mz,na,ne,ng,ni,nl,no,nz,oa,om,pa,pe,pg,ph,pl,pt,py,qa,ro,rs,ru,rw,sa,sc,sd,se,sg,si,sk,sl,sm,sn,st,su,sv,sy,sz,td,tg,th,tj,tm,tn,tr,tt,tw,tz,ua,ug,us,uy,uz,vc,ve,vn,wo,yu,za,zm,zw";
      
      
      window.experiments.keywordWizard = true;
      
      
      
      window.experiments.definitions = true;

      window.Polymer = {
        dom: 'shady',
        lazyRegister: true,
      };
    </script>

    <script src="//www.gstatic.com/patent-search/frontend/patent-search.search_20240108_RC01/scs/compiled_dir/webcomponentsjs/webcomponents-lite.min.js"></script>
    <link rel="import" href="//www.gstatic.com/patent-search/frontend/patent-search.search_20240108_RC01/scs/compiled_dir/search-app-vulcanized.html">
  </head>
  <body unresolved>
    <script src="//www.gstatic.com/patent-search/frontend/patent-search.search_20240108_RC01/scs/compiled_dir/search-app-vulcanized.js"></script>
    <search-app>
      
      

      <article class="result" itemscope itemtype="http://schema.org/ScholarlyArticle">
  <h1 itemprop="pageTitle">US20220161818A1 - Method and system for supporting autonomous driving of an autonomous vehicle 
        - Google Patents</h1>
  <span itemprop="title">Method and system for supporting autonomous driving of an autonomous vehicle 
       </span>

  <meta itemprop="type" content="patent">
  <a href="https://patentimages.storage.googleapis.com/47/99/4a/cc180e6469f48b/US20220161818A1.pdf" itemprop="pdfLink">Download PDF</a>
  <h2>Info</h2>

  <dl>
    <dt>Publication number</dt>
    <dd itemprop="publicationNumber">US20220161818A1</dd>
    <meta itemprop="numberWithoutCodes" content="20220161818">
    <meta itemprop="kindCode" content="A1">
    <meta itemprop="publicationDescription" content="Patent application publication">
    <span>US20220161818A1</span>
    <span>US17/599,595</span>
    <span>US201917599595A</span>
    <span>US2022161818A1</span>
    <span>US 20220161818 A1</span>
    <span>US20220161818 A1</span>
    <span>US 20220161818A1</span>
    <span>  </span>
    <span> </span>
    <span> </span>
    <span>US 201917599595 A</span>
    <span>US201917599595 A</span>
    <span>US 201917599595A</span>
    <span>US 2022161818 A1</span>
    <span>US2022161818 A1</span>
    <span>US 2022161818A1</span>

    <dt>Authority</dt>
    <dd itemprop="countryCode">US</dd>
    <dd itemprop="countryName">United States</dd>

    <dt>Prior art keywords</dt>
    <dd itemprop="priorArtKeywords" repeat>vru</dd>
    <dd itemprop="priorArtKeywords" repeat>vehicle</dd>
    <dd itemprop="priorArtKeywords" repeat>data</dd>
    <dd itemprop="priorArtKeywords" repeat>autonomous vehicle</dd>
    <dd itemprop="priorArtKeywords" repeat>mobile device</dd>

    <dt>Prior art date</dt>
    <dd><time itemprop="priorArtDate" datetime="2019-04-05">2019-04-05</time></dd>

    <dt>Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)</dt>
    <dd itemprop="legalStatusIfi" itemscope>
      <span itemprop="status">Pending</span>
    </dd>
  </dl>

  <dt>Application number</dt>
  <dd itemprop="applicationNumber">US17/599,595</dd>

  

  

  <dt>Inventor</dt>
  <dd itemprop="inventor" repeat>GÃ¼rkan SOLMAZ</dd>
  <dd itemprop="inventor" repeat>Everton Luis BERZ</dd>
  <dd itemprop="inventor" repeat>Jonathan Fuerst</dd>
  <dd itemprop="inventor" repeat>Bin Cheng</dd>
  <dd itemprop="inventor" repeat>Mauricio Fadel Argerich</dd>

  <dt>Current Assignee (The listed assignees may be inaccurate. Google has not performed a legal analysis and makes no representation or warranty as to the accuracy of the list.)</dt>
  <dd itemprop="assigneeCurrent" repeat>
    NEC Laboratories Europe GmbH
  </dd>

  <dt>Original Assignee</dt>
  <dd itemprop="assigneeOriginal" repeat>NEC Laboratories Europe GmbH</dd>

  <dt>Priority date (The priority date is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the date listed.)</dt>
  <dd><time itemprop="priorityDate" datetime="2019-04-05">2019-04-05</time></dd>

  <dt>Filing date</dt>
  <dd><time itemprop="filingDate" datetime="2019-12-06">2019-12-06</time></dd>

  <dt>Publication date</dt>
  <dd><time itemprop="publicationDate" datetime="2022-05-26">2022-05-26</time></dd>

  
  <dd itemprop="events" itemscope repeat>
    <time itemprop="date" datetime="2019-12-06">2019-12-06</time>
    <span itemprop="title">Application filed by NEC Laboratories Europe GmbH</span>
    <span itemprop="type">filed</span>
    <span itemprop="critical" content="true" bool>Critical</span>
    
    
    
    <span itemprop="assigneeSearch">NEC Laboratories Europe GmbH</span>
  </dd>
  <dd itemprop="events" itemscope repeat>
    <time itemprop="date" datetime="2021-10-12">2021-10-12</time>
    <span itemprop="title">Assigned to NEC Laboratories Europe GmbH</span>
    <span itemprop="type">reassignment</span>
    
    
    
    
    <span itemprop="assigneeSearch">NEC Laboratories Europe GmbH</span>
    <span itemprop="description" repeat>ASSIGNMENT OF ASSIGNORS INTEREST (SEE DOCUMENT FOR DETAILS).</span>
    <span itemprop="description" repeat>Assignors: CHENG, BIN, FUERST, JONATHAN, FADEL ARGERICH, MUARICIO, BERZ, Everton Luis, Solmaz, Gurkan</span>
  </dd>
  <dd itemprop="events" itemscope repeat>
    <time itemprop="date" datetime="2022-05-26">2022-05-26</time>
    <span itemprop="title">Publication of US20220161818A1</span>
    <span itemprop="type">publication</span>
    <span itemprop="critical" content="true" bool>Critical</span>
    
    
    <span itemprop="documentId">patent/US20220161818A1/en</span>
    
  </dd>
  <dd itemprop="events" itemscope repeat>
    <time itemprop="date">Status</time>
    <span itemprop="title">Pending</span>
    <span itemprop="type">legal-status</span>
    <span itemprop="critical" content="true" bool>Critical</span>
    <span itemprop="current" content="true" bool>Current</span>
    
    
    
  </dd>

  <h2>Links</h2>
  <ul>
    <li itemprop="links" itemscope repeat>
          <meta itemprop="id" content="usptoLink">
          <a href="https://appft.uspto.gov/netacgi/nph-Parser?Sect1=PTO1&Sect2=HITOFF&p=1&u=/netahtml/PTO/srchnum.html&r=1&f=G&l=50&d=PG01&s1=20220161818.PGNR." itemprop="url" target="_blank"><span itemprop="text">USPTO</span></a>
        </li>
        
        <li itemprop="links" itemscope repeat>
          <meta itemprop="id" content="usptoPatentCenterLink">
          <a href="https://patentcenter.uspto.gov/applications/17599595" itemprop="url" target="_blank"><span itemprop="text">USPTO PatentCenter</span></a>
        </li>
        <li itemprop="links" itemscope repeat>
          <meta itemprop="id" content="usptoAssignmentLink">
          <a href="https://assignment.uspto.gov/patent/index.html#/patent/search/resultFilter?searchInput=20220161818" itemprop="url" target="_blank"><span itemprop="text">USPTO Assignment</span></a>
        </li>

    <li itemprop="links" itemscope repeat>
        <meta itemprop="id" content="espacenetLink">
        <a href="https://worldwide.espacenet.com/publicationDetails/biblio?CC=US&amp;NR=2022161818A1&amp;KC=A1&amp;FT=D" itemprop="url" target="_blank"><span itemprop="text">Espacenet</span></a>
      </li>
      

    

    
      <li itemprop="links" itemscope repeat>
        <meta itemprop="id" content="globalDossierLink">
        <a href="https://globaldossier.uspto.gov/#/result/publication/US/20220161818/1" itemprop="url" target="_blank"><span itemprop="text">Global Dossier</span></a>
      </li>

      

      

      

      <li itemprop="links" itemscope repeat>
        <meta itemprop="id" content="stackexchangeLink">
        <a href="https://patents.stackexchange.com/questions/tagged/US20220161818" itemprop="url"><span itemprop="text">Discuss</span></a>
      </li>
      
  </ul>

  <ul itemprop="concept" itemscope>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000000034</span>
      <span itemprop="name">method</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>title</span>
      <span itemprop="sections" repeat>claims</span>
      <span itemprop="sections" repeat>abstract</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">54</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000010801</span>
      <span itemprop="name">machine learning</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>claims</span>
      <span itemprop="sections" repeat>abstract</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">49</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000009471</span>
      <span itemprop="name">action</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>claims</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">12</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000012545</span>
      <span itemprop="name">processing</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>claims</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">10</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000008569</span>
      <span itemprop="name">process</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>claims</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">9</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000001514</span>
      <span itemprop="name">detection method</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">23</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000004891</span>
      <span itemprop="name">communication</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">11</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000013528</span>
      <span itemprop="name">artificial neural network</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">10</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000012549</span>
      <span itemprop="name">training</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">10</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000002372</span>
      <span itemprop="name">labelling</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">9</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000012360</span>
      <span itemprop="name">testing method</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">9</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000002474</span>
      <span itemprop="name">experimental method</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">5</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000006399</span>
      <span itemprop="name">behavior</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">4</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000006870</span>
      <span itemprop="name">function</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">4</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000008901</span>
      <span itemprop="name">benefit</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">3</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000000295</span>
      <span itemprop="name">complement effect</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">3</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000003062</span>
      <span itemprop="name">neural network model</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">3</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000011160</span>
      <span itemprop="name">research</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">3</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000013459</span>
      <span itemprop="name">approach</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">2</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000005516</span>
      <span itemprop="name">engineering process</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">2</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000011156</span>
      <span itemprop="name">evaluation</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">2</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000003993</span>
      <span itemprop="name">interaction</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">2</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000005259</span>
      <span itemprop="name">measurement</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">2</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">210000002569</span>
      <span itemprop="name">neuron</span>
      <span itemprop="domain">Anatomy</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">2</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000004088</span>
      <span itemprop="name">simulation</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">2</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000007704</span>
      <span itemprop="name">transition</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">2</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000001413</span>
      <span itemprop="name">cellular effect</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000013461</span>
      <span itemprop="name">design</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000011161</span>
      <span itemprop="name">development</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000002708</span>
      <span itemprop="name">enhancing effect</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000007613</span>
      <span itemprop="name">environmental effect</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">239000000284</span>
      <span itemprop="name">extract</span>
      <span itemprop="domain">Substances</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000006872</span>
      <span itemprop="name">improvement</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000010354</span>
      <span itemprop="name">integration</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000007774</span>
      <span itemprop="name">longterm</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000012986</span>
      <span itemprop="name">modification</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000004048</span>
      <span itemprop="name">modification</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000008520</span>
      <span itemprop="name">organization</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">210000004205</span>
      <span itemprop="name">output neuron</span>
      <span itemprop="domain">Anatomy</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000003909</span>
      <span itemprop="name">pattern recognition</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000009467</span>
      <span itemprop="name">reduction</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000012827</span>
      <span itemprop="name">research and development</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000001953</span>
      <span itemprop="name">sensory effect</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000012358</span>
      <span itemprop="name">sourcing</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000010200</span>
      <span itemprop="name">validation analysis</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
  </ul>

  <section>
    <h2>Images</h2>
    <ul>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/85/0c/95/0e67abf5ec567f/US20220161818A1-20220526-D00000.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/92/1d/3a/01837468622c2b/US20220161818A1-20220526-D00000.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="0">
            <meta itemprop="id" content="1">
            <meta itemprop="label" content="aforementioned Step">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="177">
              <meta itemprop="top" content="34">
              <meta itemprop="right" content="197">
              <meta itemprop="bottom" content="62">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="0">
            <meta itemprop="id" content="2">
            <meta itemprop="label" content="case">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="449">
              <meta itemprop="top" content="34">
              <meta itemprop="right" content="471">
              <meta itemprop="bottom" content="61">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="0">
            <meta itemprop="id" content="3">
            <meta itemprop="label" content="case">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="184">
              <meta itemprop="top" content="397">
              <meta itemprop="right" content="201">
              <meta itemprop="bottom" content="432">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="0">
            <meta itemprop="id" content="3">
            <meta itemprop="label" content="case">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="350">
              <meta itemprop="top" content="466">
              <meta itemprop="right" content="373">
              <meta itemprop="bottom" content="493">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="0">
            <meta itemprop="id" content="3">
            <meta itemprop="label" content="case">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1757">
              <meta itemprop="top" content="364">
              <meta itemprop="right" content="1776">
              <meta itemprop="bottom" content="391">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/de/2f/e5/17716f7eda6e5a/US20220161818A1-20220526-D00001.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/86/fe/b4/cff4ccf88a57be/US20220161818A1-20220526-D00001.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="1">
            <meta itemprop="id" content="1">
            <meta itemprop="label" content="aforementioned Step">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="189">
              <meta itemprop="top" content="46">
              <meta itemprop="right" content="210">
              <meta itemprop="bottom" content="73">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="1">
            <meta itemprop="id" content="2">
            <meta itemprop="label" content="case">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="460">
              <meta itemprop="top" content="47">
              <meta itemprop="right" content="482">
              <meta itemprop="bottom" content="74">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="1">
            <meta itemprop="id" content="3">
            <meta itemprop="label" content="case">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="196">
              <meta itemprop="top" content="409">
              <meta itemprop="right" content="213">
              <meta itemprop="bottom" content="444">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="1">
            <meta itemprop="id" content="3">
            <meta itemprop="label" content="case">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="363">
              <meta itemprop="top" content="477">
              <meta itemprop="right" content="386">
              <meta itemprop="bottom" content="503">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="1">
            <meta itemprop="id" content="3">
            <meta itemprop="label" content="case">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1768">
              <meta itemprop="top" content="377">
              <meta itemprop="right" content="1790">
              <meta itemprop="bottom" content="404">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/f9/94/e2/68431b0f01aee9/US20220161818A1-20220526-D00002.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/38/d1/68/959fdced47e11f/US20220161818A1-20220526-D00002.png">
        <ul>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/58/3b/80/ad8ec759aec438/US20220161818A1-20220526-D00003.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/36/30/04/16bd668869f22d/US20220161818A1-20220526-D00003.png">
        <ul>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/cb/c7/a4/b08a55922ec23a/US20220161818A1-20220526-D00004.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/3c/10/f1/35f8ea1ec92bc7/US20220161818A1-20220526-D00004.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="4">
            <meta itemprop="id" content="1">
            <meta itemprop="label" content="aforementioned Step">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="749">
              <meta itemprop="top" content="743">
              <meta itemprop="right" content="775">
              <meta itemprop="bottom" content="786">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/15/f1/42/851e94e1139a02/US20220161818A1-20220526-D00005.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/18/06/61/c2827edaafa86c/US20220161818A1-20220526-D00005.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="5">
            <meta itemprop="id" content="1">
            <meta itemprop="label" content="aforementioned Step">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="791">
              <meta itemprop="top" content="805">
              <meta itemprop="right" content="817">
              <meta itemprop="bottom" content="844">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/cd/48/48/fc76226b417071/US20220161818A1-20220526-D00006.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/69/59/b0/2ffd6f1be02d68/US20220161818A1-20220526-D00006.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="6">
            <meta itemprop="id" content="1">
            <meta itemprop="label" content="aforementioned Step">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="126">
              <meta itemprop="top" content="1545">
              <meta itemprop="right" content="141">
              <meta itemprop="bottom" content="1581">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="6">
            <meta itemprop="id" content="1">
            <meta itemprop="label" content="aforementioned Step">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1013">
              <meta itemprop="top" content="795">
              <meta itemprop="right" content="1031">
              <meta itemprop="bottom" content="823">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="6">
            <meta itemprop="id" content="1">
            <meta itemprop="label" content="aforementioned Step">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="791">
              <meta itemprop="top" content="553">
              <meta itemprop="right" content="810">
              <meta itemprop="bottom" content="579">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="6">
            <meta itemprop="id" content="1">
            <meta itemprop="label" content="aforementioned Step">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="858">
              <meta itemprop="top" content="2205">
              <meta itemprop="right" content="871">
              <meta itemprop="bottom" content="2241">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="6">
            <meta itemprop="id" content="1">
            <meta itemprop="label" content="aforementioned Step">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="511">
              <meta itemprop="top" content="689">
              <meta itemprop="right" content="534">
              <meta itemprop="bottom" content="729">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="6">
            <meta itemprop="id" content="1">
            <meta itemprop="label" content="aforementioned Step">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="976">
              <meta itemprop="top" content="263">
              <meta itemprop="right" content="994">
              <meta itemprop="bottom" content="289">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="6">
            <meta itemprop="id" content="2">
            <meta itemprop="label" content="case">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="644">
              <meta itemprop="top" content="748">
              <meta itemprop="right" content="666">
              <meta itemprop="bottom" content="783">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="6">
            <meta itemprop="id" content="2">
            <meta itemprop="label" content="case">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="869">
              <meta itemprop="top" content="2087">
              <meta itemprop="right" content="895">
              <meta itemprop="bottom" content="2123">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="6">
            <meta itemprop="id" content="2">
            <meta itemprop="label" content="case">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="354">
              <meta itemprop="top" content="1543">
              <meta itemprop="right" content="377">
              <meta itemprop="bottom" content="1579">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="6">
            <meta itemprop="id" content="2">
            <meta itemprop="label" content="case">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="340">
              <meta itemprop="top" content="238">
              <meta itemprop="right" content="364">
              <meta itemprop="bottom" content="263">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="6">
            <meta itemprop="id" content="2">
            <meta itemprop="label" content="case">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="756">
              <meta itemprop="top" content="803">
              <meta itemprop="right" content="783">
              <meta itemprop="bottom" content="831">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="6">
            <meta itemprop="id" content="3">
            <meta itemprop="label" content="case">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="394">
              <meta itemprop="top" content="780">
              <meta itemprop="right" content="417">
              <meta itemprop="bottom" content="806">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="6">
            <meta itemprop="id" content="3">
            <meta itemprop="label" content="case">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="788">
              <meta itemprop="top" content="692">
              <meta itemprop="right" content="811">
              <meta itemprop="bottom" content="727">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="6">
            <meta itemprop="id" content="3">
            <meta itemprop="label" content="case">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="846">
              <meta itemprop="top" content="2003">
              <meta itemprop="right" content="873">
              <meta itemprop="bottom" content="2037">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/61/ef/e7/25371fab65cddb/US20220161818A1-20220526-D00007.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/93/49/86/9c6314102509dd/US20220161818A1-20220526-D00007.png">
        <ul>
        </ul>
      </li>
    </ul>
  </section>

  <section>
    <h2>Classifications</h2>
    <ul>
      <li>
        <ul itemprop="classifications" itemscope repeat>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B</span>&mdash;<span itemprop="Description">PERFORMING OPERATIONS; TRANSPORTING</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B60</span>&mdash;<span itemprop="Description">VEHICLES IN GENERAL</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B60W</span>&mdash;<span itemprop="Description">CONJOINT CONTROL OF VEHICLE SUB-UNITS OF DIFFERENT TYPE OR DIFFERENT FUNCTION; CONTROL SYSTEMS SPECIALLY ADAPTED FOR HYBRID VEHICLES; ROAD VEHICLE DRIVE CONTROL SYSTEMS FOR PURPOSES NOT RELATED TO THE CONTROL OF A PARTICULAR SUB-UNIT</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B60W60/00</span>&mdash;<span itemprop="Description">Drive control systems specially adapted for autonomous road vehicles</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B60W60/001</span>&mdash;<span itemprop="Description">Planning or execution of driving tasks</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B60W60/0011</span>&mdash;<span itemprop="Description">Planning or execution of driving tasks involving control alternatives for a single driving scenario, e.g. planning several paths to avoid obstacles</span>
            <meta itemprop="Leaf" content="true"><meta itemprop="FirstCode" content="true"><meta itemprop="IsCPC" content="true">
          </li>
        </ul>
      </li>
      <li>
        <ul itemprop="classifications" itemscope repeat>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B</span>&mdash;<span itemprop="Description">PERFORMING OPERATIONS; TRANSPORTING</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B60</span>&mdash;<span itemprop="Description">VEHICLES IN GENERAL</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B60W</span>&mdash;<span itemprop="Description">CONJOINT CONTROL OF VEHICLE SUB-UNITS OF DIFFERENT TYPE OR DIFFERENT FUNCTION; CONTROL SYSTEMS SPECIALLY ADAPTED FOR HYBRID VEHICLES; ROAD VEHICLE DRIVE CONTROL SYSTEMS FOR PURPOSES NOT RELATED TO THE CONTROL OF A PARTICULAR SUB-UNIT</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B60W40/00</span>&mdash;<span itemprop="Description">Estimation or calculation of non-directly measurable driving parameters for road vehicle drive control systems not related to the control of a particular sub unit, e.g. by using mathematical models</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B60W40/02</span>&mdash;<span itemprop="Description">Estimation or calculation of non-directly measurable driving parameters for road vehicle drive control systems not related to the control of a particular sub unit, e.g. by using mathematical models related to ambient conditions</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B60W40/04</span>&mdash;<span itemprop="Description">Traffic conditions</span>
            <meta itemprop="Leaf" content="true"><meta itemprop="IsCPC" content="true">
          </li>
        </ul>
      </li>
      <li>
        <ul itemprop="classifications" itemscope repeat>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B</span>&mdash;<span itemprop="Description">PERFORMING OPERATIONS; TRANSPORTING</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B60</span>&mdash;<span itemprop="Description">VEHICLES IN GENERAL</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B60W</span>&mdash;<span itemprop="Description">CONJOINT CONTROL OF VEHICLE SUB-UNITS OF DIFFERENT TYPE OR DIFFERENT FUNCTION; CONTROL SYSTEMS SPECIALLY ADAPTED FOR HYBRID VEHICLES; ROAD VEHICLE DRIVE CONTROL SYSTEMS FOR PURPOSES NOT RELATED TO THE CONTROL OF A PARTICULAR SUB-UNIT</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B60W60/00</span>&mdash;<span itemprop="Description">Drive control systems specially adapted for autonomous road vehicles</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B60W60/001</span>&mdash;<span itemprop="Description">Planning or execution of driving tasks</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B60W60/0015</span>&mdash;<span itemprop="Description">Planning or execution of driving tasks specially adapted for safety</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B60W60/0017</span>&mdash;<span itemprop="Description">Planning or execution of driving tasks specially adapted for safety of other traffic participants</span>
            <meta itemprop="Leaf" content="true"><meta itemprop="IsCPC" content="true">
          </li>
        </ul>
      </li>
      <li>
        <ul itemprop="classifications" itemscope repeat>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B</span>&mdash;<span itemprop="Description">PERFORMING OPERATIONS; TRANSPORTING</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B60</span>&mdash;<span itemprop="Description">VEHICLES IN GENERAL</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B60W</span>&mdash;<span itemprop="Description">CONJOINT CONTROL OF VEHICLE SUB-UNITS OF DIFFERENT TYPE OR DIFFERENT FUNCTION; CONTROL SYSTEMS SPECIALLY ADAPTED FOR HYBRID VEHICLES; ROAD VEHICLE DRIVE CONTROL SYSTEMS FOR PURPOSES NOT RELATED TO THE CONTROL OF A PARTICULAR SUB-UNIT</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B60W60/00</span>&mdash;<span itemprop="Description">Drive control systems specially adapted for autonomous road vehicles</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B60W60/001</span>&mdash;<span itemprop="Description">Planning or execution of driving tasks</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B60W60/0027</span>&mdash;<span itemprop="Description">Planning or execution of driving tasks using trajectory prediction for other traffic participants</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B60W60/00274</span>&mdash;<span itemprop="Description">Planning or execution of driving tasks using trajectory prediction for other traffic participants considering possible movement changes</span>
            <meta itemprop="Leaf" content="true"><meta itemprop="IsCPC" content="true">
          </li>
        </ul>
      </li>
      <li>
        <ul itemprop="classifications" itemscope repeat>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G</span>&mdash;<span itemprop="Description">PHYSICS</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06</span>&mdash;<span itemprop="Description">COMPUTING; CALCULATING OR COUNTING</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06N</span>&mdash;<span itemprop="Description">COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06N3/00</span>&mdash;<span itemprop="Description">Computing arrangements based on biological models</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06N3/02</span>&mdash;<span itemprop="Description">Neural networks</span>
            <meta itemprop="Leaf" content="true"><meta itemprop="IsCPC" content="true">
          </li>
        </ul>
      </li>
      <li>
        <ul itemprop="classifications" itemscope repeat>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G</span>&mdash;<span itemprop="Description">PHYSICS</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06</span>&mdash;<span itemprop="Description">COMPUTING; CALCULATING OR COUNTING</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06V</span>&mdash;<span itemprop="Description">IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06V20/00</span>&mdash;<span itemprop="Description">Scenes; Scene-specific elements</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06V20/50</span>&mdash;<span itemprop="Description">Context or environment of the image</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06V20/56</span>&mdash;<span itemprop="Description">Context or environment of the image exterior to a vehicle by using sensors mounted on the vehicle</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06V20/58</span>&mdash;<span itemprop="Description">Recognition of moving objects or obstacles, e.g. vehicles or pedestrians; Recognition of traffic objects, e.g. traffic signs, traffic lights or roads</span>
            <meta itemprop="Leaf" content="true"><meta itemprop="IsCPC" content="true">
          </li>
        </ul>
      </li>
      <li>
        <ul itemprop="classifications" itemscope repeat>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G</span>&mdash;<span itemprop="Description">PHYSICS</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G08</span>&mdash;<span itemprop="Description">SIGNALLING</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G08G</span>&mdash;<span itemprop="Description">TRAFFIC CONTROL SYSTEMS</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G08G1/00</span>&mdash;<span itemprop="Description">Traffic control systems for road vehicles</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G08G1/09</span>&mdash;<span itemprop="Description">Arrangements for giving variable traffic instructions</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G08G1/0962</span>&mdash;<span itemprop="Description">Arrangements for giving variable traffic instructions having an indicator mounted inside the vehicle, e.g. giving voice messages</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G08G1/0967</span>&mdash;<span itemprop="Description">Systems involving transmission of highway information, e.g. weather, speed limits</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G08G1/096708</span>&mdash;<span itemprop="Description">Systems involving transmission of highway information, e.g. weather, speed limits where the received information might be used to generate an automatic action on the vehicle control</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G08G1/096725</span>&mdash;<span itemprop="Description">Systems involving transmission of highway information, e.g. weather, speed limits where the received information might be used to generate an automatic action on the vehicle control where the received information generates an automatic action on the vehicle control</span>
            <meta itemprop="Leaf" content="true"><meta itemprop="IsCPC" content="true">
          </li>
        </ul>
      </li>
      <li>
        <ul itemprop="classifications" itemscope repeat>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G</span>&mdash;<span itemprop="Description">PHYSICS</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G08</span>&mdash;<span itemprop="Description">SIGNALLING</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G08G</span>&mdash;<span itemprop="Description">TRAFFIC CONTROL SYSTEMS</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G08G1/00</span>&mdash;<span itemprop="Description">Traffic control systems for road vehicles</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G08G1/16</span>&mdash;<span itemprop="Description">Anti-collision systems</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G08G1/161</span>&mdash;<span itemprop="Description">Decentralised systems, e.g. inter-vehicle communication</span>
            <meta itemprop="Leaf" content="true"><meta itemprop="IsCPC" content="true">
          </li>
        </ul>
      </li>
      <li>
        <ul itemprop="classifications" itemscope repeat>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G</span>&mdash;<span itemprop="Description">PHYSICS</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G08</span>&mdash;<span itemprop="Description">SIGNALLING</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G08G</span>&mdash;<span itemprop="Description">TRAFFIC CONTROL SYSTEMS</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G08G1/00</span>&mdash;<span itemprop="Description">Traffic control systems for road vehicles</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G08G1/16</span>&mdash;<span itemprop="Description">Anti-collision systems</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G08G1/166</span>&mdash;<span itemprop="Description">Anti-collision systems for active traffic, e.g. moving vehicles, pedestrians, bikes</span>
            <meta itemprop="Leaf" content="true"><meta itemprop="IsCPC" content="true">
          </li>
        </ul>
      </li>
      <li>
        <ul itemprop="classifications" itemscope repeat>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G</span>&mdash;<span itemprop="Description">PHYSICS</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G16</span>&mdash;<span itemprop="Description">INFORMATION AND COMMUNICATION TECHNOLOGY [ICT] SPECIALLY ADAPTED FOR SPECIFIC APPLICATION FIELDS</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G16Y</span>&mdash;<span itemprop="Description">INFORMATION AND COMMUNICATION TECHNOLOGY SPECIALLY ADAPTED FOR THE INTERNET OF THINGS [IoT]</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G16Y40/00</span>&mdash;<span itemprop="Description">IoT characterised by the purpose of the information processing</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G16Y40/50</span>&mdash;<span itemprop="Description">Safety; Security of things, users, data or systems</span>
            <meta itemprop="Leaf" content="true"><meta itemprop="IsCPC" content="true">
          </li>
        </ul>
      </li>
      <li>
        <ul itemprop="classifications" itemscope repeat>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">H</span>&mdash;<span itemprop="Description">ELECTRICITY</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">H04</span>&mdash;<span itemprop="Description">ELECTRIC COMMUNICATION TECHNIQUE</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">H04W</span>&mdash;<span itemprop="Description">WIRELESS COMMUNICATION NETWORKS</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">H04W4/00</span>&mdash;<span itemprop="Description">Services specially adapted for wireless communication networks; Facilities therefor</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">H04W4/30</span>&mdash;<span itemprop="Description">Services specially adapted for particular environments, situations or purposes</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">H04W4/40</span>&mdash;<span itemprop="Description">Services specially adapted for particular environments, situations or purposes for vehicles, e.g. vehicle-to-pedestrians [V2P]</span>
            <meta itemprop="Leaf" content="true"><meta itemprop="IsCPC" content="true">
          </li>
        </ul>
      </li>
      <li>
        <ul itemprop="classifications" itemscope repeat>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B</span>&mdash;<span itemprop="Description">PERFORMING OPERATIONS; TRANSPORTING</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B60</span>&mdash;<span itemprop="Description">VEHICLES IN GENERAL</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B60W</span>&mdash;<span itemprop="Description">CONJOINT CONTROL OF VEHICLE SUB-UNITS OF DIFFERENT TYPE OR DIFFERENT FUNCTION; CONTROL SYSTEMS SPECIALLY ADAPTED FOR HYBRID VEHICLES; ROAD VEHICLE DRIVE CONTROL SYSTEMS FOR PURPOSES NOT RELATED TO THE CONTROL OF A PARTICULAR SUB-UNIT</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B60W2420/00</span>&mdash;<span itemprop="Description">Indexing codes relating to the type of sensors based on the principle of their operation</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B60W2420/40</span>&mdash;<span itemprop="Description">Photo or light sensitive means, e.g. infrared sensors</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B60W2420/403</span>&mdash;<span itemprop="Description">Image sensing, e.g. optical camera</span>
            <meta itemprop="Leaf" content="true"><meta itemprop="Additional" content="true"><meta itemprop="IsCPC" content="true">
          </li>
        </ul>
      </li>
      <li>
        <ul itemprop="classifications" itemscope repeat>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B</span>&mdash;<span itemprop="Description">PERFORMING OPERATIONS; TRANSPORTING</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B60</span>&mdash;<span itemprop="Description">VEHICLES IN GENERAL</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B60W</span>&mdash;<span itemprop="Description">CONJOINT CONTROL OF VEHICLE SUB-UNITS OF DIFFERENT TYPE OR DIFFERENT FUNCTION; CONTROL SYSTEMS SPECIALLY ADAPTED FOR HYBRID VEHICLES; ROAD VEHICLE DRIVE CONTROL SYSTEMS FOR PURPOSES NOT RELATED TO THE CONTROL OF A PARTICULAR SUB-UNIT</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B60W2420/00</span>&mdash;<span itemprop="Description">Indexing codes relating to the type of sensors based on the principle of their operation</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B60W2420/42</span>&mdash;<span itemprop="Description">Image sensing, e.g. optical camera</span>
            <meta itemprop="Leaf" content="true"><meta itemprop="Additional" content="true"><meta itemprop="IsCPC" content="true">
          </li>
        </ul>
      </li>
      <li>
        <ul itemprop="classifications" itemscope repeat>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B</span>&mdash;<span itemprop="Description">PERFORMING OPERATIONS; TRANSPORTING</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B60</span>&mdash;<span itemprop="Description">VEHICLES IN GENERAL</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B60W</span>&mdash;<span itemprop="Description">CONJOINT CONTROL OF VEHICLE SUB-UNITS OF DIFFERENT TYPE OR DIFFERENT FUNCTION; CONTROL SYSTEMS SPECIALLY ADAPTED FOR HYBRID VEHICLES; ROAD VEHICLE DRIVE CONTROL SYSTEMS FOR PURPOSES NOT RELATED TO THE CONTROL OF A PARTICULAR SUB-UNIT</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B60W2554/00</span>&mdash;<span itemprop="Description">Input parameters relating to objects</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B60W2554/40</span>&mdash;<span itemprop="Description">Dynamic objects, e.g. animals, windblown objects</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B60W2554/402</span>&mdash;<span itemprop="Description">Type</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B60W2554/4026</span>&mdash;<span itemprop="Description">Cycles</span>
            <meta itemprop="Leaf" content="true"><meta itemprop="Additional" content="true"><meta itemprop="IsCPC" content="true">
          </li>
        </ul>
      </li>
      <li>
        <ul itemprop="classifications" itemscope repeat>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B</span>&mdash;<span itemprop="Description">PERFORMING OPERATIONS; TRANSPORTING</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B60</span>&mdash;<span itemprop="Description">VEHICLES IN GENERAL</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B60W</span>&mdash;<span itemprop="Description">CONJOINT CONTROL OF VEHICLE SUB-UNITS OF DIFFERENT TYPE OR DIFFERENT FUNCTION; CONTROL SYSTEMS SPECIALLY ADAPTED FOR HYBRID VEHICLES; ROAD VEHICLE DRIVE CONTROL SYSTEMS FOR PURPOSES NOT RELATED TO THE CONTROL OF A PARTICULAR SUB-UNIT</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B60W2554/00</span>&mdash;<span itemprop="Description">Input parameters relating to objects</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B60W2554/40</span>&mdash;<span itemprop="Description">Dynamic objects, e.g. animals, windblown objects</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B60W2554/402</span>&mdash;<span itemprop="Description">Type</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B60W2554/4029</span>&mdash;<span itemprop="Description">Pedestrians</span>
            <meta itemprop="Leaf" content="true"><meta itemprop="Additional" content="true"><meta itemprop="IsCPC" content="true">
          </li>
        </ul>
      </li>
      <li>
        <ul itemprop="classifications" itemscope repeat>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B</span>&mdash;<span itemprop="Description">PERFORMING OPERATIONS; TRANSPORTING</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B60</span>&mdash;<span itemprop="Description">VEHICLES IN GENERAL</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B60W</span>&mdash;<span itemprop="Description">CONJOINT CONTROL OF VEHICLE SUB-UNITS OF DIFFERENT TYPE OR DIFFERENT FUNCTION; CONTROL SYSTEMS SPECIALLY ADAPTED FOR HYBRID VEHICLES; ROAD VEHICLE DRIVE CONTROL SYSTEMS FOR PURPOSES NOT RELATED TO THE CONTROL OF A PARTICULAR SUB-UNIT</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B60W2554/00</span>&mdash;<span itemprop="Description">Input parameters relating to objects</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B60W2554/40</span>&mdash;<span itemprop="Description">Dynamic objects, e.g. animals, windblown objects</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B60W2554/404</span>&mdash;<span itemprop="Description">Characteristics</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B60W2554/4041</span>&mdash;<span itemprop="Description">Position</span>
            <meta itemprop="Leaf" content="true"><meta itemprop="Additional" content="true"><meta itemprop="IsCPC" content="true">
          </li>
        </ul>
      </li>
      <li>
        <ul itemprop="classifications" itemscope repeat>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B</span>&mdash;<span itemprop="Description">PERFORMING OPERATIONS; TRANSPORTING</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B60</span>&mdash;<span itemprop="Description">VEHICLES IN GENERAL</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B60W</span>&mdash;<span itemprop="Description">CONJOINT CONTROL OF VEHICLE SUB-UNITS OF DIFFERENT TYPE OR DIFFERENT FUNCTION; CONTROL SYSTEMS SPECIALLY ADAPTED FOR HYBRID VEHICLES; ROAD VEHICLE DRIVE CONTROL SYSTEMS FOR PURPOSES NOT RELATED TO THE CONTROL OF A PARTICULAR SUB-UNIT</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B60W2554/00</span>&mdash;<span itemprop="Description">Input parameters relating to objects</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B60W2554/40</span>&mdash;<span itemprop="Description">Dynamic objects, e.g. animals, windblown objects</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B60W2554/404</span>&mdash;<span itemprop="Description">Characteristics</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B60W2554/4044</span>&mdash;<span itemprop="Description">Direction of movement, e.g. backwards</span>
            <meta itemprop="Leaf" content="true"><meta itemprop="Additional" content="true"><meta itemprop="IsCPC" content="true">
          </li>
        </ul>
      </li>
      <li>
        <ul itemprop="classifications" itemscope repeat>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B</span>&mdash;<span itemprop="Description">PERFORMING OPERATIONS; TRANSPORTING</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B60</span>&mdash;<span itemprop="Description">VEHICLES IN GENERAL</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B60W</span>&mdash;<span itemprop="Description">CONJOINT CONTROL OF VEHICLE SUB-UNITS OF DIFFERENT TYPE OR DIFFERENT FUNCTION; CONTROL SYSTEMS SPECIALLY ADAPTED FOR HYBRID VEHICLES; ROAD VEHICLE DRIVE CONTROL SYSTEMS FOR PURPOSES NOT RELATED TO THE CONTROL OF A PARTICULAR SUB-UNIT</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B60W2554/00</span>&mdash;<span itemprop="Description">Input parameters relating to objects</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B60W2554/40</span>&mdash;<span itemprop="Description">Dynamic objects, e.g. animals, windblown objects</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B60W2554/404</span>&mdash;<span itemprop="Description">Characteristics</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B60W2554/4045</span>&mdash;<span itemprop="Description">Intention, e.g. lane change or imminent movement</span>
            <meta itemprop="Leaf" content="true"><meta itemprop="Additional" content="true"><meta itemprop="IsCPC" content="true">
          </li>
        </ul>
      </li>
      <li>
        <ul itemprop="classifications" itemscope repeat>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B</span>&mdash;<span itemprop="Description">PERFORMING OPERATIONS; TRANSPORTING</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B60</span>&mdash;<span itemprop="Description">VEHICLES IN GENERAL</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B60W</span>&mdash;<span itemprop="Description">CONJOINT CONTROL OF VEHICLE SUB-UNITS OF DIFFERENT TYPE OR DIFFERENT FUNCTION; CONTROL SYSTEMS SPECIALLY ADAPTED FOR HYBRID VEHICLES; ROAD VEHICLE DRIVE CONTROL SYSTEMS FOR PURPOSES NOT RELATED TO THE CONTROL OF A PARTICULAR SUB-UNIT</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B60W2556/00</span>&mdash;<span itemprop="Description">Input parameters relating to data</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B60W2556/40</span>&mdash;<span itemprop="Description">High definition maps</span>
            <meta itemprop="Leaf" content="true"><meta itemprop="Additional" content="true"><meta itemprop="IsCPC" content="true">
          </li>
        </ul>
      </li>
      <li>
        <ul itemprop="classifications" itemscope repeat>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B</span>&mdash;<span itemprop="Description">PERFORMING OPERATIONS; TRANSPORTING</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B60</span>&mdash;<span itemprop="Description">VEHICLES IN GENERAL</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B60W</span>&mdash;<span itemprop="Description">CONJOINT CONTROL OF VEHICLE SUB-UNITS OF DIFFERENT TYPE OR DIFFERENT FUNCTION; CONTROL SYSTEMS SPECIALLY ADAPTED FOR HYBRID VEHICLES; ROAD VEHICLE DRIVE CONTROL SYSTEMS FOR PURPOSES NOT RELATED TO THE CONTROL OF A PARTICULAR SUB-UNIT</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B60W2556/00</span>&mdash;<span itemprop="Description">Input parameters relating to data</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B60W2556/45</span>&mdash;<span itemprop="Description">External transmission of data to or from the vehicle</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">B60W2556/50</span>&mdash;<span itemprop="Description">External transmission of data to or from the vehicle for navigation systems</span>
            <meta itemprop="Leaf" content="true"><meta itemprop="Additional" content="true"><meta itemprop="IsCPC" content="true">
          </li>
        </ul>
      </li>
    </ul>
  </section>

  

  

  <section>
    <h2>Definitions</h2>
    <ul>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the present disclosure</span>
        <span itemprop="definition">relates to a method and a system for supporting autonomous driving of an autonomous vehicle, in particular in terms of an interaction with a vulnerable road user that is in the vicinity of the autonomous vehicle.</span>
        <meta itemprop="num_attr" content="0003">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">IoT</span>
        <span itemprop="definition">Internet of Things</span>
        <meta itemprop="num_attr" content="0005">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">various IoT platforms</span>
        <span itemprop="definition">are provided by various major vendors such as Microsoft Azure, AWS IoT, and IBM Watson IoT platform, new large-scale deployments (e.g., city-scale) and experimental testbeds leveraging IoT technologies have become available.</span>
        <meta itemprop="num_attr" content="0005">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the present disclosure</span>
        <span itemprop="definition">provides a method for supporting autonomous driving of an autonomous vehicle.</span>
        <meta itemprop="num_attr" content="0008">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the method</span>
        <span itemprop="definition">includes detecting, by an in-vehicle internet-of-things (IoT) platform of the autonomous vehicle, a vulnerable road user (VRU) having a mobile device in a vicinity of the autonomous vehicle.</span>
        <meta itemprop="num_attr" content="0008">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a mobility application</span>
        <span itemprop="definition">runs on the mobile device of the VRU and sends VRU-specific data to the in-vehicle IoT platform of the autonomous vehicle.</span>
        <meta itemprop="num_attr" content="0008">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the VRU</span>
        <span itemprop="definition">is detected based on the VRU-specific data and/or in-vehicle sensor data of the autonomous vehicle.</span>
        <meta itemprop="num_attr" content="0008">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the method</span>
        <span itemprop="definition">further includes determining, by the in-vehicle IoT platform, a movement intention prediction for the VRU based on the VRU-specific data provided by the mobile device.</span>
        <meta itemprop="num_attr" content="0008">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the movement intention prediction</span>
        <span itemprop="definition">is computed by use of a machine learning model.</span>
        <meta itemprop="num_attr" content="0008">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the VRU-specific data of the mobile device</span>
        <span itemprop="definition">are provided as input data for the machine learning model.</span>
        <meta itemprop="num_attr" content="0008">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the method</span>
        <span itemprop="definition">includes performing, by the in-vehicle IoT platform, an autonomous driving decision for the autonomous vehicle based on the movement intention prediction.</span>
        <meta itemprop="num_attr" content="0008">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 1</span>
        <span itemprop="definition">is a schematic view illustrating a method or a system according to an embodiment</span>
        <meta itemprop="num_attr" content="0010">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 2</span>
        <span itemprop="definition">is a schematic view illustrating an overview of an architecture of a system in accordance with an embodiment</span>
        <meta itemprop="num_attr" content="0011">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 3</span>
        <span itemprop="definition">is a schematic view illustrating a pedestrian movement intention prediction model according to an embodiment</span>
        <meta itemprop="num_attr" content="0012">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 4</span>
        <span itemprop="definition">is a schematic view illustrating a pedestrian movement intention prediction model according to a further embodiment</span>
        <meta itemprop="num_attr" content="0013">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 5</span>
        <span itemprop="definition">is a schematic view illustrating a pedestrian movement intention prediction model according to a further embodiment</span>
        <meta itemprop="num_attr" content="0014">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 6</span>
        <span itemprop="definition">is a schematic view illustrating a petri net model for supporting autonomous driving decision making according to an embodiment</span>
        <meta itemprop="num_attr" content="0015">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 7</span>
        <span itemprop="definition">is a schematic view illustrating an interface where pedestrian and vehicle trajectories are visualized for a particular run by animation of real data in discrete time intervals.</span>
        <meta itemprop="num_attr" content="0016">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the present disclosure</span>
        <span itemprop="definition">provides a method and a system for supporting autonomous driving of an autonomous vehicle in such a way that road safety is improved, in particular in terms of preventing possible accidents between the autonomous vehicle and a vulnerable road user that is in the vicinity of the approaching vehicle.</span>
        <meta itemprop="num_attr" content="0017">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a method</span>
        <span itemprop="definition">for supporting autonomous driving of an autonomous vehicle, in particular in terms of an interaction with a vulnerable road user that is in the vicinity of the autonomous vehicle.</span>
        <meta itemprop="num_attr" content="0018">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the method</span>
        <span itemprop="definition">includes detecting, by an in-vehicle IoT platform of the autonomous vehicle, a vulnerable road user, âVRUâ, having a mobile device in the vicinity of the autonomous vehicle, wherein a mobility application runs on the mobile device of the VRU and sends VRU-specific data to the in-vehicle IoT platform of the autonomous vehicle, wherein the VRU is detected based on the VRU-specific data and/or in-vehicle sensor data of the autonomous vehicle; determining, by the in-vehicle IoT platform, a movement intention prediction for the VRU based on the VRU-specific data provided by the mobile device, wherein the movement intention prediction is computed by the use of a machine learning model, wherein the VRU-specific data of the mobile device are employed as input data for said machine learning model; and performing, by the in-veh</span>
        <meta itemprop="num_attr" content="0018">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a system</span>
        <span itemprop="definition">for supporting autonomous driving of an autonomous vehicle, the system comprising an in-vehicle IoT platform that is implemented in the autonomous vehicle and a mobility application running on a mobile device of a vulnerable road user, âVRUâ, wherein the mobility application running on the mobile device of the VRU is configured to send VRU-specific data to the in-vehicle IoT platform of the autonomous vehicle, wherein the in-vehicle IoT platform of the autonomous vehicle is configured to detect the VRU having the mobile device in the vicinity of the autonomous vehicle, wherein the VRU is detected based on the VRU-specific data and/or in-vehicle sensor data of the autonomous vehicle, wherein the in-vehicle IoT platform is further configured to determine a movement intention prediction for the VRU based on the VRU-specific data provided by the mobile device, wherein the movement intention prediction is computed by the use of a machine learning model, wherein the VRU-specific data of the mobile device are employed as input data for said machine learning model, and where</span>
        <meta itemprop="num_attr" content="0019">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">an in-vehicle IoT (Internet of Things) platform of the autonomous vehicle</span>
        <span itemprop="definition">is configured to detect a vulnerable road user (VRU) having a mobile device in the vicinity of the autonomous vehicle.</span>
        <meta itemprop="num_attr" content="0020">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">VRU</span>
        <span itemprop="definition">vulnerable road user</span>
        <meta itemprop="num_attr" content="0020">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a mobility application</span>
        <span itemprop="definition">runs on the mobile device of the VRU and sends VRU-specific data to the in-vehicle IoT platform of the autonomous vehicle, wherein the VRU is detected based on the VRU-specific data provided by the mobile device and/or based on in-vehicle sensor data of the autonomous vehicle.</span>
        <meta itemprop="num_attr" content="0020">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the VRU</span>
        <span itemprop="definition">may be detected based on a combination of VRU-specific data from the mobile device and in-vehicle sensor data that is acquired/measured by the autonomous vehicle.</span>
        <meta itemprop="num_attr" content="0020">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the in-vehicle IoT platform</span>
        <span itemprop="definition">is further configured to determine a movement intention prediction for the VRU, based on the VRU-specific data provided by the mobile device, wherein the movement intention prediction is computed by the use of a machine learning model.</span>
        <meta itemprop="num_attr" content="0020">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the VRU-specific data of the mobile device</span>
        <span itemprop="definition">are employed as input data for the machine learning model. Then, the in-vehicle IoT platform can perform an autonomous driving decision for the autonomous vehicle based on the previously determined movement intention prediction.</span>
        <meta itemprop="num_attr" content="0020">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the present disclosure</span>
        <span itemprop="definition">provides a method and a system for supporting autonomous driving of an autonomous vehicle, wherein road safety is improved, in particular in terms of preventing possible accidents between the autonomous vehicle and a vulnerable road user that is in the vicinity of the approaching vehicle.</span>
        <meta itemprop="num_attr" content="0021">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">V2V</span>
        <span itemprop="definition">vehicle to vehicle</span>
        <meta itemprop="num_attr" content="0022">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">V2X</span>
        <span itemprop="definition">vehicle to everything</span>
        <meta itemprop="num_attr" content="0022">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">machine learning model</span>
        <span itemprop="definition">may refer to a mathematical representation of a process which can be generated with an algorithm using training data.</span>
        <meta itemprop="num_attr" content="0023">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the machine learning model</span>
        <span itemprop="definition">may be an artificial neural network (ANN).</span>
        <meta itemprop="num_attr" content="0023">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">an exemplary system</span>
        <span itemprop="definition">may include a mobile device, autonomous car(s), an in-vehicle (edge) IoT platform, and a VRU intention-based decision-making software that runs on top of the platform.</span>
        <meta itemprop="num_attr" content="0024">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">movement intention prediction</span>
        <span itemprop="definition">may be understood, in particular in the claims, preferably in the description as the possible next movement action of the VRU such as of a pedestrian.</span>
        <meta itemprop="num_attr" content="0025">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the mobile device user</span>
        <span itemprop="definition">can be considered as the vulnerable road user that may be a pedestrian in the vicinity of an approaching autonomous vehicle/car.</span>
        <meta itemprop="num_attr" content="0025">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the decision-making of autonomous driving</span>
        <span itemprop="definition">may be supplemented with the outcome of a method or system according to an embodiment as a complementary input in order to protect the vulnerable pedestrian.</span>
        <meta itemprop="num_attr" content="0025">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a transportation mode of the VRU</span>
        <span itemprop="definition">is determined using a machine learning process.</span>
        <meta itemprop="num_attr" content="0026">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the machine learning process</span>
        <span itemprop="definition">can determine whether the VRU is a pedestrian or a cyclist. Then, the input data can be fed into a movement intention classifier that computes a movement intention prediction for a VRU using a machine learning model.</span>
        <meta itemprop="num_attr" content="0026">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the machine learning process</span>
        <span itemprop="definition">may include computing the transportation mode of the VRU by the use of a weak supervision-based machine learning model. Weak supervision may be understood as a branch of machine learning for labelling data through noisy or remote labelling sources which are called weak supervisors.</span>
        <meta itemprop="num_attr" content="0026">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Weak supervision</span>
        <span itemprop="definition">enables labelling data through the weak supervisors and therefore avoiding the need for ground-truth collection (labels for peoples&#39; transportation modes).</span>
        <meta itemprop="num_attr" content="0026">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Weak supervised systems</span>
        <span itemprop="definition">such as Snorkel (retrievable at http://snorkel.org) can be used for classifying transport modes through weak supervision.</span>
        <meta itemprop="num_attr" content="0026">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">video processing</span>
        <span itemprop="definition">is performed based on image data (footage) that is gathered by a sensor device such as a camera of the autonomous vehicle in order to detect the VRU and/or to determine the transportation mode of the VRU.</span>
        <meta itemprop="num_attr" content="0027">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">image data</span>
        <span itemprop="definition">footage</span>
        <meta itemprop="num_attr" content="0027">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a sensor device</span>
        <span itemprop="definition">such as a camera of the autonomous vehicle</span>
        <meta itemprop="num_attr" content="0027">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">high-accuracy detection of the VRU and its classification</span>
        <span itemprop="definition">i.e., pedestrian or cyclist</span>
        <meta itemprop="num_attr" content="0027">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the VRU-specific data</span>
        <span itemprop="definition">may include sensor data that are collected by one or more sensors of the mobile device of the VRU.</span>
        <meta itemprop="num_attr" content="0028">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the sensor data</span>
        <span itemprop="definition">may comprise location/position dataâin particular GNSS data such as GPS dataâ, accelerometer data and/or gyroscope data.</span>
        <meta itemprop="num_attr" content="0028">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the VRU-specific data</span>
        <span itemprop="definition">may include position data, heading angle information and/or (average) speed information of the VRU.</span>
        <meta itemprop="num_attr" content="0029">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the VRU-specific data</span>
        <span itemprop="definition">may include a trajectory of the VRU.</span>
        <meta itemprop="num_attr" content="0030">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the outcome and accuracy of computations with regard to VRU detection and determination of movement intention prediction</span>
        <span itemprop="definition">can be improved.</span>
        <meta itemprop="num_attr" content="0030">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the in-vehicle sensor data</span>
        <span itemprop="definition">may include sensor data that are gathered by one or more sensors of the autonomous vehicle.</span>
        <meta itemprop="num_attr" content="0031">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the outcome and accuracy of computations with regard to VRU detection and determination of movement intention prediction</span>
        <span itemprop="definition">can be improved.</span>
        <meta itemprop="num_attr" content="0031">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the input data for the machine learning model</span>
        <span itemprop="definition">may further include in-vehicle sensor data of the autonomous vehicle for the VRU.</span>
        <meta itemprop="num_attr" content="0032">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the input data for the machine learning model</span>
        <span itemprop="definition">may further include additional data from one or more IoT data sources.</span>
        <meta itemprop="num_attr" content="0033">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">This additional information</span>
        <span itemprop="definition">may provide further information relating to an environment in the vicinity of the autonomous vehicle.</span>
        <meta itemprop="num_attr" content="0033">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the additional data</span>
        <span itemprop="definition">may include (online) map data, in particular 3D model data, in order to learn from map features.</span>
        <meta itemprop="num_attr" content="0034">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">map features</span>
        <span itemprop="definition">may include angle to road, distance to road, map landmarks, etc.</span>
        <meta itemprop="num_attr" content="0034">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the machine learning model</span>
        <span itemprop="definition">i.e., for instance, the artificial neural network</span>
        <meta itemprop="num_attr" content="0034">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the machine learning model</span>
        <span itemprop="definition">may learn from the map features and the prediction of the VRU&#39;s next movement intention can be determined/computed with higher accuracy.</span>
        <meta itemprop="num_attr" content="0034">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the additional data</span>
        <span itemprop="definition">may include internet service data from one or more internet services, wherein the internet service data include information on weather conditions, traffic lights, live events, and/or traffic situations, in an environment of the vicinity of the autonomous vehicle.</span>
        <meta itemprop="num_attr" content="0035">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the machine learning model</span>
        <span itemprop="definition">i.e., for instance, the artificial neural network</span>
        <meta itemprop="num_attr" content="0035">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the machine learning model</span>
        <span itemprop="definition">may learn from these additional information in order to predict the VRU&#39;s next movement intention with higher accuracy.</span>
        <meta itemprop="num_attr" content="0035">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the additional data</span>
        <span itemprop="definition">may include information on event schedules of the VRU.</span>
        <meta itemprop="num_attr" content="0036">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the outcome and accuracy of computations with regard to the determination of movement intention prediction for the VRU</span>
        <span itemprop="definition">can be improved.</span>
        <meta itemprop="num_attr" content="0036">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the input data for the machine learning model</span>
        <span itemprop="definition">may further include information on the movement history of the VRU.</span>
        <meta itemprop="num_attr" content="0037">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the historical user data</span>
        <span itemprop="definition">may include the VRU&#39;s previous traffic-related history of any violation such as jaywalking. These data can be considered for probabilistic prediction of the movement intention for the VRU&#39;s next walking movement decision.</span>
        <meta itemprop="num_attr" content="0037">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the movement intention prediction that is determined by the machine learning model</span>
        <span itemprop="definition">may represent a user action that is expected to be performed next by the VRU.</span>
        <meta itemprop="num_attr" content="0038">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a set of user actions</span>
        <span itemprop="definition">may be defined for the movement intention prediction that is determinable by the machine learning model, wherein the set of actions comprises waiting, walking straight, turning left, turning right and/or turning back (i.e. U-turn).</span>
        <meta itemprop="num_attr" content="0039">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Embodiments</span>
        <span itemprop="definition">may relate to a method or a system which combines IoT data sources such as measurements of autonomous vehicles&#39; sensors, mobile device users&#39; data and other IoT data sources from internet sources such as online map data and event schedules of mobile device users, to improve autonomous driving decisions taken by autonomous vehicles to improve road safety of pedestrians.</span>
        <meta itemprop="num_attr" content="0040">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">IoT data sources</span>
        <span itemprop="definition">such as measurements of autonomous vehicles&#39; sensors, mobile device users&#39; data and other IoT data sources from internet sources such as online map data and event schedules of mobile device users, to improve autonomous driving decisions taken by autonomous vehicles to improve road safety of pedestrians.</span>
        <meta itemprop="num_attr" content="0040">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">embodiments</span>
        <span itemprop="definition">may relate to a real-time IoT system for the smart mobility domain.</span>
        <meta itemprop="num_attr" content="0041">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">An application scenario for a method or system according to an embodiment</span>
        <span itemprop="definition">may include the following:</span>
        <meta itemprop="num_attr" content="0041">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the machine learning software</span>
        <span itemprop="definition">leverages data sources for training such as GPS data from the mobility application and other open datasets as well as online maps to learn from map features.</span>
        <meta itemprop="num_attr" content="0047">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the system</span>
        <span itemprop="definition">first detects existence of a vulnerable road user (VRU) that is a pedestrian in the vicinity of an approaching autonomous vehicle/car. If the VRU is using the mobility application, the mobile device of the VRU directly (through V2V) or indirectly (through 4G/5G) transmits VRU-specific data to the in-vehicle IoT platform of the autonomous vehicle. Then, the machine learning software implemented on the in-vehicle IoT platform of the autonomous vehicle predicts the movement intention of the pedestrian, wherein the movement intention can be defined as the next movement choice with a simple set of actions: for instance, waiting, walking straight, turning left, turning right, and/or turning back.</span>
        <meta itemprop="num_attr" content="0048">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">VRU</span>
        <span itemprop="definition">vulnerable road user</span>
        <meta itemprop="num_attr" content="0048">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the machine learning software engine</span>
        <span itemprop="definition">is trained with datasets including location/position data (such as GPS data), heading information, and speed information as well as map features. Furthermore, the machine learning software engine may incorporate data sources such as event schedule (e.g., lecture schedule in a university campus) of the mobile device user, if the data is available in a timely manner. Lastly, the system components on the in-vehicle IoT platform of the autonomous car may decide on the autonomous driving action such as slowing down the car, keeping the same speed, or breaking the car in unsafe situations. This decision is based on VRU detection and pedestrian intention prediction models to assess safety based on information from in-vehicle sensors and mobile device data (i.e. VRU-specific data).</span>
        <meta itemprop="num_attr" content="0049">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the data</span>
        <span itemprop="definition">may be collected in the in-vehicle IoT platform.</span>
        <meta itemprop="num_attr" content="0050">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the software engine for VRU detection, the VRU movement intention prediction, and autonomous driving decision</span>
        <span itemprop="definition">may be part of (or may run on top of) the in-vehicle IoT platform.</span>
        <meta itemprop="num_attr" content="0050">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the in-vehicle IoT platform</span>
        <span itemprop="definition">can be considered as an edge component.</span>
        <meta itemprop="num_attr" content="0050">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the communication</span>
        <span itemprop="definition">can be done directly in between the mobile device, autonomous car, or RSU.</span>
        <meta itemprop="num_attr" content="0050">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">internet sources</span>
        <span itemprop="definition">they can be reached using 4G/5G communications. Some of the internet sources such as lecture schedule in a campus or weather information can be gathered before the pedestrian comes to the road side.</span>
        <meta itemprop="num_attr" content="0050">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 1</span>
        <span itemprop="definition">shows a schematic view illustrating a method or a system according to an embodiment.</span>
        <meta itemprop="num_attr" content="0057">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 1</span>
        <span itemprop="definition">gives a simplistic overview of an idea of pedestrian intention-based autonomous driving in accordance with an embodiment.</span>
        <meta itemprop="num_attr" content="0057">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a main target of the embodiment</span>
        <span itemprop="definition">is an understanding of pedestrian movement intentions using and combining available IoT (Internet of Things) data sources as well as pre-trained prediction components in-vehicle.</span>
        <meta itemprop="num_attr" content="0057">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">IoT</span>
        <span itemprop="definition">Internet of Things</span>
        <meta itemprop="num_attr" content="0057">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Possible data sources and actors</span>
        <span itemprop="definition">are listed on the left side of FIG. 1 , given as inputs to the autonomous driving, while the outputs are the autonomous driving decisions that are applied to the vehicle/car on the right side of FIG. 1 .</span>
        <meta itemprop="num_attr" content="0057">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the approach according to the embodiment</span>
        <span itemprop="definition">may comprise the following steps: (1) vulnerable road user (VRU) detection, (2) pedestrian intention prediction, and (3) autonomous decision making.</span>
        <meta itemprop="num_attr" content="0058">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">VRU</span>
        <span itemprop="definition">vulnerable road user</span>
        <meta itemprop="num_attr" content="0058">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the first step</span>
        <span itemprop="definition">leverages video processing based on footage received from a camera deployed in the vehicle/car for high-accuracy detection of vulnerable road users (VRUs) and their classification (i.e., pedestrian and cyclist).</span>
        <meta itemprop="num_attr" content="0059">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the second step</span>
        <span itemprop="definition">leverages smartphone data (e.g., GPS, gyroscope) and internet sources (e.g., map data) to predict the pedestrian&#39;s movement intentions.</span>
        <meta itemprop="num_attr" content="0059">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">smartphone data</span>
        <span itemprop="definition">e.g., GPS, gyroscope</span>
        <meta itemprop="num_attr" content="0059">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">internet sources</span>
        <span itemprop="definition">e.g., map data</span>
        <meta itemprop="num_attr" content="0059">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the third step</span>
        <span itemprop="definition">combines the outcome/output from the first two steps and makes an autonomous driving decision.</span>
        <meta itemprop="num_attr" content="0059">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a petri net model for classifying behaviors such as slowing down</span>
        <span itemprop="definition">may be considered, for example as illustrated by FIG. 6 .</span>
        <meta itemprop="num_attr" content="0059">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 2</span>
        <span itemprop="definition">shows a schematic view illustrating an overview of a system architecture for a method or a system in accordance with an embodiment.</span>
        <meta itemprop="num_attr" content="0060">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the embodiment illustrated by FIG. 2</span>
        <span itemprop="definition">comprise three main participants as follows: in-vehicle IoT platform, mobile device, and cloud IoT platform.</span>
        <meta itemprop="num_attr" content="0060">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the key components of FIG. 2</span>
        <span itemprop="definition">comprise a mobility application implemented on the mobile device. Further, the key components comprise a VRU detection entity, a pedestrian intention estimation entity and an autonomous driving input entity, which are all implemented on the in-vehicle IoT platform of the car.</span>
        <meta itemprop="num_attr" content="0062">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the custom-built autonomous car/vehicle of the described embodiment</span>
        <span itemprop="definition">includes various sensors such as cameras, Mobileye, Lidar, and so on.</span>
        <meta itemprop="num_attr" content="0063">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the in-vehicle IoT platform</span>
        <span itemprop="definition">contains a Robot Operating System (ROS), which can be considered as the operating system of the car.</span>
        <meta itemprop="num_attr" content="0063">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">ROS</span>
        <span itemprop="definition">receives/collects the data published from various sensors, in-vehicle software components (e.g., analytics, image/video processing components), mobile devices (e.g., the mobility app for smartphones), as well as the cloud platform.</span>
        <meta itemprop="num_attr" content="0063">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the collection from the cloud platform and the mobile devices</span>
        <span itemprop="definition">is supported by a custom-developed lightweight IoT broker component. This component queries/subscribes to these other sources and deliver the data to the ROS.</span>
        <meta itemprop="num_attr" content="0063">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the ROS files</span>
        <span itemprop="definition">are stored in the storage.</span>
        <meta itemprop="num_attr" content="0063">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">VRU detection and pedestrian intention estimation components</span>
        <span itemprop="definition">can be run offline using rosbag files (i.e., simulation using real data). As these components run on ROS environment using the same ROS data, with the same setup they can be transferred to a real setup in the in-vehicle IoT platform.</span>
        <meta itemprop="num_attr" content="0063">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the autonomous driving input component</span>
        <span itemprop="definition">is considered for providing valuable input to autonomous driving by leveraging and combining the outputs of the VRU detection and pedestrian intention estimation.</span>
        <meta itemprop="num_attr" content="0063">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Mobile device</span>
        <span itemprop="definition">Any mobile device such as smartphones and wearables with sensors and communication capabilities may be considered as possible components of the system from the VRU side.</span>
        <meta itemprop="num_attr" content="0064">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the system</span>
        <span itemprop="definition">involves the usage of mobile devices by the VRUs.</span>
        <meta itemprop="num_attr" content="0064">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the mobile devices</span>
        <span itemprop="definition">include a set of sensors, antennas for communication, as well as the mobility app, i.e. the mobility application.</span>
        <meta itemprop="num_attr" content="0064">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the sensors of the mobile device</span>
        <span itemprop="definition">include, e.g., GPS, gyroscope and accelerometer.</span>
        <meta itemprop="num_attr" content="0064">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the mobile device</span>
        <span itemprop="definition">push data through 4G communication (or 5G in the near future).</span>
        <meta itemprop="num_attr" content="0064">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the communication capabilities</span>
        <span itemprop="definition">may include vehicle to vehicle (V2V) protocols such as ITS-G5 for direct communication to the vehicle. This communication can be satisfied only in the case that the VRU and the autonomous vehicle are in the wireless range of each other (i.e., less than 100 m).</span>
        <meta itemprop="num_attr" content="0064">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">V2V</span>
        <span itemprop="definition">vehicle to vehicle</span>
        <meta itemprop="num_attr" content="0064">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">ITS-G5</span>
        <span itemprop="definition">ITS-G5 for direct communication to the vehicle. This communication can be satisfied only in the case that the VRU and the autonomous vehicle are in the wireless range of each other (i.e.,</span>
        <meta itemprop="num_attr" content="0064">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Cloud IoT platform</span>
        <span itemprop="definition">Although the cloud platform includes various components and different aspects, in this embodiment it is focused on the two standard-based IoT platforms that are mainly used for collecting and providing the VRU mobility-related data: FIWARE (retrievable at https://www.fiware.org/) and oneM2M (retrievable at http://www.onem2 m.org/).</span>
        <meta itemprop="num_attr" content="0065">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIWARE</span>
        <span itemprop="definition">FIWARE</span>
        <meta itemprop="num_attr" content="0065">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">M2M</span>
        <span itemprop="definition">retrievable at http://www.onem2 m.org/</span>
        <meta itemprop="num_attr" content="0065">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the data from the mobility application</span>
        <span itemprop="definition">can be pushed to FIWARE IoT platform which is bidirectionally connected to the oneM2M platform through a custom-developed interworking proxy component, which handles the data exchanges and format convergence in between these two standard-based platform.</span>
        <meta itemprop="num_attr" content="0065">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a system according to an embodiment such as illustrated by FIG. 2</span>
        <span itemprop="definition">may perform steps as follows:</span>
        <meta itemprop="num_attr" content="0066">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Step 1</span>
        <span itemprop="definition">VRU Detection</span>
        <meta itemprop="num_attr" content="">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the method</span>
        <span itemprop="definition">may have three cases of VRU detection: Case 1: existence of only mobile device data, i.e. the VRU-specific data; Case 2: existence of only camera data, i.e. in-vehicle sensor data; and Case 3: existence of both camera data and mobile device data for the VRU</span>
        <meta itemprop="num_attr" content="0067">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the location/position data</span>
        <span itemprop="definition">is received from the mobile device into the in-vehicle IoT platform.</span>
        <meta itemprop="num_attr" content="0068">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the location/position data</span>
        <span itemprop="definition">is leveraged for later safety assessment and autonomous driving decision based on that.</span>
        <meta itemprop="num_attr" content="0068">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the image processing</span>
        <span itemprop="definition">is used. This model extracts all obstacles from image processing and if it is a person, classifies the type of the person (i.e., pedestrian or cyclist) using the images. Moreover, the image processing can compute the relative position of the person to the vehicle.</span>
        <meta itemprop="num_attr" content="0069">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">both camera data and mobile device data</span>
        <span itemprop="definition">are collected in the in-vehicle platform.</span>
        <meta itemprop="num_attr" content="0070">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the image processing</span>
        <span itemprop="definition">finds the relative positions and combines with the vehicle location data (i.e., GPS) to find the coordinates of the obstacles.</span>
        <meta itemprop="num_attr" content="0070">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the VRU detection</span>
        <span itemprop="definition">compares this information about the coordinates from multiple obstacles with the coordinates available from the mobile device(s). This comparison is performed over multiple image frames for a predetermined period of time (e.g., 8 frames/second) and the best match obstacle is marked as the mobile device user.</span>
        <meta itemprop="num_attr" content="0070">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the VRU detection</span>
        <span itemprop="definition">is performed using camera data measured by the autonomous vehicle.</span>
        <meta itemprop="num_attr" content="0070">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Step 2</span>
        <span itemprop="definition">Transportation Mode Detection</span>
        <meta itemprop="num_attr" content="">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a machine learning model</span>
        <span itemprop="definition">is trained to classify the transportation mode of vulnerable road users. This classification, performed by a machine learning process, is required to identify VRUs such as pedestrians and bicyclists before their data is fed into the movement intention classifier that computes a movement intention prediction for a VRU using a machine learning model (such as an artificial neural network). For not relying on extensive labeling of ground truth transportation modes via crowdsourcing, a weak supervision can be applied to quickly collect vast amounts of noisy training data.</span>
        <meta itemprop="num_attr" content="0071">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a weak supervision-based machine learning model</span>
        <span itemprop="definition">is used, where multiple supervisors are defined based on subject matter expert knowledge (e.g., bicycle, pedestrian, car speed constraints, length of trip, sequence of trip segments), geographical information from existing knowledge bases (e.g., bus and train stops from OpenStreetMap) and other integrated third party data sources (e.g., weather data). These labeling functions are applied on detected trips and trip segments that have been integrated with OpenStreetMap and weather data. Based on the resulting probabilistic labels, the machine learning model can then be trained. The provided model is able to generalize the training data and apply it to mobility data from other deployments and cities without a repeated collection of training data (e.g., through crowd-sourcing or manual labeling).</span>
        <meta itemprop="num_attr" content="0071">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">subject matter expert knowledge</span>
        <span itemprop="definition">e.g., bicycle, pedestrian, car speed constraints, length of trip, sequence of trip segments</span>
        <meta itemprop="num_attr" content="0071">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">geographical information from existing knowledge bases</span>
        <span itemprop="definition">e.g., bus and train stops from OpenStreetMap</span>
        <meta itemprop="num_attr" content="0071">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">third party data sources</span>
        <span itemprop="definition">e.g., weather data</span>
        <meta itemprop="num_attr" content="0071">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Step 3</span>
        <span itemprop="definition">Vru/Pedestrian Movement Intentions</span>
        <meta itemprop="num_attr" content="">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a method in accordance with an embodiment</span>
        <span itemprop="definition">includes a step of estimating/determining the next movement action of the vulnerable road user.</span>
        <meta itemprop="num_attr" content="0072">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 3</span>
        <span itemprop="definition">shows a schematic view illustrating a pedestrian movement intention prediction model according to an embodiment.</span>
        <meta itemprop="num_attr" content="0072">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 3</span>
        <span itemprop="definition">shows a method of an embodiment that combines personal information, i.e. VRU-specific data coming from the mobile device of the VRU, and in-vehicle sensor data for VRU as well as information from IoT data sources such as map/3D model environmental data and data from internet services.</span>
        <meta itemprop="num_attr" content="0072">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the described data</span>
        <span itemprop="definition">include the latest movement steps (short trajectory) of the pedestrian and mobile devices sensors (e.g., heading), user data (i.e., event schedule, movement history of the user), position of pedestrian using the previous VRU detection step, map features (e.g., distance to road, angle to road), and data from cloud/edge IoT services (e.g., traffic lights, live events/traffic situation/other information in the environment).</span>
        <meta itemprop="num_attr" content="0072">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the historical user data</span>
        <span itemprop="definition">may include the user&#39;s previous traffic-related history of any violation such as jaywalking. These data is considered for probabilistic prediction of the âpedestrian intentionâ for their next walking movement decisions.</span>
        <meta itemprop="num_attr" content="0072">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the proposed machine learning model</span>
        <span itemprop="definition">uses mobile device&#39;s sensor data such as the GPS trajectory values of pedestrians in order to predict their next movements.</span>
        <meta itemprop="num_attr" content="0073">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">An Artificial Neural Network</span>
        <span itemprop="definition">(ANN) is modelled, consisting of n neurons in the input layer and five neurons as output, where n is the number of steps from the previous pedestrian trajectory from t_ 1 until t_n, plus the heading angle and average speed information.</span>
        <meta itemprop="num_attr" content="0073">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Each output neuron</span>
        <span itemprop="definition">represents the next movement intention or turn direction of the pedestrian, i.e. waiting, walking straight, turning right, turning left or U-turn (i.e., turning back).</span>
        <meta itemprop="num_attr" content="0073">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 4 and FIG. 5</span>
        <span itemprop="definition">illustrate a neural network model considering a basic ANN (without map features) and an ANN with using map features according to embodiments.</span>
        <meta itemprop="num_attr" content="0074">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 4</span>
        <span itemprop="definition">shows an example of a neural network model for movement intention prediction of a pedestrian, using only features of the mobile device (not using other IoT sources).</span>
        <meta itemprop="num_attr" content="0074">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 5</span>
        <span itemprop="definition">shows a further example of a neural network model for movement intention prediction of a pedestrian, using features of the mobile device together with map features and possibly other IoT sources.</span>
        <meta itemprop="num_attr" content="0074">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the machine learning model training process</span>
        <span itemprop="definition">is fed by the data collected in the offline phase and the mobile device data, i.e. the VRU-specific data, is partitioned into training, validation and testing datasets.</span>
        <meta itemprop="num_attr" content="0075">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a method</span>
        <span itemprop="definition">Based on the concept of data programming, a method according to an embodiment provides heuristic rules applied over a geometric model to help in the creation of labeled training sets. Thus, it is not necessary to manually collect labeled intentions from pedestrians, as the training process uses the results from labeling functions.</span>
        <meta itemprop="num_attr" content="0076">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">well-known geometric formulas</span>
        <span itemprop="definition">are applied to calculate the bearing (direction or angle between the north-south line of earth or meridian and the line connecting the target and the reference point) of movement in degrees and, based on this angle and the walked distance, a set of rules are applied to give the turning direction, waiting or walking straight status.</span>
        <meta itemprop="num_attr" content="0076">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the machine learning model</span>
        <span itemprop="definition">can be extended using other data coming from the mobile device user (i.e. the VRU) such as the appointment schedule (e.g., lecture schedule of a student in a university campus) or the next navigation destination as well as events from the online sources such as large-scale events in a city to improve the movement intention prediction accuracy.</span>
        <meta itemprop="num_attr" content="0076">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">f  â  ( a , b , c )</span>
        <span itemprop="definition">â  waiting , if  â   â  d ab &#43; d bc  â  T d right , if  â   â  (  â   â  - 180 - T a )  â  (  â  &gt; T a  â   â   â  180 - T a ) left , if  â   â  (  â  &gt; 180 &#43; T a )  â  (  â   â  0 - T a  â   â  &gt; - 180 &#43; T a ) straight , if  â   â   â  0 - T a  â   â  T a uturn , otherwise ,</span>
        <meta itemprop="num_attr" content="0000">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">â</span>
        <span itemprop="definition">is the normalized angle of direction from (a,b) to (b,c)</span>
        <meta itemprop="num_attr" content="0000">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">d xi</span>
        <span itemprop="definition">is the Haversine distance between coordinates (x,y)</span>
        <meta itemprop="num_attr" content="0000">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">T d and T a</span>
        <span itemprop="definition">are the threshold (tolerance) from the distance and angle of movement, respectively.</span>
        <meta itemprop="num_attr" content="0000">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the embodiment</span>
        <span itemprop="definition">combines position information from in-vehicle image processing with the data (i.e. VRU-specific data) from the mobile device for pedestrian movement intention detection. This can be done by finding in the image processing VRU detection results the corresponding mobile device user (i.e., matching image of pedestrian to mobile device data source) for leveraging camera-based positioning when applicable through the aforementioned Step 1 and Step 2 (for only Case 3).</span>
        <meta itemprop="num_attr" content="0078">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Step 4</span>
        <span itemprop="definition">Autonomous Decision-Making</span>
        <meta itemprop="num_attr" content="">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a method in accordance with an embodiment</span>
        <span itemprop="definition">includes a step of performing an autonomous driving decision for the autonomous vehicle/car. How to support autonomous decision-making using the results from the previous steps can be described as follows: Autonomous decision making can be a final step of the proposed procedure. According to embodiments, this step is built on top of the previously described steps.</span>
        <meta itemprop="num_attr" content="0079">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a simple model using stochastic priority petri nets</span>
        <span itemprop="definition">is used in order to illustrate a procedural method.</span>
        <meta itemprop="num_attr" content="0079">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 6</span>
        <span itemprop="definition">shows a schematic view illustrating a petri net model for supporting autonomous driving decision making according to an embodiment.</span>
        <meta itemprop="num_attr" content="0079">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 6</span>
        <span itemprop="definition">shows the model with places (big circles), transitions (rectangles), and the tokens at the initial stage.</span>
        <meta itemprop="num_attr" content="0080">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">â</span>
        <span itemprop="definition">denotes the probabilistic variables based on the transition step</span>
        <meta itemprop="num_attr" content="0080">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">curly-braced numbers</span>
        <span itemprop="definition">indicate the priority labels and numbers without curly braces denote the number of tokens.</span>
        <meta itemprop="num_attr" content="0080">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the initial places on the top</span>
        <span itemprop="definition">are fired in the case of autonomous driving.</span>
        <meta itemprop="num_attr" content="0084">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">three possible cases during driving</span>
        <span itemprop="definition">are considered:</span>
        <meta itemprop="num_attr" content="0084">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a pre-trained world model</span>
        <span itemprop="definition">is used to create a list of VRUs and classify them (i.e., pedestrian or cyclist).</span>
        <meta itemprop="num_attr" content="0088">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the found VRUs</span>
        <span itemprop="definition">are also matched with the mobile device data.</span>
        <meta itemprop="num_attr" content="0088">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the outputs of the pre-trained model</span>
        <span itemprop="definition">are given for assessing the safety (the bottom-left place).</span>
        <meta itemprop="num_attr" content="0088">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the distance</span>
        <span itemprop="definition">is calculated and given to safety assessment using vehicle and person location data.</span>
        <meta itemprop="num_attr" content="0089">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the pre-trained model</span>
        <span itemprop="definition">is used to probabilistically predict the transport mode.</span>
        <meta itemprop="num_attr" content="0089">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the pre-trained model for pedestrian movement intentions</span>
        <span itemprop="definition">is used to predict.</span>
        <meta itemprop="num_attr" content="0089">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">This input</span>
        <span itemprop="definition">is also given to the safety assessment.</span>
        <meta itemprop="num_attr" content="0089">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">other vehicle- or person-related data</span>
        <span itemprop="definition">can also be used by the autonomous driving decision making to decide based on a set of final actions (illustrated bottom-right of FIG. 6 ).</span>
        <meta itemprop="num_attr" content="0089">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">three probabilistic actions for safety</span>
        <span itemprop="definition">are defined:</span>
        <meta itemprop="num_attr" content="0089">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">An extended model</span>
        <span itemprop="definition">might be applied for more complex behaviors.</span>
        <meta itemprop="num_attr" content="0093">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 7</span>
        <span itemprop="definition">shows a schematic view illustrating an interface where pedestrian and vehicle trajectories are visualized for a particular run by animation of real data in discrete time intervals.</span>
        <meta itemprop="num_attr" content="0094">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 7</span>
        <span itemprop="definition">illustrates the map-view interface for controlled experiments.</span>
        <meta itemprop="num_attr" content="0094">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the short trajectory p on the left side</span>
        <span itemprop="definition">represents the pedestrian.</span>
        <meta itemprop="num_attr" content="0094">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the longer trajectory c on the right side</span>
        <span itemprop="definition">represents the car.</span>
        <meta itemprop="num_attr" content="0094">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">autonomous driving pilot tests</span>
        <span itemprop="definition">have been conducted mainly at a university campus while some tests are conducted at a business campus.</span>
        <meta itemprop="num_attr" content="0095">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the tests</span>
        <span itemprop="definition">are conducted by collaboration of multiple multi-domain research groups.</span>
        <meta itemprop="num_attr" content="0095">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the university campus</span>
        <span itemprop="definition">has a 2-km road network and 30 km/h speed limit for cars.</span>
        <meta itemprop="num_attr" content="0095">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a custom-built autonomous car prototype</span>
        <span itemprop="definition">(Toyota Prius) is used in the tests.</span>
        <meta itemprop="num_attr" content="0095">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the car</span>
        <span itemprop="definition">has a custom mobile ITS-G5 device connected to the in-vehicle IoT platform.</span>
        <meta itemprop="num_attr" content="0095">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">two VRUs</span>
        <span itemprop="definition">carry these ITS-G5 devices.</span>
        <meta itemprop="num_attr" content="0095">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the broker in the in-vehicle IoT platform</span>
        <span itemprop="definition">is connected to cloud platforms (oneM2M via MQTT and FIWARE via HTTP) using cellular 4G connection.</span>
        <meta itemprop="num_attr" content="0095">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 7</span>
        <span itemprop="definition">shows the interface where the pedestrian and car trajectories for a particular run by animation of the real data in discrete time intervals.</span>
        <meta itemprop="num_attr" content="0095">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the embodiment</span>
        <span itemprop="definition">leverages the potential of using IoT technologies (i.e., data sources, platforms) and machine learning for enhancing the autonomous driving in terms of safety and efficiency. It is proposed a method and a system which combines IoT data sources such as measurements of autonomous vehicles&#39; sensors, mobile device users&#39; data and other IoT data sources from Internet such as OpenStreetMap data.</span>
        <meta itemprop="num_attr" content="0096">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the required components of the system</span>
        <span itemprop="definition">includes a mobile device, autonomous car(s), an in-vehicle (edge) IoT platform, and the pedestrian intention-based decision-making software which runs on top of the in-vehicle (edge) IoT platform.</span>
        <meta itemprop="num_attr" content="0096">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the mobile device user</span>
        <span itemprop="definition">is considered as a vulnerable road user who may be a pedestrian in the vicinity of an approaching autonomous car.</span>
        <meta itemprop="num_attr" content="0096">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the IoT platform</span>
        <span itemprop="definition">receives real-time updates from the IoT data sources, the decision-making is trained via deep neural networks to predict the pedestrians intentions for their next movement decisions using historical data from the custom-developed autonomous car and the data collected from the mobile device mobility application.</span>
        <meta itemprop="num_attr" content="0096">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the recitation of âat least one of A, B and Câ</span>
        <span itemprop="definition">should be interpreted as one or more of a group of elements consisting of A, B and C, and should not be interpreted as requiring at least one of each of the listed elements A, B and C, regardless of whether A, B and C are related as categories or otherwise.</span>
        <meta itemprop="num_attr" content="0098">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the recitation of âA, B and/or Câ or âat least one of A, B or Câ</span>
        <span itemprop="definition">should be interpreted as including any singular entity from the listed elements, e.g., A, any subset from the listed elements, e.g., A and B, or the entire list of elements A, B and C.</span>
        <meta itemprop="num_attr" content="0098">
      </li>
    </ul>
  </section>

  


  <section itemprop="abstract" itemscope>
    <h2>Abstract</h2>
    
    <div itemprop="content" html><abstract mxw-id="PA503030447" lang="EN" source="national office" load-source="docdb">
    <div class="abstract">A method for supporting autonomous driving of an autonomous vehicle includes detecting, by an in-vehicle internet-of-things (IoT) platform of the autonomous vehicle, a vulnerable road user (VRU) having a mobile device in a vicinity of the autonomous vehicle. A mobility application runs on the mobile device of the VRU and sends VRU-specific data to the in-vehicle IoT platform of the autonomous vehicle. The VRU is detected based on the VRU-specific data and/or in-vehicle sensor data of the autonomous vehicle. The method further includes determining, by the in-vehicle IoT platform, a movement intention prediction based on the VRU-specific data. The movement intention prediction is computed by use of a machine learning model. The VRU-specific data of the mobile device are provided as input data for the machine learning model. In addition, the method includes performing an autonomous driving decision for the autonomous vehicle based on the movement intention prediction.</div>
  </abstract>
  </div>
  </section>

  <section itemprop="description" itemscope>
    <h2>Description</h2>
    
    <div itemprop="content" html><ul mxw-id="PDES330219261" lang="EN" load-source="patent-office" class="description">
    
    <heading id="h-0001">CROSS REFERENCE TO RELATED APPLICATIONS</heading>
    <li> <para-num num="[0001]"> </para-num> <div id="p-0002" num="0001" class="description-line">This application is a U.S. National Phase application under 35 U.S.C. Â§ 371 of International Application No. PCT/EP2019/084044, filed on Dec. 6, 2019, and claims benefit to European Patent Application No. EP 19167609.7, filed on Apr. 5, 2019. The International Application was published in English on Oct. 8, 2020, as WO 2020/200502 A1 under PCT Article 21(2).</div>
    
    
    </li> <heading id="h-0002">STATEMENT REGARDING SPONSORED RESEARCH AND DEVELOPMENT</heading>
    <li> <para-num num="[0002]"> </para-num> <div id="p-0003" num="0002" class="description-line">The project leading to this application has received funding from the European Union&#39;s Horizon 2020 research and innovation programme under grant agreement No 731993.</div>
    
    
    </li> <heading id="h-0003">FIELD</heading>
    <li> <para-num num="[0003]"> </para-num> <div id="p-0004" num="0003" class="description-line">The present disclosure relates to a method and a system for supporting autonomous driving of an autonomous vehicle, in particular in terms of an interaction with a vulnerable road user that is in the vicinity of the autonomous vehicle.</div>
    </li> <heading id="h-0004">BACKGROUND</heading>
    <li> <para-num num="[0004]"> </para-num> <div id="p-0005" num="0004" class="description-line">In recent years, there have been major advancements in machine learning research due to increased availability of computation capabilities as well as open datasets (e.g., popularly used labelled image datasets) which allow researchers to easily benchmark their approaches against the state of the art. For example, it is referred to the non-patent literature of A. Geiger, P. Lenz, and R. Urtasun, â<i>Are we ready for Autonomous Driving? The KITTI Vision Benchmark Suiteâ in Conference on Computer Vision and Pattern Recognition </i>(<i>CVPR</i>), 2012. The KITTI Vision Benchmark Suite is an example of those, specifically used in autonomous driving. Furthermore, the development of machine learning frameworks such as TensorFlow (retrievable at https://www.tensorflow.org/) enables easy prototyping and experimenting with new machine learning systems.</div>
    </li> <li> <para-num num="[0005]"> </para-num> <div id="p-0006" num="0005" class="description-line">Simultaneously, the concept of Internet of Things (IoT) has been expanding to many domains such as smart cities and smart industries, and it has appealed to more and more researchers in recent years. While various IoT platforms are provided by various major vendors such as Microsoft Azure, AWS IoT, and IBM Watson IoT platform, new large-scale deployments (e.g., city-scale) and experimental testbeds leveraging IoT technologies have become available.</div>
    </li> <li> <para-num num="[0006]"> </para-num> <div id="p-0007" num="0006" class="description-line">The non-patent literature of R. Bastani Zadeh, M Ghatee, and H. R. Eftekhari, â<i>Three</i>-<i>Phases Smartphone</i>-<i>Based Warning System to Protect Vulnerable Road Users Under Fuzzy Conditionsâ, IEEE Transactions on Intelligent Transportation Systems</i>, vol. 19, no. 7, pp. 2086-2098, jul 2018 [Online] retrievable at https://ieeexplore.ieee.org/document/8054717/describes a warning system based on smartphones to protect vulnerable road users. The system is activated by a geometric model and a fuzzy inference engine estimates the collision risk. In real-world evaluation samples, results show a 96% accuracy in six types of accident scenarios.</div>
    </li> <li> <para-num num="[0007]"> </para-num> <div id="p-0008" num="0007" class="description-line">The non-patent literature of M Goldhammer, S. Kauhler, S. Zernetsch, K Doll, B. Sick, and K Dietmayer, â<i>Intentions of Vulnerable Road UsersâDetection and Forecasting by Means of Machine Learning</i>,â pp. 1-10, mar 2018 [Online] retrievable at http://arxiv.org/abs/1803.03577 describes movement models based on machine learning methods in order to classify motion state (waiting, starting, moving, stopping) and to predict the future trajectory of vulnerable road users. Results show an accuracy of 88.6% for the motion state classification and a reduction of the trajectory prediction error by 41% on stopping motion scenarios.</div>
    </li> <heading id="h-0005">SUMMARY</heading>
    <li> <para-num num="[0008]"> </para-num> <div id="p-0009" num="0008" class="description-line">In an embodiment, the present disclosure provides a method for supporting autonomous driving of an autonomous vehicle. The method includes detecting, by an in-vehicle internet-of-things (IoT) platform of the autonomous vehicle, a vulnerable road user (VRU) having a mobile device in a vicinity of the autonomous vehicle. A mobility application runs on the mobile device of the VRU and sends VRU-specific data to the in-vehicle IoT platform of the autonomous vehicle. The VRU is detected based on the VRU-specific data and/or in-vehicle sensor data of the autonomous vehicle. The method further includes determining, by the in-vehicle IoT platform, a movement intention prediction for the VRU based on the VRU-specific data provided by the mobile device. The movement intention prediction is computed by use of a machine learning model. The VRU-specific data of the mobile device are provided as input data for the machine learning model. In addition, the method includes performing, by the in-vehicle IoT platform, an autonomous driving decision for the autonomous vehicle based on the movement intention prediction.</div>
    
    
    </li> <description-of-drawings>
      <heading id="h-0006">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
      <li> <para-num num="[0009]"> </para-num> <div id="p-0010" num="0009" class="description-line">Subject matter of the present disclosure will be described in even greater detail below based on the exemplary figures. All features described and/or illustrated herein can be used alone or combined in different combinations. The features and advantages of various embodiments will become apparent by reading the following detailed description with reference to the attached drawings, which illustrate the following:</div>
      </li> <li> <para-num num="[0010]"> </para-num> <div id="p-0011" num="0010" class="description-line"> <figref idrefs="DRAWINGS">FIG. 1</figref> is a schematic view illustrating a method or a system according to an embodiment,</div>
      </li> <li> <para-num num="[0011]"> </para-num> <div id="p-0012" num="0011" class="description-line"> <figref idrefs="DRAWINGS">FIG. 2</figref> is a schematic view illustrating an overview of an architecture of a system in accordance with an embodiment,</div>
      </li> <li> <para-num num="[0012]"> </para-num> <div id="p-0013" num="0012" class="description-line"> <figref idrefs="DRAWINGS">FIG. 3</figref> is a schematic view illustrating a pedestrian movement intention prediction model according to an embodiment,</div>
      </li> <li> <para-num num="[0013]"> </para-num> <div id="p-0014" num="0013" class="description-line"> <figref idrefs="DRAWINGS">FIG. 4</figref> is a schematic view illustrating a pedestrian movement intention prediction model according to a further embodiment,</div>
      </li> <li> <para-num num="[0014]"> </para-num> <div id="p-0015" num="0014" class="description-line"> <figref idrefs="DRAWINGS">FIG. 5</figref> is a schematic view illustrating a pedestrian movement intention prediction model according to a further embodiment,</div>
      </li> <li> <para-num num="[0015]"> </para-num> <div id="p-0016" num="0015" class="description-line"> <figref idrefs="DRAWINGS">FIG. 6</figref> is a schematic view illustrating a petri net model for supporting autonomous driving decision making according to an embodiment, and</div>
      </li> <li> <para-num num="[0016]"> </para-num> <div id="p-0017" num="0016" class="description-line"> <figref idrefs="DRAWINGS">FIG. 7</figref> is a schematic view illustrating an interface where pedestrian and vehicle trajectories are visualized for a particular run by animation of real data in discrete time intervals.</div>
    </li> </description-of-drawings>
    
    
    <heading id="h-0007">DETAILED DESCRIPTION</heading>
    <li> <para-num num="[0017]"> </para-num> <div id="p-0018" num="0017" class="description-line">The present disclosure provides a method and a system for supporting autonomous driving of an autonomous vehicle in such a way that road safety is improved, in particular in terms of preventing possible accidents between the autonomous vehicle and a vulnerable road user that is in the vicinity of the approaching vehicle.</div>
    </li> <li> <para-num num="[0018]"> </para-num> <div id="p-0019" num="0018" class="description-line">In accordance with the present disclosure, a method is provided for supporting autonomous driving of an autonomous vehicle, in particular in terms of an interaction with a vulnerable road user that is in the vicinity of the autonomous vehicle. The method includes detecting, by an in-vehicle IoT platform of the autonomous vehicle, a vulnerable road user, âVRUâ, having a mobile device in the vicinity of the autonomous vehicle, wherein a mobility application runs on the mobile device of the VRU and sends VRU-specific data to the in-vehicle IoT platform of the autonomous vehicle, wherein the VRU is detected based on the VRU-specific data and/or in-vehicle sensor data of the autonomous vehicle; determining, by the in-vehicle IoT platform, a movement intention prediction for the VRU based on the VRU-specific data provided by the mobile device, wherein the movement intention prediction is computed by the use of a machine learning model, wherein the VRU-specific data of the mobile device are employed as input data for said machine learning model; and performing, by the in-vehicle IoT platform, an autonomous driving decision for the autonomous vehicle based on said movement intention prediction.</div>
    </li> <li> <para-num num="[0019]"> </para-num> <div id="p-0020" num="0019" class="description-line">Furthermore, a system is provided for supporting autonomous driving of an autonomous vehicle, the system comprising an in-vehicle IoT platform that is implemented in the autonomous vehicle and a mobility application running on a mobile device of a vulnerable road user, âVRUâ, wherein the mobility application running on the mobile device of the VRU is configured to send VRU-specific data to the in-vehicle IoT platform of the autonomous vehicle, wherein the in-vehicle IoT platform of the autonomous vehicle is configured to detect the VRU having the mobile device in the vicinity of the autonomous vehicle, wherein the VRU is detected based on the VRU-specific data and/or in-vehicle sensor data of the autonomous vehicle, wherein the in-vehicle IoT platform is further configured to determine a movement intention prediction for the VRU based on the VRU-specific data provided by the mobile device, wherein the movement intention prediction is computed by the use of a machine learning model, wherein the VRU-specific data of the mobile device are employed as input data for said machine learning model, and wherein the in-vehicle IoT platform is configured to perform an autonomous driving decision for the autonomous vehicle based on said movement intention prediction.</div>
    </li> <li> <para-num num="[0020]"> </para-num> <div id="p-0021" num="0020" class="description-line">According to the present disclosure, it has first been recognized that an enormous improvement with regard to preventing potential accidents and collisions between the vulnerable road user and the approaching autonomous vehicle can be achieved by leveraging useful information coming directly and voluntarily from the vulnerable road user&#39;s mobile device. This in contrast to most of the current autonomous driving systems, which focus only on in-built or attached car sensors and road-side units for taking autonomous driving decisions. Thus, according to the present disclosure, an in-vehicle IoT (Internet of Things) platform of the autonomous vehicle is configured to detect a vulnerable road user (VRU) having a mobile device in the vicinity of the autonomous vehicle. A mobility application runs on the mobile device of the VRU and sends VRU-specific data to the in-vehicle IoT platform of the autonomous vehicle, wherein the VRU is detected based on the VRU-specific data provided by the mobile device and/or based on in-vehicle sensor data of the autonomous vehicle. Thus, the VRU may be detected based on a combination of VRU-specific data from the mobile device and in-vehicle sensor data that is acquired/measured by the autonomous vehicle. The in-vehicle IoT platform is further configured to determine a movement intention prediction for the VRU, based on the VRU-specific data provided by the mobile device, wherein the movement intention prediction is computed by the use of a machine learning model. The VRU-specific data of the mobile device are employed as input data for the machine learning model. Then, the in-vehicle IoT platform can perform an autonomous driving decision for the autonomous vehicle based on the previously determined movement intention prediction.</div>
    </li> <li> <para-num num="[0021]"> </para-num> <div id="p-0022" num="0021" class="description-line">Thus, the present disclosure provides a method and a system for supporting autonomous driving of an autonomous vehicle, wherein road safety is improved, in particular in terms of preventing possible accidents between the autonomous vehicle and a vulnerable road user that is in the vicinity of the approaching vehicle.</div>
    </li> <li> <para-num num="[0022]"> </para-num> <div id="p-0023" num="0022" class="description-line">With the advancements in the vehicle to vehicle (V2V) or vehicle to road side as well as vehicle to everything (V2X) communications in the 5G era, the communications from the sensors in the road infrastructure or road side units (RSUs) as well as any mobile device (e.g., smartphone or wearable) close to road side and the car communication can be handled in very short time. Therefore, embodiments of the present disclosure become more feasible in terms of real-time applicability and usage for improving traffic safety.</div>
    </li> <li> <para-num num="[0023]"> </para-num> <div id="p-0024" num="0023" class="description-line">The term âmachine learning modelâ may refer to a mathematical representation of a process which can be generated with an algorithm using training data. According to embodiments, the machine learning model may be an artificial neural network (ANN).</div>
    </li> <li> <para-num num="[0024]"> </para-num> <div id="p-0025" num="0024" class="description-line">According to embodiments, an exemplary system may include a mobile device, autonomous car(s), an in-vehicle (edge) IoT platform, and a VRU intention-based decision-making software that runs on top of the platform.</div>
    </li> <li> <para-num num="[0025]"> </para-num> <div id="p-0026" num="0025" class="description-line">The term âmovement intention predictionâ may be understood, in particular in the claims, preferably in the description as the possible next movement action of the VRU such as of a pedestrian. Thus, the mobile device user can be considered as the vulnerable road user that may be a pedestrian in the vicinity of an approaching autonomous vehicle/car. The decision-making of autonomous driving may be supplemented with the outcome of a method or system according to an embodiment as a complementary input in order to protect the vulnerable pedestrian.</div>
    </li> <li> <para-num num="[0026]"> </para-num> <div id="p-0027" num="0026" class="description-line">According to embodiments, it may be provided that, in particular upon detecting of the VRU and prior to determining of the movement intention prediction, a transportation mode of the VRU is determined using a machine learning process. Thus, for example, the machine learning process can determine whether the VRU is a pedestrian or a cyclist. Then, the input data can be fed into a movement intention classifier that computes a movement intention prediction for a VRU using a machine learning model. The machine learning process may include computing the transportation mode of the VRU by the use of a weak supervision-based machine learning model. Weak supervision may be understood as a branch of machine learning for labelling data through noisy or remote labelling sources which are called weak supervisors. Weak supervision enables labelling data through the weak supervisors and therefore avoiding the need for ground-truth collection (labels for peoples&#39; transportation modes). Weak supervised systems such as Snorkel (retrievable at http://snorkel.org) can be used for classifying transport modes through weak supervision.</div>
    </li> <li> <para-num num="[0027]"> </para-num> <div id="p-0028" num="0027" class="description-line">According to embodiments, it may be provided that video processing is performed based on image data (footage) that is gathered by a sensor device such as a camera of the autonomous vehicle in order to detect the VRU and/or to determine the transportation mode of the VRU. Thus, high-accuracy detection of the VRU and its classification (i.e., pedestrian or cyclist) can be provided.</div>
    </li> <li> <para-num num="[0028]"> </para-num> <div id="p-0029" num="0028" class="description-line">According to embodiments, the VRU-specific data may include sensor data that are collected by one or more sensors of the mobile device of the VRU. For example, the sensor data may comprise location/position dataâin particular GNSS data such as GPS dataâ, accelerometer data and/or gyroscope data. Thus, the outcome of computations with regard to VRU detection and determination of movement intention prediction is improved.</div>
    </li> <li> <para-num num="[0029]"> </para-num> <div id="p-0030" num="0029" class="description-line">According to embodiments, the VRU-specific data may include position data, heading angle information and/or (average) speed information of the VRU. Thus, the outcome and accuracy of computations with regard to VRU detection and determination of movement intention prediction is improved.</div>
    </li> <li> <para-num num="[0030]"> </para-num> <div id="p-0031" num="0030" class="description-line">According to embodiments, the VRU-specific data may include a trajectory of the VRU. Thus, the outcome and accuracy of computations with regard to VRU detection and determination of movement intention prediction can be improved.</div>
    </li> <li> <para-num num="[0031]"> </para-num> <div id="p-0032" num="0031" class="description-line">According to embodiments, the in-vehicle sensor data may include sensor data that are gathered by one or more sensors of the autonomous vehicle. Thus, the outcome and accuracy of computations with regard to VRU detection and determination of movement intention prediction can be improved.</div>
    </li> <li> <para-num num="[0032]"> </para-num> <div id="p-0033" num="0032" class="description-line">According to embodiments, the input data for the machine learning model may further include in-vehicle sensor data of the autonomous vehicle for the VRU. Thus, the outcome and accuracy of computations with regard to VRU detection and determination of movement intention prediction can be improved.</div>
    </li> <li> <para-num num="[0033]"> </para-num> <div id="p-0034" num="0033" class="description-line">According to embodiments, the input data for the machine learning model may further include additional data from one or more IoT data sources. This additional information may provide further information relating to an environment in the vicinity of the autonomous vehicle.</div>
    </li> <li> <para-num num="[0034]"> </para-num> <div id="p-0035" num="0034" class="description-line">According to embodiments, the additional data may include (online) map data, in particular 3D model data, in order to learn from map features. For example, the map features may include angle to road, distance to road, map landmarks, etc. Thus, the machine learning model (i.e., for instance, the artificial neural network) may learn from the map features and the prediction of the VRU&#39;s next movement intention can be determined/computed with higher accuracy.</div>
    </li> <li> <para-num num="[0035]"> </para-num> <div id="p-0036" num="0035" class="description-line">According to embodiments, the additional data may include internet service data from one or more internet services, wherein the internet service data include information on weather conditions, traffic lights, live events, and/or traffic situations, in an environment of the vicinity of the autonomous vehicle. Thus, the machine learning model (i.e., for instance, the artificial neural network) may learn from these additional information in order to predict the VRU&#39;s next movement intention with higher accuracy.</div>
    </li> <li> <para-num num="[0036]"> </para-num> <div id="p-0037" num="0036" class="description-line">According to embodiments, the additional data may include information on event schedules of the VRU. Thus, the outcome and accuracy of computations with regard to the determination of movement intention prediction for the VRU can be improved.</div>
    </li> <li> <para-num num="[0037]"> </para-num> <div id="p-0038" num="0037" class="description-line">According to embodiments, the input data for the machine learning model may further include information on the movement history of the VRU. The historical user data may include the VRU&#39;s previous traffic-related history of any violation such as jaywalking. These data can be considered for probabilistic prediction of the movement intention for the VRU&#39;s next walking movement decision.</div>
    </li> <li> <para-num num="[0038]"> </para-num> <div id="p-0039" num="0038" class="description-line">According to embodiments, the movement intention prediction that is determined by the machine learning model may represent a user action that is expected to be performed next by the VRU.</div>
    </li> <li> <para-num num="[0039]"> </para-num> <div id="p-0040" num="0039" class="description-line">According to embodiments, a set of user actions may be defined for the movement intention prediction that is determinable by the machine learning model, wherein the set of actions comprises waiting, walking straight, turning left, turning right and/or turning back (i.e. U-turn).</div>
    </li> <li> <para-num num="[0040]"> </para-num> <div id="p-0041" num="0040" class="description-line">Embodiments may relate to a method or a system which combines IoT data sources such as measurements of autonomous vehicles&#39; sensors, mobile device users&#39; data and other IoT data sources from internet sources such as online map data and event schedules of mobile device users, to improve autonomous driving decisions taken by autonomous vehicles to improve road safety of pedestrians.</div>
    </li> <li> <para-num num="[0041]"> </para-num> <div id="p-0042" num="0041" class="description-line">Thus, embodiments may relate to a real-time IoT system for the smart mobility domain. An application scenario for a method or system according to an embodiment may include the following:
</div> </li> <ul> <li id="ul0001-0001" num="0000"> <ul> <li id="ul0002-0001" num="0042">1) an autonomous vehicle/car,</li> <li id="ul0002-0002" num="0043">2) a mobile device user (i.e. the VRU) with a mobility application running on the mobile device,</li> <li id="ul0002-0003" num="0044">3) an in-vehicle IoT platform of the autonomous car,</li> <li id="ul0002-0004" num="0045">4) machine learning software engine implemented on the in-vehicle IoT platform, and</li> <li id="ul0002-0005" num="0046">5) (optional) other vehicles or IoT data sources.</li> </ul> </li> </ul>

    <li> <para-num num="[0047]"> </para-num> <div id="p-0043" num="0047" class="description-line">The machine learning software leverages data sources for training such as GPS data from the mobility application and other open datasets as well as online maps to learn from map features.</div>
    </li> <li> <para-num num="[0048]"> </para-num> <div id="p-0044" num="0048" class="description-line">According to embodiments, the system first detects existence of a vulnerable road user (VRU) that is a pedestrian in the vicinity of an approaching autonomous vehicle/car. If the VRU is using the mobility application, the mobile device of the VRU directly (through V2V) or indirectly (through 4G/5G) transmits VRU-specific data to the in-vehicle IoT platform of the autonomous vehicle. Then, the machine learning software implemented on the in-vehicle IoT platform of the autonomous vehicle predicts the movement intention of the pedestrian, wherein the movement intention can be defined as the next movement choice with a simple set of actions: for instance, waiting, walking straight, turning left, turning right, and/or turning back.</div>
    </li> <li> <para-num num="[0049]"> </para-num> <div id="p-0045" num="0049" class="description-line">For determining the movement intention prediction, the machine learning software engine is trained with datasets including location/position data (such as GPS data), heading information, and speed information as well as map features. Furthermore, the machine learning software engine may incorporate data sources such as event schedule (e.g., lecture schedule in a university campus) of the mobile device user, if the data is available in a timely manner. Lastly, the system components on the in-vehicle IoT platform of the autonomous car may decide on the autonomous driving action such as slowing down the car, keeping the same speed, or breaking the car in unsafe situations. This decision is based on VRU detection and pedestrian intention prediction models to assess safety based on information from in-vehicle sensors and mobile device data (i.e. VRU-specific data).</div>
    </li> <li> <para-num num="[0050]"> </para-num> <div id="p-0046" num="0050" class="description-line">According to embodiments, the data may be collected in the in-vehicle IoT platform. The software engine for VRU detection, the VRU movement intention prediction, and autonomous driving decision may be part of (or may run on top of) the in-vehicle IoT platform. The in-vehicle IoT platform can be considered as an edge component. The communication can be done directly in between the mobile device, autonomous car, or RSU. In the case of internet sources, they can be reached using 4G/5G communications. Some of the internet sources such as lecture schedule in a campus or weather information can be gathered before the pedestrian comes to the road side.</div>
    </li> <li> <para-num num="[0051]"> </para-num> <div id="p-0047" num="0051" class="description-line">At least one embodiment may have at least one of the following advantages and characteristics:
</div> </li> <ul> <li id="ul0003-0001" num="0000"> <ul> <li id="ul0004-0001" num="0052">A system and a method according to an embodiment improve autonomous driving safety by leveraging IoT data sources and mobile device data of pedestrian, whereas most of the current systems rely on car or road-side sensors.</li> <li id="ul0004-0002" num="0053">A system and a method according to an embodiment may complement the current state of the art with additional input to consider before making autonomous decisions. It may be particularly useful in the case of absence of cameras or obstacle presence.</li> <li id="ul0004-0003" num="0054">Embodiments aim at providing an extra-layer of security for pedestrians by combining different sources of data. In specific places such as smart cities or smart campuses, it may be useful as the people may use the mobility application given by the organization.</li> <li id="ul0004-0004" num="0055">Embodiments leverage useful information coming directly and voluntarily from pedestrians&#39; mobile devices as well as their IoT information such as their event schedules or internet-based services for scheduled events in urban areas. Embodiments can be considered complementary to existing autonomous driving decision systems and can be used as an additional input for decision-making.</li> </ul> </li> </ul>

    <li> <para-num num="[0056]"> </para-num> <div id="p-0048" num="0056" class="description-line">There are several ways how to design and further develop the teaching of the present disclosure in an advantageous way. To this end, it is to be referred to the following explanation of further embodiments illustrated by the figures on the other hand.</div>
    </li> <li> <para-num num="[0057]"> </para-num> <div id="p-0049" num="0057" class="description-line"> <figref idrefs="DRAWINGS">FIG. 1</figref> shows a schematic view illustrating a method or a system according to an embodiment. <figref idrefs="DRAWINGS">FIG. 1</figref> gives a simplistic overview of an idea of pedestrian intention-based autonomous driving in accordance with an embodiment. A main target of the embodiment is an understanding of pedestrian movement intentions using and combining available IoT (Internet of Things) data sources as well as pre-trained prediction components in-vehicle. Possible data sources and actors are listed on the left side of <figref idrefs="DRAWINGS">FIG. 1</figref>, given as inputs to the autonomous driving, while the outputs are the autonomous driving decisions that are applied to the vehicle/car on the right side of <figref idrefs="DRAWINGS">FIG. 1</figref>.</div>
    </li> <li> <para-num num="[0058]"> </para-num> <div id="p-0050" num="0058" class="description-line">The approach according to the embodiment may comprise the following steps: (1) vulnerable road user (VRU) detection, (2) pedestrian intention prediction, and (3) autonomous decision making.</div>
    </li> <li> <para-num num="[0059]"> </para-num> <div id="p-0051" num="0059" class="description-line">The first step leverages video processing based on footage received from a camera deployed in the vehicle/car for high-accuracy detection of vulnerable road users (VRUs) and their classification (i.e., pedestrian and cyclist). The second step leverages smartphone data (e.g., GPS, gyroscope) and internet sources (e.g., map data) to predict the pedestrian&#39;s movement intentions. In the second step, long-term historical data from pedestrians for pre-training may also be used. The third step combines the outcome/output from the first two steps and makes an autonomous driving decision. In this regard, a petri net model for classifying behaviors such as slowing down may be considered, for example as illustrated by <figref idrefs="DRAWINGS">FIG. 6</figref>.</div>
    </li> <li> <para-num num="[0060]"> </para-num> <div id="p-0052" num="0060" class="description-line"> <figref idrefs="DRAWINGS">FIG. 2</figref> shows a schematic view illustrating an overview of a system architecture for a method or a system in accordance with an embodiment. The embodiment illustrated by <figref idrefs="DRAWINGS">FIG. 2</figref> comprise three main participants as follows: in-vehicle IoT platform, mobile device, and cloud IoT platform.</div>
    </li> <li> <para-num num="[0061]"> </para-num> <div id="p-0053" num="0061" class="description-line">The key components relevant to implementing the embodiment for VRU and/or pedestrian intention-based autonomous driving are marked as squared boxes with underlined text in <figref idrefs="DRAWINGS">FIG. 2</figref>, whereas all other components that may be required are presented in rounded boxes.</div>
    </li> <li> <para-num num="[0062]"> </para-num> <div id="p-0054" num="0062" class="description-line">The key components of <figref idrefs="DRAWINGS">FIG. 2</figref> comprise a mobility application implemented on the mobile device. Further, the key components comprise a VRU detection entity, a pedestrian intention estimation entity and an autonomous driving input entity, which are all implemented on the in-vehicle IoT platform of the car.</div>
    </li> <li> <para-num num="[0063]"> </para-num> <div id="p-0055" num="0063" class="description-line">In-vehicle IoT platform: The custom-built autonomous car/vehicle of the described embodiment includes various sensors such as cameras, Mobileye, Lidar, and so on. The in-vehicle IoT platform contains a Robot Operating System (ROS), which can be considered as the operating system of the car. ROS receives/collects the data published from various sensors, in-vehicle software components (e.g., analytics, image/video processing components), mobile devices (e.g., the mobility app for smartphones), as well as the cloud platform. The collection from the cloud platform and the mobile devices is supported by a custom-developed lightweight IoT broker component. This component queries/subscribes to these other sources and deliver the data to the ROS. The ROS files are stored in the storage. There are three components, which can also be seen as standalone applications running on the in-vehicle IoT platform. For testing or simulation purposes using collected offline data, VRU detection and pedestrian intention estimation components can be run offline using rosbag files (i.e., simulation using real data). As these components run on ROS environment using the same ROS data, with the same setup they can be transferred to a real setup in the in-vehicle IoT platform. The autonomous driving input component is considered for providing valuable input to autonomous driving by leveraging and combining the outputs of the VRU detection and pedestrian intention estimation.</div>
    </li> <li> <para-num num="[0064]"> </para-num> <div id="p-0056" num="0064" class="description-line">Mobile device: Any mobile device such as smartphones and wearables with sensors and communication capabilities may be considered as possible components of the system from the VRU side. The system involves the usage of mobile devices by the VRUs. The mobile devices include a set of sensors, antennas for communication, as well as the mobility app, i.e. the mobility application. The sensors of the mobile device include, e.g., GPS, gyroscope and accelerometer. The mobile device push data through 4G communication (or 5G in the near future). The communication capabilities may include vehicle to vehicle (V2V) protocols such as ITS-G5 for direct communication to the vehicle. This communication can be satisfied only in the case that the VRU and the autonomous vehicle are in the wireless range of each other (i.e., less than 100 m). The mobility application collects the sensory data and pushes it to the cloud (or optionally to in-vehicle platform). The mobility application uses a geo-location API (Application Programming Interface).</div>
    </li> <li> <para-num num="[0065]"> </para-num> <div id="p-0057" num="0065" class="description-line">Cloud IoT platform: Although the cloud platform includes various components and different aspects, in this embodiment it is focused on the two standard-based IoT platforms that are mainly used for collecting and providing the VRU mobility-related data: FIWARE (retrievable at https://www.fiware.org/) and oneM2M (retrievable at http://www.onem2 m.org/). The data from the mobility application can be pushed to FIWARE IoT platform which is bidirectionally connected to the oneM2M platform through a custom-developed interworking proxy component, which handles the data exchanges and format convergence in between these two standard-based platform.</div>
    </li> <li> <para-num num="[0066]"> </para-num> <div id="p-0058" num="0066" class="description-line">A system according to an embodiment such as illustrated by <figref idrefs="DRAWINGS">FIG. 2</figref> may perform steps as follows:</div>
    </li> <heading id="h-0008">Step 1: VRU Detection</heading>
    <li> <para-num num="[0067]"> </para-num> <div id="p-0059" num="0067" class="description-line">Considering a single person as vulnerable road user (VRU), the method may have three cases of VRU detection: Case 1: existence of only mobile device data, i.e. the VRU-specific data; Case 2: existence of only camera data, i.e. in-vehicle sensor data; and Case 3: existence of both camera data and mobile device data for the VRU</div>
    </li> <li> <para-num num="[0068]"> </para-num> <div id="p-0060" num="0068" class="description-line">In <figure-callout id="1" label="case" filenames="US20220161818A1-20220526-D00000.png,US20220161818A1-20220526-D00001.png" state="{{state}}">case</figure-callout> 1, the location/position data is received from the mobile device into the in-vehicle IoT platform. The location/position data is leveraged for later safety assessment and autonomous driving decision based on that.</div>
    </li> <li> <para-num num="[0069]"> </para-num> <div id="p-0061" num="0069" class="description-line">In the <figure-callout id="2" label="case" filenames="US20220161818A1-20220526-D00000.png,US20220161818A1-20220526-D00001.png" state="{{state}}">case</figure-callout> 2, the image processing is used. This model extracts all obstacles from image processing and if it is a person, classifies the type of the person (i.e., pedestrian or cyclist) using the images. Moreover, the image processing can compute the relative position of the person to the vehicle.</div>
    </li> <li> <para-num num="[0070]"> </para-num> <div id="p-0062" num="0070" class="description-line">In the <figure-callout id="3" label="case" filenames="US20220161818A1-20220526-D00000.png,US20220161818A1-20220526-D00001.png" state="{{state}}">case</figure-callout> 3, both camera data and mobile device data are collected in the in-vehicle platform. In this case, the image processing finds the relative positions and combines with the vehicle location data (i.e., GPS) to find the coordinates of the obstacles. Then, the VRU detection compares this information about the coordinates from multiple obstacles with the coordinates available from the mobile device(s). This comparison is performed over multiple image frames for a predetermined period of time (e.g., 8 frames/second) and the best match obstacle is marked as the mobile device user. In this case, the VRU detection is performed using camera data measured by the autonomous vehicle.</div>
    </li> <heading id="h-0009">Step 2: Transportation Mode Detection</heading>
    <li> <para-num num="[0071]"> </para-num> <div id="p-0063" num="0071" class="description-line">A machine learning model is trained to classify the transportation mode of vulnerable road users. This classification, performed by a machine learning process, is required to identify VRUs such as pedestrians and bicyclists before their data is fed into the movement intention classifier that computes a movement intention prediction for a VRU using a machine learning model (such as an artificial neural network). For not relying on extensive labeling of ground truth transportation modes via crowdsourcing, a weak supervision can be applied to quickly collect vast amounts of noisy training data. Specifically, a weak supervision-based machine learning model is used, where multiple supervisors are defined based on subject matter expert knowledge (e.g., bicycle, pedestrian, car speed constraints, length of trip, sequence of trip segments), geographical information from existing knowledge bases (e.g., bus and train stops from OpenStreetMap) and other integrated third party data sources (e.g., weather data). These labeling functions are applied on detected trips and trip segments that have been integrated with OpenStreetMap and weather data. Based on the resulting probabilistic labels, the machine learning model can then be trained. The provided model is able to generalize the training data and apply it to mobility data from other deployments and cities without a repeated collection of training data (e.g., through crowd-sourcing or manual labeling).</div>
    </li> <heading id="h-0010">Step 3: Vru/Pedestrian Movement Intentions</heading>
    <li> <para-num num="[0072]"> </para-num> <div id="p-0064" num="0072" class="description-line">A method in accordance with an embodiment includes a step of estimating/determining the next movement action of the vulnerable road user. In this regard, it is referred to <figref idrefs="DRAWINGS">FIG. 3</figref> that shows a schematic view illustrating a pedestrian movement intention prediction model according to an embodiment. Specifically, <figref idrefs="DRAWINGS">FIG. 3</figref> shows a method of an embodiment that combines personal information, i.e. VRU-specific data coming from the mobile device of the VRU, and in-vehicle sensor data for VRU as well as information from IoT data sources such as map/3D model environmental data and data from internet services. The described data include the latest movement steps (short trajectory) of the pedestrian and mobile devices sensors (e.g., heading), user data (i.e., event schedule, movement history of the user), position of pedestrian using the previous VRU detection step, map features (e.g., distance to road, angle to road), and data from cloud/edge IoT services (e.g., traffic lights, live events/traffic situation/other information in the environment). The historical user data may include the user&#39;s previous traffic-related history of any violation such as jaywalking. These data is considered for probabilistic prediction of the âpedestrian intentionâ for their next walking movement decisions.</div>
    </li> <li> <para-num num="[0073]"> </para-num> <div id="p-0065" num="0073" class="description-line">According to embodiments, the proposed machine learning model uses mobile device&#39;s sensor data such as the GPS trajectory values of pedestrians in order to predict their next movements. An Artificial Neural Network (ANN) is modelled, consisting of n neurons in the input layer and five neurons as output, where n is the number of steps from the previous pedestrian trajectory from t_<b>1</b> until t_n, plus the heading angle and average speed information. Each output neuron represents the next movement intention or turn direction of the pedestrian, i.e. waiting, walking straight, turning right, turning left or U-turn (i.e., turning back).</div>
    </li> <li> <para-num num="[0074]"> </para-num> <div id="p-0066" num="0074" class="description-line"> <figref idrefs="DRAWINGS">FIG. 4</figref> and <figref idrefs="DRAWINGS">FIG. 5</figref> illustrate a neural network model considering a basic ANN (without map features) and an ANN with using map features according to embodiments. Thus, <figref idrefs="DRAWINGS">FIG. 4</figref> shows an example of a neural network model for movement intention prediction of a pedestrian, using only features of the mobile device (not using other IoT sources). <figref idrefs="DRAWINGS">FIG. 5</figref> shows a further example of a neural network model for movement intention prediction of a pedestrian, using features of the mobile device together with map features and possibly other IoT sources.</div>
    </li> <li> <para-num num="[0075]"> </para-num> <div id="p-0067" num="0075" class="description-line">The machine learning model training process is fed by the data collected in the offline phase and the mobile device data, i.e. the VRU-specific data, is partitioned into training, validation and testing datasets.</div>
    </li> <li> <para-num num="[0076]"> </para-num> <div id="p-0068" num="0076" class="description-line">Based on the concept of data programming, a method according to an embodiment provides heuristic rules applied over a geometric model to help in the creation of labeled training sets. Thus, it is not necessary to manually collect labeled intentions from pedestrians, as the training process uses the results from labeling functions. As part of the labeling function, well-known geometric formulas are applied to calculate the bearing (direction or angle between the north-south line of earth or meridian and the line connecting the target and the reference point) of movement in degrees and, based on this angle and the walked distance, a set of rules are applied to give the turning direction, waiting or walking straight status. Except than the map features using services such as OpenStreetMap, the machine learning model can be extended using other data coming from the mobile device user (i.e. the VRU) such as the appointment schedule (e.g., lecture schedule of a student in a university campus) or the next navigation destination as well as events from the online sources such as large-scale events in a city to improve the movement intention prediction accuracy.</div>
    </li> <li> <para-num num="[0077]"> </para-num> <div id="p-0069" num="0077" class="description-line">The equation below presents a final labeling function with heuristic rules for state and direction definition:</div>
    </li> <li> <div id="p-0070" num="0000" class="description-line">
      <maths id="MATH-US-00001" num="00001">
        <math overflow="scroll">
          <mrow>
            <mrow>
              <mi>f</mi>
              <mo>â¡</mo>
              <mrow>
                <mo>(</mo>
                <mrow>
                  <mi>a</mi>
                  <mo>,</mo>
                  <mi>b</mi>
                  <mo>,</mo>
                  <mi>c</mi>
                </mrow>
                <mo>)</mo>
              </mrow>
            </mrow>
            <mo>=</mo>
            <mrow>
              <mo>{</mo>
              <mtable>
                <mtr>
                  <mtd>
                    <mrow>
                      <mi>waiting</mi>
                      <mo>,</mo>
                    </mrow>
                  </mtd>
                  <mtd>
                    <mrow>
                      <mrow>
                        <mrow>
                          <mi>if</mi>
                          <mo>â¢</mo>
                          <mstyle>
                            <mspace width="0.8em" height="0.8ex"> </mspace>
                          </mstyle>
                          <mo>â¢</mo>
                          <msub>
                            <mi>d</mi>
                            <mi>ab</mi>
                          </msub>
                        </mrow>
                        <mo>+</mo>
                        <msub>
                          <mi>d</mi>
                          <mi>bc</mi>
                        </msub>
                      </mrow>
                      <mo>&lt;</mo>
                      <msub>
                        <mi>T</mi>
                        <mi>d</mi>
                      </msub>
                    </mrow>
                  </mtd>
                </mtr>
                <mtr>
                  <mtd>
                    <mrow>
                      <mi>right</mi>
                      <mo>,</mo>
                    </mrow>
                  </mtd>
                  <mtd>
                    <mrow>
                      <mrow>
                        <mi>if</mi>
                        <mo>â¢</mo>
                        <mstyle>
                          <mspace width="0.8em" height="0.8ex"> </mspace>
                        </mstyle>
                        <mo>â¢</mo>
                        <mrow>
                          <mo>(</mo>
                          <mrow>
                            <mi>Î´</mi>
                            <mo>&lt;</mo>
                            <mrow>
                              <mrow>
                                <mo>-</mo>
                                <mn>180</mn>
                              </mrow>
                              <mo>-</mo>
                              <msub>
                                <mi>T</mi>
                                <mi>a</mi>
                              </msub>
                            </mrow>
                          </mrow>
                          <mo>)</mo>
                        </mrow>
                      </mrow>
                      <mo>â©</mo>
                    </mrow>
                  </mtd>
                </mtr>
                <mtr>
                  <mtd>
                    <mstyle>
                      <mspace width="0.3em" height="0.3ex"> </mspace>
                    </mstyle>
                  </mtd>
                  <mtd>
                    <mrow>
                      <mo>(</mo>
                      <mrow>
                        <mrow>
                          <mi>Î´</mi>
                          <mo>&gt;</mo>
                          <msub>
                            <mi>T</mi>
                            <mi>a</mi>
                          </msub>
                        </mrow>
                        <mo>â©</mo>
                        <mrow>
                          <mi>Î´</mi>
                          <mo>&lt;</mo>
                          <mrow>
                            <mn>180</mn>
                            <mo>-</mo>
                            <msub>
                              <mi>T</mi>
                              <mi>a</mi>
                            </msub>
                          </mrow>
                        </mrow>
                      </mrow>
                      <mo>)</mo>
                    </mrow>
                  </mtd>
                </mtr>
                <mtr>
                  <mtd>
                    <mrow>
                      <mi>left</mi>
                      <mo>,</mo>
                    </mrow>
                  </mtd>
                  <mtd>
                    <mrow>
                      <mrow>
                        <mi>if</mi>
                        <mo>â¢</mo>
                        <mstyle>
                          <mspace width="0.8em" height="0.8ex"> </mspace>
                        </mstyle>
                        <mo>â¢</mo>
                        <mrow>
                          <mo>(</mo>
                          <mrow>
                            <mi>Î´</mi>
                            <mo>&gt;</mo>
                            <mrow>
                              <mn>180</mn>
                              <mo>+</mo>
                              <msub>
                                <mi>T</mi>
                                <mi>a</mi>
                              </msub>
                            </mrow>
                          </mrow>
                          <mo>)</mo>
                        </mrow>
                      </mrow>
                      <mo>â©</mo>
                    </mrow>
                  </mtd>
                </mtr>
                <mtr>
                  <mtd>
                    <mstyle>
                      <mspace width="0.3em" height="0.3ex"> </mspace>
                    </mstyle>
                  </mtd>
                  <mtd>
                    <mrow>
                      <mo>(</mo>
                      <mrow>
                        <mrow>
                          <mi>Î´</mi>
                          <mo>&lt;</mo>
                          <mrow>
                            <mn>0</mn>
                            <mo>-</mo>
                            <msub>
                              <mi>T</mi>
                              <mi>a</mi>
                            </msub>
                          </mrow>
                        </mrow>
                        <mo>â©</mo>
                        <mrow>
                          <mi>Î´</mi>
                          <mo>&gt;</mo>
                          <mrow>
                            <mrow>
                              <mo>-</mo>
                              <mn>180</mn>
                            </mrow>
                            <mo>+</mo>
                            <msub>
                              <mi>T</mi>
                              <mi>a</mi>
                            </msub>
                          </mrow>
                        </mrow>
                      </mrow>
                      <mo>)</mo>
                    </mrow>
                  </mtd>
                </mtr>
                <mtr>
                  <mtd>
                    <mrow>
                      <mi>straight</mi>
                      <mo>,</mo>
                    </mrow>
                  </mtd>
                  <mtd>
                    <mrow>
                      <mrow>
                        <mrow>
                          <mi>if</mi>
                          <mo>â¢</mo>
                          <mstyle>
                            <mspace width="0.8em" height="0.8ex"> </mspace>
                          </mstyle>
                          <mo>â¢</mo>
                          <mi>Î´</mi>
                        </mrow>
                        <mo>â¥</mo>
                        <mrow>
                          <mn>0</mn>
                          <mo>-</mo>
                          <msub>
                            <mi>T</mi>
                            <mi>a</mi>
                          </msub>
                        </mrow>
                      </mrow>
                      <mo>â©</mo>
                      <mrow>
                        <mi>Î´</mi>
                        <mo>â¤</mo>
                        <msub>
                          <mi>T</mi>
                          <mi>a</mi>
                        </msub>
                      </mrow>
                    </mrow>
                  </mtd>
                </mtr>
                <mtr>
                  <mtd>
                    <mrow>
                      <mi>uturn</mi>
                      <mo>,</mo>
                    </mrow>
                  </mtd>
                  <mtd>
                    <mrow>
                      <mi>otherwise</mi>
                      <mo>,</mo>
                    </mrow>
                  </mtd>
                </mtr>
              </mtable>
            </mrow>
          </mrow>
        </math>
      </maths>
    </div>
    </li> <li> <div id="p-0071" num="0000" class="description-line">where a, b and c are two line segments representing the pedestrian trajectory, Î´ is the normalized angle of direction from (a,b) to (b,c), d<sub>xi </sub>is the Haversine distance between coordinates (x,y), T<sub>d </sub>and T<sub>a </sub>are the threshold (tolerance) from the distance and angle of movement, respectively.</div>
    </li> <li> <para-num num="[0078]"> </para-num> <div id="p-0072" num="0078" class="description-line">Thus, the embodiment combines position information from in-vehicle image processing with the data (i.e. VRU-specific data) from the mobile device for pedestrian movement intention detection. This can be done by finding in the image processing VRU detection results the corresponding mobile device user (i.e., matching image of pedestrian to mobile device data source) for leveraging camera-based positioning when applicable through the <figure-callout id="1" label="aforementioned Step" filenames="US20220161818A1-20220526-D00000.png,US20220161818A1-20220526-D00001.png" state="{{state}}">aforementioned Step</figure-callout> 1 and Step 2 (for only Case 3).</div>
    </li> <heading id="h-0011">Step 4: Autonomous Decision-Making</heading>
    <li> <para-num num="[0079]"> </para-num> <div id="p-0073" num="0079" class="description-line">A method in accordance with an embodiment includes a step of performing an autonomous driving decision for the autonomous vehicle/car. How to support autonomous decision-making using the results from the previous steps can be described as follows: Autonomous decision making can be a final step of the proposed procedure. According to embodiments, this step is built on top of the previously described steps. Here, a simple model using stochastic priority petri nets is used in order to illustrate a procedural method. <figref idrefs="DRAWINGS">FIG. 6</figref> shows a schematic view illustrating a petri net model for supporting autonomous driving decision making according to an embodiment.</div>
    </li> <li> <para-num num="[0080]"> </para-num> <div id="p-0074" num="0080" class="description-line">Specifically, <figref idrefs="DRAWINGS">FIG. 6</figref> shows the model with places (big circles), transitions (rectangles), and the tokens at the initial stage. In <figref idrefs="DRAWINGS">FIG. 6</figref>, Î» denotes the probabilistic variables based on the transition step, whereas the curly-braced numbers indicate the priority labels and numbers without curly braces denote the number of tokens.</div>
    </li> <li> <para-num num="[0081]"> </para-num> <div id="p-0075" num="0081" class="description-line">In the embodiment illustrated by <figref idrefs="DRAWINGS">FIG. 6</figref>, an existence of two types of people (i.e., vulnerable road users) is considered:
</div> </li> <ul> <li id="ul0005-0001" num="0000"> <ul> <li id="ul0006-0001" num="0082">1) mobile device users, meaning the users who downloaded the mobility application in their mobile device, and</li> <li id="ul0006-0002" num="0083">2) people without mobility application who may or may not have mobile devices.</li> </ul> </li> </ul>

    <li> <para-num num="[0084]"> </para-num> <div id="p-0076" num="0084" class="description-line">The initial places on the top (person and autonomous vehicle) are fired in the case of autonomous driving. In this embodiment, three possible cases during driving are considered:
</div> </li> <ul> <li id="ul0007-0001" num="0000"> <ul> <li id="ul0008-0001" num="0085">1) when mobile device user and vehicle camera data both available in the in-vehicle IoT platform,</li> <li id="ul0008-0002" num="0086">2) only mobile device data is available,</li> <li id="ul0008-0003" num="0087">3) only vehicle camera data is available.</li> </ul> </li> </ul>

    <li> <para-num num="[0088]"> </para-num> <div id="p-0077" num="0088" class="description-line">For cases 1) and 3), a pre-trained world model is used to create a list of VRUs and classify them (i.e., pedestrian or cyclist). For case 1), the found VRUs are also matched with the mobile device data. The outputs of the pre-trained model are given for assessing the safety (the bottom-left place).</div>
    </li> <li> <para-num num="[0089]"> </para-num> <div id="p-0078" num="0089" class="description-line">For case 2), the distance is calculated and given to safety assessment using vehicle and person location data. For case 1), the pre-trained model is used to probabilistically predict the transport mode. In the case of pedestrian mode, the pre-trained model for pedestrian movement intentions is used to predict. This input is also given to the safety assessment. Other than the shown inputs, other vehicle- or person-related data can also be used by the autonomous driving decision making to decide based on a set of final actions (illustrated bottom-right of <figref idrefs="DRAWINGS">FIG. 6</figref>). For simplicity, three probabilistic actions for safety are defined:
</div> </li> <ul> <li id="ul0009-0001" num="0000"> <ul> <li id="ul0010-0001" num="0090">1) keeping the same pace,</li> <li id="ul0010-0002" num="0091">2) slowing down,</li> <li id="ul0010-0003" num="0092">3) breaking.</li> </ul> </li> </ul>

    <li> <para-num num="[0093]"> </para-num> <div id="p-0079" num="0093" class="description-line">An extended model might be applied for more complex behaviors.</div>
    </li> <li> <para-num num="[0094]"> </para-num> <div id="p-0080" num="0094" class="description-line">Finally, <figref idrefs="DRAWINGS">FIG. 7</figref> shows a schematic view illustrating an interface where pedestrian and vehicle trajectories are visualized for a particular run by animation of real data in discrete time intervals. Thus, <figref idrefs="DRAWINGS">FIG. 7</figref> illustrates the map-view interface for controlled experiments. The short trajectory p on the left side represents the pedestrian. The longer trajectory c on the right side represents the car.</div>
    </li> <li> <para-num num="[0095]"> </para-num> <div id="p-0081" num="0095" class="description-line">With regard to an evaluation of this embodiment, autonomous driving pilot tests have been conducted mainly at a university campus while some tests are conducted at a business campus. The tests are conducted by collaboration of multiple multi-domain research groups. The university campus has a 2-km road network and 30 km/h speed limit for cars. A custom-built autonomous car prototype (Toyota Prius) is used in the tests. The car has a custom mobile ITS-G5 device connected to the in-vehicle IoT platform. Furthermore, two VRUs carry these ITS-G5 devices. The broker in the in-vehicle IoT platform is connected to cloud platforms (oneM2M via MQTT and FIWARE via HTTP) using cellular 4G connection. Integration tests and three pilot tests (each about 1 to 2 weeks-long) are conducted in one-year time period. The data from the pilot tests are collected as rosbag files as well as CSV files. Each software component in the vehicle or the cloud (via the IoT broker) publishes data to ROS in real time. After data collected through controlled experiments, they analyzed to see the performance of the VRU detection as well as the pedestrian intention estimation. As the controlled experiments, 21 experiments (consisting of total 70 70 runs) are conducted where the VRU behavior is predefined, whereas the autonomous driving behaviors are mostly not predefined and the driving is affected by the vehicle sensors or other factors. The controlled experiments includes both autonomous and manual driving modes. Various tools can visualize the experimental data. <figref idrefs="DRAWINGS">FIG. 7</figref> shows the interface where the pedestrian and car trajectories for a particular run by animation of the real data in discrete time intervals.</div>
    </li> <li> <para-num num="[0096]"> </para-num> <div id="p-0082" num="0096" class="description-line">Thus, the embodiment leverages the potential of using IoT technologies (i.e., data sources, platforms) and machine learning for enhancing the autonomous driving in terms of safety and efficiency. It is proposed a method and a system which combines IoT data sources such as measurements of autonomous vehicles&#39; sensors, mobile device users&#39; data and other IoT data sources from Internet such as OpenStreetMap data. The required components of the system includes a mobile device, autonomous car(s), an in-vehicle (edge) IoT platform, and the pedestrian intention-based decision-making software which runs on top of the in-vehicle (edge) IoT platform. Here, the mobile device user is considered as a vulnerable road user who may be a pedestrian in the vicinity of an approaching autonomous car. While the IoT platform receives real-time updates from the IoT data sources, the decision-making is trained via deep neural networks to predict the pedestrians intentions for their next movement decisions using historical data from the custom-developed autonomous car and the data collected from the mobile device mobility application.</div>
    </li> <li> <para-num num="[0097]"> </para-num> <div id="p-0083" num="0097" class="description-line">While subject matter of the present disclosure has been illustrated and described in detail in the drawings and foregoing description, such illustration and description are to be considered illustrative or exemplary and not restrictive. Any statement made herein characterizing the invention is also to be considered illustrative or exemplary and not restrictive as the invention is defined by the claims. It will be understood that changes and modifications may be made, by those of ordinary skill in the art, within the scope of the following claims, which may include any combination of features from different embodiments described above.</div>
    </li> <li> <para-num num="[0098]"> </para-num> <div id="p-0084" num="0098" class="description-line">The terms used in the claims should be construed to have the broadest reasonable interpretation consistent with the foregoing description. For example, the use of the article âaâ or âtheâ in introducing an element should not be interpreted as being exclusive of a plurality of elements. Likewise, the recitation of âorâ should be interpreted as being inclusive, such that the recitation of âA or Bâ is not exclusive of âA and B,â unless it is clear from the context or the foregoing description that only one of A and B is intended. Further, the recitation of âat least one of A, B and Câ should be interpreted as one or more of a group of elements consisting of A, B and C, and should not be interpreted as requiring at least one of each of the listed elements A, B and C, regardless of whether A, B and C are related as categories or otherwise. Moreover, the recitation of âA, B and/or Câ or âat least one of A, B or Câ should be interpreted as including any singular entity from the listed elements, e.g., A, any subset from the listed elements, e.g., A and B, or the entire list of elements A, B and C.</div>
    
  </li> </ul>
  </div>
  </section>

  <section itemprop="claims" itemscope>
    <h2>Claims (<span itemprop="count">15</span>)</h2>
    
    <div itemprop="content" html><div mxw-id="PCLM325638512" lang="EN" load-source="patent-office" class="claims">
    <div class="claim"> <div id="CLM-00001" num="00001" class="claim">
      <div class="claim-text"> <b>1</b>: A method for supporting autonomous driving of an autonomous vehicle, the method comprising:
<div class="claim-text">detecting, by an in-vehicle internet-of-things (IoT) platform of the autonomous vehicle, a vulnerable road user (VRU having a mobile device in a vicinity of the autonomous vehicle, wherein a mobility application runs on the mobile device of the VRU and sends VRU-specific data to the in-vehicle IoT platform of the autonomous vehicle, wherein the VRU is detected based on the VRU-specific data and/or in-vehicle sensor data of the autonomous vehicle;</div> <div class="claim-text">determining, by the in-vehicle IoT platform, a movement intention prediction for the VRU based on the VRU-specific data provided by the mobile device, wherein the movement intention prediction is computed by use of a machine learning model, wherein the VRU-specific data of the mobile device are provided as input data for the machine learning model; and</div> <div class="claim-text">performing, by the in-vehicle IoT platform, an autonomous driving decision for the autonomous vehicle based on the movement intention prediction.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00002" num="00002" class="claim">
      <div class="claim-text"> <b>2</b>: The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein upon the detecting of the VRU and prior to the determining of the movement intention prediction, the method further comprises:
<div class="claim-text">determining a transportation mode of the VRU using a machine learning process, wherein the machine learning process includes computing the transportation mode of the VRU by use of a weak supervision-based machine learning model.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00003" num="00003" class="claim">
      <div class="claim-text"> <b>3</b>: The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein video processing is performed based on image data gathered by a sensor device of the autonomous vehicle in order to detect the VRU and/or to determine the transportation mode of the VRU.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00004" num="00004" class="claim">
      <div class="claim-text"> <b>4</b>: The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the VRU-specific data include sensor data that are collected by one or more sensors of the mobile device of the VRU.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00005" num="00005" class="claim">
      <div class="claim-text"> <b>5</b>: The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the VRU-specific data include position data of the VRU, heading angle information of the VRU, and/or speed information of the VRU.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00006" num="00006" class="claim">
      <div class="claim-text"> <b>6</b>: The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the VRU-specific data include a trajectory of the VRU.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00007" num="00007" class="claim">
      <div class="claim-text"> <b>7</b>: The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the in-vehicle sensor data include sensor data that are gathered by one or more sensors of the autonomous vehicle.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00008" num="00008" class="claim">
      <div class="claim-text"> <b>8</b>: The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the input data for the machine learning model further include in-vehicle sensor data of the autonomous vehicle for the VRU.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00009" num="00009" class="claim">
      <div class="claim-text"> <b>9</b>: The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the input data for the machine learning model further include additional data from one or more IoT data sources.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00010" num="00010" class="claim">
      <div class="claim-text"> <b>10</b>: The method according to <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein the additional data include map data in order to learn from map features.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00011" num="00011" class="claim">
      <div class="claim-text"> <b>11</b>: The method according to <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein the additional data include internet service data from one or more internet services, wherein the internet service data include information on weather conditions, traffic lights, live events, and/or traffic situations, in an environment of the vicinity of the autonomous vehicle.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00012" num="00012" class="claim">
      <div class="claim-text"> <b>12</b>: The method according to <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein the additional data include information on event schedules of the VRU.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00013" num="00013" class="claim">
      <div class="claim-text"> <b>13</b>: The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the movement intention prediction represents a user action that is expected to be performed next by the VRU.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00014" num="00014" class="claim">
      <div class="claim-text"> <b>14</b>: The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein a set of user actions is defined for the movement intention prediction that is determinable by the machine learning model, wherein the set of actions comprises waiting, walking straight, turning left, turning right and/or turning back.</div>
    </div>
    </div> <div class="claim"> <div id="CLM-00015" num="00015" class="claim">
      <div class="claim-text"> <b>15</b>: A system for supporting autonomous driving of an autonomous vehicle, the system comprising:
<div class="claim-text">an in-vehicle internet-of-things (IoT) platform implemented in the autonomous vehicle and a mobility application running on a mobile device of a vulnerable road user (VRU),</div> <div class="claim-text">wherein the mobility application running on the mobile device of the VRU is configured to send VRU-specific data to the in-vehicle IoT platform of the autonomous vehicle,</div> <div class="claim-text">wherein the in-vehicle IoT platform of the autonomous vehicle is configured to detect the VRU having the mobile device in a vicinity of the autonomous vehicle, wherein the VRU is detected based on the VRU-specific data and/or in-vehicle sensor data of the autonomous vehicle,</div> <div class="claim-text">wherein the in-vehicle IoT platform is further configured to determine a movement intention prediction for the VRU based on the VRU-specific data provided by the mobile device, wherein the movement intention prediction is computed by use of a machine learning model, wherein the VRU-specific data of the mobile device are provided as input data for the machine learning model, and</div> <div class="claim-text">wherein the in-vehicle IoT platform is configured to perform an autonomous driving decision for the autonomous vehicle based on the movement intention prediction.</div> </div>
    </div>
  </div> </div>
  </div>
  </section>

  <section itemprop="application" itemscope>

    <section itemprop="metadata" itemscope>
      <span itemprop="applicationNumber">US17/599,595</span>
      <span itemprop="priorityDate">2019-04-05</span>
      <span itemprop="filingDate">2019-12-06</span>
      <span itemprop="title">Method and system for supporting autonomous driving of an autonomous vehicle 
       </span>
      <span itemprop="ifiStatus">Pending</span>
      
      <a href="/patent/US20220161818A1/en">
        <span itemprop="representativePublication">US20220161818A1</span>
        (<span itemprop="primaryLanguage">en</span>)
      </a>
    </section>

    

    <h2>Applications Claiming Priority (3)</h2>
    <table>
      <thead>
        <tr>
          <th>Application Number</th>
          <th>Priority Date</th>
          <th>Filing Date</th>
          <th>Title</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="appsClaimingPriority" itemscope repeat>
          <td>
            <span itemprop="applicationNumber">EP19167609</span>
            
          </td>
          <td itemprop="priorityDate"></td>
          <td itemprop="filingDate">2019-04-05</td>
          <td itemprop="title"></td>
        </tr>
        <tr itemprop="appsClaimingPriority" itemscope repeat>
          <td>
            <span itemprop="applicationNumber">EP19167609.7</span>
            
          </td>
          <td itemprop="priorityDate"></td>
          <td itemprop="filingDate">2019-04-05</td>
          <td itemprop="title"></td>
        </tr>
        <tr itemprop="appsClaimingPriority" itemscope repeat>
          <td>
            <span itemprop="applicationNumber">PCT/EP2019/084044</span>
            <a href="/patent/WO2020200502A1/en">
              <span itemprop="representativePublication">WO2020200502A1</span>
                (<span itemprop="primaryLanguage">en</span>)
            </a>
          </td>
          <td itemprop="priorityDate">2019-04-05</td>
          <td itemprop="filingDate">2019-12-06</td>
          <td itemprop="title">Method and system for supporting autonomous driving of an autonomous vehicle 
       </td>
        </tr>
      </tbody>
    </table>

    

    

    <h2>Publications (1)</h2>
    <table>
      <thead>
        <tr>
          <th>Publication Number</th>
          <th>Publication Date</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="pubs" itemscope repeat>
          <td>
            <span itemprop="publicationNumber">US20220161818A1</span>
            
            <span itemprop="thisPatent">true</span>
            <a href="/patent/US20220161818A1/en">
              US20220161818A1
              (<span itemprop="primaryLanguage">en</span>)
            </a>
          </td>
          <td itemprop="publicationDate">2022-05-26</td>
        </tr>
      </tbody>
    </table>

  </section>

  <section itemprop="family" itemscope>
    <h1>Family</h1>
    <h2>ID=67437199</h2>

    <h2>Family Applications (1)</h2>
    <table>
      <thead>
        <tr>
          <th>Application Number</th>
          <th>Title</th>
          <th>Priority Date</th>
          <th>Filing Date</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="applications" itemscope repeat>
          <td>
            <span itemprop="applicationNumber">US17/599,595</span>
            <span itemprop="ifiStatus">Pending</span>
            
            <a href="/patent/US20220161818A1/en">
              <span itemprop="representativePublication">US20220161818A1</span>
                (<span itemprop="primaryLanguage">en</span>)
            </a>
          </td>
          <td itemprop="priorityDate">2019-04-05</td>
          <td itemprop="filingDate">2019-12-06</td>
          <td itemprop="title">Method and system for supporting autonomous driving of an autonomous vehicle 
       </td>
        </tr>
      </tbody>
    </table>

    

    

    <h2>Country Status (3)</h2>
    <table>
      <thead>
        <tr>
          <th>Country</th>
          <th>Link</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="countryStatus" itemscope repeat>
          <td>
            <span itemprop="countryCode">US</span>
            (<span itemprop="num">1</span>)
            <meta itemprop="thisCountry" content="true">
          </td>
          <td>
            <a href="/patent/US20220161818A1/en">
              <span itemprop="representativePublication">US20220161818A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
          </td>
        </tr>
        <tr itemprop="countryStatus" itemscope repeat>
          <td>
            <span itemprop="countryCode">EP</span>
            (<span itemprop="num">1</span>)
            
          </td>
          <td>
            <a href="/patent/EP3948821A1/en">
              <span itemprop="representativePublication">EP3948821A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
          </td>
        </tr>
        <tr itemprop="countryStatus" itemscope repeat>
          <td>
            <span itemprop="countryCode">WO</span>
            (<span itemprop="num">1</span>)
            
          </td>
          <td>
            <a href="/patent/WO2020200502A1/en">
              <span itemprop="representativePublication">WO2020200502A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
          </td>
        </tr>
      </tbody>
    </table>

    <h2>Cited By (3)</h2>
    <table>
      <caption>* Cited by examiner, â  Cited by third party</caption>
      <thead>
        <tr>
          <th>Publication number</th>
          <th>Priority date</th>
          <th>Publication date</th>
          <th>Assignee</th>
          <th>Title</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="forwardReferencesOrig" itemscope repeat>
          <td>
            <a href="/patent/US20220281485A1/en">
              <span itemprop="publicationNumber">US20220281485A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2021-03-08</td>
          <td itemprop="publicationDate">2022-09-08</td>
          <td><span itemprop="assigneeOriginal">Toyota Jidosha Kabushiki Kaisha</span></td>
          <td itemprop="title">Control apparatus, system, vehicle, and control method 
       </td>
        </tr>
        <tr itemprop="forwardReferencesOrig" itemscope repeat>
          <td>
            <a href="/patent/US11506797B1/en">
              <span itemprop="publicationNumber">US11506797B1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2021-11-09</td>
          <td itemprop="publicationDate">2022-11-22</td>
          <td><span itemprop="assigneeOriginal">Msrs Llc</span></td>
          <td itemprop="title">Method, apparatus, and computer readable medium for a multi-source reckoning system 
       </td>
        </tr>
        <tr itemprop="forwardReferencesOrig" itemscope repeat>
          <td>
            <a href="/patent/US20230043474A1/en">
              <span itemprop="publicationNumber">US20230043474A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2021-08-05</td>
          <td itemprop="publicationDate">2023-02-09</td>
          <td><span itemprop="assigneeOriginal">Argo AI, LLC</span></td>
          <td itemprop="title">Systems and Methods for Prediction of a Jaywalker Trajectory Through an Intersection 
       </td>
        </tr>
      </tbody>
    </table>

    <h2>Families Citing this family (2)</h2>
    <table>
      <caption>* Cited by examiner, â  Cited by third party</caption>
      <thead>
        <tr>
          <th>Publication number</th>
          <th>Priority date</th>
          <th>Publication date</th>
          <th>Assignee</th>
          <th>Title</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="forwardReferencesFamily" itemscope repeat>
          <td>
            <a href="/patent/CN113029154B/en">
              <span itemprop="publicationNumber">CN113029154B</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2021-04-01</td>
          <td itemprop="publicationDate">2022-07-12</td>
          <td><span itemprop="assigneeOriginal">åäº¬æ·±ç¿åèç§ææéè´£ä»»å¬å¸</span></td>
          <td itemprop="title">Navigation method and device for blind people 
       </td>
        </tr>
        <tr itemprop="forwardReferencesFamily" itemscope repeat>
          <td>
            <a href="/patent/CN113420707B/en">
              <span itemprop="publicationNumber">CN113420707B</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2021-07-05</td>
          <td itemprop="publicationDate">2022-07-15</td>
          <td><span itemprop="assigneeOriginal">ç¥æçµå­ææ¯è¡ä»½æéå¬å¸</span></td>
          <td itemprop="title">Video target detection method based on weak supervised learning 
       </td>
        </tr>
      </tbody>
    </table>

    <h2>Citations (7)</h2>
    <table>
      <caption>* Cited by examiner, â  Cited by third party</caption>
      <thead>
        <tr>
          <th>Publication number</th>
          <th>Priority date</th>
          <th>Publication date</th>
          <th>Assignee</th>
          <th>Title</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="backwardReferencesOrig" itemscope repeat>
          <td>
            <a href="/patent/US20050073438A1/en">
              <span itemprop="publicationNumber">US20050073438A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2003-09-23</td>
          <td itemprop="publicationDate">2005-04-07</td>
          <td>
            <span itemprop="assigneeOriginal">Rodgers Charles E.</span>
          </td>
          <td itemprop="title">System and method for providing pedestrian alerts 
       </td>
        </tr>
        <tr itemprop="backwardReferencesOrig" itemscope repeat>
          <td>
            <a href="/patent/US20180136651A1/en">
              <span itemprop="publicationNumber">US20180136651A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2015-11-04</td>
          <td itemprop="publicationDate">2018-05-17</td>
          <td>
            <span itemprop="assigneeOriginal">Zoox, Inc.</span>
          </td>
          <td itemprop="title">Teleoperation system and method for trajectory modification of autonomous vehicles 
       </td>
        </tr>
        <tr itemprop="backwardReferencesOrig" itemscope repeat>
          <td>
            <a href="/patent/US20190039570A1/en">
              <span itemprop="publicationNumber">US20190039570A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2016-02-04</td>
          <td itemprop="publicationDate">2019-02-07</td>
          <td>
            <span itemprop="assigneeOriginal">Apple Inc.</span>
          </td>
          <td itemprop="title">System and method for vehicle authorization 
       </td>
        </tr>
        <tr itemprop="backwardReferencesOrig" itemscope repeat>
          <td>
            <a href="/patent/US20190171988A1/en">
              <span itemprop="publicationNumber">US20190171988A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2017-12-06</td>
          <td itemprop="publicationDate">2019-06-06</td>
          <td>
            <span itemprop="assigneeOriginal">International Business Machines Corporation</span>
          </td>
          <td itemprop="title">Cognitive ride scheduling 
       </td>
        </tr>
        <tr itemprop="backwardReferencesOrig" itemscope repeat>
          <td>
            <a href="/patent/US20200026283A1/en">
              <span itemprop="publicationNumber">US20200026283A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2016-09-21</td>
          <td itemprop="publicationDate">2020-01-23</td>
          <td>
            <span itemprop="assigneeOriginal">Oxford University Innovation Limited</span>
          </td>
          <td itemprop="title">Autonomous route determination 
     </td>
        </tr>
        <tr itemprop="backwardReferencesOrig" itemscope repeat>
          <td>
            <a href="/patent/US20200241545A1/en">
              <span itemprop="publicationNumber">US20200241545A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2019-01-30</td>
          <td itemprop="publicationDate">2020-07-30</td>
          <td>
            <span itemprop="assigneeOriginal">Perceptive Automata, Inc.</span>
          </td>
          <td itemprop="title">Automatic braking of autonomous vehicles using machine learning based prediction of behavior of a traffic entity 
       </td>
        </tr>
        <tr itemprop="backwardReferencesOrig" itemscope repeat>
          <td>
            <a href="/patent/US11119477B1/en">
              <span itemprop="publicationNumber">US11119477B1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2016-01-22</td>
          <td itemprop="publicationDate">2021-09-14</td>
          <td>
            <span itemprop="assigneeOriginal">State Farm Mutual Automobile Insurance Company</span>
          </td>
          <td itemprop="title">Anomalous condition detection and response for autonomous vehicles 
       </td>
        </tr>
      </tbody>
    </table>

    <h2>Family Cites Families (1)</h2>
    <table>
      <caption>* Cited by examiner, â  Cited by third party</caption>
      <thead>
        <tr>
          <th>Publication number</th>
          <th>Priority date</th>
          <th>Publication date</th>
          <th>Assignee</th>
          <th>Title</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="backwardReferencesFamily" itemscope repeat>
          <td>
            <a href="/patent/US20180090005A1/en">
              <span itemprop="publicationNumber">US20180090005A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2016-09-27</td>
          <td itemprop="publicationDate">2018-03-29</td>
          <td><span itemprop="assigneeOriginal">GM Global Technology Operations LLC</span></td>
          <td itemprop="title">Method And Apparatus For Vulnerable Road User Incidence Avoidance 
     </td>
        </tr>
      </tbody>
    </table>

    <ul>
      <li itemprop="applicationsByYear" itemscope repeat>
        <span itemprop="year">2019</span>
        <ul>
          <li itemprop="application" itemscope repeat>
            <span itemprop="filingDate">2019-12-06</span>
            <span itemprop="countryCode">US</span>
            <span itemprop="applicationNumber">US17/599,595</span>
            <a href="/patent/US20220161818A1/en"><span itemprop="documentId">patent/US20220161818A1/en</span></a>
            <span itemprop="legalStatusCat">active</span>
            <span itemprop="legalStatus">Pending</span>
            <span itemprop="thisApp" content="true" bool></span>
          </li>
          <li itemprop="application" itemscope repeat>
            <span itemprop="filingDate">2019-12-06</span>
            <span itemprop="countryCode">EP</span>
            <span itemprop="applicationNumber">EP19828969.6A</span>
            <a href="/patent/EP3948821A1/en"><span itemprop="documentId">patent/EP3948821A1/en</span></a>
            <span itemprop="legalStatusCat">active</span>
            <span itemprop="legalStatus">Pending</span>
            
          </li>
          <li itemprop="application" itemscope repeat>
            <span itemprop="filingDate">2019-12-06</span>
            <span itemprop="countryCode">WO</span>
            <span itemprop="applicationNumber">PCT/EP2019/084044</span>
            <a href="/patent/WO2020200502A1/en"><span itemprop="documentId">patent/WO2020200502A1/en</span></a>
            <span itemprop="legalStatusCat">unknown</span>
            <span itemprop="legalStatus"></span>
            
          </li>
        </ul>
      </li>
    </ul>

    </section>

  <section>
    <h2>Patent Citations (7)</h2>
    <table>
      <caption>* Cited by examiner, â  Cited by third party</caption>
      <thead>
        <tr>
          <th>Publication number</th>
          <th>Priority date</th>
          <th>Publication date</th>
          <th>Assignee</th>
          <th>Title</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="backwardReferences" itemscope repeat>
          <td>
            <a href="/patent/US20050073438A1/en">
              <span itemprop="publicationNumber">US20050073438A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2003-09-23</td>
          <td itemprop="publicationDate">2005-04-07</td>
          <td><span itemprop="assigneeOriginal">Rodgers Charles E.</span></td>
          <td itemprop="title">System and method for providing pedestrian alerts 
       </td>
        </tr>
        <tr itemprop="backwardReferences" itemscope repeat>
          <td>
            <a href="/patent/US20180136651A1/en">
              <span itemprop="publicationNumber">US20180136651A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2015-11-04</td>
          <td itemprop="publicationDate">2018-05-17</td>
          <td><span itemprop="assigneeOriginal">Zoox, Inc.</span></td>
          <td itemprop="title">Teleoperation system and method for trajectory modification of autonomous vehicles 
       </td>
        </tr>
        <tr itemprop="backwardReferences" itemscope repeat>
          <td>
            <a href="/patent/US11119477B1/en">
              <span itemprop="publicationNumber">US11119477B1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2016-01-22</td>
          <td itemprop="publicationDate">2021-09-14</td>
          <td><span itemprop="assigneeOriginal">State Farm Mutual Automobile Insurance Company</span></td>
          <td itemprop="title">Anomalous condition detection and response for autonomous vehicles 
       </td>
        </tr>
        <tr itemprop="backwardReferences" itemscope repeat>
          <td>
            <a href="/patent/US20190039570A1/en">
              <span itemprop="publicationNumber">US20190039570A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2016-02-04</td>
          <td itemprop="publicationDate">2019-02-07</td>
          <td><span itemprop="assigneeOriginal">Apple Inc.</span></td>
          <td itemprop="title">System and method for vehicle authorization 
       </td>
        </tr>
        <tr itemprop="backwardReferences" itemscope repeat>
          <td>
            <a href="/patent/US20200026283A1/en">
              <span itemprop="publicationNumber">US20200026283A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2016-09-21</td>
          <td itemprop="publicationDate">2020-01-23</td>
          <td><span itemprop="assigneeOriginal">Oxford University Innovation Limited</span></td>
          <td itemprop="title">Autonomous route determination 
     </td>
        </tr>
        <tr itemprop="backwardReferences" itemscope repeat>
          <td>
            <a href="/patent/US20190171988A1/en">
              <span itemprop="publicationNumber">US20190171988A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2017-12-06</td>
          <td itemprop="publicationDate">2019-06-06</td>
          <td><span itemprop="assigneeOriginal">International Business Machines Corporation</span></td>
          <td itemprop="title">Cognitive ride scheduling 
       </td>
        </tr>
        <tr itemprop="backwardReferences" itemscope repeat>
          <td>
            <a href="/patent/US20200241545A1/en">
              <span itemprop="publicationNumber">US20200241545A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2019-01-30</td>
          <td itemprop="publicationDate">2020-07-30</td>
          <td><span itemprop="assigneeOriginal">Perceptive Automata, Inc.</span></td>
          <td itemprop="title">Automatic braking of autonomous vehicles using machine learning based prediction of behavior of a traffic entity 
       </td>
        </tr>
      </tbody>
    </table>
  </section>

  

  <h2>Cited By (4)</h2>
  <table>
    <caption>* Cited by examiner, â  Cited by third party</caption>
    <thead>
      <tr>
        <th>Publication number</th>
        <th>Priority date</th>
        <th>Publication date</th>
        <th>Assignee</th>
        <th>Title</th>
      </tr>
    </thead>
    <tbody>
      <tr itemprop="forwardReferences" itemscope repeat>
        <td>
          <a href="/patent/US20220281485A1/en">
            <span itemprop="publicationNumber">US20220281485A1</span>
            (<span itemprop="primaryLanguage">en</span>)
          </a>
          <span itemprop="examinerCited">*</span>
          
        </td>
        <td itemprop="priorityDate">2021-03-08</td>
        <td itemprop="publicationDate">2022-09-08</td>
        <td><span itemprop="assigneeOriginal">Toyota Jidosha Kabushiki Kaisha</span></td>
        <td itemprop="title">Control apparatus, system, vehicle, and control method 
       </td>
      </tr>
      <tr itemprop="forwardReferences" itemscope repeat>
        <td>
          <a href="/patent/US20230043474A1/en">
            <span itemprop="publicationNumber">US20230043474A1</span>
            (<span itemprop="primaryLanguage">en</span>)
          </a>
          <span itemprop="examinerCited">*</span>
          
        </td>
        <td itemprop="priorityDate">2021-08-05</td>
        <td itemprop="publicationDate">2023-02-09</td>
        <td><span itemprop="assigneeOriginal">Argo AI, LLC</span></td>
        <td itemprop="title">Systems and Methods for Prediction of a Jaywalker Trajectory Through an Intersection 
       </td>
      </tr>
      <tr itemprop="forwardReferences" itemscope repeat>
        <td>
          <a href="/patent/US11904906B2/en">
            <span itemprop="publicationNumber">US11904906B2</span>
            (<span itemprop="primaryLanguage">en</span>)
          </a>
          <span itemprop="examinerCited">*</span>
          
        </td>
        <td itemprop="priorityDate">2021-08-05</td>
        <td itemprop="publicationDate">2024-02-20</td>
        <td><span itemprop="assigneeOriginal">Argo AI, LLC</span></td>
        <td itemprop="title">Systems and methods for prediction of a jaywalker trajectory through an intersection 
       </td>
      </tr>
      <tr itemprop="forwardReferences" itemscope repeat>
        <td>
          <a href="/patent/US11506797B1/en">
            <span itemprop="publicationNumber">US11506797B1</span>
            (<span itemprop="primaryLanguage">en</span>)
          </a>
          <span itemprop="examinerCited">*</span>
          
        </td>
        <td itemprop="priorityDate">2021-11-09</td>
        <td itemprop="publicationDate">2022-11-22</td>
        <td><span itemprop="assigneeOriginal">Msrs Llc</span></td>
        <td itemprop="title">Method, apparatus, and computer readable medium for a multi-source reckoning system 
       </td>
      </tr>
    </tbody>
  </table>

  <section>
    <h2>Also Published As</h2>
    <table>
      <thead>
        <tr>
          <th>Publication number</th>
          <th>Publication date</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="docdbFamily" itemscope repeat>
          <td>
            <a href="/patent/EP3948821A1/en">
              <span itemprop="publicationNumber">EP3948821A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
          </td>
          <td itemprop="publicationDate">2022-02-09</td>
        </tr>
        <tr itemprop="docdbFamily" itemscope repeat>
          <td>
            <a href="/patent/WO2020200502A1/en">
              <span itemprop="publicationNumber">WO2020200502A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
          </td>
          <td itemprop="publicationDate">2020-10-08</td>
        </tr>
      </tbody>
    </table>
  </section>

  <section>
    <h2>Similar Documents</h2>
    <table>
      <thead>
        <tr>
          <th>Publication</th>
          <th>Publication Date</th>
          <th>Title</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/EP3726439B1/en">
                <span itemprop="publicationNumber">EP3726439B1</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2023-03-01">2023-03-01</time>
            
            
          </td>
          <td itemprop="title">Edge learning 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/US20220161818A1/en">
                <span itemprop="publicationNumber">US20220161818A1</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2022-05-26">2022-05-26</time>
            
            
          </td>
          <td itemprop="title">Method and system for supporting autonomous driving of an autonomous vehicle 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/EP3757789A1/en">
                <span itemprop="publicationNumber">EP3757789A1</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2020-12-30">2020-12-30</time>
            
            
          </td>
          <td itemprop="title">Managed edge learning in heterogeneous environments 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/RU2734744C1/en">
                <span itemprop="publicationNumber">RU2734744C1</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2020-10-22">2020-10-22</time>
            
            
          </td>
          <td itemprop="title">Operational control of autonomous vehicle, including operation of model instance of partially observed markov process of decision making 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/US11537134B1/en">
                <span itemprop="publicationNumber">US11537134B1</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2022-12-27">2022-12-27</time>
            
            
          </td>
          <td itemprop="title">Generating environmental input encoding for training neural networks 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            
            <meta itemprop="isScholar" content="true">
              <meta itemprop="scholarID" content="3327936227671438974">
              <a href="/scholar/3327936227671438974"><span itemprop="scholarAuthors">Aoude et al.</span></a>
            
          </td>
          <td>
            
            <time itemprop="publicationDate" datetime="2010">2010</time>
            
          </td>
          <td itemprop="title">Threat assessment design for driver assistance system at intersections</td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/RU2734732C1/en">
                <span itemprop="publicationNumber">RU2734732C1</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2020-10-22">2020-10-22</time>
            
            
          </td>
          <td itemprop="title">Traffic network blocking tracking during operational control of autonomous vehicle 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            
            <meta itemprop="isScholar" content="true">
              <meta itemprop="scholarID" content="4250356882174188923">
              <a href="/scholar/4250356882174188923"><span itemprop="scholarAuthors">Kim et al.</span></a>
            
          </td>
          <td>
            
            <time itemprop="publicationDate" datetime="2017">2017</time>
            
          </td>
          <td itemprop="title">Autonomous campus mobility services using driverless taxi</td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/CN109814520A/en">
                <span itemprop="publicationNumber">CN109814520A</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2019-05-28">2019-05-28</time>
            
            
          </td>
          <td itemprop="title">System and method for determining the security incident of autonomous vehicle 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            
            <meta itemprop="isScholar" content="true">
              <meta itemprop="scholarID" content="16069845053140467750">
              <a href="/scholar/16069845053140467750"><span itemprop="scholarAuthors">Kuru et al.</span></a>
            
          </td>
          <td>
            
            <time itemprop="publicationDate" datetime="2020">2020</time>
            
          </td>
          <td itemprop="title">A framework for the synergistic integration of fully autonomous ground vehicles with smart city</td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/US20220261601A1/en">
                <span itemprop="publicationNumber">US20220261601A1</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2022-08-18">2022-08-18</time>
            
            
          </td>
          <td itemprop="title">Multiple Stage Image Based Object Detection and Recognition 
     </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            
            <meta itemprop="isScholar" content="true">
              <meta itemprop="scholarID" content="717221292723784218">
              <a href="/scholar/717221292723784218"><span itemprop="scholarAuthors">Chandra Shit</span></a>
            
          </td>
          <td>
            
            <time itemprop="publicationDate" datetime="2020">2020</time>
            
          </td>
          <td itemprop="title">Crowd intelligence for sustainable futuristic intelligent transportation system: a review</td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/RU2759975C1/en">
                <span itemprop="publicationNumber">RU2759975C1</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2021-11-19">2021-11-19</time>
            
            
          </td>
          <td itemprop="title">Operational control of autonomous vehicle with visual salence perception control 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/US20200159213A1/en">
                <span itemprop="publicationNumber">US20200159213A1</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2020-05-21">2020-05-21</time>
            
            
          </td>
          <td itemprop="title">Introspective Autonomous Vehicle Operational Management 
     </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            
            <meta itemprop="isScholar" content="true">
              <meta itemprop="scholarID" content="17484691731960861723">
              <a href="/scholar/17484691731960861723"><span itemprop="scholarAuthors">Shimosaka et al.</span></a>
            
          </td>
          <td>
            
            <time itemprop="publicationDate" datetime="2014">2014</time>
            
          </td>
          <td itemprop="title">Modeling risk anticipation and defensive driving on residential roads with inverse reinforcement learning</td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            
            <meta itemprop="isScholar" content="true">
              <meta itemprop="scholarID" content="18219858924756292555">
              <a href="/scholar/18219858924756292555"><span itemprop="scholarAuthors">Buchholz et al.</span></a>
            
          </td>
          <td>
            
            <time itemprop="publicationDate" datetime="2021">2021</time>
            
          </td>
          <td itemprop="title">Handling occlusions in automated driving using a multiaccess edge computing server-based environment model from infrastructure sensors</td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/GB2562049A/en">
                <span itemprop="publicationNumber">GB2562049A</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2018-11-07">2018-11-07</time>
            
            
          </td>
          <td itemprop="title">Improved pedestrian prediction by using enhanced map data in automated vehicles 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/US20230154332A1/en">
                <span itemprop="publicationNumber">US20230154332A1</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2023-05-18">2023-05-18</time>
            
            
          </td>
          <td itemprop="title">Predicting traffic violation hotspots using map features and sensors data 
     </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            
            <meta itemprop="isScholar" content="true">
              <meta itemprop="scholarID" content="1727833719614308456">
              <a href="/scholar/1727833719614308456"><span itemprop="scholarAuthors">Liao et al.</span></a>
            
          </td>
          <td>
            
            <time itemprop="publicationDate" datetime="2023">2023</time>
            
          </td>
          <td itemprop="title">Driver digital twin for online prediction of personalized lane change behavior</td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            
            <meta itemprop="isScholar" content="true">
              <meta itemprop="scholarID" content="6080473393158366752">
              <a href="/scholar/6080473393158366752"><span itemprop="scholarAuthors">Dabiri et al.</span></a>
            
          </td>
          <td>
            
            <time itemprop="publicationDate" datetime="2018">2018</time>
            
          </td>
          <td itemprop="title">Transport-domain applications of widely used data sources in the smart transportation: A survey</td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/US20230033672A1/en">
                <span itemprop="publicationNumber">US20230033672A1</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2023-02-02">2023-02-02</time>
            
            
          </td>
          <td itemprop="title">Determining traffic violation hotspots 
     </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            
            <meta itemprop="isScholar" content="true">
              <meta itemprop="scholarID" content="9440530018406514231">
              <a href="/scholar/9440530018406514231"><span itemprop="scholarAuthors">Jeong</span></a>
            
          </td>
          <td>
            
            <time itemprop="publicationDate" datetime="2021">2021</time>
            
          </td>
          <td itemprop="title">Predictive lane change decision making using bidirectional long shot-term memory for autonomous driving on highways</td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            
            <meta itemprop="isScholar" content="true">
              <meta itemprop="scholarID" content="3561636784616254538">
              <a href="/scholar/3561636784616254538"><span itemprop="scholarAuthors">Zhang et al.</span></a>
            
          </td>
          <td>
            
            <time itemprop="publicationDate" datetime="2021">2021</time>
            
          </td>
          <td itemprop="title">A learning-based method for predicting heterogeneous traffic agent trajectories: Implications for transfer learning</td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            
            <meta itemprop="isScholar" content="true">
              <meta itemprop="scholarID" content="8090789951737415836">
              <a href="/scholar/8090789951737415836"><span itemprop="scholarAuthors">Solmaz et al.</span></a>
            
          </td>
          <td>
            
            <time itemprop="publicationDate" datetime="2019">2019</time>
            
          </td>
          <td itemprop="title">Learn from IoT: pedestrian detection and intention prediction for autonomous driving</td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            
            <meta itemprop="isScholar" content="true">
              <meta itemprop="scholarID" content="11389374170180105602">
              <a href="/scholar/11389374170180105602"><span itemprop="scholarAuthors">de Souza et al.</span></a>
            
          </td>
          <td>
            
            <time itemprop="publicationDate" datetime="2020">2020</time>
            
          </td>
          <td itemprop="title">Enhancing sensing and decision-making of automated driving systems with multi-access edge computing and machine learning</td>
        </tr>
      </tbody>
    </table>
  </section>

  <section>
    <h2>Legal Events</h2>
    <table>
      <thead>
        <tr>
          <th>Date</th>
          <th>Code</th>
          <th>Title</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="legalEvents" itemscope repeat>
          <td><time itemprop="date" datetime="2021-10-12">2021-10-12</time></td>
          <td itemprop="code">AS</td>
          <td itemprop="title">Assignment</td>
          <td>
            <p itemprop="attributes" itemscope repeat>
              <strong itemprop="label">Owner name</strong>:
              <span itemprop="value">NEC LABORATORIES EUROPE GMBH, GERMANY</span>
            </p>
            <p itemprop="attributes" itemscope repeat>
              <strong itemprop="label">Free format text</strong>:
              <span itemprop="value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:SOLMAZ, GURKAN;BERZ, EVERTON LUIS;FUERST, JONATHAN;AND OTHERS;SIGNING DATES FROM 20210901 TO 20210914;REEL/FRAME:057757/0391</span>
            </p>
          </td>
        </tr>
        <tr itemprop="legalEvents" itemscope repeat>
          <td><time itemprop="date" datetime="2022-03-17">2022-03-17</time></td>
          <td itemprop="code">STPP</td>
          <td itemprop="title">Information on status: patent application and granting procedure in general</td>
          <td>
            <p itemprop="attributes" itemscope repeat>
              <strong itemprop="label">Free format text</strong>:
              <span itemprop="value">DOCKETED NEW CASE - READY FOR EXAMINATION</span>
            </p>
          </td>
        </tr>
        <tr itemprop="legalEvents" itemscope repeat>
          <td><time itemprop="date" datetime="2023-11-01">2023-11-01</time></td>
          <td itemprop="code">STPP</td>
          <td itemprop="title">Information on status: patent application and granting procedure in general</td>
          <td>
            <p itemprop="attributes" itemscope repeat>
              <strong itemprop="label">Free format text</strong>:
              <span itemprop="value">NON FINAL ACTION MAILED</span>
            </p>
          </td>
        </tr>
        <tr itemprop="legalEvents" itemscope repeat>
          <td><time itemprop="date" datetime="2024-02-03">2024-02-03</time></td>
          <td itemprop="code">STPP</td>
          <td itemprop="title">Information on status: patent application and granting procedure in general</td>
          <td>
            <p itemprop="attributes" itemscope repeat>
              <strong itemprop="label">Free format text</strong>:
              <span itemprop="value">RESPONSE TO NON-FINAL OFFICE ACTION ENTERED AND FORWARDED TO EXAMINER</span>
            </p>
          </td>
        </tr>
      </tbody>
    </table>
  </section>

</article>

    </search-app>
    <script type="text/javascript" src="//www.gstatic.com/feedback/api.js"></script>
    <script type="text/javascript" src="//www.gstatic.com/feedback/js/help/prod/service/lazy.min.js"></script>
    <script type="text/javascript">
      if (window.help && window.help.service) {
        helpApi = window.help.service.Lazy.create(0, {apiKey: 'AIzaSyDTEI_0tLX4varJ7bwK8aT-eOI5qr3BmyI', locale: 'en-US'});
        window.requestedSurveys = new Set();
        window.requestSurvey = function(triggerId) {
          if (window.requestedSurveys.has(triggerId)) {
            return;
          }
          window.requestedSurveys.add(triggerId);
          helpApi.requestSurvey({
            triggerId: triggerId,
            enableTestingMode: false,
            callback: (requestSurveyCallbackParam) => {
              if (!requestSurveyCallbackParam.surveyData) {
                return;
              }
              helpApi.presentSurvey({
                productData: {
                  productVersion: window.version,
                  customData: {
                    "experiments": "72459301,72474719",
                  },
                },
                surveyData: requestSurveyCallbackParam.surveyData,
                colorScheme: 1,
                customZIndex: 10000,
              });
            }
          });
        };

        window.requestSurvey('YXTwAsvoW0kedxbuTdH0RArc9VhT');
      }
    </script>
    <script src="/sw/null_loader.js"></script>
  </body>
</html>
