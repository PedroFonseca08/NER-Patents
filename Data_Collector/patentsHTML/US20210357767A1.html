<!DOCTYPE html>
<html lang="en">
  <head>
    <title>US20210357767A1 - Automated knowledge infusion for robust and transferable machine learning 
        - Google Patents</title>

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta charset="UTF-8">
    <meta name="referrer" content="origin-when-crossorigin">
    <link rel="canonical" href="https://patents.google.com/patent/US20210357767A1/en">
    <meta name="description" content="
     A method for using knowledge infusion for robust and transferable machine learning models includes receiving a plurality of adaptive and programmable knowledge functions comprising a plurality of strong functions and a plurality of weak functions. A knowledge model is generated based on the plurality of strong functions and the plurality of weak functions. A machine learning model is trained based on the generated knowledge model. 
   
   ">
    <meta name="DC.type" content="patent">
    <meta name="DC.title" content="Automated knowledge infusion for robust and transferable machine learning 
       ">
    <meta name="DC.date" content="2020-09-29" scheme="dateSubmitted">
    <meta name="DC.description" content="
     A method for using knowledge infusion for robust and transferable machine learning models includes receiving a plurality of adaptive and programmable knowledge functions comprising a plurality of strong functions and a plurality of weak functions. A knowledge model is generated based on the plurality of strong functions and the plurality of weak functions. A machine learning model is trained based on the generated knowledge model. 
   
   ">
    <meta name="citation_patent_application_number" content="US:17/035,967">
    <meta name="citation_pdf_url" content="https://patentimages.storage.googleapis.com/0b/58/01/fe1f8b7426916e/US20210357767A1.pdf">
    <meta name="citation_patent_publication_number" content="US:20210357767:A1">
    <meta name="DC.date" content="2021-11-18">
    <meta name="DC.contributor" content="Jonathan Fuerst" scheme="inventor">
    <meta name="DC.contributor" content="Mauricio Fadel Argerich" scheme="inventor">
    <meta name="DC.contributor" content="Bin Cheng" scheme="inventor">
    <meta name="DC.contributor" content="NEC Laboratories Europe GmbH" scheme="assignee">
    <meta name="DC.relation" content="US:20170230410:A1" scheme="references">
    <meta name="DC.relation" content="US:20210279615:A1" scheme="references">
    <meta name="citation_reference" content="Kursuncu, Ugur, Manas Gaur, and Amit Sheth. &#34;Knowledge infused learning (k-il): Towards deep incorporation of knowledge in deep learning.&#34; arXiv preprint arXiv:1912.00512 (2019). (Year: 2019)" scheme="references">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:400,400italic,500,500italic,700">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Product+Sans">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Google+Sans:wght@400;500;700">

    <style>
      body { transition: none; }
    </style>

    <script>
      window.version = 'patent-search.search_20240108_RC01';

      function sendFeedback() {
        userfeedback.api.startFeedback({
          'productId': '713680',
          'bucket': 'patent-search-web',
          'productVersion': window.version,
        });
      }

      window.experiments = {};
      window.experiments.patentCountries = "ae,ag,al,am,ao,ap,ar,at,au,aw,az,ba,bb,bd,be,bf,bg,bh,bj,bn,bo,br,bw,bx,by,bz,ca,cf,cg,ch,ci,cl,cm,cn,co,cr,cs,cu,cy,cz,dd,de,dj,dk,dm,do,dz,ea,ec,ee,eg,em,ep,es,fi,fr,ga,gb,gc,gd,ge,gh,gm,gn,gq,gr,gt,gw,hk,hn,hr,hu,ib,id,ie,il,in,ir,is,it,jo,jp,ke,kg,kh,km,kn,kp,kr,kw,kz,la,lc,li,lk,lr,ls,lt,lu,lv,ly,ma,mc,md,me,mg,mk,ml,mn,mo,mr,mt,mw,mx,my,mz,na,ne,ng,ni,nl,no,nz,oa,om,pa,pe,pg,ph,pl,pt,py,qa,ro,rs,ru,rw,sa,sc,sd,se,sg,si,sk,sl,sm,sn,st,su,sv,sy,sz,td,tg,th,tj,tm,tn,tr,tt,tw,tz,ua,ug,us,uy,uz,vc,ve,vn,wo,yu,za,zm,zw";
      
      
      window.experiments.keywordWizard = true;
      
      
      
      window.experiments.definitions = true;

      window.Polymer = {
        dom: 'shady',
        lazyRegister: true,
      };
    </script>

    <script src="//www.gstatic.com/patent-search/frontend/patent-search.search_20240108_RC01/scs/compiled_dir/webcomponentsjs/webcomponents-lite.min.js"></script>
    <link rel="import" href="//www.gstatic.com/patent-search/frontend/patent-search.search_20240108_RC01/scs/compiled_dir/search-app-vulcanized.html">
  </head>
  <body unresolved>
    <script src="//www.gstatic.com/patent-search/frontend/patent-search.search_20240108_RC01/scs/compiled_dir/search-app-vulcanized.js"></script>
    <search-app>
      
      

      <article class="result" itemscope itemtype="http://schema.org/ScholarlyArticle">
  <h1 itemprop="pageTitle">US20210357767A1 - Automated knowledge infusion for robust and transferable machine learning 
        - Google Patents</h1>
  <span itemprop="title">Automated knowledge infusion for robust and transferable machine learning 
       </span>

  <meta itemprop="type" content="patent">
  <a href="https://patentimages.storage.googleapis.com/0b/58/01/fe1f8b7426916e/US20210357767A1.pdf" itemprop="pdfLink">Download PDF</a>
  <h2>Info</h2>

  <dl>
    <dt>Publication number</dt>
    <dd itemprop="publicationNumber">US20210357767A1</dd>
    <meta itemprop="numberWithoutCodes" content="20210357767">
    <meta itemprop="kindCode" content="A1">
    <meta itemprop="publicationDescription" content="Patent application publication">
    <span>US20210357767A1</span>
    <span>US17/035,967</span>
    <span>US202017035967A</span>
    <span>US2021357767A1</span>
    <span>US 20210357767 A1</span>
    <span>US20210357767 A1</span>
    <span>US 20210357767A1</span>
    <span>  </span>
    <span> </span>
    <span> </span>
    <span>US 202017035967 A</span>
    <span>US202017035967 A</span>
    <span>US 202017035967A</span>
    <span>US 2021357767 A1</span>
    <span>US2021357767 A1</span>
    <span>US 2021357767A1</span>

    <dt>Authority</dt>
    <dd itemprop="countryCode">US</dd>
    <dd itemprop="countryName">United States</dd>

    <dt>Prior art keywords</dt>
    <dd itemprop="priorArtKeywords" repeat>knowledge</dd>
    <dd itemprop="priorArtKeywords" repeat>model</dd>
    <dd itemprop="priorArtKeywords" repeat>machine learning</dd>
    <dd itemprop="priorArtKeywords" repeat>functions</dd>
    <dd itemprop="priorArtKeywords" repeat>learning model</dd>

    <dt>Prior art date</dt>
    <dd><time itemprop="priorArtDate" datetime="2020-05-15">2020-05-15</time></dd>

    <dt>Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)</dt>
    <dd itemprop="legalStatusIfi" itemscope>
      <span itemprop="status">Pending</span>
    </dd>
  </dl>

  <dt>Application number</dt>
  <dd itemprop="applicationNumber">US17/035,967</dd>

  

  

  <dt>Inventor</dt>
  <dd itemprop="inventor" repeat>Jonathan Fuerst</dd>
  <dd itemprop="inventor" repeat>Mauricio Fadel Argerich</dd>
  <dd itemprop="inventor" repeat>Bin Cheng</dd>

  <dt>Current Assignee (The listed assignees may be inaccurate. Google has not performed a legal analysis and makes no representation or warranty as to the accuracy of the list.)</dt>
  <dd itemprop="assigneeCurrent" repeat>
    NEC Laboratories Europe GmbH
  </dd>

  <dt>Original Assignee</dt>
  <dd itemprop="assigneeOriginal" repeat>NEC Laboratories Europe GmbH</dd>

  <dt>Priority date (The priority date is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the date listed.)</dt>
  <dd><time itemprop="priorityDate" datetime="2020-05-15">2020-05-15</time></dd>

  <dt>Filing date</dt>
  <dd><time itemprop="filingDate" datetime="2020-09-29">2020-09-29</time></dd>

  <dt>Publication date</dt>
  <dd><time itemprop="publicationDate" datetime="2021-11-18">2021-11-18</time></dd>

  
  <dd itemprop="events" itemscope repeat>
    <time itemprop="date" datetime="2020-09-29">2020-09-29</time>
    <span itemprop="title">Application filed by NEC Laboratories Europe GmbH</span>
    <span itemprop="type">filed</span>
    <span itemprop="critical" content="true" bool>Critical</span>
    
    
    
    <span itemprop="assigneeSearch">NEC Laboratories Europe GmbH</span>
  </dd>
  <dd itemprop="events" itemscope repeat>
    <time itemprop="date" datetime="2020-10-06">2020-10-06</time>
    <span itemprop="title">Assigned to NEC Laboratories Europe GmbH</span>
    <span itemprop="type">reassignment</span>
    
    
    
    
    <span itemprop="assigneeSearch">NEC Laboratories Europe GmbH</span>
    <span itemprop="description" repeat>ASSIGNMENT OF ASSIGNORS INTEREST (SEE DOCUMENT FOR DETAILS).</span>
    <span itemprop="description" repeat>Assignors: ARGERICH, MAURICIO FADEL, FUERST, JONATHAN, CHENG, BIN</span>
  </dd>
  <dd itemprop="events" itemscope repeat>
    <time itemprop="date" datetime="2021-11-18">2021-11-18</time>
    <span itemprop="title">Publication of US20210357767A1</span>
    <span itemprop="type">publication</span>
    <span itemprop="critical" content="true" bool>Critical</span>
    
    
    <span itemprop="documentId">patent/US20210357767A1/en</span>
    
  </dd>
  <dd itemprop="events" itemscope repeat>
    <time itemprop="date">Status</time>
    <span itemprop="title">Pending</span>
    <span itemprop="type">legal-status</span>
    <span itemprop="critical" content="true" bool>Critical</span>
    <span itemprop="current" content="true" bool>Current</span>
    
    
    
  </dd>

  <h2>Links</h2>
  <ul>
    <li itemprop="links" itemscope repeat>
          <meta itemprop="id" content="usptoLink">
          <a href="https://appft.uspto.gov/netacgi/nph-Parser?Sect1=PTO1&Sect2=HITOFF&p=1&u=/netahtml/PTO/srchnum.html&r=1&f=G&l=50&d=PG01&s1=20210357767.PGNR." itemprop="url" target="_blank"><span itemprop="text">USPTO</span></a>
        </li>
        
        <li itemprop="links" itemscope repeat>
          <meta itemprop="id" content="usptoPatentCenterLink">
          <a href="https://patentcenter.uspto.gov/applications/17035967" itemprop="url" target="_blank"><span itemprop="text">USPTO PatentCenter</span></a>
        </li>
        <li itemprop="links" itemscope repeat>
          <meta itemprop="id" content="usptoAssignmentLink">
          <a href="https://assignment.uspto.gov/patent/index.html#/patent/search/resultFilter?searchInput=20210357767" itemprop="url" target="_blank"><span itemprop="text">USPTO Assignment</span></a>
        </li>

    <li itemprop="links" itemscope repeat>
        <meta itemprop="id" content="espacenetLink">
        <a href="https://worldwide.espacenet.com/publicationDetails/biblio?CC=US&amp;NR=2021357767A1&amp;KC=A1&amp;FT=D" itemprop="url" target="_blank"><span itemprop="text">Espacenet</span></a>
      </li>
      

    

    
      <li itemprop="links" itemscope repeat>
        <meta itemprop="id" content="globalDossierLink">
        <a href="https://globaldossier.uspto.gov/#/result/publication/US/20210357767/1" itemprop="url" target="_blank"><span itemprop="text">Global Dossier</span></a>
      </li>

      

      

      

      <li itemprop="links" itemscope repeat>
        <meta itemprop="id" content="stackexchangeLink">
        <a href="https://patents.stackexchange.com/questions/tagged/US20210357767" itemprop="url"><span itemprop="text">Discuss</span></a>
      </li>
      
  </ul>

  <ul itemprop="concept" itemscope>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000010801</span>
      <span itemprop="name">machine learning</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>title</span>
      <span itemprop="sections" repeat>claims</span>
      <span itemprop="sections" repeat>abstract</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">261</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000001802</span>
      <span itemprop="name">infusion</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>title</span>
      <span itemprop="sections" repeat>claims</span>
      <span itemprop="sections" repeat>abstract</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">84</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000006870</span>
      <span itemprop="name">function</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>claims</span>
      <span itemprop="sections" repeat>abstract</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">252</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000000034</span>
      <span itemprop="name">method</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>claims</span>
      <span itemprop="sections" repeat>abstract</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">120</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000003044</span>
      <span itemprop="name">adaptive effect</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>claims</span>
      <span itemprop="sections" repeat>abstract</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">26</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000012549</span>
      <span itemprop="name">training</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>claims</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">69</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000004927</span>
      <span itemprop="name">fusion</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>claims</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">33</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000013507</span>
      <span itemprop="name">mapping</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>claims</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">4</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000004806</span>
      <span itemprop="name">packaging method and process</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>claims</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">2</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">239000003795</span>
      <span itemprop="name">chemical substances by application</span>
      <span itemprop="domain">Substances</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">56</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000032258</span>
      <span itemprop="name">transport</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">33</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000009471</span>
      <span itemprop="name">action</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">23</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000007726</span>
      <span itemprop="name">management method</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">21</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000013459</span>
      <span itemprop="name">approach</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">20</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000008569</span>
      <span itemprop="name">process</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">18</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000002787</span>
      <span itemprop="name">reinforcement</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">18</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000001514</span>
      <span itemprop="name">detection method</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">15</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000013526</span>
      <span itemprop="name">transfer learning</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">12</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000002372</span>
      <span itemprop="name">labelling</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">11</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000012545</span>
      <span itemprop="name">processing</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">11</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000013528</span>
      <span itemprop="name">artificial neural network</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">9</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000004364</span>
      <span itemprop="name">calculation method</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">9</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000008901</span>
      <span itemprop="name">benefit</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">8</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000012546</span>
      <span itemprop="name">transfer</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">8</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000006399</span>
      <span itemprop="name">behavior</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">5</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000009826</span>
      <span itemprop="name">distribution</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">5</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000000694</span>
      <span itemprop="name">effects</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">5</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000007246</span>
      <span itemprop="name">mechanism</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">5</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000007637</span>
      <span itemprop="name">random forest analysis</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">5</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000009423</span>
      <span itemprop="name">ventilation</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">5</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">CURLTUGMZLYLDI-UHFFFAOYSA-N</span>
      <span itemprop="name">Carbon dioxide</span>
      <span itemprop="domain">Chemical compound</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles">O=C=O</span>
      <span itemprop="inchi_key">CURLTUGMZLYLDI-UHFFFAOYSA-N</span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">4</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">235000000332</span>
      <span itemprop="name">black box</span>
      <span itemprop="domain">Nutrition</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">4</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000005265</span>
      <span itemprop="name">energy consumption</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">4</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000001932</span>
      <span itemprop="name">seasonal effect</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">4</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000003860</span>
      <span itemprop="name">storage</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">4</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">241000282412</span>
      <span itemprop="name">Homo</span>
      <span itemprop="domain">Species</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">3</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000008859</span>
      <span itemprop="name">change</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">3</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000004891</span>
      <span itemprop="name">communication</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">3</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000012937</span>
      <span itemprop="name">correction</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">3</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000013480</span>
      <span itemprop="name">data collection</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">3</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000010438</span>
      <span itemprop="name">heat treatment</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">3</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000006872</span>
      <span itemprop="name">improvement</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">3</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000012544</span>
      <span itemprop="name">monitoring process</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">3</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000011218</span>
      <span itemprop="name">segmentation</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">3</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000012360</span>
      <span itemprop="name">testing method</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">3</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000007704</span>
      <span itemprop="name">transition</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">3</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">229910002092</span>
      <span itemprop="name">carbon dioxide</span>
      <span itemprop="domain">Inorganic materials</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">2</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">239000001569</span>
      <span itemprop="name">carbon dioxide</span>
      <span itemprop="domain">Substances</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">2</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">235000009508</span>
      <span itemprop="name">confectionery</span>
      <span itemprop="domain">Nutrition</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">2</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000001276</span>
      <span itemprop="name">controlling effect</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">2</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000001816</span>
      <span itemprop="name">cooling</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">2</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000007613</span>
      <span itemprop="name">environmental effect</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">2</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000011156</span>
      <span itemprop="name">evaluation</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">2</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000005021</span>
      <span itemprop="name">gait</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">2</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">239000000463</span>
      <span itemprop="name">material</span>
      <span itemprop="domain">Substances</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">2</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000037230</span>
      <span itemprop="name">mobility</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">2</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000003287</span>
      <span itemprop="name">optical effect</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">2</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000009467</span>
      <span itemprop="name">reduction</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">2</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000005070</span>
      <span itemprop="name">sampling</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">2</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000013515</span>
      <span itemprop="name">script</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">2</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000004088</span>
      <span itemprop="name">simulation</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">2</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">239000000758</span>
      <span itemprop="name">substrate</span>
      <span itemprop="domain">Substances</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">2</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000013106</span>
      <span itemprop="name">supervised machine learning method</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">2</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">239000002699</span>
      <span itemprop="name">waste material</span>
      <span itemprop="domain">Substances</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">2</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000004378</span>
      <span itemprop="name">air conditioning</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000009411</span>
      <span itemprop="name">base construction</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000013531</span>
      <span itemprop="name">bayesian neural network</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000009286</span>
      <span itemprop="name">beneficial effect</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000004422</span>
      <span itemprop="name">calculation algorithm</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000015556</span>
      <span itemprop="name">catabolic process</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000001413</span>
      <span itemprop="name">cellular effect</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000006243</span>
      <span itemprop="name">chemical reaction</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000008867</span>
      <span itemprop="name">communication pathway</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000013499</span>
      <span itemprop="name">data model</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000003247</span>
      <span itemprop="name">decreasing effect</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000013135</span>
      <span itemprop="name">deep learning</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000006731</span>
      <span itemprop="name">degradation reaction</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000013461</span>
      <span itemprop="name">design</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000011161</span>
      <span itemprop="name">development</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000018109</span>
      <span itemprop="name">developmental process</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000000605</span>
      <span itemprop="name">extraction</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000003993</span>
      <span itemprop="name">interaction</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000012423</span>
      <span itemprop="name">maintenance</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000004519</span>
      <span itemprop="name">manufacturing process</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">239000011159</span>
      <span itemprop="name">matrix material</span>
      <span itemprop="domain">Substances</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000012986</span>
      <span itemprop="name">modification</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000004048</span>
      <span itemprop="name">modification</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000001537</span>
      <span itemprop="name">neural effect</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000005457</span>
      <span itemprop="name">optimization</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000037081</span>
      <span itemprop="name">physical activity</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000001105</span>
      <span itemprop="name">regulatory effect</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000011160</span>
      <span itemprop="name">research</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000005096</span>
      <span itemprop="name">rolling process</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000003068</span>
      <span itemprop="name">static effect</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000010025</span>
      <span itemprop="name">steaming</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">108020001568</span>
      <span itemprop="name">subdomains</span>
      <span itemprop="domain">Proteins</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000001960</span>
      <span itemprop="name">triggered effect</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000000007</span>
      <span itemprop="name">visual effect</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">239000002023</span>
      <span itemprop="name">wood</span>
      <span itemprop="domain">Substances</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000003245</span>
      <span itemprop="name">working effect</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
  </ul>

  <section>
    <h2>Images</h2>
    <ul>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/26/bd/60/3528bba3b0ad2f/US20210357767A1-20211118-D00000.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/cd/17/ae/c6c0dd19f8ce67/US20210357767A1-20211118-D00000.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="0">
            <meta itemprop="id" content="100">
            <meta itemprop="label" content="system architecture">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="774">
              <meta itemprop="top" content="1155">
              <meta itemprop="right" content="829">
              <meta itemprop="bottom" content="1182">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="0">
            <meta itemprop="id" content="102">
            <meta itemprop="label" content="external knowledge sources">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1817">
              <meta itemprop="top" content="132">
              <meta itemprop="right" content="1866">
              <meta itemprop="bottom" content="155">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="0">
            <meta itemprop="id" content="104">
            <meta itemprop="label" content="knowledge base">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1524">
              <meta itemprop="top" content="685">
              <meta itemprop="right" content="1573">
              <meta itemprop="bottom" content="709">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="0">
            <meta itemprop="id" content="106">
            <meta itemprop="label" content="user interface">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="995">
              <meta itemprop="top" content="853">
              <meta itemprop="right" content="1043">
              <meta itemprop="bottom" content="874">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="0">
            <meta itemprop="id" content="108">
            <meta itemprop="label" content="knowledge infusion device">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1179">
              <meta itemprop="top" content="259">
              <meta itemprop="right" content="1226">
              <meta itemprop="bottom" content="282">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="0">
            <meta itemprop="id" content="110">
            <meta itemprop="label" content="knowledge fusion model">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1176">
              <meta itemprop="top" content="37">
              <meta itemprop="right" content="1226">
              <meta itemprop="bottom" content="61">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/00/71/d5/378592c3c231e1/US20210357767A1-20211118-D00001.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/fa/e7/af/63b1ed78045c99/US20210357767A1-20211118-D00001.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="1">
            <meta itemprop="id" content="100">
            <meta itemprop="label" content="system architecture">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1751">
              <meta itemprop="top" content="1589">
              <meta itemprop="right" content="1793">
              <meta itemprop="bottom" content="1672">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="1">
            <meta itemprop="id" content="102">
            <meta itemprop="label" content="external knowledge sources">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="214">
              <meta itemprop="top" content="25">
              <meta itemprop="right" content="243">
              <meta itemprop="bottom" content="96">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="1">
            <meta itemprop="id" content="104">
            <meta itemprop="label" content="knowledge base">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1047">
              <meta itemprop="top" content="465">
              <meta itemprop="right" content="1079">
              <meta itemprop="bottom" content="539">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="1">
            <meta itemprop="id" content="106">
            <meta itemprop="label" content="user interface">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1297">
              <meta itemprop="top" content="1265">
              <meta itemprop="right" content="1332">
              <meta itemprop="bottom" content="1338">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="1">
            <meta itemprop="id" content="108">
            <meta itemprop="label" content="knowledge infusion device">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="401">
              <meta itemprop="top" content="989">
              <meta itemprop="right" content="434">
              <meta itemprop="bottom" content="1062">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="1">
            <meta itemprop="id" content="110">
            <meta itemprop="label" content="knowledge fusion model">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="68">
              <meta itemprop="top" content="990">
              <meta itemprop="right" content="98">
              <meta itemprop="bottom" content="1063">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/bd/5c/5b/d435ec93ded924/US20210357767A1-20211118-D00002.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/2a/ae/a9/9672e68914e536/US20210357767A1-20211118-D00002.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="2">
            <meta itemprop="id" content="104">
            <meta itemprop="label" content="knowledge base">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="632">
              <meta itemprop="top" content="829">
              <meta itemprop="right" content="668">
              <meta itemprop="bottom" content="903">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="2">
            <meta itemprop="id" content="110">
            <meta itemprop="label" content="knowledge fusion model">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="779">
              <meta itemprop="top" content="1708">
              <meta itemprop="right" content="811">
              <meta itemprop="bottom" content="1783">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="2">
            <meta itemprop="id" content="200">
            <meta itemprop="label" content="method architectures">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1809">
              <meta itemprop="top" content="1549">
              <meta itemprop="right" content="1851">
              <meta itemprop="bottom" content="1637">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="2">
            <meta itemprop="id" content="202">
            <meta itemprop="label" content="new data">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="879">
              <meta itemprop="top" content="2706">
              <meta itemprop="right" content="912">
              <meta itemprop="bottom" content="2780">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="2">
            <meta itemprop="id" content="204">
            <meta itemprop="label" content="block">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="929">
              <meta itemprop="top" content="689">
              <meta itemprop="right" content="963">
              <meta itemprop="bottom" content="766">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="2">
            <meta itemprop="id" content="206">
            <meta itemprop="label" content="output">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1434">
              <meta itemprop="top" content="228">
              <meta itemprop="right" content="1469">
              <meta itemprop="bottom" content="303">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/84/9b/61/88603e51084b4d/US20210357767A1-20211118-D00003.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/ae/45/d6/3b4c112eac2825/US20210357767A1-20211118-D00003.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="3">
            <meta itemprop="id" content="104">
            <meta itemprop="label" content="knowledge base">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="36">
              <meta itemprop="top" content="801">
              <meta itemprop="right" content="69">
              <meta itemprop="bottom" content="874">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="3">
            <meta itemprop="id" content="110">
            <meta itemprop="label" content="knowledge fusion model">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1012">
              <meta itemprop="top" content="2746">
              <meta itemprop="right" content="1042">
              <meta itemprop="bottom" content="2820">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="3">
            <meta itemprop="id" content="202">
            <meta itemprop="label" content="new data">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="591">
              <meta itemprop="top" content="2583">
              <meta itemprop="right" content="621">
              <meta itemprop="bottom" content="2654">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="3">
            <meta itemprop="id" content="204">
            <meta itemprop="label" content="block">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="613">
              <meta itemprop="top" content="1302">
              <meta itemprop="right" content="645">
              <meta itemprop="bottom" content="1376">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="3">
            <meta itemprop="id" content="300">
            <meta itemprop="label" content="embodiment">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1872">
              <meta itemprop="top" content="1434">
              <meta itemprop="right" content="1913">
              <meta itemprop="bottom" content="1521">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="3">
            <meta itemprop="id" content="302">
            <meta itemprop="label" content="sensors">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="48">
              <meta itemprop="top" content="1518">
              <meta itemprop="right" content="79">
              <meta itemprop="bottom" content="1592">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="3">
            <meta itemprop="id" content="304">
            <meta itemprop="label" content="smart city platform">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1086">
              <meta itemprop="top" content="457">
              <meta itemprop="right" content="1122">
              <meta itemprop="bottom" content="533">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="3">
            <meta itemprop="id" content="306">
            <meta itemprop="label" content="actuating infrastructure">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1140">
              <meta itemprop="top" content="2184">
              <meta itemprop="right" content="1172">
              <meta itemprop="bottom" content="2259">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/de/61/90/185dd8683a91a1/US20210357767A1-20211118-D00004.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/d7/70/65/252fb5a3d3a71d/US20210357767A1-20211118-D00004.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="4">
            <meta itemprop="id" content="104">
            <meta itemprop="label" content="knowledge base">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="319">
              <meta itemprop="top" content="303">
              <meta itemprop="right" content="351">
              <meta itemprop="bottom" content="374">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="4">
            <meta itemprop="id" content="110">
            <meta itemprop="label" content="knowledge fusion model">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1478">
              <meta itemprop="top" content="1582">
              <meta itemprop="right" content="1508">
              <meta itemprop="bottom" content="1656">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="4">
            <meta itemprop="id" content="204">
            <meta itemprop="label" content="block">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1036">
              <meta itemprop="top" content="1591">
              <meta itemprop="right" content="1069">
              <meta itemprop="bottom" content="1668">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="4">
            <meta itemprop="id" content="400">
            <meta itemprop="label" content="embodiment">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1922">
              <meta itemprop="top" content="1393">
              <meta itemprop="right" content="1963">
              <meta itemprop="bottom" content="1480">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="4">
            <meta itemprop="id" content="402">
            <meta itemprop="label" content="smart city platform">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1055">
              <meta itemprop="top" content="2234">
              <meta itemprop="right" content="1087">
              <meta itemprop="bottom" content="2310">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="4">
            <meta itemprop="id" content="404">
            <meta itemprop="label" content="city sensing infrastructure">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="21">
              <meta itemprop="top" content="1701">
              <meta itemprop="right" content="53">
              <meta itemprop="bottom" content="1777">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="4">
            <meta itemprop="id" content="406">
            <meta itemprop="label" content="actuating infrastructure">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="172">
              <meta itemprop="top" content="625">
              <meta itemprop="right" content="204">
              <meta itemprop="bottom" content="697">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/cc/a8/3a/4de37da0a89f7c/US20210357767A1-20211118-D00005.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/a9/92/31/ad5c688056e4c8/US20210357767A1-20211118-D00005.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="5">
            <meta itemprop="id" content="104">
            <meta itemprop="label" content="knowledge base">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="567">
              <meta itemprop="top" content="487">
              <meta itemprop="right" content="601">
              <meta itemprop="bottom" content="563">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="5">
            <meta itemprop="id" content="110">
            <meta itemprop="label" content="knowledge fusion model">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="454">
              <meta itemprop="top" content="1851">
              <meta itemprop="right" content="484">
              <meta itemprop="bottom" content="1925">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="5">
            <meta itemprop="id" content="204">
            <meta itemprop="label" content="block">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="489">
              <meta itemprop="top" content="2345">
              <meta itemprop="right" content="521">
              <meta itemprop="bottom" content="2421">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="5">
            <meta itemprop="id" content="500">
            <meta itemprop="label" content="knowledge infusion system">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1782">
              <meta itemprop="top" content="1463">
              <meta itemprop="right" content="1821">
              <meta itemprop="bottom" content="1548">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="5">
            <meta itemprop="id" content="502">
            <meta itemprop="label" content="BMS server">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="898">
              <meta itemprop="top" content="1846">
              <meta itemprop="right" content="931">
              <meta itemprop="bottom" content="1919">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="5">
            <meta itemprop="id" content="506">
            <meta itemprop="label" content="HVAC devices">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1654">
              <meta itemprop="top" content="2329">
              <meta itemprop="right" content="1685">
              <meta itemprop="bottom" content="2403">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="5">
            <meta itemprop="id" content="508">
            <meta itemprop="label" content="light devices">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1658">
              <meta itemprop="top" content="1949">
              <meta itemprop="right" content="1689">
              <meta itemprop="bottom" content="2024">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="5">
            <meta itemprop="id" content="512">
            <meta itemprop="label" content="management level">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1012">
              <meta itemprop="top" content="625">
              <meta itemprop="right" content="1057">
              <meta itemprop="bottom" content="712">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="5">
            <meta itemprop="id" content="514">
            <meta itemprop="label" content="automation">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1270">
              <meta itemprop="top" content="630">
              <meta itemprop="right" content="1308">
              <meta itemprop="bottom" content="717">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="5">
            <meta itemprop="id" content="516">
            <meta itemprop="label" content="field level">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1518">
              <meta itemprop="top" content="770">
              <meta itemprop="right" content="1557">
              <meta itemprop="bottom" content="857">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/7b/22/78/ece42182d8ed18/US20210357767A1-20211118-D00006.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/a0/e7/5a/f37270200395ac/US20210357767A1-20211118-D00006.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="6">
            <meta itemprop="id" content="600">
            <meta itemprop="label" content="process">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="805">
              <meta itemprop="top" content="2096">
              <meta itemprop="right" content="892">
              <meta itemprop="bottom" content="2137">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="6">
            <meta itemprop="id" content="602">
            <meta itemprop="label" content="block">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1802">
              <meta itemprop="top" content="97">
              <meta itemprop="right" content="1876">
              <meta itemprop="bottom" content="132">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="6">
            <meta itemprop="id" content="604">
            <meta itemprop="label" content="block">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1803">
              <meta itemprop="top" content="539">
              <meta itemprop="right" content="1880">
              <meta itemprop="bottom" content="574">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="6">
            <meta itemprop="id" content="606">
            <meta itemprop="label" content="block">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1803">
              <meta itemprop="top" content="969">
              <meta itemprop="right" content="1878">
              <meta itemprop="bottom" content="1004">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="6">
            <meta itemprop="id" content="608">
            <meta itemprop="label" content="block">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1803">
              <meta itemprop="top" content="1377">
              <meta itemprop="right" content="1875">
              <meta itemprop="bottom" content="1413">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="6">
            <meta itemprop="id" content="610">
            <meta itemprop="label" content="block">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1802">
              <meta itemprop="top" content="1789">
              <meta itemprop="right" content="1880">
              <meta itemprop="bottom" content="1823">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/0e/84/e3/fc7ac1c75f5d93/US20210357767A1-20211118-D00007.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/58/b0/23/a123956a3c6dda/US20210357767A1-20211118-D00007.png">
        <ul>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/9c/47/70/ea3cdfd7bc1805/US20210357767A1-20211118-D00008.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/eb/fb/eb/36b8ff5b688724/US20210357767A1-20211118-D00008.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="8">
            <meta itemprop="id" content="802">
            <meta itemprop="label" content="data collection phase">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="68">
              <meta itemprop="top" content="2399">
              <meta itemprop="right" content="101">
              <meta itemprop="bottom" content="2474">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="8">
            <meta itemprop="id" content="804">
            <meta itemprop="label" content="Segmentation Phase">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="20">
              <meta itemprop="top" content="1965">
              <meta itemprop="right" content="54">
              <meta itemprop="bottom" content="2041">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="8">
            <meta itemprop="id" content="806">
            <meta itemprop="label" content="Training Phase">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="28">
              <meta itemprop="top" content="486">
              <meta itemprop="right" content="63">
              <meta itemprop="bottom" content="561">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="8">
            <meta itemprop="id" content="808">
            <meta itemprop="label" content="Classification Phase">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1668">
              <meta itemprop="top" content="1251">
              <meta itemprop="right" content="1701">
              <meta itemprop="bottom" content="1327">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/67/ae/53/5926ece2cbbc16/US20210357767A1-20211118-D00009.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/c2/4f/b9/a868028b767eea/US20210357767A1-20211118-D00009.png">
        <ul>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/90/83/16/4833b39238288e/US20210357767A1-20211118-D00010.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/34/f5/d0/bd913e4e38264d/US20210357767A1-20211118-D00010.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="10">
            <meta itemprop="id" content="1002">
            <meta itemprop="label" content="knowledge functions">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1403">
              <meta itemprop="top" content="67">
              <meta itemprop="right" content="1501">
              <meta itemprop="bottom" content="100">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="10">
            <meta itemprop="id" content="1004">
            <meta itemprop="label" content="tutor">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1446">
              <meta itemprop="top" content="518">
              <meta itemprop="right" content="1545">
              <meta itemprop="bottom" content="554">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="10">
            <meta itemprop="id" content="1006">
            <meta itemprop="label" content="agent">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1448">
              <meta itemprop="top" content="980">
              <meta itemprop="right" content="1548">
              <meta itemprop="bottom" content="1011">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="10">
            <meta itemprop="id" content="1010">
            <meta itemprop="label" content="experts">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="524">
              <meta itemprop="top" content="21">
              <meta itemprop="right" content="622">
              <meta itemprop="bottom" content="53">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/b9/bf/ac/a9b8067e15387d/US20210357767A1-20211118-D00011.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/fd/58/b5/c7f40ff9869119/US20210357767A1-20211118-D00011.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="11">
            <meta itemprop="id" content="1100">
            <meta itemprop="label" content="graphical representation">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1320">
              <meta itemprop="top" content="1459">
              <meta itemprop="right" content="1359">
              <meta itemprop="bottom" content="1570">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/9b/f7/d3/7b5ccb68e70700/US20210357767A1-20211118-D00012.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/87/d1/45/457e964f4294f8/US20210357767A1-20211118-D00012.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="12">
            <meta itemprop="id" content="1202">
            <meta itemprop="label" content="external knowledge">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="18">
              <meta itemprop="top" content="19">
              <meta itemprop="right" content="52">
              <meta itemprop="bottom" content="117">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="12">
            <meta itemprop="id" content="1212">
            <meta itemprop="label" content="new data">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="705">
              <meta itemprop="top" content="2689">
              <meta itemprop="right" content="739">
              <meta itemprop="bottom" content="2790">
            </span>
          </li>
        </ul>
      </li>
    </ul>
  </section>

  <section>
    <h2>Classifications</h2>
    <ul>
      <li>
        <ul itemprop="classifications" itemscope repeat>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G</span>&mdash;<span itemprop="Description">PHYSICS</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06</span>&mdash;<span itemprop="Description">COMPUTING; CALCULATING OR COUNTING</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06N</span>&mdash;<span itemprop="Description">COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06N20/00</span>&mdash;<span itemprop="Description">Machine learning</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06N20/20</span>&mdash;<span itemprop="Description">Ensemble learning</span>
            <meta itemprop="Leaf" content="true"><meta itemprop="FirstCode" content="true"><meta itemprop="IsCPC" content="true">
          </li>
        </ul>
      </li>
      <li>
        <ul itemprop="classifications" itemscope repeat>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G</span>&mdash;<span itemprop="Description">PHYSICS</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06</span>&mdash;<span itemprop="Description">COMPUTING; CALCULATING OR COUNTING</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06F</span>&mdash;<span itemprop="Description">ELECTRIC DIGITAL DATA PROCESSING</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06F18/00</span>&mdash;<span itemprop="Description">Pattern recognition</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06F18/20</span>&mdash;<span itemprop="Description">Analysing</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06F18/25</span>&mdash;<span itemprop="Description">Fusion techniques</span>
            <meta itemprop="Leaf" content="true"><meta itemprop="IsCPC" content="true">
          </li>
        </ul>
      </li>
      <li>
        <ul itemprop="classifications" itemscope repeat>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06K9/6202</span>&mdash;<span itemprop="Description"></span>
            <meta itemprop="Leaf" content="true"><meta itemprop="IsCPC" content="true">
          </li>
        </ul>
      </li>
      <li>
        <ul itemprop="classifications" itemscope repeat>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06K9/6288</span>&mdash;<span itemprop="Description"></span>
            <meta itemprop="Leaf" content="true"><meta itemprop="IsCPC" content="true">
          </li>
        </ul>
      </li>
      <li>
        <ul itemprop="classifications" itemscope repeat>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G</span>&mdash;<span itemprop="Description">PHYSICS</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06</span>&mdash;<span itemprop="Description">COMPUTING; CALCULATING OR COUNTING</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06N</span>&mdash;<span itemprop="Description">COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06N3/00</span>&mdash;<span itemprop="Description">Computing arrangements based on biological models</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06N3/02</span>&mdash;<span itemprop="Description">Neural networks</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06N3/04</span>&mdash;<span itemprop="Description">Architecture, e.g. interconnection topology</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06N3/042</span>&mdash;<span itemprop="Description">Knowledge-based neural networks; Logical representations of neural networks</span>
            <meta itemprop="Leaf" content="true"><meta itemprop="IsCPC" content="true">
          </li>
        </ul>
      </li>
      <li>
        <ul itemprop="classifications" itemscope repeat>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G</span>&mdash;<span itemprop="Description">PHYSICS</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06</span>&mdash;<span itemprop="Description">COMPUTING; CALCULATING OR COUNTING</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06N</span>&mdash;<span itemprop="Description">COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06N3/00</span>&mdash;<span itemprop="Description">Computing arrangements based on biological models</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06N3/02</span>&mdash;<span itemprop="Description">Neural networks</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06N3/04</span>&mdash;<span itemprop="Description">Architecture, e.g. interconnection topology</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06N3/045</span>&mdash;<span itemprop="Description">Combinations of networks</span>
            <meta itemprop="Leaf" content="true"><meta itemprop="IsCPC" content="true">
          </li>
        </ul>
      </li>
      <li>
        <ul itemprop="classifications" itemscope repeat>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G</span>&mdash;<span itemprop="Description">PHYSICS</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06</span>&mdash;<span itemprop="Description">COMPUTING; CALCULATING OR COUNTING</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06N</span>&mdash;<span itemprop="Description">COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06N3/00</span>&mdash;<span itemprop="Description">Computing arrangements based on biological models</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06N3/02</span>&mdash;<span itemprop="Description">Neural networks</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06N3/08</span>&mdash;<span itemprop="Description">Learning methods</span>
            <meta itemprop="Leaf" content="true"><meta itemprop="IsCPC" content="true">
          </li>
        </ul>
      </li>
      <li>
        <ul itemprop="classifications" itemscope repeat>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G</span>&mdash;<span itemprop="Description">PHYSICS</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06</span>&mdash;<span itemprop="Description">COMPUTING; CALCULATING OR COUNTING</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06N</span>&mdash;<span itemprop="Description">COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06N5/00</span>&mdash;<span itemprop="Description">Computing arrangements using knowledge-based models</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06N5/02</span>&mdash;<span itemprop="Description">Knowledge representation; Symbolic representation</span>
            <meta itemprop="Leaf" content="true"><meta itemprop="IsCPC" content="true">
          </li>
        </ul>
      </li>
      <li>
        <ul itemprop="classifications" itemscope repeat>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G</span>&mdash;<span itemprop="Description">PHYSICS</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06</span>&mdash;<span itemprop="Description">COMPUTING; CALCULATING OR COUNTING</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06N</span>&mdash;<span itemprop="Description">COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06N5/00</span>&mdash;<span itemprop="Description">Computing arrangements using knowledge-based models</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06N5/02</span>&mdash;<span itemprop="Description">Knowledge representation; Symbolic representation</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06N5/022</span>&mdash;<span itemprop="Description">Knowledge engineering; Knowledge acquisition</span>
            <meta itemprop="Leaf" content="true"><meta itemprop="IsCPC" content="true">
          </li>
        </ul>
      </li>
      <li>
        <ul itemprop="classifications" itemscope repeat>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G</span>&mdash;<span itemprop="Description">PHYSICS</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06</span>&mdash;<span itemprop="Description">COMPUTING; CALCULATING OR COUNTING</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06N</span>&mdash;<span itemprop="Description">COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06N3/00</span>&mdash;<span itemprop="Description">Computing arrangements based on biological models</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06N3/02</span>&mdash;<span itemprop="Description">Neural networks</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06N3/04</span>&mdash;<span itemprop="Description">Architecture, e.g. interconnection topology</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06N3/047</span>&mdash;<span itemprop="Description">Probabilistic or stochastic networks</span>
            <meta itemprop="Leaf" content="true"><meta itemprop="Additional" content="true"><meta itemprop="IsCPC" content="true">
          </li>
        </ul>
      </li>
    </ul>
  </section>

  

  

  <section>
    <h2>Definitions</h2>
    <ul>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the present invention</span>
        <span itemprop="definition">relates to a method and system for automated knowledge infusion for machine learning applications.</span>
        <meta itemprop="num_attr" content="0002">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Machine learning (ML) applications in IoT scenarios</span>
        <span itemprop="definition">are impacted because supervision knowledge, such as labeled data for supervised learning or experience and rewards gained in reinforcement learning (RL), is scarce and expensive to obtain.</span>
        <meta itemprop="num_attr" content="0003">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">supervision knowledge</span>
        <span itemprop="definition">such as labeled data for supervised learning or experience and rewards gained in reinforcement learning (RL)</span>
        <meta itemprop="num_attr" content="0003">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">RL</span>
        <span itemprop="definition">reinforcement learning</span>
        <meta itemprop="num_attr" content="0003">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a human</span>
        <span itemprop="definition">is typically required to manually annotate events in a data stream by observing the events in the real world.</span>
        <meta itemprop="num_attr" content="0003">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">exploration</span>
        <span itemprop="definition">is expensive.</span>
        <meta itemprop="num_attr" content="0003">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">RL</span>
        <span itemprop="definition">requires actions within these real, running systems where wrong actions have real impact, cost and can even potentially cause harm to the system or its users.</span>
        <meta itemprop="num_attr" content="0003">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a supervised ML model to monitor human gait</span>
        <span itemprop="definition">may be trained in a location with a specific structure (e.g., wood); however, when the supervised ML model is used in a different structure (e.g., concrete), it may perform poorly even though the task to be performed is the same (see, e.g., Mirshekari, Mostafa, et al., âHuman gait monitoring using footstep-induced floor vibrations across different structures,â Proceedings of the 2018 ACM International Joint Conference and 2018 International Symposium on Pervasive and Ubiquitous Computing and Wearable Computers (2016), which is hereby incorporated by reference herein).</span>
        <meta itemprop="num_attr" content="0004">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a RL agent trained in a simulation environment for autonomous driving</span>
        <span itemprop="definition">may perform poorly in the real world when new situations arise (e.g., in a situation that was not available in simulation time). These problems, among others, make it hard to achieve robust, transferable and accurate machine learning for IoT systems in practice.</span>
        <meta itemprop="num_attr" content="0004">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">transfer learning</span>
        <span itemprop="definition">is to transfer knowledge learned for one task to a related task. Transferring such knowledge is beneficial for reducing the training effortâboth from a compute time and from a data collection and labeling time.</span>
        <meta itemprop="num_attr" content="0005">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">state of the art models in computer vision or NLP</span>
        <span itemprop="definition">have been trained with millions of parameters and the training compute time can costs millions of dollars for large models (see, e.g., Sharir, Or, Barak Peleg, and Yoav Shoham, âThe Cost of Training NLP Models: A Concise Overview,â arXiv preprint arXiv:2004.08900 (2020), which is hereby incorporated by reference herein).</span>
        <meta itemprop="num_attr" content="0005">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Transfer learning</span>
        <span itemprop="definition">can, for example, be achieved by replacing the final layer of a large deep neural network (e.g., a model trained with millions of images for object detection) to fit the model to a new task (e.g., a more specific object recognition for a single domain, such as smart appliances in a building).</span>
        <meta itemprop="num_attr" content="0005">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a new task</span>
        <span itemprop="definition">e.g., a more specific object recognition for a single domain, such as smart appliances in a building.</span>
        <meta itemprop="num_attr" content="0005">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">traditional approaches</span>
        <span itemprop="definition">fine-tune larger models to fit to a new task (e.g., by re-training only few layers) while leaving the more task-unspecific layers of the neural network fixed (see, e.g., Schmidhuber, JÃ¼rgen, âDeep learning in neural networks: An overview,â Neural networks 61 (2015): 85-117, which is hereby incorporated by reference herein).</span>
        <meta itemprop="num_attr" content="0005">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the present invention</span>
        <span itemprop="definition">provides a method for using knowledge infusion for robust and transferable machine learning models.</span>
        <meta itemprop="num_attr" content="0007">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the method</span>
        <span itemprop="definition">includes the steps of: receiving a plurality of adaptive and programmable knowledge functions comprising a plurality of strong functions and a plurality of weak functions; generating a knowledge model based on the plurality of strong functions and the plurality of weak functions; and training a machine learning model based on the generated knowledge model.</span>
        <meta itemprop="num_attr" content="0007">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 1</span>
        <span itemprop="definition">schematically shows a method and system architecture for an automated knowledge infusion for robust and transferable machine learning applications during a set-up phase according to an embodiment of the present invention</span>
        <meta itemprop="num_attr" content="0009">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 2</span>
        <span itemprop="definition">schematically shows a method and system architecture for an automated knowledge infusion for robust and transferable machine learning applications during an execution phase according to an embodiment of the present invention</span>
        <meta itemprop="num_attr" content="0010">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 3</span>
        <span itemprop="definition">shows a knowledge infusion system in the context of a smart city according to an embodiment of the present invention</span>
        <meta itemprop="num_attr" content="0011">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 4</span>
        <span itemprop="definition">shows another knowledge infusion system in the context of a smart city according to an embodiment of the present invention</span>
        <meta itemprop="num_attr" content="0012">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 5</span>
        <span itemprop="definition">shows a knowledge infusion system for building management according to an embodiment of the present invention</span>
        <meta itemprop="num_attr" content="0013">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 6</span>
        <span itemprop="definition">shows a process for performing automated knowledge infusion for robust and transferable machine learning in IoT systems according to an embodiment of the present invention</span>
        <meta itemprop="num_attr" content="0014">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 7</span>
        <span itemprop="definition">graphically shows the context-dimensions of machine learning models in IoT systems</span>
        <meta itemprop="num_attr" content="0015">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 8</span>
        <span itemprop="definition">shows the main building blocks used to address the transport mode detection problem</span>
        <meta itemprop="num_attr" content="0016">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 9</span>
        <span itemprop="definition">shows a table that summarizes results of using the generative model and the weakly and fully supervised random forests</span>
        <meta itemprop="num_attr" content="0017">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 10</span>
        <span itemprop="definition">shows the overall workings of a Tutor for reinforced learning (Tutor4RL) process</span>
        <meta itemprop="num_attr" content="0018">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 11</span>
        <span itemprop="definition">shows a graphical representation the mean reward per episode of two agents.</span>
        <meta itemprop="num_attr" content="0019">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 12</span>
        <span itemprop="definition">shows a knowledge infusion overview and setup according to an embodiment of the present invention.</span>
        <meta itemprop="num_attr" content="0020">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Embodiments of the present invention</span>
        <span itemprop="definition">provide an automated knowledge infusion method and system for machine learning applications.</span>
        <meta itemprop="num_attr" content="0021">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the automated knowledge infusion method and system</span>
        <span itemprop="definition">may be used in in internet of things (IoT) systems.</span>
        <meta itemprop="num_attr" content="0021">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the automated knowledge infusion method and system</span>
        <span itemprop="definition">improves the robustness, transferability and accuracy of machine learning systems and applications.</span>
        <meta itemprop="num_attr" content="0021">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the method and system</span>
        <span itemprop="definition">uses two types of knowledge functions: (a) weak knowledge functions (e.g., functions that are mostly true) and (b) strong knowledge functions that comprise axioms (e.g., canonical truths). For examples, these two functions enable the infusion of knowledge into the training phase of supervised machine learning methods through ensemble methods.</span>
        <meta itemprop="num_attr" content="0021">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">these functions</span>
        <span itemprop="definition">act as a white box counter-part to the black-box trained model/agent of a supervised or reinforcement learning system during the execution phase that are able to (a) identify and correct (infrequent) wrong outputs of the ML model/agent (by using the set of strong knowledge functions) and (b) decide, through the calculation of uncertainty values, when a model has drifted away from the input data characteristics and must be re-trained with new data to re-gain adequate results.</span>
        <meta itemprop="num_attr" content="0021">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">embodiments of the present invention</span>
        <span itemprop="definition">uses automated knowledge infusion method and system to solve two important technical issues associated using machine learning in IoT scenarios.</span>
        <meta itemprop="num_attr" content="0022">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">embodiments of the present invention</span>
        <span itemprop="definition">use weak and strong knowledge functions that include a reasoning part and a query interface to internal knowledge graphs and external knowledge sources, which enables these functions to adapt automatically based on new knowledge without any user involvement.</span>
        <meta itemprop="num_attr" content="0022">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the same knowledge infusion method and system</span>
        <span itemprop="definition">may be used across different deployments and may be updated through time.</span>
        <meta itemprop="num_attr" content="0022">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">embodiments of the present invention</span>
        <span itemprop="definition">also addresses the robustness problem of ML systems by using the strong knowledge functions and a calculation of an uncertainty value. For instance, by using these, certain outputs are able to be guaranteed (e.g., to adhere to regulations or safety).</span>
        <meta itemprop="num_attr" content="0022">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the present invention</span>
        <span itemprop="definition">provides a method for using knowledge infusion for robust and transferable machine learning models.</span>
        <meta itemprop="num_attr" content="0023">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the method</span>
        <span itemprop="definition">includes the steps of: receiving a plurality of adaptive and programmable knowledge functions comprising a plurality of strong functions and a plurality of weak functions; generating a knowledge model based on the plurality of strong functions and the plurality of weak functions; and training a machine learning model based on the generated knowledge model.</span>
        <meta itemprop="num_attr" content="0023">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the method</span>
        <span itemprop="definition">further comprises: generating a knowledge fusion model based on packaging the machine learning model with the knowledge model.</span>
        <meta itemprop="num_attr" content="0024">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the method</span>
        <span itemprop="definition">further comprises: deploying the machine learning model and the knowledge model within an environment to perform one or more operations; subsequent to deploying the machine learning model and the knowledge model within the environment, receiving new data associated with the environment from one or more sensors; inputting the new data into the machine learning model to determine one or more machine learning model outputs; inputting the new data into the knowledge model to determine one or more knowledge model outputs; and correcting the one or more machine learning model outputs based on determining the one or more machine learning model outputs contradicts the one or more knowledge model outputs.</span>
        <meta itemprop="num_attr" content="0025">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the inputting the new data into the knowledge model</span>
        <span itemprop="definition">comprises inputting the new data into at least one of the plurality of strong functions, and wherein the one or more knowledge model outputs are outputs from the plurality of strong functions.</span>
        <meta itemprop="num_attr" content="0026">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the method</span>
        <span itemprop="definition">further comprises: deploying the machine learning model and the knowledge model within an environment to perform one or more operations; subsequent to deploying the machine learning model and the knowledge model within the environment, receiving new data associated with the environment from one or more sensors; inputting the new data into the machine learning model to generate one or more machine learning model outputs and one or more probability values associated with the one or more machine learning model outputs; and calculating an uncertainty value based on the one or more machine learning model outputs and the one or more probability values, wherein the uncertainty value represents uncertainty of the one or more machine learning model outputs from the machine learning model.</span>
        <meta itemprop="num_attr" content="0027">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the method</span>
        <span itemprop="definition">further comprises: comparing the uncertainty value with a threshold; and based on the uncertainty value exceeding the threshold, re-training the machine learning model.</span>
        <meta itemprop="num_attr" content="0028">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the method</span>
        <span itemprop="definition">further comprises: based on the uncertainty value not exceeding the threshold, updating a knowledge base using the one or more machine learning model outputs; updating the knowledge model based on updating the knowledge base.</span>
        <meta itemprop="num_attr" content="0029">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the re-training of the machine learning model</span>
        <span itemprop="definition">comprises re-training the machine learning model using the updated knowledge model.</span>
        <meta itemprop="num_attr" content="0029">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the calculating the uncertainty value</span>
        <span itemprop="definition">comprises: determining a disagreement value between outputs from the knowledge model and outputs from the machine learning model, wherein the outputs from the machine learning model comprises the one or more machine learning model outputs; and calculating the uncertainty value based on the disagreement value and the one or more probability values.</span>
        <meta itemprop="num_attr" content="0030">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the method</span>
        <span itemprop="definition">further comprises: determining a moving average associated with the uncertainty value; and re-training the machine learning model based on comparing the moving average associated with the uncertainty value with a threshold.</span>
        <meta itemprop="num_attr" content="0031">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the generating the knowledge model</span>
        <span itemprop="definition">comprises generating the knowledge model based on mapping the plurality of strong functions and the plurality of weak functions using one or more ensemble methods.</span>
        <meta itemprop="num_attr" content="0032">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the one or more ensemble methods</span>
        <span itemprop="definition">comprises at least one of a majority ensemble method, a generative ensemble method, or a Tutor for Reinforced Learning (Tutor4RL) ensemble method.</span>
        <meta itemprop="num_attr" content="0032">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the receiving the plurality of adaptive and programmable knowledge functions</span>
        <span itemprop="definition">comprises receiving the plurality of adaptive and programmable knowledge functions from a user interface.</span>
        <meta itemprop="num_attr" content="0033">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the method</span>
        <span itemprop="definition">further comprises: updating the plurality of weak functions and the plurality of strong functions based on an internal knowledge base and one or more external knowledge sources.</span>
        <meta itemprop="num_attr" content="0033">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the generating the knowledge model</span>
        <span itemprop="definition">is based on updating the plurality of weak functions and the plurality of strong functions.</span>
        <meta itemprop="num_attr" content="0033">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the method</span>
        <span itemprop="definition">further comprises: subsequent to generating the knowledge model, continuously maintaining the knowledge model based on continuously querying the one or more external knowledge sources to provide and update the plurality of weak functions and the plurality of strong functions.</span>
        <meta itemprop="num_attr" content="0034">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the method</span>
        <span itemprop="definition">further comprises: deploying the machine learning model and the knowledge model within an environment to perform one or more operations.</span>
        <meta itemprop="num_attr" content="0035">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the environment</span>
        <span itemprop="definition">comprises an Internet of Things (IoT) system, a smart city system, a smart retail system, a building energy management system, or a data center energy management system.</span>
        <meta itemprop="num_attr" content="0035">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">IoT</span>
        <span itemprop="definition">Internet of Things</span>
        <meta itemprop="num_attr" content="0035">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the present invention</span>
        <span itemprop="definition">provides a system for using knowledge infusion for robust and transferable machine learning models.</span>
        <meta itemprop="num_attr" content="0036">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the system</span>
        <span itemprop="definition">comprising one or more processors which, alone or in combination, are configured to provide for execution of a method comprising: receiving a plurality of adaptive and programmable knowledge functions comprising a plurality of strong functions and a plurality of weak functions; generating a knowledge model based on the plurality of strong functions and the plurality of weak functions; and training a machine learning model based on the generated knowledge model.</span>
        <meta itemprop="num_attr" content="0036">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the system</span>
        <span itemprop="definition">may also be configured to provide for other steps of embodiments of the method.</span>
        <meta itemprop="num_attr" content="0036">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a tangible, non-transitory computer-readable medium</span>
        <span itemprop="definition">having instructions thereon which, upon being executed by one or more processors, alone or in combination, provide for execution of a method according to any embodiment of the present invention.</span>
        <meta itemprop="num_attr" content="0037">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Embodiments of the present invention</span>
        <span itemprop="definition">provide an automated knowledge infusion method and system that is different from traditional approaches.</span>
        <meta itemprop="num_attr" content="0038">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the automated knowledge infusion method and system</span>
        <span itemprop="definition">provides for knowledge infusion using adaptive weak and strong knowledge functions, which makes the training phase transferable between tasks with little effort, as the knowledge functions adapt based on the context of the task (e.g., the location where the ML model is intended to be deployed).</span>
        <meta itemprop="num_attr" content="0038">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the adaptive weak and strong knowledge functions</span>
        <span itemprop="definition">are determined based on interfacing with a knowledge graph and external knowledge sources (e.g., other knowledge bases such as OPENSTREETMAP) in order to adapt dynamically to new contexts (e.g., a different location and time) by querying these knowledge sources.</span>
        <meta itemprop="num_attr" content="0038">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Weak knowledge functions</span>
        <span itemprop="definition">may include mostly true and strong knowledge functions may include axioms (canonical truths).</span>
        <meta itemprop="num_attr" content="0038">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the automated knowledge infusion method and system</span>
        <span itemprop="definition">may combine these knowledge functions into a weak ensemble and a strong ensemble that form a âwhite-boxâ knowledge model.</span>
        <meta itemprop="num_attr" content="0038">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the knowledge model</span>
        <span itemprop="definition">may be used to train a traditional supervised machine learning model.</span>
        <meta itemprop="num_attr" content="0038">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the white box model</span>
        <span itemprop="definition">may be continuously updated (e.g., based on new knowledge and/or added/updated knowledge functions) to ensure robustness of the method and system during execution. Additionally, and/or alternatively, the white box model may also be used to determine when the context within the real world shifts away from the trained ML model and re-training is needed.</span>
        <meta itemprop="num_attr" content="0038">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">transferability</span>
        <span itemprop="definition">may be achieved through making the knowledge functions adaptive to the context of a current task. For example, they may adapt based on the location context of the current task (e.g., the knowledge functions may change their behavior when being used for a deployment in a first city (City A) as compared to a second city (City B).</span>
        <meta itemprop="num_attr" content="0039">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">knowledge functions</span>
        <span itemprop="definition">may also be stored in a knowledge base (described below) in order to facilitate their sharing/transferability.</span>
        <meta itemprop="num_attr" content="0039">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a user</span>
        <span itemprop="definition">e.g., ML developer</span>
        <meta itemprop="num_attr" content="0039">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a computing device</span>
        <span itemprop="definition">may automatically select fitting knowledge functions without the user input. In other words, the computing device may select a set of knowledge functions based on the input data.</span>
        <meta itemprop="num_attr" content="0039">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">IoT</span>
        <span itemprop="definition">internet of things</span>
        <meta itemprop="num_attr" content="0039">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a user</span>
        <span itemprop="definition">may prove input to categorize whether a function is strong or weak (e.g., by using a decorator such as â@strongâ or â@weakâ).</span>
        <meta itemprop="num_attr" content="0040">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the user</span>
        <span itemprop="definition">may further use external knowledge sources in the same way to classify strong or weak functions.</span>
        <meta itemprop="num_attr" content="0040">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a computing device</span>
        <span itemprop="definition">may automatically determine whether the functions are weak/strong without user input or with minimal user input/direction.</span>
        <meta itemprop="num_attr" content="0040">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Embodiments of the present invention</span>
        <span itemprop="definition">may be applied to achieve technological improvements in a number of technological fields. For example:</span>
        <meta itemprop="num_attr" content="0041">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Knowledge Infusion</span>
        <span itemprop="definition">is used to dynamically infuse knowledge (e.g., logic based on human reasoning and internal and external knowledge bases such as knowledge bases stored in a knowledge graph) into Teacher-based machine learning systems to improve overall robustness, transferability and accuracy.</span>
        <meta itemprop="num_attr" content="0046">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Teacher-based ML systems</span>
        <span itemprop="definition">may refer to variations of supervised learning and/or reinforcement learning, where the supervision signals are gained through modeling of rewards from the environment.</span>
        <meta itemprop="num_attr" content="0046">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">this knowledge</span>
        <span itemprop="definition">e.g., weak and strong knowledge functions</span>
        <meta itemprop="num_attr" content="0046">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">this knowledge</span>
        <span itemprop="definition">has at least two benefits: (1) it reduces the effort needed to train or startup an ML model/agent and (2) the knowledge model may be executed side-by-side with the ML model/agent, correct wrong outputs and/or enable the calculation of an uncertainty value that gives an indication of when reality and the ML model have shifted apart so much that performance would suffer.</span>
        <meta itemprop="num_attr" content="0046">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Knowledge functions</span>
        <span itemprop="definition">may output a single value, which can either be a label (e.g., for supervised machine learning), an action (e.g., for reinforcement learning), and/or the functions may choose to abstain.</span>
        <meta itemprop="num_attr" content="0047">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the inputs to knowledge functions</span>
        <span itemprop="definition">are one or multiple data points (e.g., sensor values) and one or multiple knowledge sources (e.g., an endpoint to a knowledge base).</span>
        <meta itemprop="num_attr" content="0047">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the data points</span>
        <span itemprop="definition">may include associated context meta-data, such as the location of the sensor or the observation time.</span>
        <meta itemprop="num_attr" content="0047">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Functions</span>
        <span itemprop="definition">include a reasoning part, defined by human provided logic (e.g., conditional operators) and input knowledge that is derived/queried from internal and external knowledge bases through well-defined interfaces (e.g., through Simple Protocol and resource description framework (RDF) query language (SPARQL), other graph query languages such as Graph query language (GraphQL), and so on).</span>
        <meta itemprop="num_attr" content="0047">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">RDF</span>
        <span itemprop="definition">Simple Protocol and resource description framework</span>
        <meta itemprop="num_attr" content="0047">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">GraphQL</span>
        <span itemprop="definition">graph query languages</span>
        <meta itemprop="num_attr" content="0047">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">knowledge functions</span>
        <span itemprop="definition">are practically able to adapt their behavior automatically, based on changes in the output derived from querying the knowledge bases (possibly with a different context).</span>
        <meta itemprop="num_attr" content="0047">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a knowledge function that outputs if there is a fire based on the value from a temperature sensor</span>
        <span itemprop="definition">may interface with a knowledge base that contains current weather data, including the current temperature.</span>
        <meta itemprop="num_attr" content="0047">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the reasoning logic inside the knowledge function</span>
        <span itemprop="definition">might then use the weather temperature and the value from the temperature sensor to decide if there is a fire (e.g., the output may be a binary classification such as fire: True/False).</span>
        <meta itemprop="num_attr" content="0047">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the functions</span>
        <span itemprop="definition">may adapt to different weather conditions automatically. Additionally, and/or alternatively, through associated context meta-data of the temperature sensor, the function may adapt to different contexts, such as location and time (e.g., it will retrieve knowledge for a different location).</span>
        <meta itemprop="num_attr" content="0047">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the knowledge functions</span>
        <span itemprop="definition">may choose to abstain from outputting a value when the input to the knowledge function and the external knowledge source(s) do not provide sufficient information for the specific classification task.</span>
        <meta itemprop="num_attr" content="0048">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a function</span>
        <span itemprop="definition">may decide on the transportation mode of individuals based on sensor data collected from the individuals&#39; mobile phones and external knowledge from an external knowledge source (e.g., OPENSTREETMAP).</span>
        <meta itemprop="num_attr" content="0048">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">this function</span>
        <span itemprop="definition">may choose to abstain because it cannot be certain about the transport mode.</span>
        <meta itemprop="num_attr" content="0048">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a second knowledge function</span>
        <span itemprop="definition">may use accelerometer data from the mobile phone and not abstain for the same input data.</span>
        <meta itemprop="num_attr" content="0048">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a user</span>
        <span itemprop="definition">may input the reasoning for some retrieved external knowledge from the external knowledge source.</span>
        <meta itemprop="num_attr" content="0049">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a computing device</span>
        <span itemprop="definition">may retrieve external knowledge from external knowledge data sources (e.g., OPENSTREETMAP).</span>
        <meta itemprop="num_attr" content="0049">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the user</span>
        <span itemprop="definition">may provide the reasoning for the retrieved data.</span>
        <meta itemprop="num_attr" content="0049">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the user</span>
        <span itemprop="definition">may input the reasoning information such as the difference between the current weather temperature and the sensor value.</span>
        <meta itemprop="num_attr" content="0049">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Embodiments of the present invention</span>
        <span itemprop="definition">may use strong functions as a fail-safe mechanism for the ML model.</span>
        <meta itemprop="num_attr" content="0050">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">strong functions</span>
        <span itemprop="definition">may corrects outputs from the ML model that users (e.g., experts) may know as a fact, cannot be true.</span>
        <meta itemprop="num_attr" content="0050">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">users</span>
        <span itemprop="definition">e.g., experts</span>
        <meta itemprop="num_attr" content="0050">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the strong function</span>
        <span itemprop="definition">may correct the output (e.g., the strong function may indicate that the weather temperature is within a margin of error and there is no fire).</span>
        <meta itemprop="num_attr" content="0050">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a set of both weak and strong functions</span>
        <span itemprop="definition">is combined to label the data (each function is similar to a voter for each data point that can either vote or abstain, with the strong functions over-writing weak functions).</span>
        <meta itemprop="num_attr" content="0051">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">each function</span>
        <span itemprop="definition">is similar to a voter for each data point that can either vote or abstain, with the strong functions over-writing weak functions).</span>
        <meta itemprop="num_attr" content="0051">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">three weak functions</span>
        <span itemprop="definition">may vote BUS and two weak functions may vote CAR.</span>
        <meta itemprop="num_attr" content="0051">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the computing device</span>
        <span itemprop="definition">may take these votes and select and choose a label (e.g., BUS because the majority (three) of the weak functions voted for it).</span>
        <meta itemprop="num_attr" content="0051">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the computing device</span>
        <span itemprop="definition">may choose BIKE instead.</span>
        <meta itemprop="num_attr" content="0051">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the strong function output of BIKE</span>
        <span itemprop="definition">may override the weak functions outputs of CAR and BUS.</span>
        <meta itemprop="num_attr" content="0051">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the computing device</span>
        <span itemprop="definition">may use the labeled data to train a ML model, such as neural net, random forest, and so on.</span>
        <meta itemprop="num_attr" content="0051">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the black-box ML model</span>
        <span itemprop="definition">may provide a better performance because it has learned the patterns in the data and removes some noise.</span>
        <meta itemprop="num_attr" content="0052">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the advantage of using both the ML model and the white box knowledge model</span>
        <span itemprop="definition">is that: 1) it may correct obvious wrong outputs with the help of the strong functions; and 2) it can discover if the ML model does not fit anymore to the input data distribution. This may happen if the model is moved to a new location (e.g., City B rather than City A) or just the real world changes over time. Having just the ML model, this may be difficult to discover.</span>
        <meta itemprop="num_attr" content="0052">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">embodiments of the present invention</span>
        <span itemprop="definition">may observe when there is too much disagreement.</span>
        <meta itemprop="num_attr" content="0052">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the computing device</span>
        <span itemprop="definition">may re-train the ML model with the new input data distribution and labeled with the adaptive knowledge model (e.g., the knowledge model adapts automatically to a new location using OPENSTREETMAP external knowledge).</span>
        <meta itemprop="num_attr" content="0052">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Embodiments of the present invention</span>
        <span itemprop="definition">create a knowledge model that includes and/or incorporates an ensemble of knowledge functions (e.g., strong and weak knowledge functions) that are used to label data points and then used to train a ML model. Additionally, and/or alternatively, in an embodiment of the present invention for RL, this step might not be needed because the agent may start interacting directly with its environment. During execution, both the knowledge model and the ML model, are then used jointly (e.g., both may be used to process every new input). FIG. 1 describes these steps in more detail.</span>
        <meta itemprop="num_attr" content="0053">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">knowledge functions</span>
        <span itemprop="definition">e.g., strong and weak knowledge functions</span>
        <meta itemprop="num_attr" content="0053">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the method and system architecture 100</span>
        <span itemprop="definition">may be used in in internet of things (IoT) systems.</span>
        <meta itemprop="num_attr" content="0054">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the architecture 100</span>
        <span itemprop="definition">includes external knowledge sources 102 (e.g., ontologies, domain knowledge, physical models, and/or knowledge bases), a knowledge base 104 , one or more user interfaces 106 , a knowledge infusion device 108 , and a knowledge infusion model 110 .</span>
        <meta itemprop="num_attr" content="0054">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">external knowledge sources 102</span>
        <span itemprop="definition">e.g., ontologies, domain knowledge, physical models, and/or knowledge bases</span>
        <meta itemprop="num_attr" content="0054">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a knowledge base 104</span>
        <span itemprop="definition">e.g., one or more user interfaces 106 , a knowledge infusion device 108 , and a knowledge infusion model 110 .</span>
        <meta itemprop="num_attr" content="0054">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the knowledge infusion device 108</span>
        <span itemprop="definition">includes multiple knowledge functions (e.g., a first knowledge function (KF 1 ), a second knowledge function (KF 2 ), and so on), a knowledge function abstraction layer, multiple ensembles (e.g., majority ensemble, generative ensemble, tutor for reinforced learning (Tutor4RL), and so on), and a knowledge model abstraction layer.</span>
        <meta itemprop="num_attr" content="0054">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">external knowledge sources 102</span>
        <span itemprop="definition">may be an application programming interface (API) such as a weather API that is directly accessed by the knowledge functions of the knowledge infusion device 108 .</span>
        <meta itemprop="num_attr" content="0054">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">API</span>
        <span itemprop="definition">application programming interface</span>
        <meta itemprop="num_attr" content="0054">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the external knowledge sources 102</span>
        <span itemprop="definition">may be a knowledge graph that integrates/links into a common knowledge base (e.g., a knowledge graph that integrates various aspects of a smart city).</span>
        <meta itemprop="num_attr" content="0054">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the same computing device</span>
        <span itemprop="definition">may be used for setting up the knowledge infusion model and for executing the knowledge infusion model.</span>
        <meta itemprop="num_attr" content="0054">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the same computing device</span>
        <span itemprop="definition">may perform the functionalities of the knowledge infusion device 108 and for the knowledge infusion model 110 .</span>
        <meta itemprop="num_attr" content="0054">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">different computing devices</span>
        <span itemprop="definition">may be used for setting up and executing the knowledge infusion model.</span>
        <meta itemprop="num_attr" content="0054">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the architecture 100</span>
        <span itemprop="definition">will be described in further detail below.</span>
        <meta itemprop="num_attr" content="0054">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 2</span>
        <span itemprop="definition">illustrates a method and system architecture 200 that uses the knowledge fusion model 110 (from FIG. 1 ) during an execution phase according to an embodiment of the present invention is shown.</span>
        <meta itemprop="num_attr" content="0055">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">new data 202</span>
        <span itemprop="definition">may processed by both the ML model and the knowledge model of the knowledge fusion model 110 .</span>
        <meta itemprop="num_attr" content="0055">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the knowledge fusion model 110</span>
        <span itemprop="definition">permits the correction of potential wrong outputs of the ML model such that it improves overall robustness and is used to calculate an uncertainty value that enables knowledge infusion systems (e.g., systems that employ knowledge infusion) to understand if reality has drifted away from the ML model.</span>
        <meta itemprop="num_attr" content="0055">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Such uncertainty values</span>
        <span itemprop="definition">may be calculated based on the probability values obtained from the ML model as well as the windowed disagreement between the knowledge model and the ML model (e.g., if ML model and Knowledge model disagree in 50% of all cases, this may be a strong indication for a shift).</span>
        <meta itemprop="num_attr" content="0055">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the probability values obtained from the ML model</span>
        <span itemprop="definition">may be/include a confidence value (e.g., 0.9 or 90% confidence of the output from the ML model).</span>
        <meta itemprop="num_attr" content="0055">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the probability values by itself</span>
        <span itemprop="definition">might not be a good indicator of whether the output is correct (e.g., at times, it may be tricked using adversarial inputs).</span>
        <meta itemprop="num_attr" content="0055">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">embodiments of the present invention</span>
        <span itemprop="definition">may combine both the probability values and the windowed disagreement values into an uncertainty value.</span>
        <meta itemprop="num_attr" content="0055">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a moving average of this uncertainty value over a period of time</span>
        <span itemprop="definition">may be used to decide whether the output 206 is added to the knowledge base 104 or if the ML model is re-trained using the knowledge model.</span>
        <meta itemprop="num_attr" content="0055">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the final threshold from block 204 as well as the parameter for the probability and disagreement that is used to determine the uncertainty value</span>
        <span itemprop="definition">may be configured by a user. Because the re-training may occur with an updated knowledge model, the resulting ML model may then better fit to reality, which may result in improved performance. In some instances, the re-training may be performed by the same computing device that set up the knowledge infusion model (e.g., the computing device in FIG. 1 that set up the knowledge infusion model). Additionally, and/or alternatively, a separate computing device (e.g., a more powerful) computing device may be used for re-training the ML model.</span>
        <meta itemprop="num_attr" content="0055">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the uncertainty value</span>
        <span itemprop="definition">may be determined from a combination (e.g., addition) of the probability values and the windowed disagreements values. Additionally, and/or alternatively, these values may first be weighted (e.g., weigh the windowed disagreement value higher or with a stronger weight than the probability values) and then combined together. Additionally, and/or alternatively, in some instances, embodiments of the present invention may just use the windowed disagreement value to determine the uncertainty value.</span>
        <meta itemprop="num_attr" content="0056">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the workflow</span>
        <span itemprop="definition">may be as follows:</span>
        <meta itemprop="num_attr" content="0057">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">users</span>
        <span itemprop="definition">may use the user interface 106 to develop weak and strong knowledge functions. These functions may interface with an internal knowledge base 104 (e.g., through a query language) and external knowledge sources 102 (e.g., through available APIs). Knowledge functions output a label or action based on the user provided logic and the knowledge received/queried from the knowledge base and external knowledge sources. For example, the user may define a knowledge function that outputs a transport mode for location traces based on data from an external GIS (e.g., OPENSTREETMAP) and from the user&#39;s logic (e.g., if location is on a highway, transport mode is car).</span>
        <meta itemprop="num_attr" content="0059">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">an external GIS</span>
        <span itemprop="definition">e.g., OPENSTREETMAP</span>
        <meta itemprop="num_attr" content="0059">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">knowledge functions</span>
        <span itemprop="definition">become adaptive such as by changing their behavior with a new context from the knowledge base (e.g., road has a new speed limit).</span>
        <meta itemprop="num_attr" content="0059">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the user</span>
        <span itemprop="definition">may use the user interface 106 to provide or generate a knowledge function that outputs a label (e.g., class) or action (e.g., what should be done next).</span>
        <meta itemprop="num_attr" content="0059">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the user interface 106 and/or the knowledge infusion device 108</span>
        <span itemprop="definition">may update or adapt this knowledge function based on interfacing with (e.g., receiving information from and/or communicating with) the internal knowledge base 104 and/or the external knowledge sources 102 .</span>
        <meta itemprop="num_attr" content="0059">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the knowledge infusion device 108</span>
        <span itemprop="definition">may store the knowledge functions.</span>
        <meta itemprop="num_attr" content="0059">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the set of knowledge functions from the user interface 106</span>
        <span itemprop="definition">(e.g., that the user has generated) is mapped to ensemble methods in the knowledge function abstraction layer of the knowledge infusion device 108 .</span>
        <meta itemprop="num_attr" content="0061">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">ensemble methods</span>
        <span itemprop="definition">combine multiple supervision sources into a unified model. For example, majority voting ensemble (i.e., majority ensemble) treats each supervision source equally, while other techniques, including a generative ensemble such as SNORKEL (see, e.g., Ratner, Alexander, et al., âSnorkel: Rapid training data creation with weak supervision,â The VLDB Journal 29.2 (2020): 709-730, which is hereby incorporated by reference herein), model the difference in quality of different (weak) sources in a generative process that may provide improved performance.</span>
        <meta itemprop="num_attr" content="0061">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">SNORKEL</span>
        <span itemprop="definition">a generative ensemble</span>
        <meta itemprop="num_attr" content="0061">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Embodiments of the present invention</span>
        <span itemprop="definition">may be configured to use multiple and/or extensible ensemble methods.</span>
        <meta itemprop="num_attr" content="0061">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the knowledge infusion device 108</span>
        <span itemprop="definition">then creates two ensembles and combines them into a Knowledge Model.</span>
        <meta itemprop="num_attr" content="0061">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the two ensembles</span>
        <span itemprop="definition">include a first ensemble that is based on the set of weak knowledge functions and a second ensemble based on the set of strong knowledge functions.</span>
        <meta itemprop="num_attr" content="0061">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Step 3</span>
        <span itemprop="definition">ML Model Training</span>
        <meta itemprop="num_attr" content="0062">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the ML model</span>
        <span itemprop="definition">may be trained using the created knowledge model. This training may help to generalize beyond the knowledge encoded in the knowledge model by discovering new patterns in the data and removing some of the noise of the knowledge model, which increases the overall performance of the ML model as compared to the knowledge model.</span>
        <meta itemprop="num_attr" content="0063">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the knowledge functions</span>
        <span itemprop="definition">may be combined together and used to label the data.</span>
        <meta itemprop="num_attr" content="0063">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the knowledge functions</span>
        <span itemprop="definition">may be combined in many ways (e.g., in ensembles such as a majority ensemble). Further, due to the classification of weak and strong functions, the output of the strong functions may override the output of weak functions.</span>
        <meta itemprop="num_attr" content="0063">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">this step</span>
        <span itemprop="definition">may be omitted because the agent may be âtrainedâ actively through interactions with its environment. Additionally, and/or alternatively, in an embodiment of the present invention, the present invention may use the knowledge model to pre-train the RL policy instead of training it actively during runtime (e.g., execution). This will be discussed in further detail below.</span>
        <meta itemprop="num_attr" content="0064">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Step 4</span>
        <span itemprop="definition">Combination of Knowledge Model and ML Model into Knowledge Fusion Model</span>
        <meta itemprop="num_attr" content="0065">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the knowledge model and the trained ML model</span>
        <span itemprop="definition">may be packaged into a self-contained knowledge fusion model 110 .</span>
        <meta itemprop="num_attr" content="0066">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">This model 110</span>
        <span itemprop="definition">includes a fusion component that processes the outputs of both the ML model and the knowledge model to create a single output (e.g., the strong ensemble might over-write the output of the ML model) and the logic to calculate and/or act on a configurable uncertainty value.</span>
        <meta itemprop="num_attr" content="0066">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the fusion component</span>
        <span itemprop="definition">may be software code implemented by hardware (e.g., processor/memory of a computing device) that processes both outputsâthe one from the knowledge model and the one from the ML mode.</span>
        <meta itemprop="num_attr" content="0066">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the weak ensemble</span>
        <span itemprop="definition">e.g., the weak functions</span>
        <meta itemprop="num_attr" content="0066">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the outputs of the weak ensemble</span>
        <span itemprop="definition">(together with the strong ensemble) may be used to determine when the black-box ML model does not fit to reality (input data distribution) anymore based on the disagreement and probability values described above.</span>
        <meta itemprop="num_attr" content="0066">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Step 5</span>
        <span itemprop="definition">Execution of Knowledge Fusion Model</span>
        <meta itemprop="num_attr" content="0067">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the knowledge fusion model 110</span>
        <span itemprop="definition">is deployed (e.g., in a container, or as part of an IoT cloud-edge framework) and processes new data 202 .</span>
        <meta itemprop="num_attr" content="0068">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the incoming data 202</span>
        <span itemprop="definition">is processed by both the ML model and the knowledge model. Their output is then processed by a knowledge fusion component, which evaluates both outputs.</span>
        <meta itemprop="num_attr" content="0068">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the knowledge fusion component</span>
        <span itemprop="definition">may overwrite outputs in which input states are covered by the strong ensemble (e.g., based on the strong knowledge functions provided initially by the user) with the outputs of the strong ensemble. This achieves robustness and helps to avoid unsafe outputs.</span>
        <meta itemprop="num_attr" content="0068">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the knowledge fusion component</span>
        <span itemprop="definition">also outputs a calculated uncertainty value based on the outputs of the knowledge model and the ML model as well as the probability values available for ML models.</span>
        <meta itemprop="num_attr" content="0068">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the moving mean value of the uncertainty value</span>
        <span itemprop="definition">may be calculated and based on a configurable threshold (e.g., user-defined threshold), embodiments of the present invention may determine one of the following decisions:</span>
        <meta itemprop="num_attr" content="0070">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the knowledge base 104</span>
        <span itemprop="definition">may be updated with the new output from the knowledge fusion model 110 .</span>
        <meta itemprop="num_attr" content="0072">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the knowledge model within the knowledge fusion model 110</span>
        <span itemprop="definition">may be updated using the new knowledge from the knowledge base 104 (e.g., for a different location context).</span>
        <meta itemprop="num_attr" content="0072">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the moving mean value of the uncertainty value</span>
        <span itemprop="definition">is greater than the threshold, this may indicate that reality (e.g., data distribution, environment properties) may have shifted away from the ML model and the ML model might not be able to create outputs with a good performance (e.g., with sufficient accuracy).</span>
        <meta itemprop="num_attr" content="0074">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a re-training of the ML model</span>
        <span itemprop="definition">(for the RL agent, the RL policy may be reset) may be triggered. The re-training may occur through the continuously updated knowledge model that reflects changes in external 102 and internal knowledge bases 104 through its adaptive knowledge functions.</span>
        <meta itemprop="num_attr" content="0074">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the knowledge model part</span>
        <span itemprop="definition">may automatically be updated based on knowledge about speed limits and/or street and public transport characteristics (e.g., a new bus line) from a GIS knowledge base.</span>
        <meta itemprop="num_attr" content="0074">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the knowledge fusion model 110 for RL</span>
        <span itemprop="definition">may be used to pre-train the RL policy rather than performing it and/or training it actively.</span>
        <meta itemprop="num_attr" content="0076">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the knowledge fusion model 110</span>
        <span itemprop="definition">may be used as an offline âteacherâ for the RL agent in combination with already available data of states&#39; transitions or some model of states&#39; transitions of the RL environment and some basic reward scheme.</span>
        <meta itemprop="num_attr" content="0076">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the states&#39; transitions</span>
        <span itemprop="definition">may be fed to both the RL agent and the Knowledge Model and then a reward may be calculated (e.g., a conflict between the RL agent&#39;s chosen action and Knowledge Model&#39;s chosen actions may be used as a negative reward whereas agreements may be used as a positive reward for the RL agent).</span>
        <meta itemprop="num_attr" content="0076">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">This process</span>
        <span itemprop="definition">is iterated until the RL policy acquires a certain degree of agreements with the Knowledge Model such that the initial performance of the RL agent in the real environment is improved.</span>
        <meta itemprop="num_attr" content="0076">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the knowledge model</span>
        <span itemprop="definition">may be executed for uncertain outputs of the ML model (based on the perceived probability).</span>
        <meta itemprop="num_attr" content="0077">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the knowledge model</span>
        <span itemprop="definition">may be executed for uncertain inputs (e.g., inputs that the ML model cannot clearly discriminate). For example, for inputs where the ML model is very certain, the knowledge model may agree with the ML model in most cases. As such, this embodiment may save additional computational resources.</span>
        <meta itemprop="num_attr" content="0077">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the knowledge model</span>
        <span itemprop="definition">may be updated based on batch processing instead of streaming-based processing. For instance, in steaming-based processing, the knowledge model may be updated for each new data input that is processed (e.g., a new value that is received from a sensor). However, in some embodiments, the present invention may also update the knowledge model in batches (e.g., after multiple new data input values are available). This reduces processing time. For example, the interval for new batches may either be fixed (e.g., every tenth new value) or it can be done when a threshold parameter on the probability of the ML model is reached. For instance, when uncertainty of the ML model rises, it cannot discriminate well between its output classes/actions. Through the re-creation of the knowledge model, the present invention may then verify if the ML model is to be re-trained.</span>
        <meta itemprop="num_attr" content="0078">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the interval for new batches</span>
        <span itemprop="definition">may either be fixed (e.g., every tenth new value) or it can be done when a threshold parameter on the probability of the ML model is reached. For instance, when uncertainty</span>
        <meta itemprop="num_attr" content="0078">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Human-In-The-Loop</span>
        <span itemprop="definition">may be used for re-training of ML model.</span>
        <meta itemprop="num_attr" content="0079">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a human</span>
        <span itemprop="definition">e.g., user operating a computing device such as user interface 106</span>
        <meta itemprop="num_attr" content="0079">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a human</span>
        <span itemprop="definition">may manually perform small tweaks to the existing functions or add/remove knowledge functions and verify the overall performance of the knowledge model using a small, labeled testing data-set.</span>
        <meta itemprop="num_attr" content="0079">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 3</span>
        <span itemprop="definition">illustrates an embodiment 300 of the present invention that uses a knowledge infusion system in the context of a smart city.</span>
        <meta itemprop="num_attr" content="0081">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the knowledge fusion model</span>
        <span itemprop="definition">receives input (e.g., data 202 ) directly from sensors 302 (e.g., sensing infrastructure) available in the city. These sensors 302 may be either from individual wearables and smartphones and/or from infrastructure in the city, such as video cameras and environmental sensors.</span>
        <meta itemprop="num_attr" content="0081">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">New sensor data 202</span>
        <span itemprop="definition">will be processed by the knowledge infusion model and system 110 and based on the perceived uncertainty, will either result in a re-training of the ML model or a successful classification/action.</span>
        <meta itemprop="num_attr" content="0082">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the output</span>
        <span itemprop="definition">is sent to the smart city platform 304 .</span>
        <meta itemprop="num_attr" content="0082">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the city platform 304</span>
        <span itemprop="definition">may then perform an actuation (e.g., change the traffic light schedule) in the city using the actuating infrastructure 306 and also updates the city knowledge graph 104 with the output.</span>
        <meta itemprop="num_attr" content="0082">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the knowledge fusion model 110</span>
        <span itemprop="definition">may directly query the city knowledge graph for updating its state (e.g., its knowledge that is used in the knowledge functions).</span>
        <meta itemprop="num_attr" content="0082">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a city sensing and actuating infrastructure</span>
        <span itemprop="definition">may be unified and abstracted to the present invention through a smart city platform that handles accessing these sensors and actuators and makes them available through a common interface for various applications.</span>
        <meta itemprop="num_attr" content="0083">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 4</span>
        <span itemprop="definition">illustrates an embodiment 400 of the present invention that uses such a variation in which the city platform plays a more central role in connecting to the sensing 404 and actuating infrastructure 406 of the city.</span>
        <meta itemprop="num_attr" content="0083">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the smart city platform 402</span>
        <span itemprop="definition">connects to the city sensing infrastructure 404 and stores new values in the knowledge graph 104 .</span>
        <meta itemprop="num_attr" content="0083">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the present invention</span>
        <span itemprop="definition">will subscribe through an available interface directly to the knowledge graph 104 to receive both: (1) New updates from sensing infrastructure 404 and (2) knowledge updates. Outputs will be sent to the city platform 402 , which then performs necessary actuations using the actuating infrastructure 406 and stores the outputs in the knowledge graph 104 .</span>
        <meta itemprop="num_attr" content="0083">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 5</span>
        <span itemprop="definition">illustrates a knowledge infusion system 500 for Building Management according to an embodiment of the present invention.</span>
        <meta itemprop="num_attr" content="0085">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">non-residential buildings</span>
        <span itemprop="definition">usually include a Building Management System (BMS) that connects and controls building sub-systems such as lighting, heating, ventilation and air conditioning or automatic blinds.</span>
        <meta itemprop="num_attr" content="0085">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">BMS</span>
        <span itemprop="definition">consist of multiple, tightly integrated layers from management level 512 to automation 514 and field level 516 .</span>
        <meta itemprop="num_attr" content="0085">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the field level 516</span>
        <span itemprop="definition">contains single sensors and actuators (e.g., HVAC devices 506 , light devices 508 , and blind devices 510 ).</span>
        <meta itemprop="num_attr" content="0085">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the present invention</span>
        <span itemprop="definition">may connect to such a system through an interface to the BMS server 502 on the management level 512 .</span>
        <meta itemprop="num_attr" content="0085">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the BMS server 502</span>
        <span itemprop="definition">may receive updates from sensor values that are then processed by the knowledge fusion model 110 .</span>
        <meta itemprop="num_attr" content="0085">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the knowledge fusion model 110 and block 504</span>
        <span itemprop="definition">may send actuation commands directly to the BMS server 502 that result in changed building configurations, such as HVAC setting, lighting or blinds changes.</span>
        <meta itemprop="num_attr" content="0085">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the present invention</span>
        <span itemprop="definition">directly updates the knowledge graph 104 with new sensing values and the outputs of the knowledge fusion model 110 .</span>
        <meta itemprop="num_attr" content="0086">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Other applications and users</span>
        <span itemprop="definition">might update the knowledge graph 104 as well.</span>
        <meta itemprop="num_attr" content="0086">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the present invention</span>
        <span itemprop="definition">is able to adapt the model automatically and ensure robustness in its output according to safety regulations.</span>
        <meta itemprop="num_attr" content="0086">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">NGSI-LD</span>
        <span itemprop="definition">allows users to query knowledge sources through a standardized query interface, while using open and shared data models. It is especially popular in the context of Internet of Things systems, such as the ones seen in smart cities (see, e.g., ETSI GS CIM 009: âContext Information Management (CIM); NGSI-LD API,â https://www.etsi.org/deliver/etsi_gs/CIM/001_099/009/01.02.01_60/gs_CIM009v010201p.pdf, which is hereby incorporated by reference herein).</span>
        <meta itemprop="num_attr" content="0088">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">CIM</span>
        <span itemprop="definition">Context Information Management</span>
        <meta itemprop="num_attr" content="0088">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the below example</span>
        <span itemprop="definition">shows an instance of the present invention that uses an NGSI-LD accessible knowledge base to retrieve public weather data.</span>
        <meta itemprop="num_attr" content="0089">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the application scenario</span>
        <span itemprop="definition">is that the user is interested in classifying two classes: âFIREâ or âNO_FIREâ, based on sensed temperature values deployed inside a building.</span>
        <meta itemprop="num_attr" content="0089">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the weak knowledge function below</span>
        <span itemprop="definition">shows an example that takes as input the sensed temperature (e.g., from sensors deployed in the building) and the knowledge source used.</span>
        <meta itemprop="num_attr" content="0089">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the endpoint</span>
        <span itemprop="definition">is an NGSI-LD endpoint, but the present invention may support any available application programming interfaces (APIs) and query interfaces (e.g., a SPARQL endpoint or any available Web API).</span>
        <meta itemprop="num_attr" content="0089">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">APIs</span>
        <span itemprop="definition">application programming interfaces</span>
        <meta itemprop="num_attr" content="0089">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">SPARQL endpoint</span>
        <span itemprop="definition">e.g., a SPARQL endpoint or any available Web API</span>
        <meta itemprop="num_attr" content="0089">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the sensed temperature entity</span>
        <span itemprop="definition">has multiple context/meta-data associated with it, which is unpacked in line 02-04 (the actual value, the location and the time).</span>
        <meta itemprop="num_attr" content="0090">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the payload for the NGSI-LD interface</span>
        <span itemprop="definition">is constructed, which will query temperature data from available weather observations in a proximity of 100 meters (m) to the sensed temperature entity.</span>
        <meta itemprop="num_attr" content="0091">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a method and system for automated knowledge infusion for robust and transferable machine learning in IoT systems</span>
        <span itemprop="definition">comprises the steps of:</span>
        <meta itemprop="num_attr" content="0098">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 6</span>
        <span itemprop="definition">is an exemplary process 600 for using knowledge infusion for robust and transferable machine learning models for IoT systems in accordance with one or more embodiments of the present application.</span>
        <meta itemprop="num_attr" content="0107">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the descriptions, illustrations, and processes of FIG. 6</span>
        <span itemprop="definition">are merely exemplary and the process 600 may use other descriptions, illustrations, and processes using knowledge infusion for robust and transferable machine learning models for IoT systems.</span>
        <meta itemprop="num_attr" content="0107">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the process 600</span>
        <span itemprop="definition">may be performed by one or more computing devices.</span>
        <meta itemprop="num_attr" content="0107">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the computing devices</span>
        <span itemprop="definition">may include one or more processors and memory.</span>
        <meta itemprop="num_attr" content="0107">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the memory</span>
        <span itemprop="definition">may store instructions that when executed by the one or more processors, are configured to perform the process 600 .</span>
        <meta itemprop="num_attr" content="0107">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a computing device</span>
        <span itemprop="definition">receives a plurality of adaptive and programmable knowledge functions.</span>
        <meta itemprop="num_attr" content="0108">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the knowledge functions</span>
        <span itemprop="definition">may include a plurality of strong functions (e.g., axioms) and a plurality of weak functions (e.g., mostly true statements).</span>
        <meta itemprop="num_attr" content="0108">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the user interface 106</span>
        <span itemprop="definition">may provide the plurality of adaptive and programmable knowledge functions to a computing device such as the knowledge infusion computing device 108 .</span>
        <meta itemprop="num_attr" content="0108">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the computing device and/or the user interface 106</span>
        <span itemprop="definition">may update the knowledge functions using one or more external knowledge sources 102 and/or an internal knowledge base 104 (e.g., through a query language).</span>
        <meta itemprop="num_attr" content="0109">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the external knowledge sources 102</span>
        <span itemprop="definition">may include APIs (e.g., weather APIs) and/or knowledge graphs such as ontologies.</span>
        <meta itemprop="num_attr" content="0109">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the knowledge functions</span>
        <span itemprop="definition">may output a label or action based on the user provided logic and the knowledge received/queried from the knowledge base and external knowledge sources.</span>
        <meta itemprop="num_attr" content="0109">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the computing device</span>
        <span itemprop="definition">generates a knowledge model based on the plurality of strong functions and the plurality of weak functions. For example, to generate the knowledge model, the computing device may map the strong and weak functions to one or more ensemble methods (e.g. a majority ensemble method, a generative ensemble method, or a Tutor for Reinforced Learning (Tutor4RL) ensemble method).</span>
        <meta itemprop="num_attr" content="0110">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">ensemble methods</span>
        <span itemprop="definition">e.g. a majority ensemble method, a generative ensemble method, or a Tutor for Reinforced Learning (Tutor4RL) ensemble method.</span>
        <meta itemprop="num_attr" content="0110">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the computing device and/or the user interface 106</span>
        <span itemprop="definition">may continuously maintain the knowledge model based on continuously querying the one or more external knowledge sources 102 and/or the knowledge base 104 to provide and update the plurality of weak and strong functions. For instance, each time a pre-defined time period elapses, the computing device and/or the user interface 106 may provide a query to the external knowledge sources 102 and/or the knowledge base 104 indicating whether any knowledge functions are to be updated. Based on the query, the computing device and/or user interface 106 may receive updated information from the external knowledge sources 102 and/or the knowledge base 104 and may use the updated information to update the weak and strong functions.</span>
        <meta itemprop="num_attr" content="0111">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the computing device</span>
        <span itemprop="definition">trains a machine learning model based on the generated knowledge model.</span>
        <meta itemprop="num_attr" content="0112">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the computing device</span>
        <span itemprop="definition">may use the strong and weak functions and/or ensembles to train a machine learning model.</span>
        <meta itemprop="num_attr" content="0112">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the machine learning model</span>
        <span itemprop="definition">may be a supervised machine learning model and/or a reinforced learning (RL) model.</span>
        <meta itemprop="num_attr" content="0112">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">block 606</span>
        <span itemprop="definition">may be performed subsequent to block 608 (e.g., deploying the machine learning model and/or the knowledge model within an environment).</span>
        <meta itemprop="num_attr" content="0113">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the machine learning model</span>
        <span itemprop="definition">may be an RL model that may be actively trained within the environment during runtime.</span>
        <meta itemprop="num_attr" content="0113">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the computing device</span>
        <span itemprop="definition">(or another computing device) may train the RL model during runtime and after deployment.</span>
        <meta itemprop="num_attr" content="0113">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the machine learning model</span>
        <span itemprop="definition">may be an RL model and the computing device may pre-train the RL model (e.g., RL policy) prior to deployment (e.g., prior to block 608 ).</span>
        <meta itemprop="num_attr" content="0113">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the computing device</span>
        <span itemprop="definition">may use the knowledge model as an offline âteacherâ to train the RL model prior to deployment.</span>
        <meta itemprop="num_attr" content="0113">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the computing device</span>
        <span itemprop="definition">deploys the machine learning model and the knowledge model within an environment to perform one or more operations.</span>
        <meta itemprop="num_attr" content="0114">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the computing device</span>
        <span itemprop="definition">may package the machine learning model, the knowledge model, and/or a knowledge fusion component within a knowledge fusion model (e.g., knowledge fusion model 110 ).</span>
        <meta itemprop="num_attr" content="0114">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the computing device</span>
        <span itemprop="definition">may deploy the knowledge fusion model as a container and/or as part of an IoT cloud-edge framework.</span>
        <meta itemprop="num_attr" content="0114">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the environments</span>
        <span itemprop="definition">may include, but are not limited to, operation within a smart city (e.g., a smart city system), operation for building management (e.g., a building energy management system), operation using NGSI-LD knowledge sources, operation for a data center (e.g., a data center energy management system), and/or operation in a retail system (e.g., a smart retail system).</span>
        <meta itemprop="num_attr" content="0114">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a smart city</span>
        <span itemprop="definition">e.g., a smart city system</span>
        <meta itemprop="num_attr" content="0114">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">operation for building management</span>
        <span itemprop="definition">e.g., a building energy management system</span>
        <meta itemprop="num_attr" content="0114">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">operation using NGSI-LD knowledge sources</span>
        <span itemprop="definition">e.g., a data center energy management system</span>
        <meta itemprop="num_attr" content="0114">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a data center energy management system</span>
        <span itemprop="definition">e.g., a data center energy management system</span>
        <meta itemprop="num_attr" content="0114">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a retail system</span>
        <span itemprop="definition">e.g., a smart retail system</span>
        <meta itemprop="num_attr" content="0114">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the computing device</span>
        <span itemprop="definition">may provide the knowledge fusion model including the machine learning model, the knowledge model, and/or the knowledge fusion component to a second computing device.</span>
        <meta itemprop="num_attr" content="0115">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the computing device</span>
        <span itemprop="definition">performs the one or more operations within the environment using the machine learning model and the knowledge model. For example, subsequent to deploying the machine learning model and the knowledge model within the environment, the first or second computing device receives new data (e.g., data 202 from FIG. 2 ) associated with the environment from one or more sensors. The computing device may input the new data into the machine learning model and/or the knowledge model. Based on inputting the new data into the machine learning model, the computing device may determine or generate one or more machine learning model outputs and/or one or more probability values associated with the machine learning model outputs.</span>
        <meta itemprop="num_attr" content="0116">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">new data</span>
        <span itemprop="definition">e.g., data 202 from FIG. 2</span>
        <meta itemprop="num_attr" content="0116">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the computing device</span>
        <span itemprop="definition">may input the new data into the machine learning model and/or the knowledge model. Based on inputting the new data into the machine learning model, the computing device may determine or generate one or more machine learning model outputs and/or one or more probability values associated with the machine learning model outputs.</span>
        <meta itemprop="num_attr" content="0116">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the computing device</span>
        <span itemprop="definition">may determine or generate one or more knowledge model outputs.</span>
        <meta itemprop="num_attr" content="0116">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the computing device</span>
        <span itemprop="definition">may use the knowledge fusion component of the knowledge fusion model 110 to determine a fused output. For instance, based on the knowledge model outputs and the machine learning model outputs, the computing device may correct and/or overwrite the machine learning model outputs using the knowledge model outputs. For example, if the knowledge model outputs (e.g., the outputs from the strong knowledge functions) contradict the outputs from the machine learning model, the computing device may overwrite or correct the machine learning model outputs with the outputs from the strong knowledge functions. Additionally, and/or alternatively, the computing device may determine a disagreement value based on the disagreements between the knowledge and machine learning models (e.g., contradictions of outputs from knowledge model and machine learning model).</span>
        <meta itemprop="num_attr" content="0116">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the computing device</span>
        <span itemprop="definition">may determine an uncertainty value based on the one or more machine learning model outputs and/or the one or probability values.</span>
        <meta itemprop="num_attr" content="0117">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the uncertainty value</span>
        <span itemprop="definition">represents uncertainty of the one or more machine learning model outputs from the machine learning model.</span>
        <meta itemprop="num_attr" content="0117">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the computing device</span>
        <span itemprop="definition">may calculate or determine the uncertainty value based on the one or more probability values and the disagreement value. For instance, as described above, the computing device may combine the disagreement value and the probability values to determine the uncertainty value.</span>
        <meta itemprop="num_attr" content="0117">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the computing device</span>
        <span itemprop="definition">may compare the uncertainty value with a threshold (e.g., as described in block 204 ). Based on the uncertainty value not exceeding (e.g., being less than) the threshold, the computing device may update a knowledge base 104 using the one or more machine learning model outputs. Additionally, and/or alternatively, the computing device may update the knowledge model within the knowledge fusion model 110 using the updated knowledge base 104 . Based on the uncertainty value exceeding (e.g., being greater than) the threshold, the computing device may re-train the machine learning model.</span>
        <meta itemprop="num_attr" content="0118">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a threshold</span>
        <span itemprop="definition">e.g., as described in block 204 .</span>
        <meta itemprop="num_attr" content="0118">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the computing device</span>
        <span itemprop="definition">may update a knowledge base 104 using the one or more machine learning model outputs. Additionally, and/or alternatively, the computing device may update the knowledge model within the knowledge fusion model 110 using the updated knowledge base 104 . Based on the uncertainty value exceeding (e.g., being greater than) the threshold, the computing device may re-train the machine learning model.</span>
        <meta itemprop="num_attr" content="0118">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the computing device</span>
        <span itemprop="definition">may re-train the machine learning model using the knowledge base 104 and/or the updated knowledge base 104 (e.g., the knowledge base 104 that has been updated with one or more outputs from the machine learning model and/or the external knowledge sources 102 ).</span>
        <meta itemprop="num_attr" content="0118">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the updated knowledge base 104</span>
        <span itemprop="definition">e.g., the knowledge base 104 that has been updated with one or more outputs from the machine learning model and/or the external knowledge sources 102 .</span>
        <meta itemprop="num_attr" content="0118">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the computing device that re-trains the machine learning model</span>
        <span itemprop="definition">may be the same computing device that initially trained the machine learning model.</span>
        <meta itemprop="num_attr" content="0119">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the set-up phase</span>
        <span itemprop="definition">e.g., blocks 602 - 608</span>
        <meta itemprop="num_attr" content="0119">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the execution phase</span>
        <span itemprop="definition">e.g., block 610</span>
        <meta itemprop="num_attr" content="0119">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the second computing device</span>
        <span itemprop="definition">may provide instructions to the first computing to re-train the machine learning model.</span>
        <meta itemprop="num_attr" content="0119">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the first device</span>
        <span itemprop="definition">may provide the re-trained machine learning model back to the second computing device.</span>
        <meta itemprop="num_attr" content="0119">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the computing device</span>
        <span itemprop="definition">may determine a moving average associated with the uncertainty value.</span>
        <meta itemprop="num_attr" content="0120">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the computing device</span>
        <span itemprop="definition">may determine a plurality of uncertainty values over a period of time and determine a moving average based on the uncertainty values.</span>
        <meta itemprop="num_attr" content="0120">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the computing device</span>
        <span itemprop="definition">may compare the moving average with a threshold to determine whether to update the knowledge base 104 with the outputs from the machine learning model or whether to re-train the machine learning model with the knowledge model.</span>
        <meta itemprop="num_attr" content="0120">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Machine learning (ML) applications in Internet of Things (IoT) scenarios</span>
        <span itemprop="definition">face the issue that supervision signals, such as labeled data, may be scarce and expensive to obtain. For example, it often requires a human to manually label events in a data stream by observing the same events in the real world.</span>
        <meta itemprop="num_attr" content="0122">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the performance of trained models</span>
        <span itemprop="definition">usually depends on a specific context: (1) location, (2) time and (3) data quality. This context is not static in reality, making it hard to achieve robust and transferable machine learning for IoT systems in practice. Below, these challenges are addressed with a Knowledge Infusion method and system.</span>
        <meta itemprop="num_attr" content="0122">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 7</span>
        <span itemprop="definition">illustrates the context-dimensions (e.g., Time, Location, and Data Quality) of ML in IoT systems.</span>
        <meta itemprop="num_attr" content="0123">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">RF</span>
        <span itemprop="definition">radio-frequency</span>
        <meta itemprop="num_attr" content="0124">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">machine learning in the IoT domain</span>
        <span itemprop="definition">needs to achieve robustness and transferability during setup/training as well as during execution phase in order to deal with such varying context.</span>
        <meta itemprop="num_attr" content="0127">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">this knowledge model</span>
        <span itemprop="definition">is used to train any traditional supervised machine learning model (e.g., using the labels generated with the knowledge model). As has been demonstrated, the machine learning model will usually perform better than the model/labels used for training it. The reason is that the machine learning model will learn to generalize the patterns found in the data while also partially removing noise in it.</span>
        <meta itemprop="num_attr" content="0128">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the âwhite-boxâ knowledge model</span>
        <span itemprop="definition">is continuously updated (through new knowledge or added/updated knowledge functions) and then used to ensure robustness of the system during execution, while also identifying situations in which the context in the real world shifts away from the trained ML model and re-training is needed.</span>
        <meta itemprop="num_attr" content="0129">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Transport mode detection</span>
        <span itemprop="definition">is a key enabler for physical activity monitoring as well as personal environmental impact monitoring. It is also critical to optimize urban multimodal human mobility and to enable end-user applications, such as automated and individual carbon dioxide (CO2) emission tracking.</span>
        <meta itemprop="num_attr" content="0133">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">CO2</span>
        <span itemprop="definition">carbon dioxide</span>
        <meta itemprop="num_attr" content="0133">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Transport mode detection</span>
        <span itemprop="definition">requires a two-step segmentation of sensor data to trips and sections (based on transport modes), and an accurate classification of these sections into modes (e.g., walking, bicycling, riding a bus).</span>
        <meta itemprop="num_attr" content="0134">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">previous examples</span>
        <span itemprop="definition">have proposed transport mode detection using smartphone sensors such as GPS, accelerometer, barometer, or combinations of these and adding geographic information system (GIS) data to improve accuracy.</span>
        <meta itemprop="num_attr" content="0134">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">GIS</span>
        <span itemprop="definition">geographic information system</span>
        <meta itemprop="num_attr" content="0134">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Most of these examples</span>
        <span itemprop="definition">leverage supervised ML using labeled data points as training data. This labeled data is usually provided by users/participants of the studies.</span>
        <meta itemprop="num_attr" content="0134">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Embodiments of the present invention</span>
        <span itemprop="definition">address the transport mode detection problem by adopting weak supervision techniques originally used in information extraction to this problem.</span>
        <meta itemprop="num_attr" content="0136">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 8</span>
        <span itemprop="definition">illustrates the main building blocks used to address the transport mode detection problem according to an embodiment of the present invention. In particular, FIG. 8 shows the transport mode detection steps.</span>
        <meta itemprop="num_attr" content="0136">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">sensor data</span>
        <span itemprop="definition">location and activity data</span>
        <meta itemprop="num_attr" content="0137">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">segmentation Phase 804</span>
        <span itemprop="definition">time series from multiple sensors is aligned to the same sampling time and segment time series first into trips (by applying a dwell time heuristics) and section candidates (using a developed activity supported walk point segmentation algorithm). The outcome of this step is a set of section candidates, each candidate contains a time-series of location and activity data points.</span>
        <meta itemprop="num_attr" content="0137">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a set of labeling functions</span>
        <span itemprop="definition">is applied to these candidates.</span>
        <meta itemprop="num_attr" content="0138">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Each function</span>
        <span itemprop="definition">encodes human heuristics and/or external knowledge (e.g., from OPENSTREETMAP) to âvoteâ on the transport class of a candidate section.</span>
        <meta itemprop="num_attr" content="0138">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the resulting label matrix</span>
        <span itemprop="definition">is fed into the generative ensemble, which learns a generative model from all labeling functions and their votes on each candidate section, taking into account the underlying accuracy of each labeling function.</span>
        <meta itemprop="num_attr" content="0138">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the generative model</span>
        <span itemprop="definition">is used to label all candidate segments and train a discriminative ML model with the probabilistic labels.</span>
        <meta itemprop="num_attr" content="0139">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the ML model</span>
        <span itemprop="definition">generalizes beyond the information encoded in the labeling functions.</span>
        <meta itemprop="num_attr" content="0139">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">this model</span>
        <span itemprop="definition">is then used to classify incoming candidate section into transport modes. Based on this classification, re-segmentation is performed by merging adjacent sections of the same mode and the results (classified trips and sections) are returned to users.</span>
        <meta itemprop="num_attr" content="0139">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">This method</span>
        <span itemprop="definition">was validated against a dataset that was collected in the wild over a period of 4 months, containing 300,000 datapoints from 8 end-users.</span>
        <meta itemprop="num_attr" content="0141">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Global positioning system (GPS) location</span>
        <span itemprop="definition">was sensed through iOS and Android Location API and accelerometer based activity data through the Activity API. Users have partially labeled data with a developed visual labeling tool. This data was used to evaluate the method of the present invention, splitting the data in training (1 â 2) and test data (1 â 2). The method classifies four transport modes: walk, bike, car and train.</span>
        <meta itemprop="num_attr" content="0141">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Embodiments of the present invention</span>
        <span itemprop="definition">uses seven labeling functions that combine external knowledge with sensor data to vote on the transport classification of a section. For example, functions are implemented that use the sensed speed together with human heuristics on common speeds for different modalities to vote on the transport mode (LF_median_sensed_speed and LF_quantile_sensed_speed). OPENSTREETMAP (OSM) may be integrated and used to the provided annotations of public transport stops (LF_osm). ML models may be trained using the data labeled by the generative model, oversampling underrepresented classes with synthetic minority oversampling technique (SMOTE).</span>
        <meta itemprop="num_attr" content="0142">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">SMOTE</span>
        <span itemprop="definition">synthetic minority oversampling technique</span>
        <meta itemprop="num_attr" content="0142">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 9</span>
        <span itemprop="definition">illustrates a table 900 that summarizes the overall results (e.g., F1 scores) of generated labels and end models against hand-labeled ground truth.</span>
        <meta itemprop="num_attr" content="0144">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">F1 score for fully-supervised random forest</span>
        <span itemprop="definition">was 81.0%.</span>
        <meta itemprop="num_attr" content="0144">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the F1 score for weakly-supervised random forest</span>
        <span itemprop="definition">was 80.2%.</span>
        <meta itemprop="num_attr" content="0144">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the F1 score for generative model (generated labels)</span>
        <span itemprop="definition">was 74.1%.</span>
        <meta itemprop="num_attr" content="0144">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Reinforcement Learning</span>
        <span itemprop="definition">has been proven its ability to deal with complex problems, achieving super-human performance in some cases.</span>
        <meta itemprop="num_attr" content="0146">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">its applicability in real-world problems</span>
        <span itemprop="definition">is still lagging for a number of reasons, including: (1) learning on the real system from limited samples, and (2) safety constraints that should never or at least rarely be violated.</span>
        <meta itemprop="num_attr" content="0146">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Several approaches</span>
        <span itemprop="definition">have emerged to address these problems such as (1) learning from human demonstrations or historical data, and (2) calculating uncertainty in decisions to manage safety and combinations with supervised learning and human intervention.</span>
        <meta itemprop="num_attr" content="0146">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">RL</span>
        <span itemprop="definition">has been applied to computer systems tasks, such as database management system configuration or container orchestration for Big Data and IoT systems.</span>
        <meta itemprop="num_attr" content="0147">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the traditional approaches</span>
        <span itemprop="definition">are not applicable or are inconvenient because (1) data from the system might not be available if the system is new, and even when data is available, the system deployment, load and parameters vary, making these data partially true at best; in addition, (2) the cost of incorrect actions might be high when dealing with systems in production environments, training a supervised model might not possible for the reasons mentioned before, and the reaction of a human operator is expensive and slow to accommodate the system performance in a timely manner.</span>
        <meta itemprop="num_attr" content="0147">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 10</span>
        <span itemprop="definition">illustrates the Tutor4RL used to address the problems addressed above to make RL applicable to real-world problems according to an embodiment of the present invention.</span>
        <meta itemprop="num_attr" content="0149">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 10</span>
        <span itemprop="definition">shows the overall working of the Tutor4RL.</span>
        <meta itemprop="num_attr" content="0149">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Tutor 1004</span>
        <span itemprop="definition">a new component 1004 is added to the regular RL framework called Tutor 1004 to guide the agent&#39;s 1006 decisions when the agent 1006 has no or little experience.</span>
        <meta itemprop="num_attr" content="0150">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the tutor 1004</span>
        <span itemprop="definition">is able to guide the agent 1006 to take reasonable decisions because it can directly leverage a set of knowledge functions 1002 defined by domain experts 1004 . In this way, Tutor4RL improves greatly the performance of the agent 1006 in its early phase.</span>
        <meta itemprop="num_attr" content="0150">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the tutor 1004</span>
        <span itemprop="definition">possesses external knowledge and interacts with the agent 1006 during training.</span>
        <meta itemprop="num_attr" content="0151">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the tutor 1004</span>
        <span itemprop="definition">takes as input the state of the environment, and outputs the action to take; in a similar way to the agent&#39;s policy.</span>
        <meta itemprop="num_attr" content="0151">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the tutor 1004</span>
        <span itemprop="definition">is implemented as programmable functions, in which external knowledge is used to decide the mapping between states and actions (e.g., for ATARI Breakout, the tutor 1004 takes the frame from the video game as input, and outputs in what direction the bar should be moved).</span>
        <meta itemprop="num_attr" content="0151">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the tutor 1004</span>
        <span itemprop="definition">interacts with the agent 1006 and gives advice to the agent 1006 for making better decisions, based on all provided knowledge functions 1002 .</span>
        <meta itemprop="num_attr" content="0151">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the parameter  â</span>
        <span itemprop="definition">is defined that assumes a value in the range (0, 1), which is linearly decreased during training.</span>
        <meta itemprop="num_attr" content="0152">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">â</span>
        <span itemprop="definition">is a parameter of the model and the best value to initialize it depends on the use case; thus its initial value is left to be decided during implementation.</span>
        <meta itemprop="num_attr" content="0152">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the tutor&#39;s behavior</span>
        <span itemprop="definition">provides a guide to the agent 1006 , but the agent 1006 may still improve upon it, reaching an even better performance than the one defined by experts 1010 .</span>
        <meta itemprop="num_attr" content="0153">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">This</span>
        <span itemprop="definition">is achieved thanks to two mechanisms that are already present in RL: (1) empirical evaluation of decisions and (2) E-greedy exploration.</span>
        <meta itemprop="num_attr" content="0153">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">(1)</span>
        <span itemprop="definition">if the action suggested by the Tutor 1004 is incorrect (e.g., it provides a negative reward, the agent will learn that this action is wrong and should therefore, not be used for the given state).</span>
        <meta itemprop="num_attr" content="0153">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the agent 1006</span>
        <span itemprop="definition">may still find an action that returns a higher reward thanks to maintaining an E-greedy exploration (2).</span>
        <meta itemprop="num_attr" content="0153">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the Tutor 1004 knowledge</span>
        <span itemprop="definition">is used heavily in the initial phase, more than exploration, so even when an incorrect random action is chosen, the Tutor 1004 knowledge can correct this action quickly in most cases.</span>
        <meta itemprop="num_attr" content="0153">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the initial value for E</span>
        <span itemprop="definition">may be chosen according to the use case and how high is the cost of an incorrect action.</span>
        <meta itemprop="num_attr" content="0153">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Tutor4RL</span>
        <span itemprop="definition">is implemented for a Deep Q-Networks (DQN) agent, one of the most popular and successful approaches to solve this kind of tasks in literature.</span>
        <meta itemprop="num_attr" content="0155">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">DQN</span>
        <span itemprop="definition">Deep Q-Networks</span>
        <meta itemprop="num_attr" content="0155">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the approach</span>
        <span itemprop="definition">uses the DQN implementation provided in the library Keras-RL with Tensorflow and is applied to the game BREAKOUT, using OPENAI Gym. To evaluate the performance of this approach, it is compared to a regular DQN agent and the same set of parameters is used for both agents; DQN with Tutor4RL and plain DQN.</span>
        <meta itemprop="num_attr" content="0155">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 11</span>
        <span itemprop="definition">illustrates a graphical representation 1100 of the mean reward per episode of both agents during training according to an embodiment of the present invention.</span>
        <meta itemprop="num_attr" content="0156">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 11</span>
        <span itemprop="definition">shows an average mean reward per episode achieved by plain DQN agent and DQN agent with Tutor4RL during training. The data was averaged over 4 tests for each agent and with a rolling mean of 20 episodes, bands show 0.90 confidence interval. Until step 500,000, the plain DQN Agent shows a predictable low reward ( â 15 points), while the DQN Agent with Tutor4RLâthanks to the use of its tutor&#39;s knowledge&#39;manages to achieve a mean reward between 15 and 35 points, almost double the maximum of the plain DQN Agent.</span>
        <meta itemprop="num_attr" content="0156">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">step 500,000 onwards</span>
        <span itemprop="definition">the plain DQN agent improves thanks to acquiring more experience, until finally in step 1.1 million (M) the plain DQN agent achieves similar results to the tutored one. From there on, a similar reward is seen for both agents, with the tutored agent achieving a slightly higher mean reward.</span>
        <meta itemprop="num_attr" content="0156">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the plain DQN agent</span>
        <span itemprop="definition">is seen to achieve an average reward of 40.75 points while the agent trained with Tutor4RL achieves a reward of 43.</span>
        <meta itemprop="num_attr" content="0157">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Knowledge Infusion</span>
        <span itemprop="definition">aims to dynamically infuse knowledge, i.e., logic based on human reasoning and internal and external knowledge bases (e.g., stored in a knowledge graph) into teacher-based machine learning methods (i.e., supervised learning and reinforcement learning) to improve overall robustness, transferability and accuracy.</span>
        <meta itemprop="num_attr" content="0164">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the infusion of weak and strong knowledge</span>
        <span itemprop="definition">has two benefits: (1) it reduces the effort needed to train or startup a ML model/agent and (2) the knowledge model can be executed side-by-side with the ML model/agent to correct wrong outputs, thereby improving robustness, and enabling the calculation of an uncertainty value that gives an indication of when reality and the ML model have shifted too much apart so that performance would suffer.</span>
        <meta itemprop="num_attr" content="0164">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Smart city analytics and control</span>
        <span itemprop="definition">actuation</span>
        <meta itemprop="num_attr" content="0167">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Cities</span>
        <span itemprop="definition">are increasingly becoming smart, connecting heterogeneous sensing and actuating infrastructure through smart city platforms.</span>
        <meta itemprop="num_attr" content="0167">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the key promise of such platforms</span>
        <span itemprop="definition">is to improve certain aspects of a city (e.g., traffic, air quality, life quality, waste reduction, etc.) in an informed manner, based on the processing of sensor data and the machine learning processing pipelines for this data.</span>
        <meta itemprop="num_attr" content="0167">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Knowledge infusion</span>
        <span itemprop="definition">helps to: (1) build these pipelines efficiently; (2) enable a transfer of pipelines between cities and automatically adapt them based on the context provided through the queried knowledge (for example adapt models based on knowledge of speed limits and public transport stops); (3) achieve robust ML systems, which outputs can be directly applied through actuations in the city (e.g., to traffic lights, smart parking or to guide public transport planning).</span>
        <meta itemprop="num_attr" content="0167">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Knowledge infusion</span>
        <span itemprop="definition">enables shops to develop a set of strong knowledge functions to ensure base availability of certain products or the availability of some seasonal/holiday specific products (e.g., seasonal sweets for Christmas holidays). Such predictions can be hard to learn for a ML model, but further seasons/holidays are often distinct in different countries (for example, orthodox Christmas is later than roman-catholic Christmas).</span>
        <meta itemprop="num_attr" content="0168">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">knowledge functions</span>
        <span itemprop="definition">can automatically adapt themselves by querying a knowledge base (knowledge graph) that contains the particular holiday dates (for example WIKIDATA, or an internal knowledge base).</span>
        <meta itemprop="num_attr" content="0168">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">HVAC</span>
        <span itemprop="definition">heating, ventilation and cooling</span>
        <meta itemprop="num_attr" content="0169">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the most advanced energy management systems for buildings</span>
        <span itemprop="definition">have applied machine learning (for example they have been controlling HVAC based on an occupancy prediction).</span>
        <meta itemprop="num_attr" content="0169">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">commercial buildings</span>
        <span itemprop="definition">have strong safety regulations that specify certain conditions that always need to be met (e.g., a minimum flow of ventilation).</span>
        <meta itemprop="num_attr" content="0169">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">these regulations</span>
        <span itemprop="definition">can be encoded in strong knowledge functions. They can be updated dynamically to regulations in different states or countries through the knowledge base.</span>
        <meta itemprop="num_attr" content="0169">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the combination of the knowledge model (the combined ensemble of weak and strong knowledge functions) and the ML model</span>
        <span itemprop="definition">can safely be applied to actuate the energy management system of a building, ensuring robustness in relation to the current regulations.</span>
        <meta itemprop="num_attr" content="0169">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Knowledge</span>
        <span itemprop="definition">is infused through adaptive weak and strong knowledge functions.</span>
        <meta itemprop="num_attr" content="0172">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Knowledge functions</span>
        <span itemprop="definition">output a single value, which can either be a label (for supervised machine learning) or an action (for reinforcement learning).</span>
        <meta itemprop="num_attr" content="0172">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Functions</span>
        <span itemprop="definition">consist of a reasoning part, defined by human provided logic (e.g., conditional operators) and input knowledge that is derived/queried from internal and external knowledge bases through well-defined interfaces (e.g., through SPARQL, other graph query languages such as GraphQL or IoT specific standards such as NGSI-LD).</span>
        <meta itemprop="num_attr" content="0172">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">SPARQL</span>
        <span itemprop="definition">other graph query languages</span>
        <meta itemprop="num_attr" content="0172">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">IoT specific standards</span>
        <span itemprop="definition">such as NGSI-LD</span>
        <meta itemprop="num_attr" content="0172">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a knowledge function</span>
        <span itemprop="definition">that outputs if there is a fire based on values from a temperature sensor can interface with a knowledge base that contains current weather data, including the current temperature.</span>
        <meta itemprop="num_attr" content="0172">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the reasoning logic inside the knowledge function</span>
        <span itemprop="definition">might then use the weather temperature and the value from the temperature sensor to decide if there is a fire (binary classification, fire: True/False).</span>
        <meta itemprop="num_attr" content="0172">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a fire</span>
        <span itemprop="definition">binary classification, fire: True/False</span>
        <meta itemprop="num_attr" content="0172">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Such a function</span>
        <span itemprop="definition">may adapt to different weather conditions automatically.</span>
        <meta itemprop="num_attr" content="0172">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Strong knowledge functions</span>
        <span itemprop="definition">are thought to be mostly true, while strong knowledge functions comprise axioms (canonical truths). Strong functions can be used as a fail-safe mechanism for the ML model, correcting outputs that experts know as a fact, cannot be true. In the previous example, it may be known that if temperature from the temperature sensor is within a margin of error from the weather temperature, then there is no fire. Even though the ML model will work correctly almost always in this case, it could happen that a very high, unusual weather temperature is reached in a hot wave and the model incorrectly indicates there is a fire. In an embodiment, the strong function will correct the output.</span>
        <meta itemprop="num_attr" content="0173">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 12</span>
        <span itemprop="definition">illustrates a knowledge infusion overview and setup.</span>
        <meta itemprop="num_attr" content="0174">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">external knowledge 1202</span>
        <span itemprop="definition">might either be directly accessed by the knowledge functions (e.g., a weather API) or integrated/linked into a common knowledge base 1204 (e.g., a knowledge graph that integrated various aspects of a smart city).</span>
        <meta itemprop="num_attr" content="0174">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">new data 1212</span>
        <span itemprop="definition">is processed by both the ML model and the knowledge model.</span>
        <meta itemprop="num_attr" content="0176">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the knowledge model</span>
        <span itemprop="definition">allows for correction of some obviously wrong outputs of the ML model (improving overall robustness) and to calculate an uncertainty value that enables knowledge infusion systems to understand if the reality has drifted away from the ML model.</span>
        <meta itemprop="num_attr" content="0176">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Such uncertainty value</span>
        <span itemprop="definition">may be calculated based on the probability values obtained from the ML model as well as the windowed disagreement between the knowledge and the ML models.</span>
        <meta itemprop="num_attr" content="0176">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a moving average of this uncertainty value</span>
        <span itemprop="definition">is then used to decide if the output is added to the knowledge base 104 when the output is certain, or if re-training the ML model is needed. As the re-training will occur with an updated knowledge model, the resulting ML model will then better fit to reality, resulting in improved performance.</span>
        <meta itemprop="num_attr" content="0176">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Transfer learning</span>
        <span itemprop="definition">aims to transfer knowledge learned for one task to a related task. Transferring such knowledge has the benefit of reducing the training effort, both from computing time and from data collection and labeling time (state of the art models in computer vision or NLP have been trained with millions of datapoints and the training compute time can costs millions of dollars for large models). Transfer learning can, for example, be achieved by replacing the final layer of a large deep neural network (e.g., a model trained with millions of images for object detection) to fit the model to the new task (e.g., a more specific object recognition for a single domain, such as smart appliances in a building).</span>
        <meta itemprop="num_attr" content="0179">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a large deep neural network</span>
        <span itemprop="definition">e.g., a model trained with millions of images for object detection</span>
        <meta itemprop="num_attr" content="0179">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Safe learning systems</span>
        <span itemprop="definition">such as safe reinforcement learning ensure that the current system state is bound to a terminal set of states that is known to be safe. Uncertainty estimates are also used to limit the risks assumed by RL agents, regulating the exploration of actions in early learning phases as well as in new situations in which the agent has not experience and is uncertain about how to act. Another related emerging field is trustworthy machine learning, which among others, tries to improve adversarial robustness to protect against adversaries which can fool traditional machine learning systems.</span>
        <meta itemprop="num_attr" content="0181">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the present invention of knowledge infusion</span>
        <span itemprop="definition">differs from these traditional approaches described above. Instead of transferring trained knowledge to another task (as in transfer learning), knowledge infusion intends to transfer knowledge used for the training phase between tasks with little effort.</span>
        <meta itemprop="num_attr" content="0182">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the knowledge model</span>
        <span itemprop="definition">is employed not only during the training phase, but is also used during execution.</span>
        <meta itemprop="num_attr" content="0182">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">robustness during execution</span>
        <span itemprop="definition">is provided, while also providing a trigger for a re-training of the ML model in case of a context shift.</span>
        <meta itemprop="num_attr" content="0182">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">This approach</span>
        <span itemprop="definition">was inspired by Leslie Valiant&#39;s early work on knowledge infusion.</span>
        <meta itemprop="num_attr" content="0182">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the ideas of combining reasoning techniques with learned knowledge</span>
        <span itemprop="definition">may be introduced to the above described knowledge infusion method.</span>
        <meta itemprop="num_attr" content="0182">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Knowledge Infusion</span>
        <span itemprop="definition">aims to improve the robustness, transferability and accuracy of machine learning in IoT systems.</span>
        <meta itemprop="num_attr" content="0183">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">two types of knowledge functions</span>
        <span itemprop="definition">are proposed: (a) weak knowledge functions, that are thought to be mostly true and (b) strong knowledge functions that comprise axioms (canonical truths).</span>
        <meta itemprop="num_attr" content="0183">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the embodiments</span>
        <span itemprop="definition">may include one or more computer entities (e.g., systems, user interfaces, computing apparatus, devices, servers, special-purpose computers, smartphones, tablets or computers configured to perform functions specified herein) comprising one or more processors and memory.</span>
        <meta itemprop="num_attr" content="0185">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processors</span>
        <span itemprop="definition">can include one or more distinct processors, each having one or more cores, and access to memory. Each of the distinct processors can have the same or different structure.</span>
        <meta itemprop="num_attr" content="0185">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processors</span>
        <span itemprop="definition">can include one or more central processing units (CPUs), one or more graphics processing units (GPUs), circuitry (e.g., application specific integrated circuits (ASICs)), digital signal processors (DSPs), and the like.</span>
        <meta itemprop="num_attr" content="0185">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processors</span>
        <span itemprop="definition">can be mounted to a common substrate or to multiple different substrates.</span>
        <meta itemprop="num_attr" content="0185">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Processors</span>
        <span itemprop="definition">are configured to perform a certain function, method, or operation (e.g., are configured to provide for performance of a function, method, or operation) at least when one of the one or more of the distinct processors is capable of performing operations embodying the function, method, or operation.</span>
        <meta itemprop="num_attr" content="0185">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Processors</span>
        <span itemprop="definition">can perform operations embodying the function, method, or operation by, for example, executing code (e.g., interpreting scripts) stored on memory and/or trafficking data through one or more ASICs.</span>
        <meta itemprop="num_attr" content="0185">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Processors</span>
        <span itemprop="definition">can be configured to perform, automatically, any and all functions, methods, and operations disclosed herein. Therefore, processors can be configured to implement any of (e.g., all) the protocols, devices, mechanisms, systems, and methods described herein. For example, when the present disclosure states that a method or device performs operation or task âXâ (or that task âXâ is performed), such a statement should be understood to disclose that processor is configured to perform task âXâ.</span>
        <meta itemprop="num_attr" content="0185">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Each of the computer entities</span>
        <span itemprop="definition">can include memory.</span>
        <meta itemprop="num_attr" content="0186">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Memory</span>
        <span itemprop="definition">can include volatile memory, non-volatile memory, and any other medium capable of storing data.</span>
        <meta itemprop="num_attr" content="0186">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Each of the volatile memory, non-volatile memory, and any other type of memory</span>
        <span itemprop="definition">can include multiple different memory devices, located at multiple distinct locations and each having a different structure.</span>
        <meta itemprop="num_attr" content="0186">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Memory</span>
        <span itemprop="definition">can include remotely hosted (e.g., cloud) storage. Examples of memory include a non-transitory computer-readable media such as RAM, ROM, flash memory, EEPROM, any kind of optical storage disk such as a DVD, magnetic storage, holographic storage, a HDD, a SSD, any medium that can be used to store program code in the form of instructions or data structures, and the like. Any and all of the methods, functions, and operations described in the present application can be fully embodied in the form of tangible and/or non-transitory machine-readable code (e.g., interpretable scripts) saved in memory.</span>
        <meta itemprop="num_attr" content="0186">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Each of the computer entities</span>
        <span itemprop="definition">can include input-output devices.</span>
        <meta itemprop="num_attr" content="0187">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Input-output devices</span>
        <span itemprop="definition">can include any component for trafficking data such as ports, antennas (i.e., transceivers), printed conductive paths, and the like.</span>
        <meta itemprop="num_attr" content="0187">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Input-output devices</span>
        <span itemprop="definition">can enable wired communication via USBÂ®, DisplayPortÂ®, HDMIÂ®, Ethernet, and the like.</span>
        <meta itemprop="num_attr" content="0187">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Input-output devices</span>
        <span itemprop="definition">can enable electronic, optical, magnetic, and holographic, communication with suitable memory.</span>
        <meta itemprop="num_attr" content="0187">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Input-output devices</span>
        <span itemprop="definition">can enable wireless communication via WiFiÂ®, BluetoothÂ®, cellular (e.g., LTEÂ®, CDMAÂ®, GSMÂ®, WiMaxÂ®, NFCÂ®), GPS, and the like.</span>
        <meta itemprop="num_attr" content="0187">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Input-output devices</span>
        <span itemprop="definition">can include wired and/or wireless communication pathways.</span>
        <meta itemprop="num_attr" content="0187">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the recitation of âat least one of A, B and Câ</span>
        <span itemprop="definition">should be interpreted as one or more of a group of elements consisting of A, B and C, and should not be interpreted as requiring at least one of each of the listed elements A, B and C, regardless of whether A, B and C are related as categories or otherwise.</span>
        <meta itemprop="num_attr" content="0189">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the recitation of âA, B and/or Câ or âat least one of A, B or Câ</span>
        <span itemprop="definition">should be interpreted as including any singular entity from the listed elements, e.g., A, any subset from the listed elements, e.g., A and B, or the entire list of elements A, B and C.</span>
        <meta itemprop="num_attr" content="0189">
      </li>
    </ul>
  </section>

  


  <section itemprop="abstract" itemscope>
    <h2>Abstract</h2>
    
    <div itemprop="content" html><abstract mxw-id="PA473776603" lang="EN" source="national office" load-source="docdb">
    <div class="abstract">A method for using knowledge infusion for robust and transferable machine learning models includes receiving a plurality of adaptive and programmable knowledge functions comprising a plurality of strong functions and a plurality of weak functions. A knowledge model is generated based on the plurality of strong functions and the plurality of weak functions. A machine learning model is trained based on the generated knowledge model.</div>
  </abstract>
  </div>
  </section>

  <section itemprop="description" itemscope>
    <h2>Description</h2>
    
    <div itemprop="content" html><ul mxw-id="PDES311434307" lang="EN" load-source="patent-office" class="description">
    
    <heading id="h-0001">CROSS-REFERENCE TO RELATED APPLICATION</heading>
    <li> <para-num num="[0001]"> </para-num> <div id="p-0002" num="0001" class="description-line">Priority is claimed to EP Patent Application No. EP 20175090.8, filed on May 15, 2020, the entire disclosure of which is hereby incorporated by reference herein.</div>
    </li> <heading id="h-0002">FIELD</heading>
    <li> <para-num num="[0002]"> </para-num> <div id="p-0003" num="0002" class="description-line">The present invention relates to a method and system for automated knowledge infusion for machine learning applications.</div>
    </li> <heading id="h-0003">BACKGROUND</heading>
    <li> <para-num num="[0003]"> </para-num> <div id="p-0004" num="0003" class="description-line">Machine learning (ML) applications in IoT scenarios are impacted because supervision knowledge, such as labeled data for supervised learning or experience and rewards gained in reinforcement learning (RL), is scarce and expensive to obtain. For example, to perform supervised learning for ML applications, a human is typically required to manually annotate events in a data stream by observing the events in the real world. For RL, exploration is expensive. Further, when used in real world systems, RL requires actions within these real, running systems where wrong actions have real impact, cost and can even potentially cause harm to the system or its users.</div>
    </li> <li> <para-num num="[0004]"> </para-num> <div id="p-0005" num="0004" class="description-line">In addition, the performance of trained models usually depends on specific input data and environment context. For an IoT setting, this context is heavily influenced by (1) location, (2) time and (3) data quality. For example, a supervised ML model to monitor human gait may be trained in a location with a specific structure (e.g., wood); however, when the supervised ML model is used in a different structure (e.g., concrete), it may perform poorly even though the task to be performed is the same (see, e.g., Mirshekari, Mostafa, et al., âHuman gait monitoring using footstep-induced floor vibrations across different structures,â Proceedings of the 2018 ACM International Joint Conference and 2018 International Symposium on Pervasive and Ubiquitous Computing and Wearable Computers (2018), which is hereby incorporated by reference herein). A RL agent trained in a simulation environment for autonomous driving, may perform poorly in the real world when new situations arise (e.g., in a situation that was not available in simulation time). These problems, among others, make it hard to achieve robust, transferable and accurate machine learning for IoT systems in practice.</div>
    </li> <li> <para-num num="[0005]"> </para-num> <div id="p-0006" num="0005" class="description-line">Traditionally, the transferability problem was addressed through transfer learning. The aim of transfer learning is to transfer knowledge learned for one task to a related task. Transferring such knowledge is beneficial for reducing the training effortâboth from a compute time and from a data collection and labeling time. For instance, state of the art models in computer vision or NLP have been trained with millions of parameters and the training compute time can costs millions of dollars for large models (see, e.g., Sharir, Or, Barak Peleg, and Yoav Shoham, âThe Cost of Training NLP Models: A Concise Overview,â arXiv preprint arXiv:2004.08900 (2020), which is hereby incorporated by reference herein). Transfer learning can, for example, be achieved by replacing the final layer of a large deep neural network (e.g., a model trained with millions of images for object detection) to fit the model to a new task (e.g., a more specific object recognition for a single domain, such as smart appliances in a building). Further, traditional approaches fine-tune larger models to fit to a new task (e.g., by re-training only few layers) while leaving the more task-unspecific layers of the neural network fixed (see, e.g., Schmidhuber, JÃ¼rgen, âDeep learning in neural networks: An overview,â Neural networks 61 (2015): 85-117, which is hereby incorporated by reference herein).</div>
    </li> <li> <para-num num="[0006]"> </para-num> <div id="p-0007" num="0006" class="description-line">Recently, this robustness problem was addressed in the context of safe learning systems. For example, in safe reinforcement learning, the current system state is bound to a terminal set of states, that is known to be safe (see, e.g., Wabersich, Kim P., et al, âProbabilistic model predictive safety certification for learning-based control,â arXiv preprint arXiv:1906.10417 (2019), which is hereby incorporated by reference herein). Another related emerging field is trustworthy machine learning, which among others, tries to improve adversarial robustness to protect against adversaries that may fool traditional machine learning systems. Uncertainty estimations in machine learning have been addressed through Bayesian neural networks among others.</div>
    </li> <heading id="h-0004">SUMMARY</heading>
    <li> <para-num num="[0007]"> </para-num> <div id="p-0008" num="0007" class="description-line">In an embodiment, the present invention provides a method for using knowledge infusion for robust and transferable machine learning models. The method includes the steps of: receiving a plurality of adaptive and programmable knowledge functions comprising a plurality of strong functions and a plurality of weak functions; generating a knowledge model based on the plurality of strong functions and the plurality of weak functions; and training a machine learning model based on the generated knowledge model.</div>
    
    
    </li> <description-of-drawings>
      <heading id="h-0005">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
      <li> <para-num num="[0008]"> </para-num> <div id="p-0009" num="0008" class="description-line">Embodiments of the present invention will be described in even greater detail below based on the exemplary figures. The present invention is not limited to the exemplary embodiments. All features described and/or illustrated herein can be used alone or combined in different combinations in embodiments of the present invention. The features and advantages of various embodiments of the present invention will become apparent by reading the following detailed description with reference to the attached drawings which illustrate the following:</div>
      </li> <li> <para-num num="[0009]"> </para-num> <div id="p-0010" num="0009" class="description-line"> <figref idrefs="DRAWINGS">FIG. 1</figref> schematically shows a method and system architecture for an automated knowledge infusion for robust and transferable machine learning applications during a set-up phase according to an embodiment of the present invention;</div>
      </li> <li> <para-num num="[0010]"> </para-num> <div id="p-0011" num="0010" class="description-line"> <figref idrefs="DRAWINGS">FIG. 2</figref> schematically shows a method and system architecture for an automated knowledge infusion for robust and transferable machine learning applications during an execution phase according to an embodiment of the present invention;</div>
      </li> <li> <para-num num="[0011]"> </para-num> <div id="p-0012" num="0011" class="description-line"> <figref idrefs="DRAWINGS">FIG. 3</figref> shows a knowledge infusion system in the context of a smart city according to an embodiment of the present invention;</div>
      </li> <li> <para-num num="[0012]"> </para-num> <div id="p-0013" num="0012" class="description-line"> <figref idrefs="DRAWINGS">FIG. 4</figref> shows another knowledge infusion system in the context of a smart city according to an embodiment of the present invention;</div>
      </li> <li> <para-num num="[0013]"> </para-num> <div id="p-0014" num="0013" class="description-line"> <figref idrefs="DRAWINGS">FIG. 5</figref> shows a knowledge infusion system for building management according to an embodiment of the present invention;</div>
      </li> <li> <para-num num="[0014]"> </para-num> <div id="p-0015" num="0014" class="description-line"> <figref idrefs="DRAWINGS">FIG. 6</figref> shows a process for performing automated knowledge infusion for robust and transferable machine learning in IoT systems according to an embodiment of the present invention;</div>
      </li> <li> <para-num num="[0015]"> </para-num> <div id="p-0016" num="0015" class="description-line"> <figref idrefs="DRAWINGS">FIG. 7</figref> graphically shows the context-dimensions of machine learning models in IoT systems;</div>
      </li> <li> <para-num num="[0016]"> </para-num> <div id="p-0017" num="0016" class="description-line"> <figref idrefs="DRAWINGS">FIG. 8</figref> shows the main building blocks used to address the transport mode detection problem;</div>
      </li> <li> <para-num num="[0017]"> </para-num> <div id="p-0018" num="0017" class="description-line"> <figref idrefs="DRAWINGS">FIG. 9</figref> shows a table that summarizes results of using the generative model and the weakly and fully supervised random forests;</div>
      </li> <li> <para-num num="[0018]"> </para-num> <div id="p-0019" num="0018" class="description-line"> <figref idrefs="DRAWINGS">FIG. 10</figref> shows the overall workings of a Tutor for reinforced learning (Tutor4RL) process;</div>
      </li> <li> <para-num num="[0019]"> </para-num> <div id="p-0020" num="0019" class="description-line"> <figref idrefs="DRAWINGS">FIG. 11</figref> shows a graphical representation the mean reward per episode of two agents; and</div>
      </li> <li> <para-num num="[0020]"> </para-num> <div id="p-0021" num="0020" class="description-line"> <figref idrefs="DRAWINGS">FIG. 12</figref> shows a knowledge infusion overview and setup according to an embodiment of the present invention.</div>
    </li> </description-of-drawings>
    
    
    <heading id="h-0006">DETAILED DESCRIPTION</heading>
    <li> <para-num num="[0021]"> </para-num> <div id="p-0022" num="0021" class="description-line">Embodiments of the present invention provide an automated knowledge infusion method and system for machine learning applications. The automated knowledge infusion method and system may be used in in internet of things (IoT) systems. The automated knowledge infusion method and system improves the robustness, transferability and accuracy of machine learning systems and applications. The method and system uses two types of knowledge functions: (a) weak knowledge functions (e.g., functions that are mostly true) and (b) strong knowledge functions that comprise axioms (e.g., canonical truths). For examples, these two functions enable the infusion of knowledge into the training phase of supervised machine learning methods through ensemble methods. Additionally, these functions act as a white box counter-part to the black-box trained model/agent of a supervised or reinforcement learning system during the execution phase that are able to (a) identify and correct (infrequent) wrong outputs of the ML model/agent (by using the set of strong knowledge functions) and (b) decide, through the calculation of uncertainty values, when a model has drifted away from the input data characteristics and must be re-trained with new data to re-gain adequate results.</div>
    </li> <li> <para-num num="[0022]"> </para-num> <div id="p-0023" num="0022" class="description-line">Among other advantages, embodiments of the present invention uses automated knowledge infusion method and system to solve two important technical issues associated using machine learning in IoT scenarios. For example, embodiments of the present invention use weak and strong knowledge functions that include a reasoning part and a query interface to internal knowledge graphs and external knowledge sources, which enables these functions to adapt automatically based on new knowledge without any user involvement. By being able to adapt automatically, the same knowledge infusion method and system may be used across different deployments and may be updated through time. Additionally, embodiments of the present invention also addresses the robustness problem of ML systems by using the strong knowledge functions and a calculation of an uncertainty value. For instance, by using these, certain outputs are able to be guaranteed (e.g., to adhere to regulations or safety). Additionally, these further allow for the ML models to be updated when reality has drifted away from it. In contrast to transfer learning methods and methods from safe and trustworthy machine learning, the calculation of the uncertainty value based on both ML model and knowledge model is unique and unconventional, as well as simple, generally applicable and does not depend on specific model architectures (e.g., Bayesian Neural Nets).</div>
    </li> <li> <para-num num="[0023]"> </para-num> <div id="p-0024" num="0023" class="description-line">In an embodiment, the present invention provides a method for using knowledge infusion for robust and transferable machine learning models. The method includes the steps of: receiving a plurality of adaptive and programmable knowledge functions comprising a plurality of strong functions and a plurality of weak functions; generating a knowledge model based on the plurality of strong functions and the plurality of weak functions; and training a machine learning model based on the generated knowledge model.</div>
    </li> <li> <para-num num="[0024]"> </para-num> <div id="p-0025" num="0024" class="description-line">In an embodiment, the method further comprises: generating a knowledge fusion model based on packaging the machine learning model with the knowledge model.</div>
    </li> <li> <para-num num="[0025]"> </para-num> <div id="p-0026" num="0025" class="description-line">In an embodiment, the method further comprises: deploying the machine learning model and the knowledge model within an environment to perform one or more operations; subsequent to deploying the machine learning model and the knowledge model within the environment, receiving new data associated with the environment from one or more sensors; inputting the new data into the machine learning model to determine one or more machine learning model outputs; inputting the new data into the knowledge model to determine one or more knowledge model outputs; and correcting the one or more machine learning model outputs based on determining the one or more machine learning model outputs contradicts the one or more knowledge model outputs.</div>
    </li> <li> <para-num num="[0026]"> </para-num> <div id="p-0027" num="0026" class="description-line">In an embodiment, the inputting the new data into the knowledge model comprises inputting the new data into at least one of the plurality of strong functions, and wherein the one or more knowledge model outputs are outputs from the plurality of strong functions.</div>
    </li> <li> <para-num num="[0027]"> </para-num> <div id="p-0028" num="0027" class="description-line">In an embodiment, the method further comprises: deploying the machine learning model and the knowledge model within an environment to perform one or more operations; subsequent to deploying the machine learning model and the knowledge model within the environment, receiving new data associated with the environment from one or more sensors; inputting the new data into the machine learning model to generate one or more machine learning model outputs and one or more probability values associated with the one or more machine learning model outputs; and calculating an uncertainty value based on the one or more machine learning model outputs and the one or more probability values, wherein the uncertainty value represents uncertainty of the one or more machine learning model outputs from the machine learning model.</div>
    </li> <li> <para-num num="[0028]"> </para-num> <div id="p-0029" num="0028" class="description-line">In an embodiment, the method further comprises: comparing the uncertainty value with a threshold; and based on the uncertainty value exceeding the threshold, re-training the machine learning model.</div>
    </li> <li> <para-num num="[0029]"> </para-num> <div id="p-0030" num="0029" class="description-line">In an embodiment, the method further comprises: based on the uncertainty value not exceeding the threshold, updating a knowledge base using the one or more machine learning model outputs; updating the knowledge model based on updating the knowledge base. The re-training of the machine learning model comprises re-training the machine learning model using the updated knowledge model.</div>
    </li> <li> <para-num num="[0030]"> </para-num> <div id="p-0031" num="0030" class="description-line">In an embodiment, the calculating the uncertainty value comprises: determining a disagreement value between outputs from the knowledge model and outputs from the machine learning model, wherein the outputs from the machine learning model comprises the one or more machine learning model outputs; and calculating the uncertainty value based on the disagreement value and the one or more probability values.</div>
    </li> <li> <para-num num="[0031]"> </para-num> <div id="p-0032" num="0031" class="description-line">In an embodiment, the method further comprises: determining a moving average associated with the uncertainty value; and re-training the machine learning model based on comparing the moving average associated with the uncertainty value with a threshold.</div>
    </li> <li> <para-num num="[0032]"> </para-num> <div id="p-0033" num="0032" class="description-line">In an embodiment, the generating the knowledge model comprises generating the knowledge model based on mapping the plurality of strong functions and the plurality of weak functions using one or more ensemble methods. The one or more ensemble methods comprises at least one of a majority ensemble method, a generative ensemble method, or a Tutor for Reinforced Learning (Tutor4RL) ensemble method.</div>
    </li> <li> <para-num num="[0033]"> </para-num> <div id="p-0034" num="0033" class="description-line">In an embodiment, the receiving the plurality of adaptive and programmable knowledge functions comprises receiving the plurality of adaptive and programmable knowledge functions from a user interface. The method further comprises: updating the plurality of weak functions and the plurality of strong functions based on an internal knowledge base and one or more external knowledge sources. The generating the knowledge model is based on updating the plurality of weak functions and the plurality of strong functions.</div>
    </li> <li> <para-num num="[0034]"> </para-num> <div id="p-0035" num="0034" class="description-line">In an embodiment, the method further comprises: subsequent to generating the knowledge model, continuously maintaining the knowledge model based on continuously querying the one or more external knowledge sources to provide and update the plurality of weak functions and the plurality of strong functions.</div>
    </li> <li> <para-num num="[0035]"> </para-num> <div id="p-0036" num="0035" class="description-line">In an embodiment, the method further comprises: deploying the machine learning model and the knowledge model within an environment to perform one or more operations. The environment comprises an Internet of Things (IoT) system, a smart city system, a smart retail system, a building energy management system, or a data center energy management system.</div>
    </li> <li> <para-num num="[0036]"> </para-num> <div id="p-0037" num="0036" class="description-line">In another embodiment, the present invention provides a system for using knowledge infusion for robust and transferable machine learning models. The system comprising one or more processors which, alone or in combination, are configured to provide for execution of a method comprising: receiving a plurality of adaptive and programmable knowledge functions comprising a plurality of strong functions and a plurality of weak functions; generating a knowledge model based on the plurality of strong functions and the plurality of weak functions; and training a machine learning model based on the generated knowledge model. The system may also be configured to provide for other steps of embodiments of the method.</div>
    </li> <li> <para-num num="[0037]"> </para-num> <div id="p-0038" num="0037" class="description-line">In a further embodiment, a tangible, non-transitory computer-readable medium having instructions thereon which, upon being executed by one or more processors, alone or in combination, provide for execution of a method according to any embodiment of the present invention.</div>
    </li> <li> <para-num num="[0038]"> </para-num> <div id="p-0039" num="0038" class="description-line">Embodiments of the present invention provide an automated knowledge infusion method and system that is different from traditional approaches. For example, in contrast to transfer learning (e.g., transferring trained knowledge to another task), the automated knowledge infusion method and system provides for knowledge infusion using adaptive weak and strong knowledge functions, which makes the training phase transferable between tasks with little effort, as the knowledge functions adapt based on the context of the task (e.g., the location where the ML model is intended to be deployed). The adaptive weak and strong knowledge functions are determined based on interfacing with a knowledge graph and external knowledge sources (e.g., other knowledge bases such as OPENSTREETMAP) in order to adapt dynamically to new contexts (e.g., a different location and time) by querying these knowledge sources. Weak knowledge functions may include mostly true and strong knowledge functions may include axioms (canonical truths). After determining these knowledge functions, the automated knowledge infusion method and system may combine these knowledge functions into a weak ensemble and a strong ensemble that form a âwhite-boxâ knowledge model. The knowledge model may be used to train a traditional supervised machine learning model. The white box model may be continuously updated (e.g., based on new knowledge and/or added/updated knowledge functions) to ensure robustness of the method and system during execution. Additionally, and/or alternatively, the white box model may also be used to determine when the context within the real world shifts away from the trained ML model and re-training is needed.</div>
    </li> <li> <para-num num="[0039]"> </para-num> <div id="p-0040" num="0039" class="description-line">In some instances, transferability may be achieved through making the knowledge functions adaptive to the context of a current task. For example, they may adapt based on the location context of the current task (e.g., the knowledge functions may change their behavior when being used for a deployment in a first city (City A) as compared to a second city (City B). In some variations, knowledge functions may also be stored in a knowledge base (described below) in order to facilitate their sharing/transferability. In some examples, a user (e.g., ML developer) may chose/design a selection of fitting knowledge functions (e.g., strong/weak knowledge functions). Then, the same set of knowledge functions may be used for different deployments of the same application (e.g., in different cities such as City A and City B). Additionally, and/or alternatively, based on the input data (e.g., internet of things (IoT) data, sensor data, and so on) being modeled in a standard, compliant way, a computing device may automatically select fitting knowledge functions without the user input. In other words, the computing device may select a set of knowledge functions based on the input data.</div>
    </li> <li> <para-num num="[0040]"> </para-num> <div id="p-0041" num="0040" class="description-line">In some instances, a user may prove input to categorize whether a function is strong or weak (e.g., by using a decorator such as â@strongâ or â@weakâ). The user may further use external knowledge sources in the same way to classify strong or weak functions. Additionally, and/or alternatively, based on the knowledge source (e.g., the quality/quality of information from the knowledge source), a computing device may automatically determine whether the functions are weak/strong without user input or with minimal user input/direction.</div>
    </li> <li> <para-num num="[0041]"> </para-num> <div id="p-0042" num="0041" class="description-line">Embodiments of the present invention may be applied to achieve technological improvements in a number of technological fields. For example:
</div> </li> <ul> <li id="ul0001-0001" num="0000"> <ul> <li id="ul0002-0001" num="0042">Smart city analytics and control (actuation). Cities are increasingly becoming âsmartâ based on connecting heterogeneous sensing and actuating infrastructure through smart city platforms. The key purpose of such platforms is processing sensor data and using machine learning supported processing pipelines to improve certain aspects of a city (e.g., traffic, air quality, life quality, waste reduction, and so on) in an informed manner. To implement this, the automated knowledge infusion method and system may be used to (1) build these pipelines efficiently, (2) enable a transfer of pipelines between cities and automatically adapt them based on the context provided through the queried knowledge (for example adapt models based on knowledge of speed limits and public transport stops) and (3) achieve robust ML systems such that classification and action may be directly applied through actuations in the city (e.g., to traffic lights, smart parking or to guide public transport planning).</li> <li id="ul0002-0002" num="0043">Smart retail prediction systems. The retail sector is increasingly using machine learning to optimize their stock to fit the expected customers&#39; purchases. Embodiments of the present invention enable shops to develop a set of strong knowledge functions to ensure base availability of certain products or the availability of some seasonal/holiday specific products (e.g., seasonal sweets for Christmas). Such predictions might be difficult for a ML model to learn and also, seasons/holidays are different in different countries. For example, Orthodox Christmas is later than Roman-Catholic Christmas. Asian countries have different holidays than Western Countries. In such examples, knowledge functions may automatically adapt themselves by querying a knowledge base (knowledge graph) that contains these dates (e.g., Wikidata and/or an internal knowledge base) to determine the holidays for the particular locations and/or countries.</li> <li id="ul0002-0003" num="0044">Energy management for buildings. Buildings are one of the prime consumers of energy as humans in many countries spend most of their time inside of them. Managing the energy consumption in buildings intelligently may save large amounts of energy especially for heating, ventilation and cooling (HVAC). The most advanced energy management systems for buildings apply machine learning (e.g., ML models have been controlling HVAC based on an occupancy prediction). However, commercial buildings have strong safety regulations that specify certain conditions that always need to be met (e.g., a minimum flow of ventilation). By using embodiments of the present invention, these regulations may be encoded in strong knowledge functions. The strong knowledge functions may be dynamically updated based on regulations in different states or countries through the knowledge base. The combination of the knowledge model (the combined ensemble of weak and strong knowledge functions) and ML model may safely be applied to actuate the energy management system of a building, which may ensure robustness in relation to the current regulations.</li> <li id="ul0002-0004" num="0045">Energy management for data centers. For computation, large cloud data centers consume huge amounts of energy. The key to achieve greener data-centers may be to manage this energy consumption. To perform this, reinforcement learning (RL) may be used, which has provided some success when applied to energy management in large data centers. Embodiments of the present invention may accelerate the application of RL by providing an agent with the initial knowledge that supports the exploration of the state-action space. Embodiments of the present invention may further support the creation of strong knowledge functions that guarantee the avoidance or forces the use of some defined actions of the RL agent in certain situations, to avoid unsafe system states.</li> </ul> </li> </ul>

    <li> <para-num num="[0046]"> </para-num> <div id="p-0043" num="0046" class="description-line">Knowledge Infusion is used to dynamically infuse knowledge (e.g., logic based on human reasoning and internal and external knowledge bases such as knowledge bases stored in a knowledge graph) into Teacher-based machine learning systems to improve overall robustness, transferability and accuracy. Teacher-based ML systems may refer to variations of supervised learning and/or reinforcement learning, where the supervision signals are gained through modeling of rewards from the environment. The infusion of this knowledge (e.g., weak and strong knowledge functions) has at least two benefits: (1) it reduces the effort needed to train or startup an ML model/agent and (2) the knowledge model may be executed side-by-side with the ML model/agent, correct wrong outputs and/or enable the calculation of an uncertainty value that gives an indication of when reality and the ML model have shifted apart so much that performance would suffer.</div>
    </li> <li> <para-num num="[0047]"> </para-num> <div id="p-0044" num="0047" class="description-line">Infusing knowledge is performed using adaptive weak and strong knowledge functions. Knowledge functions may output a single value, which can either be a label (e.g., for supervised machine learning), an action (e.g., for reinforcement learning), and/or the functions may choose to abstain. The inputs to knowledge functions are one or multiple data points (e.g., sensor values) and one or multiple knowledge sources (e.g., an endpoint to a knowledge base). The data points may include associated context meta-data, such as the location of the sensor or the observation time. Functions include a reasoning part, defined by human provided logic (e.g., conditional operators) and input knowledge that is derived/queried from internal and external knowledge bases through well-defined interfaces (e.g., through Simple Protocol and resource description framework (RDF) query language (SPARQL), other graph query languages such as Graph query language (GraphQL), and so on). Through such well-defined interface(s), knowledge functions are practically able to adapt their behavior automatically, based on changes in the output derived from querying the knowledge bases (possibly with a different context). For example, a knowledge function that outputs if there is a fire based on the value from a temperature sensor may interface with a knowledge base that contains current weather data, including the current temperature. The reasoning logic inside the knowledge function might then use the weather temperature and the value from the temperature sensor to decide if there is a fire (e.g., the output may be a binary classification such as fire: True/False). In some embodiments, the functions may adapt to different weather conditions automatically. Additionally, and/or alternatively, through associated context meta-data of the temperature sensor, the function may adapt to different contexts, such as location and time (e.g., it will retrieve knowledge for a different location).</div>
    </li> <li> <para-num num="[0048]"> </para-num> <div id="p-0045" num="0048" class="description-line">In some instances, the knowledge functions may choose to abstain from outputting a value when the input to the knowledge function and the external knowledge source(s) do not provide sufficient information for the specific classification task. For instance, in an embodiment of the present invention, a function may decide on the transportation mode of individuals based on sensor data collected from the individuals&#39; mobile phones and external knowledge from an external knowledge source (e.g., OPENSTREETMAP). One function logic may vote for (e.g., determine) the transport mode to be a bus (e.g., transport_mode=BUS) in the case where there are bus stops along the global positioning system (GPS) trajectory and the speed is above a certain threshold. However, in all other cases, this function may choose to abstain because it cannot be certain about the transport mode. In such cases, a second knowledge function may use accelerometer data from the mobile phone and not abstain for the same input data.</div>
    </li> <li> <para-num num="[0049]"> </para-num> <div id="p-0046" num="0049" class="description-line">In some variations, a user (e.g., ML developer) may input the reasoning for some retrieved external knowledge from the external knowledge source. For instance, a computing device may retrieve external knowledge from external knowledge data sources (e.g., OPENSTREETMAP). The user may provide the reasoning for the retrieved data. For example, in the fire example above, the user may input the reasoning information such as the difference between the current weather temperature and the sensor value.</div>
    </li> <li> <para-num num="[0050]"> </para-num> <div id="p-0047" num="0050" class="description-line">Weak knowledge functions are thought to be mostly true, while strong knowledge functions include axioms (canonical truths). Embodiments of the present invention may use strong functions as a fail-safe mechanism for the ML model. In other words, strong functions may corrects outputs from the ML model that users (e.g., experts) may know as a fact, cannot be true. In the previous example regarding the fire, if temperature from the temperature sensor is within a margin of error from the weather temperature, then there is no fire. For example, the ML model may work properly most of the time. However, it could happen that a very high, unusual weather temperature is reached in a heat wave and the model incorrectly indicates that there is a fire. In such examples, the strong function may correct the output (e.g., the strong function may indicate that the weather temperature is within a margin of error and there is no fire).</div>
    </li> <li> <para-num num="[0051]"> </para-num> <div id="p-0048" num="0051" class="description-line">In some examples, a set of both weak and strong functions is combined to label the data (each function is similar to a voter for each data point that can either vote or abstain, with the strong functions over-writing weak functions). For example, for the transportation mode example above, three weak functions may vote BUS and two weak functions may vote CAR. In such examples, the computing device may take these votes and select and choose a label (e.g., BUS because the majority (three) of the weak functions voted for it). However, if there is an additional strong function that votes BIKE, the computing device may choose BIKE instead. In other words, the strong function output of BIKE may override the weak functions outputs of CAR and BUS. The computing device may use the labeled data to train a ML model, such as neural net, random forest, and so on.</div>
    </li> <li> <para-num num="[0052]"> </para-num> <div id="p-0049" num="0052" class="description-line">In execution, there may be two models, the black-box ML model and the white box knowledge model (based on all weak and strong functions). The computing device may use both for each new input. Traditionally, the ML model may provide a better performance because it has learned the patterns in the data and removes some noise. However, in embodiments of the present invention, the advantage of using both the ML model and the white box knowledge model is that: 1) it may correct obvious wrong outputs with the help of the strong functions; and 2) it can discover if the ML model does not fit anymore to the input data distribution. This may happen if the model is moved to a new location (e.g., City B rather than City A) or just the real world changes over time. Having just the ML model, this may be difficult to discover. Now, having the knowledge model along with the ML model, embodiments of the present invention may observe when there is too much disagreement. In this case, the computing device may re-train the ML model with the new input data distribution and labeled with the adaptive knowledge model (e.g., the knowledge model adapts automatically to a new location using OPENSTREETMAP external knowledge).</div>
    </li> <li> <para-num num="[0053]"> </para-num> <div id="p-0050" num="0053" class="description-line">Embodiments of the present invention create a knowledge model that includes and/or incorporates an ensemble of knowledge functions (e.g., strong and weak knowledge functions) that are used to label data points and then used to train a ML model. Additionally, and/or alternatively, in an embodiment of the present invention for RL, this step might not be needed because the agent may start interacting directly with its environment. During execution, both the knowledge model and the ML model, are then used jointly (e.g., both may be used to process every new input). <figref idrefs="DRAWINGS">FIG. 1</figref> describes these steps in more detail.</div>
    </li> <li> <para-num num="[0054]"> </para-num> <div id="p-0051" num="0054" class="description-line">Referring to <figref idrefs="DRAWINGS">FIG. 1</figref>, a method and <figure-callout id="100" label="system architecture" filenames="US20210357767A1-20211118-D00000.png,US20210357767A1-20211118-D00001.png" state="{{state}}">system architecture</figure-callout> <b>100</b> for setting up automated knowledge infusion for machine learning applications according to an embodiment of the present invention is shown. For example, the method and <figure-callout id="100" label="system architecture" filenames="US20210357767A1-20211118-D00000.png,US20210357767A1-20211118-D00001.png" state="{{state}}">system architecture</figure-callout> <b>100</b> may be used in in internet of things (IoT) systems. According to an embodiment of the present invention, the <figure-callout id="100" label="architecture" filenames="US20210357767A1-20211118-D00000.png,US20210357767A1-20211118-D00001.png" state="{{state}}">architecture</figure-callout> <b>100</b> includes external knowledge sources <b>102</b> (e.g., ontologies, domain knowledge, physical models, and/or knowledge bases), a <figure-callout id="104" label="knowledge base" filenames="US20210357767A1-20211118-D00000.png,US20210357767A1-20211118-D00001.png" state="{{state}}">knowledge base</figure-callout> <b>104</b>, one or <figure-callout id="106" label="more user interfaces" filenames="US20210357767A1-20211118-D00000.png,US20210357767A1-20211118-D00001.png" state="{{state}}">more user interfaces</figure-callout> <b>106</b>, a <figure-callout id="108" label="knowledge infusion device" filenames="US20210357767A1-20211118-D00000.png,US20210357767A1-20211118-D00001.png" state="{{state}}">knowledge infusion device</figure-callout> <b>108</b>, and a <figure-callout id="110" label="knowledge infusion model" filenames="US20210357767A1-20211118-D00000.png,US20210357767A1-20211118-D00001.png" state="{{state}}">knowledge infusion model</figure-callout> <b>110</b>. The <figure-callout id="108" label="knowledge infusion device" filenames="US20210357767A1-20211118-D00000.png,US20210357767A1-20211118-D00001.png" state="{{state}}">knowledge infusion device</figure-callout> <b>108</b> includes multiple knowledge functions (e.g., a first knowledge function (KF<sub>1</sub>), a second knowledge function (KF<sub>2</sub>), and so on), a knowledge function abstraction layer, multiple ensembles (e.g., majority ensemble, generative ensemble, tutor for reinforced learning (Tutor4RL), and so on), and a knowledge model abstraction layer. As shown, <figure-callout id="102" label="external knowledge sources" filenames="US20210357767A1-20211118-D00000.png,US20210357767A1-20211118-D00001.png" state="{{state}}">external knowledge sources</figure-callout> <b>102</b> may be an application programming interface (API) such as a weather API that is directly accessed by the knowledge functions of the <figure-callout id="108" label="knowledge infusion device" filenames="US20210357767A1-20211118-D00000.png,US20210357767A1-20211118-D00001.png" state="{{state}}">knowledge infusion device</figure-callout> <b>108</b>. Additionally, and/or alternatively, the <figure-callout id="102" label="external knowledge sources" filenames="US20210357767A1-20211118-D00000.png,US20210357767A1-20211118-D00001.png" state="{{state}}">external knowledge sources</figure-callout> <b>102</b> may be a knowledge graph that integrates/links into a common knowledge base (e.g., a knowledge graph that integrates various aspects of a smart city). In some examples, the same computing device may be used for setting up the knowledge infusion model and for executing the knowledge infusion model. In other words, the same computing device may perform the functionalities of the <figure-callout id="108" label="knowledge infusion device" filenames="US20210357767A1-20211118-D00000.png,US20210357767A1-20211118-D00001.png" state="{{state}}">knowledge infusion device</figure-callout> <b>108</b> and for the <figure-callout id="110" label="knowledge infusion model" filenames="US20210357767A1-20211118-D00000.png,US20210357767A1-20211118-D00001.png" state="{{state}}">knowledge infusion model</figure-callout> <b>110</b>. In other examples, different computing devices may be used for setting up and executing the knowledge infusion model. The <figure-callout id="100" label="architecture" filenames="US20210357767A1-20211118-D00000.png,US20210357767A1-20211118-D00001.png" state="{{state}}">architecture</figure-callout> <b>100</b> will be described in further detail below.</div>
    </li> <li> <para-num num="[0055]"> </para-num> <div id="p-0052" num="0055" class="description-line"> <figref idrefs="DRAWINGS">FIG. 2</figref> illustrates a method and <figure-callout id="200" label="system architecture" filenames="US20210357767A1-20211118-D00002.png" state="{{state}}">system architecture</figure-callout> <b>200</b> that uses the knowledge fusion model <b>110</b> (from <figref idrefs="DRAWINGS">FIG. 1</figref>) during an execution phase according to an embodiment of the present invention is shown. During the execution phase (e.g., after generating the <figure-callout id="110" label="knowledge fusion model" filenames="US20210357767A1-20211118-D00000.png,US20210357767A1-20211118-D00001.png" state="{{state}}">knowledge fusion model</figure-callout> <b>110</b> from <figref idrefs="DRAWINGS">FIG. 1</figref>), <figure-callout id="202" label="new data" filenames="US20210357767A1-20211118-D00002.png,US20210357767A1-20211118-D00003.png" state="{{state}}">new data</figure-callout> <b>202</b> may processed by both the ML model and the knowledge model of the <figure-callout id="110" label="knowledge fusion model" filenames="US20210357767A1-20211118-D00000.png,US20210357767A1-20211118-D00001.png" state="{{state}}">knowledge fusion model</figure-callout> <b>110</b>. As described previously, the <figure-callout id="110" label="knowledge fusion model" filenames="US20210357767A1-20211118-D00000.png,US20210357767A1-20211118-D00001.png" state="{{state}}">knowledge fusion model</figure-callout> <b>110</b> permits the correction of potential wrong outputs of the ML model such that it improves overall robustness and is used to calculate an uncertainty value that enables knowledge infusion systems (e.g., systems that employ knowledge infusion) to understand if reality has drifted away from the ML model. Such uncertainty values may be calculated based on the probability values obtained from the ML model as well as the windowed disagreement between the knowledge model and the ML model (e.g., if ML model and Knowledge model disagree in 50% of all cases, this may be a strong indication for a shift). The probability values obtained from the ML model may be/include a confidence value (e.g., 0.9 or 90% confidence of the output from the ML model). However, the probability values by itself might not be a good indicator of whether the output is correct (e.g., at times, it may be tricked using adversarial inputs). As such, embodiments of the present invention may combine both the probability values and the windowed disagreement values into an uncertainty value. Then, at <figure-callout id="204" label="block" filenames="US20210357767A1-20211118-D00002.png,US20210357767A1-20211118-D00003.png" state="{{state}}">block</figure-callout> <b>204</b>, a moving average of this uncertainty value over a period of time may be used to decide whether the <figure-callout id="206" label="output" filenames="US20210357767A1-20211118-D00002.png" state="{{state}}">output</figure-callout> <b>206</b> is added to the <figure-callout id="104" label="knowledge base" filenames="US20210357767A1-20211118-D00000.png,US20210357767A1-20211118-D00001.png" state="{{state}}">knowledge base</figure-callout> <b>104</b> or if the ML model is re-trained using the knowledge model. In an embodiment of the present invention, the final threshold from <figure-callout id="204" label="block" filenames="US20210357767A1-20211118-D00002.png,US20210357767A1-20211118-D00003.png" state="{{state}}">block</figure-callout> <b>204</b> as well as the parameter for the probability and disagreement that is used to determine the uncertainty value may be configured by a user. Because the re-training may occur with an updated knowledge model, the resulting ML model may then better fit to reality, which may result in improved performance. In some instances, the re-training may be performed by the same computing device that set up the knowledge infusion model (e.g., the computing device in <figref idrefs="DRAWINGS">FIG. 1</figref> that set up the knowledge infusion model). Additionally, and/or alternatively, a separate computing device (e.g., a more powerful) computing device may be used for re-training the ML model.</div>
    </li> <li> <para-num num="[0056]"> </para-num> <div id="p-0053" num="0056" class="description-line">In some embodiments of the present invention, the uncertainty value may be determined from a combination (e.g., addition) of the probability values and the windowed disagreements values. Additionally, and/or alternatively, these values may first be weighted (e.g., weigh the windowed disagreement value higher or with a stronger weight than the probability values) and then combined together. Additionally, and/or alternatively, in some instances, embodiments of the present invention may just use the windowed disagreement value to determine the uncertainty value.</div>
    </li> <li> <para-num num="[0057]"> </para-num> <div id="p-0054" num="0057" class="description-line">The system and <figure-callout id="100" label="method architectures" filenames="US20210357767A1-20211118-D00000.png,US20210357767A1-20211118-D00001.png" state="{{state}}"> <figure-callout id="200" label="method architectures" filenames="US20210357767A1-20211118-D00002.png" state="{{state}}">method architectures</figure-callout> </figure-callout> <b>100</b> and <b>200</b> from <figref idrefs="DRAWINGS">FIGS. 1 and 2</figref> will be described in further detail below. For instance, to setup and execute a knowledge infusion ML method and system, the workflow may be as follows:</div>
    </li> <li> <para-num num="[0058]"> </para-num> <div id="p-0055" num="0058" class="description-line">Step 1: Knowledge Function Development</div>
    </li> <li> <para-num num="[0059]"> </para-num> <div id="p-0056" num="0059" class="description-line">Referring to <figref idrefs="DRAWINGS">FIG. 1</figref>, users may use the <figure-callout id="106" label="user interface" filenames="US20210357767A1-20211118-D00000.png,US20210357767A1-20211118-D00001.png" state="{{state}}">user interface</figure-callout> <b>106</b> to develop weak and strong knowledge functions. These functions may interface with an internal knowledge base <b>104</b> (e.g., through a query language) and external knowledge sources <b>102</b> (e.g., through available APIs). Knowledge functions output a label or action based on the user provided logic and the knowledge received/queried from the knowledge base and external knowledge sources. For example, the user may define a knowledge function that outputs a transport mode for location traces based on data from an external GIS (e.g., OPENSTREETMAP) and from the user&#39;s logic (e.g., if location is on a highway, transport mode is car). Through the interface with the internal <b>104</b> and external knowledge bases <b>102</b>, knowledge functions become adaptive such as by changing their behavior with a new context from the knowledge base (e.g., road has a new speed limit). In other words, the user may use the <figure-callout id="106" label="user interface" filenames="US20210357767A1-20211118-D00000.png,US20210357767A1-20211118-D00001.png" state="{{state}}">user interface</figure-callout> <b>106</b> to provide or generate a knowledge function that outputs a label (e.g., class) or action (e.g., what should be done next). After providing the knowledge function, the <figure-callout id="106" label="user interface" filenames="US20210357767A1-20211118-D00000.png,US20210357767A1-20211118-D00001.png" state="{{state}}">user interface</figure-callout> <b>106</b> and/or the <figure-callout id="108" label="knowledge infusion device" filenames="US20210357767A1-20211118-D00000.png,US20210357767A1-20211118-D00001.png" state="{{state}}">knowledge infusion device</figure-callout> <b>108</b> may update or adapt this knowledge function based on interfacing with (e.g., receiving information from and/or communicating with) the <figure-callout id="104" label="internal knowledge base" filenames="US20210357767A1-20211118-D00000.png,US20210357767A1-20211118-D00001.png" state="{{state}}">internal knowledge base</figure-callout> <b>104</b> and/or the external knowledge sources <b>102</b>. The <figure-callout id="108" label="knowledge infusion device" filenames="US20210357767A1-20211118-D00000.png,US20210357767A1-20211118-D00001.png" state="{{state}}">knowledge infusion device</figure-callout> <b>108</b> may store the knowledge functions.</div>
    </li> <li> <para-num num="[0060]"> </para-num> <div id="p-0057" num="0060" class="description-line">Step 2: Knowledge Function Ensembles</div>
    </li> <li> <para-num num="[0061]"> </para-num> <div id="p-0058" num="0061" class="description-line">The set of knowledge functions from the user interface <b>106</b> (e.g., that the user has generated) is mapped to ensemble methods in the knowledge function abstraction layer of the <figure-callout id="108" label="knowledge infusion device" filenames="US20210357767A1-20211118-D00000.png,US20210357767A1-20211118-D00001.png" state="{{state}}">knowledge infusion device</figure-callout> <b>108</b>. Such ensemble methods combine multiple supervision sources into a unified model. For example, majority voting ensemble (i.e., majority ensemble) treats each supervision source equally, while other techniques, including a generative ensemble such as SNORKEL (see, e.g., Ratner, Alexander, et al., âSnorkel: Rapid training data creation with weak supervision,â The VLDB Journal 29.2 (2020): 709-730, which is hereby incorporated by reference herein), model the difference in quality of different (weak) sources in a generative process that may provide improved performance. Embodiments of the present invention may be configured to use multiple and/or extensible ensemble methods. The <figure-callout id="108" label="knowledge infusion device" filenames="US20210357767A1-20211118-D00000.png,US20210357767A1-20211118-D00001.png" state="{{state}}">knowledge infusion device</figure-callout> <b>108</b> then creates two ensembles and combines them into a Knowledge Model. The two ensembles include a first ensemble that is based on the set of weak knowledge functions and a second ensemble based on the set of strong knowledge functions.</div>
    </li> <li> <para-num num="[0062]"> </para-num> <div id="p-0059" num="0062" class="description-line">Step 3: ML Model Training</div>
    </li> <li> <para-num num="[0063]"> </para-num> <div id="p-0060" num="0063" class="description-line">The ML model may be trained using the created knowledge model. This training may help to generalize beyond the knowledge encoded in the knowledge model by discovering new patterns in the data and removing some of the noise of the knowledge model, which increases the overall performance of the ML model as compared to the knowledge model. For instance, as described above, the knowledge functions may be combined together and used to label the data. The knowledge functions may be combined in many ways (e.g., in ensembles such as a majority ensemble). Further, due to the classification of weak and strong functions, the output of the strong functions may override the output of weak functions.</div>
    </li> <li> <para-num num="[0064]"> </para-num> <div id="p-0061" num="0064" class="description-line">As will be explained below, for reinforcement learning, this step may be omitted because the agent may be âtrainedâ actively through interactions with its environment. Additionally, and/or alternatively, in an embodiment of the present invention, the present invention may use the knowledge model to pre-train the RL policy instead of training it actively during runtime (e.g., execution). This will be discussed in further detail below.</div>
    </li> <li> <para-num num="[0065]"> </para-num> <div id="p-0062" num="0065" class="description-line">Step 4: Combination of Knowledge Model and ML Model into Knowledge Fusion Model</div>
    </li> <li> <para-num num="[0066]"> </para-num> <div id="p-0063" num="0066" class="description-line">The knowledge model and the trained ML model may be packaged into a self-contained <figure-callout id="110" label="knowledge fusion model" filenames="US20210357767A1-20211118-D00000.png,US20210357767A1-20211118-D00001.png" state="{{state}}">knowledge fusion model</figure-callout> <b>110</b>. This <figure-callout id="110" label="model" filenames="US20210357767A1-20211118-D00000.png,US20210357767A1-20211118-D00001.png" state="{{state}}">model</figure-callout> <b>110</b> includes a fusion component that processes the outputs of both the ML model and the knowledge model to create a single output (e.g., the strong ensemble might over-write the output of the ML model) and the logic to calculate and/or act on a configurable uncertainty value. The fusion component may be software code implemented by hardware (e.g., processor/memory of a computing device) that processes both outputsâthe one from the knowledge model and the one from the ML mode. In some instances, the weak ensemble (e.g., the weak functions) might not be used to overwrite this single output, but the outputs of the weak ensemble (together with the strong ensemble) may be used to determine when the black-box ML model does not fit to reality (input data distribution) anymore based on the disagreement and probability values described above.</div>
    </li> <li> <para-num num="[0067]"> </para-num> <div id="p-0064" num="0067" class="description-line">Step 5: Execution of Knowledge Fusion Model</div>
    </li> <li> <para-num num="[0068]"> </para-num> <div id="p-0065" num="0068" class="description-line">Referring to <figref idrefs="DRAWINGS">FIG. 2</figref>, the <figure-callout id="110" label="knowledge fusion model" filenames="US20210357767A1-20211118-D00000.png,US20210357767A1-20211118-D00001.png" state="{{state}}">knowledge fusion model</figure-callout> <b>110</b> is deployed (e.g., in a container, or as part of an IoT cloud-edge framework) and processes <figure-callout id="202" label="new data" filenames="US20210357767A1-20211118-D00002.png,US20210357767A1-20211118-D00003.png" state="{{state}}">new data</figure-callout> <b>202</b>. The <figure-callout id="202" label="incoming data" filenames="US20210357767A1-20211118-D00002.png,US20210357767A1-20211118-D00003.png" state="{{state}}">incoming data</figure-callout> <b>202</b> is processed by both the ML model and the knowledge model. Their output is then processed by a knowledge fusion component, which evaluates both outputs. The knowledge fusion component may overwrite outputs in which input states are covered by the strong ensemble (e.g., based on the strong knowledge functions provided initially by the user) with the outputs of the strong ensemble. This achieves robustness and helps to avoid unsafe outputs. The knowledge fusion component also outputs a calculated uncertainty value based on the outputs of the knowledge model and the ML model as well as the probability values available for ML models.</div>
    </li> <li> <para-num num="[0069]"> </para-num> <div id="p-0066" num="0069" class="description-line">Step 6: Evaluate Uncertainty</div>
    </li> <li> <para-num num="[0070]"> </para-num> <div id="p-0067" num="0070" class="description-line">The moving mean value of the uncertainty value may be calculated and based on a configurable threshold (e.g., user-defined threshold), embodiments of the present invention may determine one of the following decisions:</div>
    </li> <li> <para-num num="[0071]"> </para-num> <div id="p-0068" num="0071" class="description-line">6.1 Value is Less than Threshold</div>
    </li> <li> <para-num num="[0072]"> </para-num> <div id="p-0069" num="0072" class="description-line">If the moving mean value of the uncertainty value is less than the threshold, this may indicate that the ML model and reality (e.g., data distribution, environment properties) still match. In such examples, the <figure-callout id="104" label="knowledge base" filenames="US20210357767A1-20211118-D00000.png,US20210357767A1-20211118-D00001.png" state="{{state}}">knowledge base</figure-callout> <b>104</b> may be updated with the new output from the <figure-callout id="110" label="knowledge fusion model" filenames="US20210357767A1-20211118-D00000.png,US20210357767A1-20211118-D00001.png" state="{{state}}">knowledge fusion model</figure-callout> <b>110</b>. The knowledge model within the <figure-callout id="110" label="knowledge fusion model" filenames="US20210357767A1-20211118-D00000.png,US20210357767A1-20211118-D00001.png" state="{{state}}">knowledge fusion model</figure-callout> <b>110</b> may be updated using the new knowledge from the knowledge base <b>104</b> (e.g., for a different location context).</div>
    </li> <li> <para-num num="[0073]"> </para-num> <div id="p-0070" num="0073" class="description-line">6.2 Value is Greater than Threshold</div>
    </li> <li> <para-num num="[0074]"> </para-num> <div id="p-0071" num="0074" class="description-line">If the moving mean value of the uncertainty value is greater than the threshold, this may indicate that reality (e.g., data distribution, environment properties) may have shifted away from the ML model and the ML model might not be able to create outputs with a good performance (e.g., with sufficient accuracy). In such examples, a re-training of the ML model (for the RL agent, the RL policy may be reset) may be triggered. The re-training may occur through the continuously updated knowledge model that reflects changes in external <b>102</b> and <figure-callout id="104" label="internal knowledge bases" filenames="US20210357767A1-20211118-D00000.png,US20210357767A1-20211118-D00001.png" state="{{state}}">internal knowledge bases</figure-callout> <b>104</b> through its adaptive knowledge functions. For example, if a knowledge infusion-based ML system for transport mode detection is transferred to another environment with different characteristics, such as a different country, the knowledge model part may automatically be updated based on knowledge about speed limits and/or street and public transport characteristics (e.g., a new bus line) from a GIS knowledge base.</div>
    </li> <li> <para-num num="[0075]"> </para-num> <div id="p-0072" num="0075" class="description-line">Additional, and/or alternative embodiments of the present invention are described below:</div>
    </li> <li> <para-num num="[0076]"> </para-num> <div id="p-0073" num="0076" class="description-line">According to an embodiment of the present invention, the <figure-callout id="110" label="knowledge fusion model" filenames="US20210357767A1-20211118-D00000.png,US20210357767A1-20211118-D00001.png" state="{{state}}">knowledge fusion model</figure-callout> <b>110</b> for RL may be used to pre-train the RL policy rather than performing it and/or training it actively. In other words, the <figure-callout id="110" label="knowledge fusion model" filenames="US20210357767A1-20211118-D00000.png,US20210357767A1-20211118-D00001.png" state="{{state}}">knowledge fusion model</figure-callout> <b>110</b> may be used as an offline âteacherâ for the RL agent in combination with already available data of states&#39; transitions or some model of states&#39; transitions of the RL environment and some basic reward scheme. The states&#39; transitions may be fed to both the RL agent and the Knowledge Model and then a reward may be calculated (e.g., a conflict between the RL agent&#39;s chosen action and Knowledge Model&#39;s chosen actions may be used as a negative reward whereas agreements may be used as a positive reward for the RL agent). This process is iterated until the RL policy acquires a certain degree of agreements with the Knowledge Model such that the initial performance of the RL agent in the real environment is improved.</div>
    </li> <li> <para-num num="[0077]"> </para-num> <div id="p-0074" num="0077" class="description-line">According to an embodiment of the present invention, the knowledge model may be executed for uncertain outputs of the ML model (based on the perceived probability). According to another embodiment of the present invention, the knowledge model may be executed for uncertain inputs (e.g., inputs that the ML model cannot clearly discriminate). For example, for inputs where the ML model is very certain, the knowledge model may agree with the ML model in most cases. As such, this embodiment may save additional computational resources.</div>
    </li> <li> <para-num num="[0078]"> </para-num> <div id="p-0075" num="0078" class="description-line">Optimization. According to an embodiment of the present invention, the knowledge model may be updated based on batch processing instead of streaming-based processing. For instance, in steaming-based processing, the knowledge model may be updated for each new data input that is processed (e.g., a new value that is received from a sensor). However, in some embodiments, the present invention may also update the knowledge model in batches (e.g., after multiple new data input values are available). This reduces processing time. For example, the interval for new batches may either be fixed (e.g., every tenth new value) or it can be done when a threshold parameter on the probability of the ML model is reached. For instance, when uncertainty of the ML model rises, it cannot discriminate well between its output classes/actions. Through the re-creation of the knowledge model, the present invention may then verify if the ML model is to be re-trained.</div>
    </li> <li> <para-num num="[0079]"> </para-num> <div id="p-0076" num="0079" class="description-line">Extension. According to an embodiment of the present invention, Human-In-The-Loop may be used for re-training of ML model. In some examples, it might be necessary/desired to involve a human (e.g., user operating a computing device such as user interface <b>106</b>) in the re-training of the ML model to supervise the re-training and to potentially provide a small set of labelled data to verify the correct output of the knowledge model. This might be necessary if knowledge functions are not able to automatically adapt to a new context and thus their performance worsens and eventually might not be used anymore to train the ML model. In this case, a human may manually perform small tweaks to the existing functions or add/remove knowledge functions and verify the overall performance of the knowledge model using a small, labeled testing data-set.</div>
    </li> <li> <para-num num="[0080]"> </para-num> <div id="p-0077" num="0080" class="description-line">Embodiments of Using the Knowledge Infusion System within a Smart City</div>
    </li> <li> <para-num num="[0081]"> </para-num> <div id="p-0078" num="0081" class="description-line"> <figref idrefs="DRAWINGS">FIG. 3</figref> illustrates an <figure-callout id="300" label="embodiment" filenames="US20210357767A1-20211118-D00003.png" state="{{state}}">embodiment</figure-callout> <b>300</b> of the present invention that uses a knowledge infusion system in the context of a smart city. The knowledge fusion model receives input (e.g., data <b>202</b>) directly from sensors <b>302</b> (e.g., sensing infrastructure) available in the city. These <figure-callout id="302" label="sensors" filenames="US20210357767A1-20211118-D00003.png" state="{{state}}">sensors</figure-callout> <b>302</b> may be either from individual wearables and smartphones and/or from infrastructure in the city, such as video cameras and environmental sensors.</div>
    </li> <li> <para-num num="[0082]"> </para-num> <div id="p-0079" num="0082" class="description-line"> <figure-callout id="202" label="New sensor data" filenames="US20210357767A1-20211118-D00002.png,US20210357767A1-20211118-D00003.png" state="{{state}}">New sensor data</figure-callout> <b>202</b> will be processed by the knowledge infusion model and <figure-callout id="110" label="system" filenames="US20210357767A1-20211118-D00000.png,US20210357767A1-20211118-D00001.png" state="{{state}}">system</figure-callout> <b>110</b> and based on the perceived uncertainty, will either result in a re-training of the ML model or a successful classification/action. In the successful case, the output is sent to the <figure-callout id="304" label="smart city platform" filenames="US20210357767A1-20211118-D00003.png" state="{{state}}">smart city platform</figure-callout> <b>304</b>. The <figure-callout id="304" label="city platform" filenames="US20210357767A1-20211118-D00003.png" state="{{state}}">city platform</figure-callout> <b>304</b> may then perform an actuation (e.g., change the traffic light schedule) in the city using the <figure-callout id="306" label="actuating infrastructure" filenames="US20210357767A1-20211118-D00003.png" state="{{state}}">actuating infrastructure</figure-callout> <b>306</b> and also updates the <figure-callout id="104" label="city knowledge graph" filenames="US20210357767A1-20211118-D00000.png,US20210357767A1-20211118-D00001.png" state="{{state}}">city knowledge graph</figure-callout> <b>104</b> with the output. The <figure-callout id="110" label="knowledge fusion model" filenames="US20210357767A1-20211118-D00000.png,US20210357767A1-20211118-D00001.png" state="{{state}}">knowledge fusion model</figure-callout> <b>110</b> may directly query the city knowledge graph for updating its state (e.g., its knowledge that is used in the knowledge functions).</div>
    </li> <li> <para-num num="[0083]"> </para-num> <div id="p-0080" num="0083" class="description-line">In some variations, a city sensing and actuating infrastructure may be unified and abstracted to the present invention through a smart city platform that handles accessing these sensors and actuators and makes them available through a common interface for various applications. <figref idrefs="DRAWINGS">FIG. 4</figref> illustrates an <figure-callout id="400" label="embodiment" filenames="US20210357767A1-20211118-D00004.png" state="{{state}}">embodiment</figure-callout> <b>400</b> of the present invention that uses such a variation in which the city platform plays a more central role in connecting to the <figure-callout id="404" label="sensing" filenames="US20210357767A1-20211118-D00004.png" state="{{state}}">sensing</figure-callout> <b>404</b> and <figure-callout id="406" label="actuating infrastructure" filenames="US20210357767A1-20211118-D00004.png" state="{{state}}">actuating infrastructure</figure-callout> <b>406</b> of the city. The <figure-callout id="402" label="smart city platform" filenames="US20210357767A1-20211118-D00004.png" state="{{state}}">smart city platform</figure-callout> <b>402</b> connects to the <figure-callout id="404" label="city sensing infrastructure" filenames="US20210357767A1-20211118-D00004.png" state="{{state}}">city sensing infrastructure</figure-callout> <b>404</b> and stores new values in the <figure-callout id="104" label="knowledge graph" filenames="US20210357767A1-20211118-D00000.png,US20210357767A1-20211118-D00001.png" state="{{state}}">knowledge graph</figure-callout> <b>104</b>. In this embodiment, the present invention will subscribe through an available interface directly to the <figure-callout id="104" label="knowledge graph" filenames="US20210357767A1-20211118-D00000.png,US20210357767A1-20211118-D00001.png" state="{{state}}">knowledge graph</figure-callout> <b>104</b> to receive both: (1) New updates from <figure-callout id="404" label="sensing infrastructure" filenames="US20210357767A1-20211118-D00004.png" state="{{state}}">sensing infrastructure</figure-callout> <b>404</b> and (2) knowledge updates. Outputs will be sent to the <figure-callout id="402" label="city platform" filenames="US20210357767A1-20211118-D00004.png" state="{{state}}">city platform</figure-callout> <b>402</b>, which then performs necessary actuations using the <figure-callout id="406" label="actuating infrastructure" filenames="US20210357767A1-20211118-D00004.png" state="{{state}}">actuating infrastructure</figure-callout> <b>406</b> and stores the outputs in the <figure-callout id="104" label="knowledge graph" filenames="US20210357767A1-20211118-D00000.png,US20210357767A1-20211118-D00001.png" state="{{state}}">knowledge graph</figure-callout> <b>104</b>.</div>
    </li> <li> <para-num num="[0084]"> </para-num> <div id="p-0081" num="0084" class="description-line">Embodiments of Using the Knowledge Infusion System for Building Management</div>
    </li> <li> <para-num num="[0085]"> </para-num> <div id="p-0082" num="0085" class="description-line"> <figref idrefs="DRAWINGS">FIG. 5</figref> illustrates a <figure-callout id="500" label="knowledge infusion system" filenames="US20210357767A1-20211118-D00005.png" state="{{state}}">knowledge infusion system</figure-callout> <b>500</b> for Building Management according to an embodiment of the present invention. For instance, non-residential buildings usually include a Building Management System (BMS) that connects and controls building sub-systems such as lighting, heating, ventilation and air conditioning or automatic blinds. BMS consist of multiple, tightly integrated layers from <figure-callout id="512" label="management level" filenames="US20210357767A1-20211118-D00005.png" state="{{state}}">management level</figure-callout> <b>512</b> to <figure-callout id="514" label="automation" filenames="US20210357767A1-20211118-D00005.png" state="{{state}}">automation</figure-callout> <b>514</b> and <figure-callout id="516" label="field level" filenames="US20210357767A1-20211118-D00005.png" state="{{state}}">field level</figure-callout> <b>516</b>. The <figure-callout id="516" label="field level" filenames="US20210357767A1-20211118-D00005.png" state="{{state}}">field level</figure-callout> <b>516</b> contains single sensors and actuators (e.g., <figure-callout id="506" label="HVAC devices" filenames="US20210357767A1-20211118-D00005.png" state="{{state}}">HVAC devices</figure-callout> <b>506</b>, <figure-callout id="508" label="light devices" filenames="US20210357767A1-20211118-D00005.png" state="{{state}}">light devices</figure-callout> <b>508</b>, and blind devices <b>510</b>). To improve building functions and reduce energy consumption, the present invention may connect to such a system through an interface to the <figure-callout id="502" label="BMS server" filenames="US20210357767A1-20211118-D00005.png" state="{{state}}">BMS server</figure-callout> <b>502</b> on the <figure-callout id="512" label="management level" filenames="US20210357767A1-20211118-D00005.png" state="{{state}}">management level</figure-callout> <b>512</b>. The <figure-callout id="502" label="BMS server" filenames="US20210357767A1-20211118-D00005.png" state="{{state}}">BMS server</figure-callout> <b>502</b> may receive updates from sensor values that are then processed by the <figure-callout id="110" label="knowledge fusion model" filenames="US20210357767A1-20211118-D00000.png,US20210357767A1-20211118-D00001.png" state="{{state}}">knowledge fusion model</figure-callout> <b>110</b>. In case uncertainty is below a configurable threshold, the <figure-callout id="110" label="knowledge fusion model" filenames="US20210357767A1-20211118-D00000.png,US20210357767A1-20211118-D00001.png" state="{{state}}">knowledge fusion model</figure-callout> <b>110</b> and block <b>504</b> may send actuation commands directly to the <figure-callout id="502" label="BMS server" filenames="US20210357767A1-20211118-D00005.png" state="{{state}}">BMS server</figure-callout> <b>502</b> that result in changed building configurations, such as HVAC setting, lighting or blinds changes.</div>
    </li> <li> <para-num num="[0086]"> </para-num> <div id="p-0083" num="0086" class="description-line">As a BMS is usually a tightly-integrated and hard to extend system, the present invention directly updates the <figure-callout id="104" label="knowledge graph" filenames="US20210357767A1-20211118-D00000.png,US20210357767A1-20211118-D00001.png" state="{{state}}">knowledge graph</figure-callout> <b>104</b> with new sensing values and the outputs of the <figure-callout id="110" label="knowledge fusion model" filenames="US20210357767A1-20211118-D00000.png,US20210357767A1-20211118-D00001.png" state="{{state}}">knowledge fusion model</figure-callout> <b>110</b>. Other applications and users might update the <figure-callout id="104" label="knowledge graph" filenames="US20210357767A1-20211118-D00000.png,US20210357767A1-20211118-D00001.png" state="{{state}}">knowledge graph</figure-callout> <b>104</b> as well. For example, there can be an interface to update building regulations, schedules and other relevant knowledge. Through these updates (and the updates in sensing and output values), the present invention is able to adapt the model automatically and ensure robustness in its output according to safety regulations.</div>
    </li> <li> <para-num num="[0087]"> </para-num> <div id="p-0084" num="0087" class="description-line">Embodiments of using Next Generation Service Interfaces for Linked Data (NGSI-LD) Knowledge Source for Weak and Strong Knowledge Functions for the knowledge infusion system:</div>
    </li> <li> <para-num num="[0088]"> </para-num> <div id="p-0085" num="0088" class="description-line">NGSI-LD allows users to query knowledge sources through a standardized query interface, while using open and shared data models. It is especially popular in the context of Internet of Things systems, such as the ones seen in smart cities (see, e.g., ETSI GS CIM 009: âContext Information Management (CIM); NGSI-LD API,â https://www.etsi.org/deliver/etsi_gs/CIM/001_099/009/01.02.01_60/gs_CIM009v010201p.pdf, which is hereby incorporated by reference herein).</div>
    </li> <li> <para-num num="[0089]"> </para-num> <div id="p-0086" num="0089" class="description-line">The below example shows an instance of the present invention that uses an NGSI-LD accessible knowledge base to retrieve public weather data. The application scenario is that the user is interested in classifying two classes: âFIREâ or âNO_FIREâ, based on sensed temperature values deployed inside a building. The weak knowledge function below shows an example that takes as input the sensed temperature (e.g., from sensors deployed in the building) and the knowledge source used. In this example, the endpoint is an NGSI-LD endpoint, but the present invention may support any available application programming interfaces (APIs) and query interfaces (e.g., a SPARQL endpoint or any available Web API).</div>
    </li> <li> <para-num num="[0090]"> </para-num> <div id="p-0087" num="0090" class="description-line">Inside the function, the sensed temperature entity has multiple context/meta-data associated with it, which is unpacked in line 02-04 (the actual value, the location and the time).</div>
    </li> <li> <para-num num="[0091]"> </para-num> <div id="p-0088" num="0091" class="description-line">The payload for the NGSI-LD interface is constructed, which will query temperature data from available weather observations in a proximity of 100 meters (m) to the sensed temperature entity.</div>
    </li> <li> <para-num num="[0092]"> </para-num> <div id="p-0089" num="0092" class="description-line">The result is a weather temperature entity (line 16), for which is again unpacked as the actual value (line 17). Now, based on human reasoning, the conditional statement in line 19-22 returns either FIRE in case that the temperature of the building sensor is greater than the temperature of the weather observation, plus some configurable margin (line 19), or NO_FIRE, in all other cases.</div>
    </li> <li> <div id="p-0090" num="0000" class="description-line">
      <tables id="TABLE-US-00001" num="00001">
        <patent-tables frame="none" colsep="0" rowsep="0" pgwide="1">
          <table align="left" colsep="0" rowsep="0" cols="2" class="description-table" width="100%">
            <thead>
              <tr class="description-tr">
                <td namest="1" nameend="2" align="center" rowsep="1" class="description-td" colspan="2"> </td>
              </tr>
            </thead>
            
              <tbody><tr class="description-tr">
                <td class="description-td">00</td>
                <td class="description-td">@weak</td>
              </tr>
              <tr class="description-tr">
                <td class="description-td">01</td>
                <td class="description-td">def KF_weather_observation(sensor_temp, knowledge_source=âhttps://my-endpoint.exampleâ):</td>
              </tr>
            
          </tbody></table>
          <table align="left" colsep="0" rowsep="0" cols="2" class="description-table" width="100%">
            <tbody><tr class="description-tr">
                <td class="description-td">02</td>
                <td class="description-td">sensor_temp_value = sensor_temp[âtemperatureâ][âvalueâ]</td>
              </tr>
              <tr class="description-tr">
                <td class="description-td">03</td>
                <td class="description-td">context_location = sensor_temp[âlocationâ][âvalueâ][âcoordinatesâ]</td>
              </tr>
              <tr class="description-tr">
                <td class="description-td">04</td>
                <td class="description-td">context_time = sensor_temp[âdateObservedFromâ][âvalueâ]</td>
              </tr>
              <tr class="description-tr">
                <td class="description-td">05</td>
                <td class="description-td">margin = 10 # 10 Â°C margin for temperature difference</td>
              </tr>
            
          </tbody></table>
          <table align="left" colsep="0" rowsep="0" cols="1" class="description-table" width="100%">
            <tbody><tr class="description-tr">
                <td class="description-td">06</td>
              </tr>
            
          </tbody></table>
          <table align="left" colsep="0" rowsep="0" cols="2" class="description-table" width="100%">
            <tbody><tr class="description-tr">
                <td class="description-td">07</td>
                <td class="description-td">payload = {</td>
              </tr>
            
          </tbody></table>
          <table align="left" colsep="0" rowsep="0" cols="2" class="description-table" width="100%">
            <tbody><tr class="description-tr">
                <td class="description-td">08</td>
                <td class="description-td">âtypeâ: âWeatherâ,</td>
              </tr>
              <tr class="description-tr">
                <td class="description-td">09</td>
                <td class="description-td">âattrsâ: âtemperatureâ,</td>
              </tr>
              <tr class="description-tr">
                <td class="description-td">10</td>
                <td class="description-td">âgeopropertyâ: âlocationâ,</td>
              </tr>
              <tr class="description-tr">
                <td class="description-td">11</td>
                <td class="description-td">âgeorelâ: ânear;minDistance==100â,</td>
              </tr>
              <tr class="description-tr">
                <td class="description-td">12</td>
                <td class="description-td">âgeometryâ: âPointâ,</td>
              </tr>
              <tr class="description-tr">
                <td class="description-td">13</td>
                <td class="description-td">âcoordinatesâ: context_location,</td>
              </tr>
              <tr class="description-tr">
                <td class="description-td">14</td>
                <td class="description-td">âdateObservedFromâ: context_time,</td>
              </tr>
            
          </tbody></table>
          <table align="left" colsep="0" rowsep="0" cols="2" class="description-table" width="100%">
            <tbody><tr class="description-tr">
                <td class="description-td">15</td>
                <td class="description-td">}</td>
              </tr>
              <tr class="description-tr">
                <td class="description-td">16</td>
                <td class="description-td">weather_temp = query_ngsi(knowledge_source, payload)</td>
              </tr>
              <tr class="description-tr">
                <td class="description-td">17</td>
                <td class="description-td">weather_temp_value = weather_temp[âtemperatureâ][âvalueâ]</td>
              </tr>
            
          </tbody></table>
          <table align="left" colsep="0" rowsep="0" cols="1" class="description-table" width="100%">
            <tbody><tr class="description-tr">
                <td class="description-td">18</td>
              </tr>
            
          </tbody></table>
          <table align="left" colsep="0" rowsep="0" cols="2" class="description-table" width="100%">
            <tbody><tr class="description-tr">
                <td class="description-td">19</td>
                <td class="description-td">if sensor_temp_value &gt; weather_temp_value + margin:</td>
              </tr>
            
          </tbody></table>
          <table align="left" colsep="0" rowsep="0" cols="2" class="description-table" width="100%">
            <tbody><tr class="description-tr">
                <td class="description-td">20</td>
                <td class="description-td">return FIRE</td>
              </tr>
            
          </tbody></table>
          <table align="left" colsep="0" rowsep="0" cols="2" class="description-table" width="100%">
            <tbody><tr class="description-tr">
                <td class="description-td">21</td>
                <td class="description-td">else:</td>
              </tr>
            
          </tbody></table>
          <table align="left" colsep="0" rowsep="0" cols="2" class="description-table" width="100%">
            <tbody><tr class="description-tr">
                <td class="description-td">22</td>
                <td class="description-td">return NO_FIRE</td>
              </tr>
              <tr class="description-tr">
                <td namest="1" nameend="2" align="center" rowsep="1" class="description-td" colspan="2"> </td>
              </tr>
            
          </tbody></table>
        </patent-tables>
      </tables>
    </div>
    </li> <li> <para-num num="[0093]"> </para-num> <div id="p-0091" num="0093" class="description-line">Below is another example that represents a basic strong knowledge function that does not require any knowledge source. The user simply has defined that when the sensed temperature is below zero degrees Celsius, there cannot be any fire (line 4-5). Note, a more sophisticated function might take the auto-ignition temperature of the material that is measured with the temperature sensor from a knowledge source, such as WIKIDATA and use this temperature point as a threshold in the condition. This would then potentially also enable the function to adapt to different materials.</div>
    </li> <li> <div id="p-0092" num="0000" class="description-line">
      <tables id="TABLE-US-00002" num="00002">
        <patent-tables frame="none" colsep="0" rowsep="0">
          <table align="left" colsep="0" rowsep="0" cols="2" class="description-table" width="100%">
            <thead>
              <tr class="description-tr">
                <td namest="1" nameend="2" align="center" rowsep="1" class="description-td" colspan="2"> </td>
              </tr>
            </thead>
            
              <tbody><tr class="description-tr">
                <td class="description-td">01</td>
                <td class="description-td">@strong</td>
              </tr>
              <tr class="description-tr">
                <td class="description-td">02</td>
                <td class="description-td">def KF_sensor_temp(sensor_temp, knowledge_source=None):</td>
              </tr>
            
          </tbody></table>
          <table align="left" colsep="0" rowsep="0" cols="2" class="description-table" width="100%">
            <tbody><tr class="description-tr">
                <td class="description-td">03</td>
                <td class="description-td">sensor_temp_value = sensor_temp[âtemperatureâ][âvalueâ]</td>
              </tr>
              <tr class="description-tr">
                <td class="description-td">04</td>
                <td class="description-td">if sensor_temp_value &lt; 0:</td>
              </tr>
            
          </tbody></table>
          <table align="left" colsep="0" rowsep="0" cols="2" class="description-table" width="100%">
            <tbody><tr class="description-tr">
                <td class="description-td">05</td>
                <td class="description-td">return NO_FIRE</td>
              </tr>
            
          </tbody></table>
          <table align="left" colsep="0" rowsep="0" cols="2" class="description-table" width="100%">
            <tbody><tr class="description-tr">
                <td class="description-td">06</td>
                <td class="description-td">else:</td>
              </tr>
            
          </tbody></table>
          <table align="left" colsep="0" rowsep="0" cols="2" class="description-table" width="100%">
            <tbody><tr class="description-tr">
                <td class="description-td">07</td>
                <td class="description-td">return ABSTAIN</td>
              </tr>
              <tr class="description-tr">
                <td namest="1" nameend="2" align="center" rowsep="1" class="description-td" colspan="2"> </td>
              </tr>
            
          </tbody></table>
        </patent-tables>
      </tables>
    </div>
    </li> <li> <para-num num="[0094]"> </para-num> <div id="p-0093" num="0094" class="description-line">Embodiments of the present invention provide for some or all of the following improvements and advantages:
</div> </li> <ul> <li id="ul0003-0001" num="0095">(1) A mechanism for human experts to inject adaptive supervision sources (in form of programmable weak and strong knowledge functions) and the ensemble of these sources into a knowledge model.</li> <li id="ul0003-0002" num="0096">(2) An ensemble of âTeacher basedâ ML (supervised learning or RL) and the knowledge model (based on the programmable knowledge functions) to ensure robustness through the application of strong functions and to calculate an uncertainty value to decide if the ML model has become outdated/obsolete.</li> <li id="ul0003-0003" num="0097">(3) Embodiments of the present invention may use a common technique to improve many issues in IoT scenarios. For instance, the weak and strong knowledge functions may include a reasoning part and a query interface to the in internal knowledge graph and external knowledge. This may enable them to adapt automatically based on new knowledge without any human involvement. Through that, the same knowledge infusion system may be used across different deployments and it will automatically update through time. The concept of strong knowledge functions and the calculation of an uncertainty value additionally addresses the robustness problem of ML systems. Certain outputs (e.g., to adhere to regulations or safety) may be guaranteed, while being able to update the ML model when reality has drifted apart from it. The calculation of an uncertainty value based on both ML model and knowledge model is simple, generally applicable and does not depend on specific model architectures such as Bayesian Neural Nets. This makes the present invention unique from both transfer learning methods and methods from safe and trustworthy machine learning.</li> </ul>

    <li> <para-num num="[0098]"> </para-num> <div id="p-0094" num="0098" class="description-line">According to an embodiment of the present invention, a method and system for automated knowledge infusion for robust and transferable machine learning in IoT systems comprises the steps of:
</div> </li> <ul> <li id="ul0004-0001" num="0000"> <ul> <li id="ul0005-0001" num="0099">The reading/execution of adaptive, programmable knowledge functions including both, strong and weak functions.</li> <li id="ul0005-0002" num="0100">The flexible mapping of a set of knowledge functions to different ensemble methods.</li> <li id="ul0005-0003" num="0101">The continuous maintenance of a knowledge model based on the created ensemble of weak and strong knowledge functions (that query external knowledge base/bases).</li> <li id="ul0005-0004" num="0102">The training of a âTeacher basedâ machine learning model based on the created knowledge model ensemble.</li> <li id="ul0005-0005" num="0103">In the execution phase, the real-time combination/ensemble of the knowledge model with the âTeacher basedâ machine learning model.</li> <li id="ul0005-0006" num="0104">The overwrite/correction of machine learning model outputs which are in contradiction with outputs of the strong knowledge ensemble in order to improve robustness.</li> <li id="ul0005-0007" num="0105">The calculation of an uncertainty value that represents the uncertainty of each output of the ML model.</li> <li id="ul0005-0008" num="0106">The re-training of the ML model if accumulated uncertainty values extend a configurable threshold.</li> </ul> </li> </ul>

    <li> <para-num num="[0107]"> </para-num> <div id="p-0095" num="0107" class="description-line"> <figref idrefs="DRAWINGS">FIG. 6</figref> is an <figure-callout id="600" label="exemplary process" filenames="US20210357767A1-20211118-D00006.png" state="{{state}}">exemplary process</figure-callout> <b>600</b> for using knowledge infusion for robust and transferable machine learning models for IoT systems in accordance with one or more embodiments of the present application. The descriptions, illustrations, and processes of <figref idrefs="DRAWINGS">FIG. 6</figref> are merely exemplary and the <figure-callout id="600" label="process" filenames="US20210357767A1-20211118-D00006.png" state="{{state}}">process</figure-callout> <b>600</b> may use other descriptions, illustrations, and processes using knowledge infusion for robust and transferable machine learning models for IoT systems. The <figure-callout id="600" label="process" filenames="US20210357767A1-20211118-D00006.png" state="{{state}}">process</figure-callout> <b>600</b> may be performed by one or more computing devices. The computing devices may include one or more processors and memory. The memory may store instructions that when executed by the one or more processors, are configured to perform the <figure-callout id="600" label="process" filenames="US20210357767A1-20211118-D00006.png" state="{{state}}">process</figure-callout> <b>600</b>.</div>
    </li> <li> <para-num num="[0108]"> </para-num> <div id="p-0096" num="0108" class="description-line">In operation, at <figure-callout id="602" label="block" filenames="US20210357767A1-20211118-D00006.png" state="{{state}}">block</figure-callout> <b>602</b>, a computing device receives a plurality of adaptive and programmable knowledge functions. The knowledge functions may include a plurality of strong functions (e.g., axioms) and a plurality of weak functions (e.g., mostly true statements). For example, referring to <figref idrefs="DRAWINGS">FIG. 1</figref>, the <figure-callout id="106" label="user interface" filenames="US20210357767A1-20211118-D00000.png,US20210357767A1-20211118-D00001.png" state="{{state}}">user interface</figure-callout> <b>106</b> may provide the plurality of adaptive and programmable knowledge functions to a computing device such as the knowledge <figure-callout id="108" label="infusion computing device" filenames="US20210357767A1-20211118-D00000.png,US20210357767A1-20211118-D00001.png" state="{{state}}">infusion computing device</figure-callout> <b>108</b>.</div>
    </li> <li> <para-num num="[0109]"> </para-num> <div id="p-0097" num="0109" class="description-line">According to at least one embodiment of the present invention, the computing device and/or the <figure-callout id="106" label="user interface" filenames="US20210357767A1-20211118-D00000.png,US20210357767A1-20211118-D00001.png" state="{{state}}">user interface</figure-callout> <b>106</b> may update the knowledge functions using one or more <figure-callout id="102" label="external knowledge sources" filenames="US20210357767A1-20211118-D00000.png,US20210357767A1-20211118-D00001.png" state="{{state}}">external knowledge sources</figure-callout> <b>102</b> and/or an internal knowledge base <b>104</b> (e.g., through a query language). The <figure-callout id="102" label="external knowledge sources" filenames="US20210357767A1-20211118-D00000.png,US20210357767A1-20211118-D00001.png" state="{{state}}">external knowledge sources</figure-callout> <b>102</b> may include APIs (e.g., weather APIs) and/or knowledge graphs such as ontologies. The knowledge functions may output a label or action based on the user provided logic and the knowledge received/queried from the knowledge base and external knowledge sources.</div>
    </li> <li> <para-num num="[0110]"> </para-num> <div id="p-0098" num="0110" class="description-line">At <figure-callout id="604" label="block" filenames="US20210357767A1-20211118-D00006.png" state="{{state}}">block</figure-callout> <b>604</b>, the computing device generates a knowledge model based on the plurality of strong functions and the plurality of weak functions. For example, to generate the knowledge model, the computing device may map the strong and weak functions to one or more ensemble methods (e.g. a majority ensemble method, a generative ensemble method, or a Tutor for Reinforced Learning (Tutor4RL) ensemble method).</div>
    </li> <li> <para-num num="[0111]"> </para-num> <div id="p-0099" num="0111" class="description-line">According to at least one embodiment of the present invention, subsequent to generating the knowledge model, the computing device and/or the <figure-callout id="106" label="user interface" filenames="US20210357767A1-20211118-D00000.png,US20210357767A1-20211118-D00001.png" state="{{state}}">user interface</figure-callout> <b>106</b> may continuously maintain the knowledge model based on continuously querying the one or more <figure-callout id="102" label="external knowledge sources" filenames="US20210357767A1-20211118-D00000.png,US20210357767A1-20211118-D00001.png" state="{{state}}">external knowledge sources</figure-callout> <b>102</b> and/or the <figure-callout id="104" label="knowledge base" filenames="US20210357767A1-20211118-D00000.png,US20210357767A1-20211118-D00001.png" state="{{state}}">knowledge base</figure-callout> <b>104</b> to provide and update the plurality of weak and strong functions. For instance, each time a pre-defined time period elapses, the computing device and/or the <figure-callout id="106" label="user interface" filenames="US20210357767A1-20211118-D00000.png,US20210357767A1-20211118-D00001.png" state="{{state}}">user interface</figure-callout> <b>106</b> may provide a query to the <figure-callout id="102" label="external knowledge sources" filenames="US20210357767A1-20211118-D00000.png,US20210357767A1-20211118-D00001.png" state="{{state}}">external knowledge sources</figure-callout> <b>102</b> and/or the <figure-callout id="104" label="knowledge base" filenames="US20210357767A1-20211118-D00000.png,US20210357767A1-20211118-D00001.png" state="{{state}}">knowledge base</figure-callout> <b>104</b> indicating whether any knowledge functions are to be updated. Based on the query, the computing device and/or <figure-callout id="106" label="user interface" filenames="US20210357767A1-20211118-D00000.png,US20210357767A1-20211118-D00001.png" state="{{state}}">user interface</figure-callout> <b>106</b> may receive updated information from the <figure-callout id="102" label="external knowledge sources" filenames="US20210357767A1-20211118-D00000.png,US20210357767A1-20211118-D00001.png" state="{{state}}">external knowledge sources</figure-callout> <b>102</b> and/or the <figure-callout id="104" label="knowledge base" filenames="US20210357767A1-20211118-D00000.png,US20210357767A1-20211118-D00001.png" state="{{state}}">knowledge base</figure-callout> <b>104</b> and may use the updated information to update the weak and strong functions.</div>
    </li> <li> <para-num num="[0112]"> </para-num> <div id="p-0100" num="0112" class="description-line">At <figure-callout id="606" label="block" filenames="US20210357767A1-20211118-D00006.png" state="{{state}}">block</figure-callout> <b>606</b>, the computing device trains a machine learning model based on the generated knowledge model. For example, the computing device may use the strong and weak functions and/or ensembles to train a machine learning model. The machine learning model may be a supervised machine learning model and/or a reinforced learning (RL) model.</div>
    </li> <li> <para-num num="[0113]"> </para-num> <div id="p-0101" num="0113" class="description-line">According to at least one embodiment of the present invention, block <b>606</b> may be performed subsequent to block <b>608</b> (e.g., deploying the machine learning model and/or the knowledge model within an environment). For instance, the machine learning model may be an RL model that may be actively trained within the environment during runtime. As such, the computing device (or another computing device) may train the RL model during runtime and after deployment. According to at least one embodiment of the present invention, the machine learning model may be an RL model and the computing device may pre-train the RL model (e.g., RL policy) prior to deployment (e.g., prior to block <b>608</b>). For instance, the computing device may use the knowledge model as an offline âteacherâ to train the RL model prior to deployment.</div>
    </li> <li> <para-num num="[0114]"> </para-num> <div id="p-0102" num="0114" class="description-line">At <figure-callout id="608" label="block" filenames="US20210357767A1-20211118-D00006.png" state="{{state}}">block</figure-callout> <b>608</b>, the computing device deploys the machine learning model and the knowledge model within an environment to perform one or more operations. For instance, the computing device may package the machine learning model, the knowledge model, and/or a knowledge fusion component within a knowledge fusion model (e.g., knowledge fusion model <b>110</b>). The computing device may deploy the knowledge fusion model as a container and/or as part of an IoT cloud-edge framework. As described above, the environments may include, but are not limited to, operation within a smart city (e.g., a smart city system), operation for building management (e.g., a building energy management system), operation using NGSI-LD knowledge sources, operation for a data center (e.g., a data center energy management system), and/or operation in a retail system (e.g., a smart retail system).</div>
    </li> <li> <para-num num="[0115]"> </para-num> <div id="p-0103" num="0115" class="description-line">According to at least one embodiment of the present invention, the computing device may provide the knowledge fusion model including the machine learning model, the knowledge model, and/or the knowledge fusion component to a second computing device.</div>
    </li> <li> <para-num num="[0116]"> </para-num> <div id="p-0104" num="0116" class="description-line">At <figure-callout id="610" label="block" filenames="US20210357767A1-20211118-D00006.png" state="{{state}}">block</figure-callout> <b>610</b>, the computing device (or the second computing device) performs the one or more operations within the environment using the machine learning model and the knowledge model. For example, subsequent to deploying the machine learning model and the knowledge model within the environment, the first or second computing device receives new data (e.g., <figure-callout id="202" label="data" filenames="US20210357767A1-20211118-D00002.png,US20210357767A1-20211118-D00003.png" state="{{state}}">data</figure-callout> <b>202</b> from <figref idrefs="DRAWINGS">FIG. 2</figref>) associated with the environment from one or more sensors. The computing device may input the new data into the machine learning model and/or the knowledge model. Based on inputting the new data into the machine learning model, the computing device may determine or generate one or more machine learning model outputs and/or one or more probability values associated with the machine learning model outputs. Based on inputting the new data into the knowledge model (e.g., the strong and/or weak functions), the computing device may determine or generate one or more knowledge model outputs. The computing device may use the knowledge fusion component of the <figure-callout id="110" label="knowledge fusion model" filenames="US20210357767A1-20211118-D00000.png,US20210357767A1-20211118-D00001.png" state="{{state}}">knowledge fusion model</figure-callout> <b>110</b> to determine a fused output. For instance, based on the knowledge model outputs and the machine learning model outputs, the computing device may correct and/or overwrite the machine learning model outputs using the knowledge model outputs. For example, if the knowledge model outputs (e.g., the outputs from the strong knowledge functions) contradict the outputs from the machine learning model, the computing device may overwrite or correct the machine learning model outputs with the outputs from the strong knowledge functions. Additionally, and/or alternatively, the computing device may determine a disagreement value based on the disagreements between the knowledge and machine learning models (e.g., contradictions of outputs from knowledge model and machine learning model).</div>
    </li> <li> <para-num num="[0117]"> </para-num> <div id="p-0105" num="0117" class="description-line">According to at least one embodiment of the present invention, the computing device (or second computing device) may determine an uncertainty value based on the one or more machine learning model outputs and/or the one or probability values. The uncertainty value represents uncertainty of the one or more machine learning model outputs from the machine learning model. Additionally, and/or alternatively, the computing device may calculate or determine the uncertainty value based on the one or more probability values and the disagreement value. For instance, as described above, the computing device may combine the disagreement value and the probability values to determine the uncertainty value.</div>
    </li> <li> <para-num num="[0118]"> </para-num> <div id="p-0106" num="0118" class="description-line">According to at least one embodiment of the present invention, the computing device (or second computing device) may compare the uncertainty value with a threshold (e.g., as described in block <b>204</b>). Based on the uncertainty value not exceeding (e.g., being less than) the threshold, the computing device may update a <figure-callout id="104" label="knowledge base" filenames="US20210357767A1-20211118-D00000.png,US20210357767A1-20211118-D00001.png" state="{{state}}">knowledge base</figure-callout> <b>104</b> using the one or more machine learning model outputs. Additionally, and/or alternatively, the computing device may update the knowledge model within the <figure-callout id="110" label="knowledge fusion model" filenames="US20210357767A1-20211118-D00000.png,US20210357767A1-20211118-D00001.png" state="{{state}}">knowledge fusion model</figure-callout> <b>110</b> using the updated <figure-callout id="104" label="knowledge base" filenames="US20210357767A1-20211118-D00000.png,US20210357767A1-20211118-D00001.png" state="{{state}}">knowledge base</figure-callout> <b>104</b>. Based on the uncertainty value exceeding (e.g., being greater than) the threshold, the computing device may re-train the machine learning model. For instance, the computing device may re-train the machine learning model using the <figure-callout id="104" label="knowledge base" filenames="US20210357767A1-20211118-D00000.png,US20210357767A1-20211118-D00001.png" state="{{state}}">knowledge base</figure-callout> <b>104</b> and/or the updated knowledge base <b>104</b> (e.g., the <figure-callout id="104" label="knowledge base" filenames="US20210357767A1-20211118-D00000.png,US20210357767A1-20211118-D00001.png" state="{{state}}">knowledge base</figure-callout> <b>104</b> that has been updated with one or more outputs from the machine learning model and/or the external knowledge sources <b>102</b>).</div>
    </li> <li> <para-num num="[0119]"> </para-num> <div id="p-0107" num="0119" class="description-line">According to at least one embodiment of the present invention, the computing device that re-trains the machine learning model may be the same computing device that initially trained the machine learning model. For instance, the set-up phase (e.g., blocks <b>602</b>-<b>608</b>) may be performed by a first computing device and the execution phase (e.g., block <b>610</b>) may be performed by a second computing device. Based on the uncertainty value exceeding the threshold, the second computing device may provide instructions to the first computing to re-train the machine learning model. After re-training the machine learning model, the first device may provide the re-trained machine learning model back to the second computing device.</div>
    </li> <li> <para-num num="[0120]"> </para-num> <div id="p-0108" num="0120" class="description-line">According to at least one embodiment of the present invention, the computing device may determine a moving average associated with the uncertainty value. In other words, the computing device may determine a plurality of uncertainty values over a period of time and determine a moving average based on the uncertainty values. The computing device may compare the moving average with a threshold to determine whether to update the <figure-callout id="104" label="knowledge base" filenames="US20210357767A1-20211118-D00000.png,US20210357767A1-20211118-D00001.png" state="{{state}}">knowledge base</figure-callout> <b>104</b> with the outputs from the machine learning model or whether to re-train the machine learning model with the knowledge model.</div>
    </li> <li> <para-num num="[0121]"> </para-num> <div id="p-0109" num="0121" class="description-line">In the following, particular embodiments of the present invention are described, along with experimental results illustrating computational improvements achieved. To some extent, the following description uses different terminology or symbols to refer to the same components or notations which are used in embodiments of the present invention described above, but would be understood by ordinarily skilled artisans as referring to the same or similar components or notations.</div>
    </li> <li> <para-num num="[0122]"> </para-num> <div id="p-0110" num="0122" class="description-line">Machine learning (ML) applications in Internet of Things (IoT) scenarios face the issue that supervision signals, such as labeled data, may be scarce and expensive to obtain. For example, it often requires a human to manually label events in a data stream by observing the same events in the real world. In addition, the performance of trained models usually depends on a specific context: (1) location, (2) time and (3) data quality. This context is not static in reality, making it hard to achieve robust and transferable machine learning for IoT systems in practice. Below, these challenges are addressed with a Knowledge Infusion method and system. First, two past case studies were performed and discussed below in which external knowledge is combined with traditional data-driven machine learning in IoT scenarios to ease the supervision effort: (1) a weak-supervision approach for the IoT domain to auto-generate labels based on external knowledge (e.g., domain knowledge) encoded in simple labeling functions. The evaluation for transport mode classification achieves a micro-F1 score of 80.2%, with only seven labeling functions, on par with a fully supervised model that relies on hand-labeled data. (2) Guiding functions are introduced to Reinforcement Learning (RL) to guide the agents&#39; decisions and experience. In some examples, the guided reinforcement learning achieves more than three times higher reward in the beginning of its training than an agent with no external knowledge. The lessons learned from these experiences are used to develop knowledge infusion. In knowledge infusion, the aim is to automate the inclusion of knowledge from existing knowledge bases and domain experts to combine it with traditional data-driven machine learning techniques during setup/training phase, but also during the execution phase.</div>
    </li> <li> <para-num num="[0123]"> </para-num> <div id="p-0111" num="0123" class="description-line">The Internet of Things (IoT) is expanding rapidly in various sectors and applications such as smart buildings, smart cities and smart transportation. At the same time, machine learning (ML) supported systems are increasingly used to provide meaningful insights by performing classification or prediction tasks on top of IoT data and to efficiently orchestrate tasks between cloud and edge. Based on practical experience, the IoT domain poses various challenges for generalizing traditional data driven ML approaches to provide robust and transferable results. This often has to do with changes in location, time and in data quality context, which is shown in <figref idrefs="DRAWINGS">FIG. 7</figref>. In other words, <figref idrefs="DRAWINGS">FIG. 7</figref> illustrates the context-dimensions (e.g., Time, Location, and Data Quality) of ML in IoT systems.</div>
    </li> <li> <para-num num="[0124]"> </para-num> <div id="p-0112" num="0124" class="description-line">Location. Different locations (e.g., separate sensor deployments in a single city or deployments in multiple cities) behave differently. For example, the radio-frequency (RF) signal propagation depends heavily on the deployment location (e.g., through varying signal attenuation).</div>
    </li> <li> <para-num num="[0125]"> </para-num> <div id="p-0113" num="0125" class="description-line">Time. Deployment characteristics as well as data patterns change through time (e.g., a ML model that works well when training data is collected such as in the lab, might degrade in performance throughout the lifetime of a deployment). Further, it is hard to quantify this degradation, because continuously obtaining ground truth data is expensive and deployment times comprise often several years.</div>
    </li> <li> <para-num num="[0126]"> </para-num> <div id="p-0114" num="0126" class="description-line">Data Quality. In IoT deployments, data is frequently noisy, sparse and heavily imbalanced (e.g., an application might require the classification of relatively rare events such as road accidents or infrequent transport modes; a sensor network deployment might result in high variances in sampling frequency and missing data due to packet loss). As IoT devices have limited power and computation, collecting highly dense data may often be difficult.</div>
    </li> <li> <para-num num="[0127]"> </para-num> <div id="p-0115" num="0127" class="description-line">As such, in view of the above, machine learning in the IoT domain needs to achieve robustness and transferability during setup/training as well as during execution phase in order to deal with such varying context.</div>
    </li> <li> <para-num num="[0128]"> </para-num> <div id="p-0116" num="0128" class="description-line">Traditionally, the transferability problem has been addressed often through transfer learning, which has the aim to transfer knowledge learned for one task to a related task. The robustness problem has been recently addressed in the context of safe learning systems (see below). In the present invention, embodiments are described that use a Knowledge Infusion method to address these issues. For instance, instead of transferring trained knowledge to another task (as in transfer learning), Knowledge Infusion intends to transfer knowledge used for the training phase between tasks with little effort. This transferability is achieved through adaptive weak and strong knowledge functions that are interfacing with a knowledge graph and external knowledge sources (for example open knowledge bases such as OPENSTREETMAP or WIKIDATA) in order to adapt dynamically to a new context by querying these knowledge sources. To achieve this, two types of knowledge functions are used: weak knowledge functions, that are thought to be mostly true and strong knowledge functions that comprise axioms (canonical truths). Then, these knowledge functions are combined into a weak ensemble and a strong ensemble that together form a âwhite-boxâ knowledge model. Next, this knowledge model is used to train any traditional supervised machine learning model (e.g., using the labels generated with the knowledge model). As has been demonstrated, the machine learning model will usually perform better than the model/labels used for training it. The reason is that the machine learning model will learn to generalize the patterns found in the data while also partially removing noise in it.</div>
    </li> <li> <para-num num="[0129]"> </para-num> <div id="p-0117" num="0129" class="description-line">In Knowledge Infusion, the âwhite-boxâ knowledge model is continuously updated (through new knowledge or added/updated knowledge functions) and then used to ensure robustness of the system during execution, while also identifying situations in which the context in the real world shifts away from the trained ML model and re-training is needed.</div>
    </li> <li> <para-num num="[0130]"> </para-num> <div id="p-0118" num="0130" class="description-line">Below, two previous experiences where external knowledge is exploited in the training process is discussed: (1) In supervised machine learning for a smart mobility use case by adapting the weak-supervision framework SNORKEL to fit the IoT domain and (2) For reinforcement-learning, where external knowledge is used to guide agent exploration. These experiences and the lessons learned open up the way to the present invention. After, a discussion of related work and an outlook on additional embodiments is discussed.</div>
    </li> <li> <para-num num="[0131]"> </para-num> <div id="p-0119" num="0131" class="description-line">Below, two previous examples are in which external knowledge is used successfully in machine learning systems in the IoT domain: (1) In supervised machine learning for transport mode detection; (2) for reinforcement-learning. The lessons learned from these examples are a starting point to develop the knowledge infusion of the present invention.</div>
    </li> <li> <para-num num="[0132]"> </para-num> <div id="p-0120" num="0132" class="description-line">Supervised Machine Learning: Transport Mode Detection</div>
    </li> <li> <para-num num="[0133]"> </para-num> <div id="p-0121" num="0133" class="description-line">An important application of context-aware computing is detecting transportation modes of people using mobile devices such as smartphones. Transport mode detection is a key enabler for physical activity monitoring as well as personal environmental impact monitoring. It is also critical to optimize urban multimodal human mobility and to enable end-user applications, such as automated and individual carbon dioxide (CO2) emission tracking.</div>
    </li> <li> <para-num num="[0134]"> </para-num> <div id="p-0122" num="0134" class="description-line">Transport mode detection requires a two-step segmentation of sensor data to trips and sections (based on transport modes), and an accurate classification of these sections into modes (e.g., walking, bicycling, riding a bus). Traditionally, previous examples have proposed transport mode detection using smartphone sensors such as GPS, accelerometer, barometer, or combinations of these and adding geographic information system (GIS) data to improve accuracy. Most of these examples leverage supervised ML using labeled data points as training data. This labeled data is usually provided by users/participants of the studies.</div>
    </li> <li> <para-num num="[0135]"> </para-num> <div id="p-0123" num="0135" class="description-line">Exemplary Approach</div>
    </li> <li> <para-num num="[0136]"> </para-num> <div id="p-0124" num="0136" class="description-line">Embodiments of the present invention address the transport mode detection problem by adopting weak supervision techniques originally used in information extraction to this problem. <figref idrefs="DRAWINGS">FIG. 8</figref> illustrates the main building blocks used to address the transport mode detection problem according to an embodiment of the present invention. In particular, <figref idrefs="DRAWINGS">FIG. 8</figref> shows the transport mode detection steps.</div>
    </li> <li> <para-num num="[0137]"> </para-num> <div id="p-0125" num="0137" class="description-line">First, in the mobile sensor <figure-callout id="802" label="data collection phase" filenames="US20210357767A1-20211118-D00008.png" state="{{state}}">data collection phase</figure-callout> <b>802</b>, sensor data (location and activity data) is sensed from user smartphones. In the <figure-callout id="804" label="Segmentation Phase" filenames="US20210357767A1-20211118-D00008.png" state="{{state}}">Segmentation Phase</figure-callout> <b>804</b>, time series from multiple sensors is aligned to the same sampling time and segment time series first into trips (by applying a dwell time heuristics) and section candidates (using a developed activity supported walk point segmentation algorithm). The outcome of this step is a set of section candidates, each candidate contains a time-series of location and activity data points.</div>
    </li> <li> <para-num num="[0138]"> </para-num> <div id="p-0126" num="0138" class="description-line">Second, in the Label &amp; <figure-callout id="806" label="Training Phase" filenames="US20210357767A1-20211118-D00008.png" state="{{state}}">Training Phase</figure-callout> <b>806</b>, a set of labeling functions is applied to these candidates. Each function encodes human heuristics and/or external knowledge (e.g., from OPENSTREETMAP) to âvoteâ on the transport class of a candidate section. The resulting label matrix is fed into the generative ensemble, which learns a generative model from all labeling functions and their votes on each candidate section, taking into account the underlying accuracy of each labeling function.</div>
    </li> <li> <para-num num="[0139]"> </para-num> <div id="p-0127" num="0139" class="description-line">Finally, the generative model is used to label all candidate segments and train a discriminative ML model with the probabilistic labels. The ML model generalizes beyond the information encoded in the labeling functions. In the <figure-callout id="808" label="Classification Phase" filenames="US20210357767A1-20211118-D00008.png" state="{{state}}">Classification Phase</figure-callout> <b>808</b>, this model is then used to classify incoming candidate section into transport modes. Based on this classification, re-segmentation is performed by merging adjacent sections of the same mode and the results (classified trips and sections) are returned to users.</div>
    </li> <li> <para-num num="[0140]"> </para-num> <div id="p-0128" num="0140" class="description-line">Results</div>
    </li> <li> <para-num num="[0141]"> </para-num> <div id="p-0129" num="0141" class="description-line">This method was validated against a dataset that was collected in the wild over a period of 4 months, containing 300,000 datapoints from 8 end-users. Global positioning system (GPS) location was sensed through iOS and Android Location API and accelerometer based activity data through the Activity API. Users have partially labeled data with a developed visual labeling tool. This data was used to evaluate the method of the present invention, splitting the data in training (Â½) and test data (Â½). The method classifies four transport modes: walk, bike, car and train.</div>
    </li> <li> <para-num num="[0142]"> </para-num> <div id="p-0130" num="0142" class="description-line">Embodiments of the present invention uses seven labeling functions that combine external knowledge with sensor data to vote on the transport classification of a section. For example, functions are implemented that use the sensed speed together with human heuristics on common speeds for different modalities to vote on the transport mode (LF_median_sensed_speed and LF_quantile_sensed_speed). OPENSTREETMAP (OSM) may be integrated and used to the provided annotations of public transport stops (LF_osm). ML models may be trained using the data labeled by the generative model, oversampling underrepresented classes with synthetic minority oversampling technique (SMOTE).</div>
    </li> <li> <para-num num="[0143]"> </para-num> <div id="p-0131" num="0143" class="description-line">Several classifiers are tested, from simple linear models to neural networks, and the best performance with Random Forests (RF) was observed, achieving 80.2% in F1 score.</div>
    </li> <li> <para-num num="[0144]"> </para-num> <div id="p-0132" num="0144" class="description-line">The results of the present invention were compared against a traditional supervised approach that uses the hand-labeled data of the training split results and results in an only marginally better F1 score of 81.0%. <figref idrefs="DRAWINGS">FIG. 9</figref> illustrates a table <b>900</b> that summarizes the overall results (e.g., F1 scores) of generated labels and end models against hand-labeled ground truth. For instance, the F1 score for fully-supervised random forest was 81.0%. The F1 score for weakly-supervised random forest was 80.2%. The F1 score for generative model (generated labels) was 74.1%.</div>
    </li> <li> <para-num num="[0145]"> </para-num> <div id="p-0133" num="0145" class="description-line">Reinforcement Learning: IOT-ML Pipeline Orchestration</div>
    </li> <li> <para-num num="[0146]"> </para-num> <div id="p-0134" num="0146" class="description-line">Reinforcement Learning (RL) has been proven its ability to deal with complex problems, achieving super-human performance in some cases. However, its applicability in real-world problems is still lagging for a number of reasons, including: (1) learning on the real system from limited samples, and (2) safety constraints that should never or at least rarely be violated. Several approaches have emerged to address these problems such as (1) learning from human demonstrations or historical data, and (2) calculating uncertainty in decisions to manage safety and combinations with supervised learning and human intervention.</div>
    </li> <li> <para-num num="[0147]"> </para-num> <div id="p-0135" num="0147" class="description-line">Traditionally, RL has been applied to computer systems tasks, such as database management system configuration or container orchestration for Big Data and IoT systems. In this domain, the traditional approaches are not applicable or are inconvenient because (1) data from the system might not be available if the system is new, and even when data is available, the system deployment, load and parameters vary, making these data partially true at best; in addition, (2) the cost of incorrect actions might be high when dealing with systems in production environments, training a supervised model might not possible for the reasons mentioned before, and the reaction of a human operator is expensive and slow to accommodate the system performance in a timely manner.</div>
    </li> <li> <para-num num="[0148]"> </para-num> <div id="p-0136" num="0148" class="description-line">Exemplary Approach</div>
    </li> <li> <para-num num="[0149]"> </para-num> <div id="p-0137" num="0149" class="description-line">To address these problems and make RL applicable to real-world problems, Tutor4RL is introduced. <figref idrefs="DRAWINGS">FIG. 10</figref> illustrates the Tutor4RL used to address the problems addressed above to make RL applicable to real-world problems according to an embodiment of the present invention. In particular, <figref idrefs="DRAWINGS">FIG. 10</figref> shows the overall working of the Tutor4RL.</div>
    </li> <li> <para-num num="[0150]"> </para-num> <div id="p-0138" num="0150" class="description-line">In particular, a <figure-callout id="1004" label="new component" filenames="US20210357767A1-20211118-D00010.png" state="{{state}}">new component</figure-callout> <b>1004</b> is added to the regular RL framework called <figure-callout id="1004" label="Tutor" filenames="US20210357767A1-20211118-D00010.png" state="{{state}}">Tutor</figure-callout> <b>1004</b> to guide the agent&#39;s <b>1006</b> decisions when the <figure-callout id="1006" label="agent" filenames="US20210357767A1-20211118-D00010.png" state="{{state}}">agent</figure-callout> <b>1006</b> has no or little experience. The <figure-callout id="1004" label="tutor" filenames="US20210357767A1-20211118-D00010.png" state="{{state}}">tutor</figure-callout> <b>1004</b> is able to guide the <figure-callout id="1006" label="agent" filenames="US20210357767A1-20211118-D00010.png" state="{{state}}">agent</figure-callout> <b>1006</b> to take reasonable decisions because it can directly leverage a set of <figure-callout id="1002" label="knowledge functions" filenames="US20210357767A1-20211118-D00010.png" state="{{state}}">knowledge functions</figure-callout> <b>1002</b> defined by <figure-callout id="1004" label="domain experts" filenames="US20210357767A1-20211118-D00010.png" state="{{state}}">domain experts</figure-callout> <b>1004</b>. In this way, Tutor4RL improves greatly the performance of the <figure-callout id="1006" label="agent" filenames="US20210357767A1-20211118-D00010.png" state="{{state}}">agent</figure-callout> <b>1006</b> in its early phase.</div>
    </li> <li> <para-num num="[0151]"> </para-num> <div id="p-0139" num="0151" class="description-line">The <figure-callout id="1004" label="tutor" filenames="US20210357767A1-20211118-D00010.png" state="{{state}}">tutor</figure-callout> <b>1004</b> possesses external knowledge and interacts with the <figure-callout id="1006" label="agent" filenames="US20210357767A1-20211118-D00010.png" state="{{state}}">agent</figure-callout> <b>1006</b> during training. The <figure-callout id="1004" label="tutor" filenames="US20210357767A1-20211118-D00010.png" state="{{state}}">tutor</figure-callout> <b>1004</b> takes as input the state of the environment, and outputs the action to take; in a similar way to the agent&#39;s policy. However, the <figure-callout id="1004" label="tutor" filenames="US20210357767A1-20211118-D00010.png" state="{{state}}">tutor</figure-callout> <b>1004</b> is implemented as programmable functions, in which external knowledge is used to decide the mapping between states and actions (e.g., for ATARI Breakout, the <figure-callout id="1004" label="tutor" filenames="US20210357767A1-20211118-D00010.png" state="{{state}}">tutor</figure-callout> <b>1004</b> takes the frame from the video game as input, and outputs in what direction the bar should be moved). For every time step, the <figure-callout id="1004" label="tutor" filenames="US20210357767A1-20211118-D00010.png" state="{{state}}">tutor</figure-callout> <b>1004</b> interacts with the <figure-callout id="1006" label="agent" filenames="US20210357767A1-20211118-D00010.png" state="{{state}}">agent</figure-callout> <b>1006</b> and gives advice to the <figure-callout id="1006" label="agent" filenames="US20210357767A1-20211118-D00010.png" state="{{state}}">agent</figure-callout> <b>1006</b> for making better decisions, based on all provided knowledge functions <b>1002</b>.</div>
    </li> <li> <para-num num="[0152]"> </para-num> <div id="p-0140" num="0152" class="description-line">In order to decide when to use the policy&#39;s decisions or the Tutor&#39;s guides, the parameter Ï is defined that assumes a value in the range (0, 1), which is linearly decreased during training. Ï is a parameter of the model and the best value to initialize it depends on the use case; thus its initial value is left to be decided during implementation.</div>
    </li> <li> <para-num num="[0153]"> </para-num> <div id="p-0141" num="0153" class="description-line">The tutor&#39;s behavior provides a guide to the <figure-callout id="1006" label="agent" filenames="US20210357767A1-20211118-D00010.png" state="{{state}}">agent</figure-callout> <b>1006</b>, but the <figure-callout id="1006" label="agent" filenames="US20210357767A1-20211118-D00010.png" state="{{state}}">agent</figure-callout> <b>1006</b> may still improve upon it, reaching an even better performance than the one defined by <figure-callout id="1010" label="experts" filenames="US20210357767A1-20211118-D00010.png" state="{{state}}">experts</figure-callout> <b>1010</b>. This is achieved thanks to two mechanisms that are already present in RL: (1) empirical evaluation of decisions and (2) E-greedy exploration. In (1), if the action suggested by the <figure-callout id="1004" label="Tutor" filenames="US20210357767A1-20211118-D00010.png" state="{{state}}">Tutor</figure-callout> <b>1004</b> is incorrect (e.g., it provides a negative reward, the agent will learn that this action is wrong and should therefore, not be used for the given state). In the case the reward is positive but could still be improved, the <figure-callout id="1006" label="agent" filenames="US20210357767A1-20211118-D00010.png" state="{{state}}">agent</figure-callout> <b>1006</b> may still find an action that returns a higher reward thanks to maintaining an E-greedy exploration (2). However, the <figure-callout id="1004" label="Tutor" filenames="US20210357767A1-20211118-D00010.png" state="{{state}}">Tutor</figure-callout> <b>1004</b> knowledge is used heavily in the initial phase, more than exploration, so even when an incorrect random action is chosen, the <figure-callout id="1004" label="Tutor" filenames="US20210357767A1-20211118-D00010.png" state="{{state}}">Tutor</figure-callout> <b>1004</b> knowledge can correct this action quickly in most cases. The initial value for E may be chosen according to the use case and how high is the cost of an incorrect action.</div>
    </li> <li> <para-num num="[0154]"> </para-num> <div id="p-0142" num="0154" class="description-line">Results</div>
    </li> <li> <para-num num="[0155]"> </para-num> <div id="p-0143" num="0155" class="description-line">In order to leverage existing methods and libraries, a well-known task in RL is chosen to evaluate the approach: ATARI games. Tutor4RL is implemented for a Deep Q-Networks (DQN) agent, one of the most popular and successful approaches to solve this kind of tasks in literature. The approach uses the DQN implementation provided in the library Keras-RL with Tensorflow and is applied to the game BREAKOUT, using OPENAI Gym. To evaluate the performance of this approach, it is compared to a regular DQN agent and the same set of parameters is used for both agents; DQN with Tutor4RL and plain DQN.</div>
    </li> <li> <para-num num="[0156]"> </para-num> <div id="p-0144" num="0156" class="description-line"> <figref idrefs="DRAWINGS">FIG. 11</figref> illustrates a <figure-callout id="1100" label="graphical representation" filenames="US20210357767A1-20211118-D00011.png" state="{{state}}">graphical representation</figure-callout> <b>1100</b> of the mean reward per episode of both agents during training according to an embodiment of the present invention. In particular, <figref idrefs="DRAWINGS">FIG. 11</figref> shows an average mean reward per episode achieved by plain DQN agent and DQN agent with Tutor4RL during training. The data was averaged over 4 tests for each agent and with a rolling mean of 20 episodes, bands show 0.90 confidence interval. Until step 500,000, the plain DQN Agent shows a predictable low reward (&lt;15 points), while the DQN Agent with Tutor4RLâthanks to the use of its tutor&#39;s knowledge&#39;manages to achieve a mean reward between 15 and 35 points, almost double the maximum of the plain DQN Agent. From step 500,000 onwards, the plain DQN agent improves thanks to acquiring more experience, until finally in step 1.1 million (M) the plain DQN agent achieves similar results to the tutored one. From there on, a similar reward is seen for both agents, with the tutored agent achieving a slightly higher mean reward.</div>
    </li> <li> <para-num num="[0157]"> </para-num> <div id="p-0145" num="0157" class="description-line">To evaluate the performance of the learned policy, both agents are tested after 1.75M steps with â=0.05 and Ï=0, so no tutor knowledge is used. The plain DQN agent is seen to achieve an average reward of 40.75 points while the agent trained with Tutor4RL achieves a reward of 43.</div>
    </li> <heading id="h-0007">Additional Embodiments</heading>
    <li> <para-num num="[0158]"> </para-num> <div id="p-0146" num="0158" class="description-line">Both, the experience with weak-supervision for a typical classification problem in the Internet of Things domain, as well as applying external knowledge in form of guiding functions to the reinforcement learning process have shown promising results. For transport mode detection, encoding external knowledge into seven simple functions was implemented, which potentially reduced the requirement for huge amounts of hand-labeled data in supervised learning scenarios. Bootstrapped the performance of an inexperienced agent in reinforcement learning cases was also performed through external knowledge. What is currently missing to tackle the challenges of dealing with different context in IoT are three aspects:</div>
    </li> <li> <para-num num="[0159]"> </para-num> <div id="p-0147" num="0159" class="description-line">1. Self-adaptive functions. Functions need to become adaptive based on the current context (e.g., a function for transport mode detection needs to adapt to different locations and their context (e.g., different speed limits) automatically).</div>
    </li> <li> <para-num num="[0160]"> </para-num> <div id="p-0148" num="0160" class="description-line">2. Notion of weak and strong functions. Often humans can easily define some conditions which they know to be true. Therefore, a notion to transfer this strong knowledge into the training and execution phase of machine learning is necessary.</div>
    </li> <li> <para-num num="[0161]"> </para-num> <div id="p-0149" num="0161" class="description-line">3. Common method for both training and execution phase. There needs to be an ability to introduce knowledge into both the training/setup phase of machine learning, but also continuously during execution in order to ensure robustness throughout changing contexts.</div>
    </li> <li> <para-num num="[0162]"> </para-num> <div id="p-0150" num="0162" class="description-line">Based on these lessons learned, the present invention is provided below for a knowledge infusion method that improves on these aspects.</div>
    </li> <li> <para-num num="[0163]"> </para-num> <div id="p-0151" num="0163" class="description-line">Knowledge Infusion</div>
    </li> <li> <para-num num="[0164]"> </para-num> <div id="p-0152" num="0164" class="description-line">Knowledge Infusion aims to dynamically infuse knowledge, i.e., logic based on human reasoning and internal and external knowledge bases (e.g., stored in a knowledge graph) into teacher-based machine learning methods (i.e., supervised learning and reinforcement learning) to improve overall robustness, transferability and accuracy. The infusion of weak and strong knowledge has two benefits: (1) it reduces the effort needed to train or startup a ML model/agent and (2) the knowledge model can be executed side-by-side with the ML model/agent to correct wrong outputs, thereby improving robustness, and enabling the calculation of an uncertainty value that gives an indication of when reality and the ML model have shifted too much apart so that performance would suffer.</div>
    </li> <li> <para-num num="[0165]"> </para-num> <div id="p-0153" num="0165" class="description-line">Application Areas</div>
    </li> <li> <para-num num="[0166]"> </para-num> <div id="p-0154" num="0166" class="description-line">Some important application areas that can benefit from Knowledge Infusion in the IoT domain are:</div>
    </li> <li> <para-num num="[0167]"> </para-num> <div id="p-0155" num="0167" class="description-line">Smart city analytics and control (actuation). Cities are increasingly becoming smart, connecting heterogeneous sensing and actuating infrastructure through smart city platforms. The key promise of such platforms is to improve certain aspects of a city (e.g., traffic, air quality, life quality, waste reduction, etc.) in an informed manner, based on the processing of sensor data and the machine learning processing pipelines for this data. Knowledge infusion helps to: (1) build these pipelines efficiently; (2) enable a transfer of pipelines between cities and automatically adapt them based on the context provided through the queried knowledge (for example adapt models based on knowledge of speed limits and public transport stops); (3) achieve robust ML systems, which outputs can be directly applied through actuations in the city (e.g., to traffic lights, smart parking or to guide public transport planning).</div>
    </li> <li> <para-num num="[0168]"> </para-num> <div id="p-0156" num="0168" class="description-line">Smart retail decisions. The retail sector is increasingly using machine learning to optimize their stock to fit the expected customers&#39; purchases. Knowledge infusion enables shops to develop a set of strong knowledge functions to ensure base availability of certain products or the availability of some seasonal/holiday specific products (e.g., seasonal sweets for Christmas holidays). Such predictions can be hard to learn for a ML model, but further seasons/holidays are often distinct in different countries (for example, orthodox Christmas is later than roman-catholic Christmas). In such examples, knowledge functions can automatically adapt themselves by querying a knowledge base (knowledge graph) that contains the particular holiday dates (for example WIKIDATA, or an internal knowledge base).</div>
    </li> <li> <para-num num="[0169]"> </para-num> <div id="p-0157" num="0169" class="description-line">Energy management for buildings. Buildings are one of the prime consumers of energy as humans in many countries spend most of their time inside them. Intelligently managing the energy consumption in buildings can save large amounts of energy especially for heating, ventilation and cooling (HVAC). The most advanced energy management systems for buildings have applied machine learning (for example they have been controlling HVAC based on an occupancy prediction). However, commercial buildings have strong safety regulations that specify certain conditions that always need to be met (e.g., a minimum flow of ventilation). Using the present invention, these regulations can be encoded in strong knowledge functions. They can be updated dynamically to regulations in different states or countries through the knowledge base. The combination of the knowledge model (the combined ensemble of weak and strong knowledge functions) and the ML model can safely be applied to actuate the energy management system of a building, ensuring robustness in relation to the current regulations.</div>
    </li> <li> <para-num num="[0170]"> </para-num> <div id="p-0158" num="0170" class="description-line">In the following, the present invention is described through two steps: (1) Setup Phase and (2) Execution Phase.</div>
    </li> <li> <para-num num="[0171]"> </para-num> <div id="p-0159" num="0171" class="description-line">Setup Phase</div>
    </li> <li> <para-num num="[0172]"> </para-num> <div id="p-0160" num="0172" class="description-line">Knowledge is infused through adaptive weak and strong knowledge functions. Knowledge functions output a single value, which can either be a label (for supervised machine learning) or an action (for reinforcement learning). Functions consist of a reasoning part, defined by human provided logic (e.g., conditional operators) and input knowledge that is derived/queried from internal and external knowledge bases through well-defined interfaces (e.g., through SPARQL, other graph query languages such as GraphQL or IoT specific standards such as NGSI-LD). Through such well-defined interface, knowledge functions are practically able to adapt their behavior automatically, based on changes in the input derived from the knowledge bases. For example, a knowledge function that outputs if there is a fire based on values from a temperature sensor can interface with a knowledge base that contains current weather data, including the current temperature. The reasoning logic inside the knowledge function might then use the weather temperature and the value from the temperature sensor to decide if there is a fire (binary classification, fire: True/False). Such a function may adapt to different weather conditions automatically.</div>
    </li> <li> <para-num num="[0173]"> </para-num> <div id="p-0161" num="0173" class="description-line">Weak knowledge functions are thought to be mostly true, while strong knowledge functions comprise axioms (canonical truths). Strong functions can be used as a fail-safe mechanism for the ML model, correcting outputs that experts know as a fact, cannot be true. In the previous example, it may be known that if temperature from the temperature sensor is within a margin of error from the weather temperature, then there is no fire. Even though the ML model will work correctly almost always in this case, it could happen that a very high, unusual weather temperature is reached in a hot wave and the model incorrectly indicates there is a fire. In an embodiment, the strong function will correct the output.</div>
    </li> <li> <para-num num="[0174]"> </para-num> <div id="p-0162" num="0174" class="description-line">In knowledge infusion, an ensemble of these knowledge functions is created and stored into a knowledge model. The ensemble is used to label data and used to train a supervised ML model. According to an embodiment of the present invention (e.g., in RL), this step might not needed but instead, the knowledge model will guide the exploration of the agent while training its policy. During execution, both are then used jointly (e.g., both are processing every new input). <figref idrefs="DRAWINGS">FIG. 12</figref> illustrates a knowledge infusion overview and setup. As shown, <figure-callout id="1202" label="external knowledge" filenames="US20210357767A1-20211118-D00012.png" state="{{state}}">external knowledge</figure-callout> <b>1202</b> might either be directly accessed by the knowledge functions (e.g., a weather API) or integrated/linked into a common knowledge base <b>1204</b> (e.g., a knowledge graph that integrated various aspects of a smart city).</div>
    </li> <li> <para-num num="[0175]"> </para-num> <div id="p-0163" num="0175" class="description-line">Execution Phase</div>
    </li> <li> <para-num num="[0176]"> </para-num> <div id="p-0164" num="0176" class="description-line">During the execution phase, <figure-callout id="1212" label="new data" filenames="US20210357767A1-20211118-D00012.png" state="{{state}}">new data</figure-callout> <b>1212</b> is processed by both the ML model and the knowledge model. As described previously, the knowledge model allows for correction of some obviously wrong outputs of the ML model (improving overall robustness) and to calculate an uncertainty value that enables knowledge infusion systems to understand if the reality has drifted away from the ML model. Such uncertainty value may be calculated based on the probability values obtained from the ML model as well as the windowed disagreement between the knowledge and the ML models. A moving average of this uncertainty value is then used to decide if the output is added to the <figure-callout id="104" label="knowledge base" filenames="US20210357767A1-20211118-D00000.png,US20210357767A1-20211118-D00001.png" state="{{state}}">knowledge base</figure-callout> <b>104</b> when the output is certain, or if re-training the ML model is needed. As the re-training will occur with an updated knowledge model, the resulting ML model will then better fit to reality, resulting in improved performance.</div>
    </li> <li> <para-num num="[0177]"> </para-num> <div id="p-0165" num="0177" class="description-line">Traditional Approaches</div>
    </li> <li> <para-num num="[0178]"> </para-num> <div id="p-0166" num="0178" class="description-line">Traditional approaches to knowledge infusion can be found in the machine learning sub domains of transfer learning, weakly-supervised learning and safe/robust or trustworthy learning.</div>
    </li> <li> <para-num num="[0179]"> </para-num> <div id="p-0167" num="0179" class="description-line">Transfer learning, aims to transfer knowledge learned for one task to a related task. Transferring such knowledge has the benefit of reducing the training effort, both from computing time and from data collection and labeling time (state of the art models in computer vision or NLP have been trained with millions of datapoints and the training compute time can costs millions of dollars for large models). Transfer learning can, for example, be achieved by replacing the final layer of a large deep neural network (e.g., a model trained with millions of images for object detection) to fit the model to the new task (e.g., a more specific object recognition for a single domain, such as smart appliances in a building). Further, traditional approaches are fine-tuning larger models to fit to a new task, by re-training only few layers, while leaving the more task-unspecific layers of the neural network fixed. In addition, hierarchical approaches in RL aim to break down the task in sub-tasks and introduce the use of sub-policies to solve them. Once these sub-policies are trained, they can be re-used in similar tasks to the original one.</div>
    </li> <li> <para-num num="[0180]"> </para-num> <div id="p-0168" num="0180" class="description-line">Weakly-supervised learning deals with the lack of labeled training data in machine learning systems through the use of noisy and higher-level supervision signals. With generative ensemble, a framework is proposed for weak supervision in which users, such as domain experts, write labeling functions that are then combined in a generative process. Generative ensemble such as SNORKEL has been successfully applied and adapted to tasks such as knowledge base construction from transistor data sheets, product classification up to transport mode detection.</div>
    </li> <li> <para-num num="[0181]"> </para-num> <div id="p-0169" num="0181" class="description-line">Safe learning systems, such as safe reinforcement learning ensure that the current system state is bound to a terminal set of states that is known to be safe. Uncertainty estimates are also used to limit the risks assumed by RL agents, regulating the exploration of actions in early learning phases as well as in new situations in which the agent has not experience and is uncertain about how to act. Another related emerging field is trustworthy machine learning, which among others, tries to improve adversarial robustness to protect against adversaries which can fool traditional machine learning systems.</div>
    </li> <li> <para-num num="[0182]"> </para-num> <div id="p-0170" num="0182" class="description-line">The present invention of knowledge infusion differs from these traditional approaches described above. Instead of transferring trained knowledge to another task (as in transfer learning), knowledge infusion intends to transfer knowledge used for the training phase between tasks with little effort. Compared to existing weak supervision approaches, the knowledge model is employed not only during the training phase, but is also used during execution. By introducing the concept of adaptive weak and strong knowledge functions, robustness during execution is provided, while also providing a trigger for a re-training of the ML model in case of a context shift. This approach was inspired by Leslie Valiant&#39;s early work on knowledge infusion. In additional embodiments of the present invention, the ideas of combining reasoning techniques with learned knowledge may be introduced to the above described knowledge infusion method.</div>
    </li> <heading id="h-0008">Conclusion and Additional Embodiments</heading>
    <li> <para-num num="[0183]"> </para-num> <div id="p-0171" num="0183" class="description-line">Some initial experiences in which external knowledge has been introduced to a data-driven machine learning process is provided. These experiences for supervised machine learning and reinforcement learning and the lessons learned with them open up the vision for Knowledge Infusion. Knowledge Infusion aims to improve the robustness, transferability and accuracy of machine learning in IoT systems. Towards that goal, two types of knowledge functions are proposed: (a) weak knowledge functions, that are thought to be mostly true and (b) strong knowledge functions that comprise axioms (canonical truths). The purpose of these functions is two-fold: (1) They enable the infusion of knowledge into the training phase of supervised machine learning methods through ensemble methods; (2) They act as a white box counter-part to the black-box trained model/agent of a supervised or reinforcement learning system during the execution phase that (a) can identify and correct (infrequent) wrong outputs of the ML model/agent (by using the set of strong knowledge functions) and (b) can identify through the calculation of uncertainty values when a model has drifted away from the input data characteristics and must be re-trained with new data to re-gain adequate performance.</div>
    </li> <li> <para-num num="[0184]"> </para-num> <div id="p-0172" num="0184" class="description-line">Knowledge infusion opens up many interesting avenues for future research on how and to which to extend to combine data-driven machine learning techniques with knowledge and reasoning.</div>
    </li> <li> <para-num num="[0185]"> </para-num> <div id="p-0173" num="0185" class="description-line">In each of the embodiments described, the embodiments may include one or more computer entities (e.g., systems, user interfaces, computing apparatus, devices, servers, special-purpose computers, smartphones, tablets or computers configured to perform functions specified herein) comprising one or more processors and memory. The processors can include one or more distinct processors, each having one or more cores, and access to memory. Each of the distinct processors can have the same or different structure. The processors can include one or more central processing units (CPUs), one or more graphics processing units (GPUs), circuitry (e.g., application specific integrated circuits (ASICs)), digital signal processors (DSPs), and the like. The processors can be mounted to a common substrate or to multiple different substrates. Processors are configured to perform a certain function, method, or operation (e.g., are configured to provide for performance of a function, method, or operation) at least when one of the one or more of the distinct processors is capable of performing operations embodying the function, method, or operation. Processors can perform operations embodying the function, method, or operation by, for example, executing code (e.g., interpreting scripts) stored on memory and/or trafficking data through one or more ASICs. Processors can be configured to perform, automatically, any and all functions, methods, and operations disclosed herein. Therefore, processors can be configured to implement any of (e.g., all) the protocols, devices, mechanisms, systems, and methods described herein. For example, when the present disclosure states that a method or device performs operation or task âXâ (or that task âXâ is performed), such a statement should be understood to disclose that processor is configured to perform task âXâ.</div>
    </li> <li> <para-num num="[0186]"> </para-num> <div id="p-0174" num="0186" class="description-line">Each of the computer entities can include memory. Memory can include volatile memory, non-volatile memory, and any other medium capable of storing data. Each of the volatile memory, non-volatile memory, and any other type of memory can include multiple different memory devices, located at multiple distinct locations and each having a different structure. Memory can include remotely hosted (e.g., cloud) storage. Examples of memory include a non-transitory computer-readable media such as RAM, ROM, flash memory, EEPROM, any kind of optical storage disk such as a DVD, magnetic storage, holographic storage, a HDD, a SSD, any medium that can be used to store program code in the form of instructions or data structures, and the like. Any and all of the methods, functions, and operations described in the present application can be fully embodied in the form of tangible and/or non-transitory machine-readable code (e.g., interpretable scripts) saved in memory.</div>
    </li> <li> <para-num num="[0187]"> </para-num> <div id="p-0175" num="0187" class="description-line">Each of the computer entities can include input-output devices. Input-output devices can include any component for trafficking data such as ports, antennas (i.e., transceivers), printed conductive paths, and the like. Input-output devices can enable wired communication via USBÂ®, DisplayPortÂ®, HDMIÂ®, Ethernet, and the like. Input-output devices can enable electronic, optical, magnetic, and holographic, communication with suitable memory. Input-output devices can enable wireless communication via WiFiÂ®, BluetoothÂ®, cellular (e.g., LTEÂ®, CDMAÂ®, GSMÂ®, WiMaxÂ®, NFCÂ®), GPS, and the like. Input-output devices can include wired and/or wireless communication pathways.</div>
    </li> <li> <para-num num="[0188]"> </para-num> <div id="p-0176" num="0188" class="description-line">While embodiments of the invention have been illustrated and described in detail in the drawings and foregoing description, such illustration and description are to be considered illustrative or exemplary and not restrictive. It will be understood that changes and modifications may be made by those of ordinary skill within the scope of the following claims. In particular, the present invention covers further embodiments with any combination of features from different embodiments described above and below. Additionally, statements made herein characterizing the invention refer to an embodiment of the invention and not necessarily all embodiments.</div>
    </li> <li> <para-num num="[0189]"> </para-num> <div id="p-0177" num="0189" class="description-line">The terms used in the claims should be construed to have the broadest reasonable interpretation consistent with the foregoing description. For example, the use of the article âaâ or âtheâ in introducing an element should not be interpreted as being exclusive of a plurality of elements. Likewise, the recitation of âorâ should be interpreted as being inclusive, such that the recitation of âA or Bâ is not exclusive of âA and B,â unless it is clear from the context or the foregoing description that only one of A and B is intended. Further, the recitation of âat least one of A, B and Câ should be interpreted as one or more of a group of elements consisting of A, B and C, and should not be interpreted as requiring at least one of each of the listed elements A, B and C, regardless of whether A, B and C are related as categories or otherwise. Moreover, the recitation of âA, B and/or Câ or âat least one of A, B or Câ should be interpreted as including any singular entity from the listed elements, e.g., A, any subset from the listed elements, e.g., A and B, or the entire list of elements A, B and C.</div>
    
  </li> </ul>
  </div>
  </section>

  <section itemprop="claims" itemscope>
    <h2>Claims (<span itemprop="count">15</span>)</h2>
    
    <div itemprop="content" html><div mxw-id="PCLM307077437" lang="EN" load-source="patent-office" class="claims">
    <claim-statement>What is claimed is:</claim-statement>
    <div class="claim"> <div id="CLM-00001" num="00001" class="claim">
      <div class="claim-text"> <b>1</b>. A method for using knowledge infusion for robust and transferable machine learning models, the method comprising:
<div class="claim-text">receiving a plurality of adaptive and programmable knowledge functions comprising a plurality of strong functions and a plurality of weak functions;</div> <div class="claim-text">generating a knowledge model based on the plurality of strong functions and the plurality of weak functions; and</div> <div class="claim-text">training a machine learning model based on the generated knowledge model.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00002" num="00002" class="claim">
      <div class="claim-text"> <b>2</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising generating a knowledge fusion model based on packaging the machine learning model with the knowledge model.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00003" num="00003" class="claim">
      <div class="claim-text"> <b>3</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:
<div class="claim-text">deploying the machine learning model and the knowledge model within an environment to perform one or more operations;</div> <div class="claim-text">subsequent to deploying the machine learning model and the knowledge model within the environment, receiving new data associated with the environment from one or more sensors;</div> <div class="claim-text">inputting the new data into the machine learning model to determine one or more machine learning model outputs;</div> <div class="claim-text">inputting the new data into the knowledge model to determine one or more knowledge model outputs; and</div> <div class="claim-text">correcting the one or more machine learning model outputs based on determining the one or more machine learning model outputs contradicts the one or more knowledge model outputs.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00004" num="00004" class="claim">
      <div class="claim-text"> <b>4</b>. The method according to <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein the inputting the new data into the knowledge model comprises inputting the new data into at least one of the plurality of strong functions, and wherein the one or more knowledge model outputs are outputs from the plurality of strong functions.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00005" num="00005" class="claim">
      <div class="claim-text"> <b>5</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:
<div class="claim-text">deploying the machine learning model and the knowledge model within an environment to perform one or more operations;</div> <div class="claim-text">subsequent to deploying the machine learning model and the knowledge model within the environment, receiving new data associated with the environment from one or more sensors;</div> <div class="claim-text">inputting the new data into the machine learning model to generate one or more machine learning model outputs and one or more probability values associated with the one or more machine learning model outputs; and</div> <div class="claim-text">calculating an uncertainty value based on the one or more machine learning model outputs and the one or more probability values, wherein the uncertainty value represents uncertainty of the one or more machine learning model outputs from the machine learning model.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00006" num="00006" class="claim">
      <div class="claim-text"> <b>6</b>. The method according to <claim-ref idref="CLM-00005">claim 5</claim-ref>, further comprising:
<div class="claim-text">comparing the uncertainty value with a threshold; and</div> <div class="claim-text">based on the uncertainty value exceeding the threshold, re-training the machine learning model.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00007" num="00007" class="claim">
      <div class="claim-text"> <b>7</b>. The method according to <claim-ref idref="CLM-00006">claim 6</claim-ref>, further comprising:
<div class="claim-text">based on the uncertainty value not exceeding the threshold, updating a knowledge base using the one or more machine learning model outputs;</div> <div class="claim-text">updating the knowledge model based on updating the knowledge base; and</div> <div class="claim-text">wherein re-training the machine learning model comprises re-training the machine learning model using the updated knowledge model.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00008" num="00008" class="claim">
      <div class="claim-text"> <b>8</b>. The method according to <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein calculating the uncertainty value comprises:
<div class="claim-text">determining a disagreement value between outputs from the knowledge model and outputs from the machine learning model, wherein the outputs from the machine learning model comprises the one or more machine learning model outputs; and</div> <div class="claim-text">calculating the uncertainty value based on the disagreement value and the one or more probability values.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00009" num="00009" class="claim">
      <div class="claim-text"> <b>9</b>. The method according to <claim-ref idref="CLM-00008">claim 8</claim-ref>, further comprising:
<div class="claim-text">determining a moving average associated with the uncertainty value; and</div> <div class="claim-text">re-training the machine learning model based on comparing the moving average associated with the uncertainty value with a threshold.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00010" num="00010" class="claim">
      <div class="claim-text"> <b>10</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein generating the knowledge model comprises generating the knowledge model based on mapping the plurality of strong functions and the plurality of weak functions using one or more ensemble methods, wherein the one or more ensemble methods comprises at least one of a majority ensemble method, a generative ensemble method, or a Tutor for Reinforced Learning (Tutor4RL) ensemble method.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00011" num="00011" class="claim">
      <div class="claim-text"> <b>11</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein receiving the plurality of adaptive and programmable knowledge functions comprises receiving the plurality of adaptive and programmable knowledge functions from a user interface, wherein the method further comprises:
<div class="claim-text">updating the plurality of weak functions and the plurality of strong functions based on an internal knowledge base and one or more external knowledge sources; and</div> <div class="claim-text">wherein generating the knowledge model is based on updating the plurality of weak functions and the plurality of strong functions.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00012" num="00012" class="claim">
      <div class="claim-text"> <b>12</b>. The method according to <claim-ref idref="CLM-00011">claim 11</claim-ref>, further comprising, subsequent to generating the knowledge model, continuously maintaining the knowledge model based on continuously querying the one or more external knowledge sources to provide and update the plurality of weak functions and the plurality of strong functions.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00013" num="00013" class="claim">
      <div class="claim-text"> <b>13</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:
<div class="claim-text">deploying the machine learning model and the knowledge model within an environment to perform one or more operations; and</div> <div class="claim-text">wherein the environment comprises an Internet of Things (IoT) system, a smart city system, a smart retail system, a building energy management system, or a data center energy management system.</div> </div>
    </div>
    </div> <div class="claim"> <div id="CLM-00014" num="00014" class="claim">
      <div class="claim-text"> <b>14</b>. A system comprising one or more processors which, alone or in combination, are configured to provide for execution of a method comprising:
<div class="claim-text">receiving a plurality of adaptive and programmable knowledge functions comprising a plurality of strong functions and a plurality of weak functions;</div> <div class="claim-text">generating a knowledge model based on the plurality of strong functions and the plurality of weak functions; and</div> <div class="claim-text">training a machine learning model based on the generated knowledge model.</div> </div>
    </div>
    </div> <div class="claim"> <div id="CLM-00015" num="00015" class="claim">
      <div class="claim-text"> <b>15</b>. A tangible, non-transitory computer-readable medium having instructions thereon which, upon being executed by one or more processors, alone or in combination, provide for execution of a method comprising:
<div class="claim-text">receiving a plurality of adaptive and programmable knowledge functions comprising a plurality of strong functions and a plurality of weak functions;</div> <div class="claim-text">generating a knowledge model based on the plurality of strong functions and the plurality of weak functions; and</div> <div class="claim-text">training a machine learning model based on the generated knowledge model.</div> </div>
    </div>
  </div> </div>
  </div>
  </section>

  <section itemprop="application" itemscope>

    <section itemprop="metadata" itemscope>
      <span itemprop="applicationNumber">US17/035,967</span>
      <span itemprop="priorityDate">2020-05-15</span>
      <span itemprop="filingDate">2020-09-29</span>
      <span itemprop="title">Automated knowledge infusion for robust and transferable machine learning 
       </span>
      <span itemprop="ifiStatus">Pending</span>
      
      <a href="/patent/US20210357767A1/en">
        <span itemprop="representativePublication">US20210357767A1</span>
        (<span itemprop="primaryLanguage">en</span>)
      </a>
    </section>

    

    <h2>Applications Claiming Priority (2)</h2>
    <table>
      <thead>
        <tr>
          <th>Application Number</th>
          <th>Priority Date</th>
          <th>Filing Date</th>
          <th>Title</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="appsClaimingPriority" itemscope repeat>
          <td>
            <span itemprop="applicationNumber">EP20175090</span>
            
          </td>
          <td itemprop="priorityDate"></td>
          <td itemprop="filingDate">2020-05-15</td>
          <td itemprop="title"></td>
        </tr>
        <tr itemprop="appsClaimingPriority" itemscope repeat>
          <td>
            <span itemprop="applicationNumber">EP20175090.8</span>
            
          </td>
          <td itemprop="priorityDate"></td>
          <td itemprop="filingDate">2020-05-15</td>
          <td itemprop="title"></td>
        </tr>
      </tbody>
    </table>

    

    

    <h2>Publications (1)</h2>
    <table>
      <thead>
        <tr>
          <th>Publication Number</th>
          <th>Publication Date</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="pubs" itemscope repeat>
          <td>
            <span itemprop="publicationNumber">US20210357767A1</span>
            
            <span itemprop="thisPatent">true</span>
            <a href="/patent/US20210357767A1/en">
              US20210357767A1
              (<span itemprop="primaryLanguage">en</span>)
            </a>
          </td>
          <td itemprop="publicationDate">2021-11-18</td>
        </tr>
      </tbody>
    </table>

  </section>

  <section itemprop="family" itemscope>
    <h1>Family</h1>
    <h2>ID=78512554</h2>

    <h2>Family Applications (1)</h2>
    <table>
      <thead>
        <tr>
          <th>Application Number</th>
          <th>Title</th>
          <th>Priority Date</th>
          <th>Filing Date</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="applications" itemscope repeat>
          <td>
            <span itemprop="applicationNumber">US17/035,967</span>
            <span itemprop="ifiStatus">Pending</span>
            
            <a href="/patent/US20210357767A1/en">
              <span itemprop="representativePublication">US20210357767A1</span>
                (<span itemprop="primaryLanguage">en</span>)
            </a>
          </td>
          <td itemprop="priorityDate">2020-05-15</td>
          <td itemprop="filingDate">2020-09-29</td>
          <td itemprop="title">Automated knowledge infusion for robust and transferable machine learning 
       </td>
        </tr>
      </tbody>
    </table>

    

    

    <h2>Country Status (1)</h2>
    <table>
      <thead>
        <tr>
          <th>Country</th>
          <th>Link</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="countryStatus" itemscope repeat>
          <td>
            <span itemprop="countryCode">US</span>
            (<span itemprop="num">1</span>)
            <meta itemprop="thisCountry" content="true">
          </td>
          <td>
            <a href="/patent/US20210357767A1/en">
              <span itemprop="representativePublication">US20210357767A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
          </td>
        </tr>
      </tbody>
    </table>

    <h2>Cited By (4)</h2>
    <table>
      <caption>* Cited by examiner, â  Cited by third party</caption>
      <thead>
        <tr>
          <th>Publication number</th>
          <th>Priority date</th>
          <th>Publication date</th>
          <th>Assignee</th>
          <th>Title</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="forwardReferencesOrig" itemscope repeat>
          <td>
            <a href="/patent/US20210406601A1/en">
              <span itemprop="publicationNumber">US20210406601A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2020-06-30</td>
          <td itemprop="publicationDate">2021-12-30</td>
          <td><span itemprop="assigneeOriginal">Google Llc</span></td>
          <td itemprop="title">Cross-modal weak supervision for media classification 
       </td>
        </tr>
        <tr itemprop="forwardReferencesOrig" itemscope repeat>
          <td>
            <a href="/patent/US20220138617A1/en">
              <span itemprop="publicationNumber">US20220138617A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2020-11-03</td>
          <td itemprop="publicationDate">2022-05-05</td>
          <td><span itemprop="assigneeOriginal">International Business Machines Corporation</span></td>
          <td itemprop="title">Artificial intelligence based application modernization advisory 
       </td>
        </tr>
        <tr itemprop="forwardReferencesOrig" itemscope repeat>
          <td>
            <a href="/patent/US11715007B2/en">
              <span itemprop="publicationNumber">US11715007B2</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2020-08-28</td>
          <td itemprop="publicationDate">2023-08-01</td>
          <td><span itemprop="assigneeOriginal">UMNAI Limited</span></td>
          <td itemprop="title">Behaviour modeling, verification, and autonomous actions and triggers of ML and AI systems 
       </td>
        </tr>
        <tr itemprop="forwardReferencesOrig" itemscope repeat>
          <td>
            <a href="/patent/WO2023249927A1/en">
              <span itemprop="publicationNumber">WO2023249927A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2022-06-21</td>
          <td itemprop="publicationDate">2023-12-28</td>
          <td><span itemprop="assigneeOriginal">The Johns Hopkins University</span></td>
          <td itemprop="title">Methods and related aspects to assure artificial intelligence systems 
       </td>
        </tr>
      </tbody>
    </table>

    

    <h2>Citations (2)</h2>
    <table>
      <caption>* Cited by examiner, â  Cited by third party</caption>
      <thead>
        <tr>
          <th>Publication number</th>
          <th>Priority date</th>
          <th>Publication date</th>
          <th>Assignee</th>
          <th>Title</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="backwardReferencesOrig" itemscope repeat>
          <td>
            <a href="/patent/US20170230410A1/en">
              <span itemprop="publicationNumber">US20170230410A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2016-02-10</td>
          <td itemprop="publicationDate">2017-08-10</td>
          <td>
            <span itemprop="assigneeOriginal">Accenture Global Solutions Limited</span>
          </td>
          <td itemprop="title">Telemetry Analysis System for Physical Process Anomaly Detection 
       </td>
        </tr>
        <tr itemprop="backwardReferencesOrig" itemscope repeat>
          <td>
            <a href="/patent/US20210279615A1/en">
              <span itemprop="publicationNumber">US20210279615A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2020-03-03</td>
          <td itemprop="publicationDate">2021-09-09</td>
          <td>
            <span itemprop="assigneeOriginal">Cisco Technology, Inc.</span>
          </td>
          <td itemprop="title">COGNITIVE AUTOMATION FOR NETWORKING, SECURITY, IoT, AND COLLABORATION 
       </td>
        </tr>
      </tbody>
    </table>

    

    <ul>
      <li itemprop="applicationsByYear" itemscope repeat>
        <span itemprop="year">2020</span>
        <ul>
          <li itemprop="application" itemscope repeat>
            <span itemprop="filingDate">2020-09-29</span>
            <span itemprop="countryCode">US</span>
            <span itemprop="applicationNumber">US17/035,967</span>
            <a href="/patent/US20210357767A1/en"><span itemprop="documentId">patent/US20210357767A1/en</span></a>
            <span itemprop="legalStatusCat">active</span>
            <span itemprop="legalStatus">Pending</span>
            <span itemprop="thisApp" content="true" bool></span>
          </li>
        </ul>
      </li>
    </ul>

    </section>

  <section>
    <h2>Patent Citations (2)</h2>
    <table>
      <caption>* Cited by examiner, â  Cited by third party</caption>
      <thead>
        <tr>
          <th>Publication number</th>
          <th>Priority date</th>
          <th>Publication date</th>
          <th>Assignee</th>
          <th>Title</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="backwardReferences" itemscope repeat>
          <td>
            <a href="/patent/US20170230410A1/en">
              <span itemprop="publicationNumber">US20170230410A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2016-02-10</td>
          <td itemprop="publicationDate">2017-08-10</td>
          <td><span itemprop="assigneeOriginal">Accenture Global Solutions Limited</span></td>
          <td itemprop="title">Telemetry Analysis System for Physical Process Anomaly Detection 
       </td>
        </tr>
        <tr itemprop="backwardReferences" itemscope repeat>
          <td>
            <a href="/patent/US20210279615A1/en">
              <span itemprop="publicationNumber">US20210279615A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2020-03-03</td>
          <td itemprop="publicationDate">2021-09-09</td>
          <td><span itemprop="assigneeOriginal">Cisco Technology, Inc.</span></td>
          <td itemprop="title">COGNITIVE AUTOMATION FOR NETWORKING, SECURITY, IoT, AND COLLABORATION 
       </td>
        </tr>
      </tbody>
    </table>
  </section>

  <section>
    <h2>Non-Patent Citations (1)</h2>
    <table>
      <caption>* Cited by examiner, â  Cited by third party</caption>
      <thead>
        <tr>
          <th>Title</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="detailedNonPatentLiterature" itemscope repeat>
          <td>
            <span itemprop="title">Kursuncu, Ugur, Manas Gaur, and Amit Sheth. "<a href='http://scholar.google.com/scholar?q="Knowledge+infused+learning+%28k-il%29%3A+Towards+deep+incorporation+of+knowledge+in+deep+learning."'>Knowledge infused learning (k-il): Towards deep incorporation of knowledge in deep learning.</a>" arXiv preprint arXiv:1912.00512 (2019). (Year: 2019)</span>
            <span itemprop="examinerCited">*</span>
            
          </td>
        </tr>
      </tbody>
    </table>
  </section>

  <h2>Cited By (5)</h2>
  <table>
    <caption>* Cited by examiner, â  Cited by third party</caption>
    <thead>
      <tr>
        <th>Publication number</th>
        <th>Priority date</th>
        <th>Publication date</th>
        <th>Assignee</th>
        <th>Title</th>
      </tr>
    </thead>
    <tbody>
      <tr itemprop="forwardReferences" itemscope repeat>
        <td>
          <a href="/patent/US20210406601A1/en">
            <span itemprop="publicationNumber">US20210406601A1</span>
            (<span itemprop="primaryLanguage">en</span>)
          </a>
          <span itemprop="examinerCited">*</span>
          
        </td>
        <td itemprop="priorityDate">2020-06-30</td>
        <td itemprop="publicationDate">2021-12-30</td>
        <td><span itemprop="assigneeOriginal">Google Llc</span></td>
        <td itemprop="title">Cross-modal weak supervision for media classification 
       </td>
      </tr>
      <tr itemprop="forwardReferences" itemscope repeat>
        <td>
          <a href="/patent/US11574145B2/en">
            <span itemprop="publicationNumber">US11574145B2</span>
            (<span itemprop="primaryLanguage">en</span>)
          </a>
          <span itemprop="examinerCited">*</span>
          
        </td>
        <td itemprop="priorityDate">2020-06-30</td>
        <td itemprop="publicationDate">2023-02-07</td>
        <td><span itemprop="assigneeOriginal">Google Llc</span></td>
        <td itemprop="title">Cross-modal weak supervision for media classification 
       </td>
      </tr>
      <tr itemprop="forwardReferences" itemscope repeat>
        <td>
          <a href="/patent/US11715007B2/en">
            <span itemprop="publicationNumber">US11715007B2</span>
            (<span itemprop="primaryLanguage">en</span>)
          </a>
          <span itemprop="examinerCited">*</span>
          
        </td>
        <td itemprop="priorityDate">2020-08-28</td>
        <td itemprop="publicationDate">2023-08-01</td>
        <td><span itemprop="assigneeOriginal">UMNAI Limited</span></td>
        <td itemprop="title">Behaviour modeling, verification, and autonomous actions and triggers of ML and AI systems 
       </td>
      </tr>
      <tr itemprop="forwardReferences" itemscope repeat>
        <td>
          <a href="/patent/US20220138617A1/en">
            <span itemprop="publicationNumber">US20220138617A1</span>
            (<span itemprop="primaryLanguage">en</span>)
          </a>
          <span itemprop="examinerCited">*</span>
          
        </td>
        <td itemprop="priorityDate">2020-11-03</td>
        <td itemprop="publicationDate">2022-05-05</td>
        <td><span itemprop="assigneeOriginal">International Business Machines Corporation</span></td>
        <td itemprop="title">Artificial intelligence based application modernization advisory 
       </td>
      </tr>
      <tr itemprop="forwardReferences" itemscope repeat>
        <td>
          <a href="/patent/WO2023249927A1/en">
            <span itemprop="publicationNumber">WO2023249927A1</span>
            (<span itemprop="primaryLanguage">en</span>)
          </a>
          <span itemprop="examinerCited">*</span>
          
        </td>
        <td itemprop="priorityDate">2022-06-21</td>
        <td itemprop="publicationDate">2023-12-28</td>
        <td><span itemprop="assigneeOriginal">The Johns Hopkins University</span></td>
        <td itemprop="title">Methods and related aspects to assure artificial intelligence systems 
       </td>
      </tr>
    </tbody>
  </table>

  

  <section>
    <h2>Similar Documents</h2>
    <table>
      <thead>
        <tr>
          <th>Publication</th>
          <th>Publication Date</th>
          <th>Title</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/US20210357767A1/en">
                <span itemprop="publicationNumber">US20210357767A1</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2021-11-18">2021-11-18</time>
            
            
          </td>
          <td itemprop="title">Automated knowledge infusion for robust and transferable machine learning 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/US11507851B2/en">
                <span itemprop="publicationNumber">US11507851B2</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2022-11-22">2022-11-22</time>
            
            
          </td>
          <td itemprop="title">System and method of integrating databases based on knowledge graph 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/US20230259796A1/en">
                <span itemprop="publicationNumber">US20230259796A1</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2023-08-17">2023-08-17</time>
            
            
          </td>
          <td itemprop="title">Bias scoring of machine learning project data 
     </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/KR102283283B1/en">
                <span itemprop="publicationNumber">KR102283283B1</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2021-07-28">2021-07-28</time>
            
            
          </td>
          <td itemprop="title">Method to decide a labeling priority to a data 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            
            <meta itemprop="isScholar" content="true">
              <meta itemprop="scholarID" content="11652999092360165932">
              <a href="/scholar/11652999092360165932"><span itemprop="scholarAuthors">Bhattacharjee et al.</span></a>
            
          </td>
          <td>
            
            <time itemprop="publicationDate" datetime="2019">2019</time>
            
          </td>
          <td itemprop="title">Stratum: A serverless framework for the lifecycle management of machine learning-based data analytics tasks</td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            
            <meta itemprop="isScholar" content="true">
              <meta itemprop="scholarID" content="15409218020226664740">
              <a href="/scholar/15409218020226664740"><span itemprop="scholarAuthors">Friederich et al.</span></a>
            
          </td>
          <td>
            
            <time itemprop="publicationDate" datetime="2021">2021</time>
            
          </td>
          <td itemprop="title">Towards data-driven reliability modeling for cyber-physical production systems</td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/CN110705646B/en">
                <span itemprop="publicationNumber">CN110705646B</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2021-11-23">2021-11-23</time>
            
            
          </td>
          <td itemprop="title">Mobile equipment streaming data identification method based on model dynamic update 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/KR20210108319A/en">
                <span itemprop="publicationNumber">KR20210108319A</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2021-09-02">2021-09-02</time>
            
            
          </td>
          <td itemprop="title">Method and system for automatic classification based on machine learning 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/US10277473B2/en">
                <span itemprop="publicationNumber">US10277473B2</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2019-04-30">2019-04-30</time>
            
            
          </td>
          <td itemprop="title">Model deployment based on benchmarked devices 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/CN116438553A/en">
                <span itemprop="publicationNumber">CN116438553A</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2023-07-14">2023-07-14</time>
            
            
          </td>
          <td itemprop="title">Machine learning model for probability prediction of success of operators in PAAS cloud environments 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/US20190325348A1/en">
                <span itemprop="publicationNumber">US20190325348A1</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2019-10-24">2019-10-24</time>
            
            
          </td>
          <td itemprop="title">Methods and apparatus to provide machine assisted programming 
     </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            
            <meta itemprop="isScholar" content="true">
              <meta itemprop="scholarID" content="111050580772080602">
              <a href="/scholar/111050580772080602"><span itemprop="scholarAuthors">Husak et al.</span></a>
            
          </td>
          <td>
            
            <time itemprop="publicationDate" datetime="2021">2021</time>
            
          </td>
          <td itemprop="title">Intelligent Real-Time Vehicle Tracking Information System.</td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/US20210192322A1/en">
                <span itemprop="publicationNumber">US20210192322A1</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2021-06-24">2021-06-24</time>
            
            
          </td>
          <td itemprop="title">Method For Determining A Confidence Level Of Inference Data Produced By Artificial Neural Network 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/US20220292529A1/en">
                <span itemprop="publicationNumber">US20220292529A1</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2022-09-15">2022-09-15</time>
            
            
          </td>
          <td itemprop="title">Utilizing machine learning for optimization of planning and value realization for private networks 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/WO2023089097A1/en">
                <span itemprop="publicationNumber">WO2023089097A1</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2023-05-25">2023-05-25</time>
            
            
          </td>
          <td itemprop="title">Scalable, data-driven digital marketplace providing a standardized secured data system for interlinking sensitive risk-related data, and method thereof 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/US20210168195A1/en">
                <span itemprop="publicationNumber">US20210168195A1</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2021-06-03">2021-06-03</time>
            
            
          </td>
          <td itemprop="title">Server and method for controlling server 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/CN114898184A/en">
                <span itemprop="publicationNumber">CN114898184A</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2022-08-12">2022-08-12</time>
            
            
          </td>
          <td itemprop="title">Model training method, data processing method and device and electronic equipment 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/CN114511077A/en">
                <span itemprop="publicationNumber">CN114511077A</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2022-05-17">2022-05-17</time>
            
            
          </td>
          <td itemprop="title">Training point cloud processing neural networks using pseudo-element based data augmentation 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/CN114492601A/en">
                <span itemprop="publicationNumber">CN114492601A</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2022-05-13">2022-05-13</time>
            
            
          </td>
          <td itemprop="title">Resource classification model training method and device, electronic equipment and storage medium 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            
            <meta itemprop="isScholar" content="true">
              <meta itemprop="scholarID" content="16920158156702414801">
              <a href="/scholar/16920158156702414801"><span itemprop="scholarAuthors">Azim et al.</span></a>
            
          </td>
          <td>
            
            <time itemprop="publicationDate" datetime="2022">2022</time>
            
          </td>
          <td itemprop="title">Cognitive mobile computing for cyber-physical systems (cps)</td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/KR20220163362A/en">
                <span itemprop="publicationNumber">KR20220163362A</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2022-12-09">2022-12-09</time>
            
            
          </td>
          <td itemprop="title">
  Generation of Performance Predictions with Uncertainty Intervals
 
     </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            
            <meta itemprop="isScholar" content="true">
              <meta itemprop="scholarID" content="42975260024700328">
              <a href="/scholar/42975260024700328"><span itemprop="scholarAuthors">Lakshman Narayana et al.</span></a>
            
          </td>
          <td>
            
            <time itemprop="publicationDate" datetime="2022">2022</time>
            
          </td>
          <td itemprop="title">An intelligent IoT framework for handling multidimensional data generated by IoT gadgets</td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/EP4260240A1/en">
                <span itemprop="publicationNumber">EP4260240A1</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2023-10-18">2023-10-18</time>
            
            
          </td>
          <td itemprop="title">Methods and apparatuses for providing transfer learning of a machine learning model 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/CN115330319B/en">
                <span itemprop="publicationNumber">CN115330319B</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2023-01-13">2023-01-13</time>
            
            
          </td>
          <td itemprop="title">Logistics information processing method based on big data and artificial intelligence server 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/US20230401829A1/en">
                <span itemprop="publicationNumber">US20230401829A1</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2023-12-14">2023-12-14</time>
            
            
          </td>
          <td itemprop="title">Training machine learning models based on unlabeled data 
     </td>
        </tr>
      </tbody>
    </table>
  </section>

  <section>
    <h2>Legal Events</h2>
    <table>
      <thead>
        <tr>
          <th>Date</th>
          <th>Code</th>
          <th>Title</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="legalEvents" itemscope repeat>
          <td><time itemprop="date" datetime="2020-10-06">2020-10-06</time></td>
          <td itemprop="code">AS</td>
          <td itemprop="title">Assignment</td>
          <td>
            <p itemprop="attributes" itemscope repeat>
              <strong itemprop="label">Owner name</strong>:
              <span itemprop="value">NEC LABORATORIES EUROPE GMBH, GERMANY</span>
            </p>
            <p itemprop="attributes" itemscope repeat>
              <strong itemprop="label">Free format text</strong>:
              <span itemprop="value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:FUERST, JONATHAN;ARGERICH, MAURICIO FADEL;CHENG, BIN;SIGNING DATES FROM 20200831 TO 20200907;REEL/FRAME:053979/0980</span>
            </p>
          </td>
        </tr>
        <tr itemprop="legalEvents" itemscope repeat>
          <td><time itemprop="date" datetime="2021-08-20">2021-08-20</time></td>
          <td itemprop="code">STPP</td>
          <td itemprop="title">Information on status: patent application and granting procedure in general</td>
          <td>
            <p itemprop="attributes" itemscope repeat>
              <strong itemprop="label">Free format text</strong>:
              <span itemprop="value">DOCKETED NEW CASE - READY FOR EXAMINATION</span>
            </p>
          </td>
        </tr>
        <tr itemprop="legalEvents" itemscope repeat>
          <td><time itemprop="date" datetime="2023-10-13">2023-10-13</time></td>
          <td itemprop="code">STPP</td>
          <td itemprop="title">Information on status: patent application and granting procedure in general</td>
          <td>
            <p itemprop="attributes" itemscope repeat>
              <strong itemprop="label">Free format text</strong>:
              <span itemprop="value">NON FINAL ACTION MAILED</span>
            </p>
          </td>
        </tr>
        <tr itemprop="legalEvents" itemscope repeat>
          <td><time itemprop="date" datetime="2024-01-10">2024-01-10</time></td>
          <td itemprop="code">STPP</td>
          <td itemprop="title">Information on status: patent application and granting procedure in general</td>
          <td>
            <p itemprop="attributes" itemscope repeat>
              <strong itemprop="label">Free format text</strong>:
              <span itemprop="value">RESPONSE TO NON-FINAL OFFICE ACTION ENTERED AND FORWARDED TO EXAMINER</span>
            </p>
          </td>
        </tr>
      </tbody>
    </table>
  </section>

</article>

    </search-app>
    <script type="text/javascript" src="//www.gstatic.com/feedback/api.js"></script>
    <script type="text/javascript" src="//www.gstatic.com/feedback/js/help/prod/service/lazy.min.js"></script>
    <script type="text/javascript">
      if (window.help && window.help.service) {
        helpApi = window.help.service.Lazy.create(0, {apiKey: 'AIzaSyDTEI_0tLX4varJ7bwK8aT-eOI5qr3BmyI', locale: 'en-US'});
        window.requestedSurveys = new Set();
        window.requestSurvey = function(triggerId) {
          if (window.requestedSurveys.has(triggerId)) {
            return;
          }
          window.requestedSurveys.add(triggerId);
          helpApi.requestSurvey({
            triggerId: triggerId,
            enableTestingMode: false,
            callback: (requestSurveyCallbackParam) => {
              if (!requestSurveyCallbackParam.surveyData) {
                return;
              }
              helpApi.presentSurvey({
                productData: {
                  productVersion: window.version,
                  customData: {
                    "experiments": "72459301,72474719",
                  },
                },
                surveyData: requestSurveyCallbackParam.surveyData,
                colorScheme: 1,
                customZIndex: 10000,
              });
            }
          });
        };

        window.requestSurvey('YXTwAsvoW0kedxbuTdH0RArc9VhT');
      }
    </script>
    <script src="/sw/null_loader.js"></script>
  </body>
</html>
