<!DOCTYPE html>
<html lang="en">
  <head>
    <title>US20230210402A1 - Methods and devices for motion monitoring 
      - Google Patents</title>

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta charset="UTF-8">
    <meta name="referrer" content="origin-when-crossorigin">
    <link rel="canonical" href="https://patents.google.com/patent/US20230210402A1/en">
    <meta name="description" content="
     The present disclosure discloses a method for displaying a motion monitoring interface. The method includes: obtaining a movement signal during a motion of a user from at least one sensor, wherein the movement signal at least includes an electromyographic signal or an attitude signal; determining information related to the motion of the user by processing the movement signal; and displaying the information related to the motion of the user. 
   
   ">
    <meta name="DC.type" content="patent">
    <meta name="DC.title" content="Methods and devices for motion monitoring 
     ">
    <meta name="DC.date" content="2023-03-13" scheme="dateSubmitted">
    <meta name="DC.description" content="
     The present disclosure discloses a method for displaying a motion monitoring interface. The method includes: obtaining a movement signal during a motion of a user from at least one sensor, wherein the movement signal at least includes an electromyographic signal or an attitude signal; determining information related to the motion of the user by processing the movement signal; and displaying the information related to the motion of the user. 
   
   ">
    <meta name="citation_patent_application_number" content="US:18/182,373">
    <meta name="citation_pdf_url" content="https://patentimages.storage.googleapis.com/6c/fa/75/424363fb3277eb/US20230210402A1.pdf">
    <meta name="citation_patent_publication_number" content="US:20230210402:A1">
    <meta name="DC.date" content="2023-07-06">
    <meta name="DC.contributor" content="Lei Su" scheme="inventor">
    <meta name="DC.contributor" content="Meiqi LI" scheme="inventor">
    <meta name="DC.contributor" content="Xin Zhou" scheme="inventor">
    <meta name="DC.contributor" content="Fengyun LIAO" scheme="inventor">
    <meta name="DC.contributor" content="Shenzhen Shokz Co Ltd" scheme="assignee">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:400,400italic,500,500italic,700">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Product+Sans">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Google+Sans:wght@400;500;700">

    <style>
      body { transition: none; }
    </style>

    <script>
      window.version = 'patent-search.search_20240108_RC01';

      function sendFeedback() {
        userfeedback.api.startFeedback({
          'productId': '713680',
          'bucket': 'patent-search-web',
          'productVersion': window.version,
        });
      }

      window.experiments = {};
      window.experiments.patentCountries = "ae,ag,al,am,ao,ap,ar,at,au,aw,az,ba,bb,bd,be,bf,bg,bh,bj,bn,bo,br,bw,bx,by,bz,ca,cf,cg,ch,ci,cl,cm,cn,co,cr,cs,cu,cy,cz,dd,de,dj,dk,dm,do,dz,ea,ec,ee,eg,em,ep,es,fi,fr,ga,gb,gc,gd,ge,gh,gm,gn,gq,gr,gt,gw,hk,hn,hr,hu,ib,id,ie,il,in,ir,is,it,jo,jp,ke,kg,kh,km,kn,kp,kr,kw,kz,la,lc,li,lk,lr,ls,lt,lu,lv,ly,ma,mc,md,me,mg,mk,ml,mn,mo,mr,mt,mw,mx,my,mz,na,ne,ng,ni,nl,no,nz,oa,om,pa,pe,pg,ph,pl,pt,py,qa,ro,rs,ru,rw,sa,sc,sd,se,sg,si,sk,sl,sm,sn,st,su,sv,sy,sz,td,tg,th,tj,tm,tn,tr,tt,tw,tz,ua,ug,us,uy,uz,vc,ve,vn,wo,yu,za,zm,zw";
      
      
      window.experiments.keywordWizard = true;
      
      
      
      window.experiments.definitions = true;

      window.Polymer = {
        dom: 'shady',
        lazyRegister: true,
      };
    </script>

    <script src="//www.gstatic.com/patent-search/frontend/patent-search.search_20240108_RC01/scs/compiled_dir/webcomponentsjs/webcomponents-lite.min.js"></script>
    <link rel="import" href="//www.gstatic.com/patent-search/frontend/patent-search.search_20240108_RC01/scs/compiled_dir/search-app-vulcanized.html">
  </head>
  <body unresolved>
    <script src="//www.gstatic.com/patent-search/frontend/patent-search.search_20240108_RC01/scs/compiled_dir/search-app-vulcanized.js"></script>
    <search-app>
      
      

      <article class="result" itemscope itemtype="http://schema.org/ScholarlyArticle">
  <h1 itemprop="pageTitle">US20230210402A1 - Methods and devices for motion monitoring 
      - Google Patents</h1>
  <span itemprop="title">Methods and devices for motion monitoring 
     </span>

  <meta itemprop="type" content="patent">
  <a href="https://patentimages.storage.googleapis.com/6c/fa/75/424363fb3277eb/US20230210402A1.pdf" itemprop="pdfLink">Download PDF</a>
  <h2>Info</h2>

  <dl>
    <dt>Publication number</dt>
    <dd itemprop="publicationNumber">US20230210402A1</dd>
    <meta itemprop="numberWithoutCodes" content="20230210402">
    <meta itemprop="kindCode" content="A1">
    <meta itemprop="publicationDescription" content="Patent application publication">
    <span>US20230210402A1</span>
    <span>US18/182,373</span>
    <span>US202318182373A</span>
    <span>US2023210402A1</span>
    <span>US 20230210402 A1</span>
    <span>US20230210402 A1</span>
    <span>US 20230210402A1</span>
    <span>  </span>
    <span> </span>
    <span> </span>
    <span>US 202318182373 A</span>
    <span>US202318182373 A</span>
    <span>US 202318182373A</span>
    <span>US 2023210402 A1</span>
    <span>US2023210402 A1</span>
    <span>US 2023210402A1</span>

    <dt>Authority</dt>
    <dd itemprop="countryCode">US</dd>
    <dd itemprop="countryName">United States</dd>

    <dt>Prior art keywords</dt>
    <dd itemprop="priorArtKeywords" repeat>movement</dd>
    <dd itemprop="priorArtKeywords" repeat>user</dd>
    <dd itemprop="priorArtKeywords" repeat>signal</dd>
    <dd itemprop="priorArtKeywords" repeat>motion</dd>
    <dd itemprop="priorArtKeywords" repeat>muscle</dd>

    <dt>Prior art date</dt>
    <dd><time itemprop="priorArtDate" datetime="2021-03-19">2021-03-19</time></dd>

    <dt>Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)</dt>
    <dd itemprop="legalStatusIfi" itemscope>
      <span itemprop="status">Pending</span>
    </dd>
  </dl>

  <dt>Application number</dt>
  <dd itemprop="applicationNumber">US18/182,373</dd>

  

  

  <dt>Inventor</dt>
  <dd itemprop="inventor" repeat>Lei Su</dd>
  <dd itemprop="inventor" repeat>Meiqi LI</dd>
  <dd itemprop="inventor" repeat>Xin Zhou</dd>
  <dd itemprop="inventor" repeat>Fengyun LIAO</dd>

  <dt>Current Assignee (The listed assignees may be inaccurate. Google has not performed a legal analysis and makes no representation or warranty as to the accuracy of the list.)</dt>
  <dd itemprop="assigneeCurrent" repeat>
    Shenzhen Shokz Co Ltd
  </dd>

  <dt>Original Assignee</dt>
  <dd itemprop="assigneeOriginal" repeat>Shenzhen Shokz Co Ltd</dd>

  <dt>Priority date (The priority date is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the date listed.)</dt>
  <dd><time itemprop="priorityDate" datetime="2021-03-19">2021-03-19</time></dd>

  <dt>Filing date</dt>
  <dd><time itemprop="filingDate" datetime="2023-03-13">2023-03-13</time></dd>

  <dt>Publication date</dt>
  <dd><time itemprop="publicationDate" datetime="2023-07-06">2023-07-06</time></dd>

  
  <dd itemprop="events" itemscope repeat>
    <time itemprop="date" datetime="2021-03-19">2021-03-19</time>
    <span itemprop="title">Priority claimed from PCT/CN2021/081931</span>
    <span itemprop="type">external-priority</span>
    
    
    
    <span itemprop="documentId">patent/WO2022193330A1/en</span>
    
  </dd>
  <dd itemprop="events" itemscope repeat>
    <time itemprop="date" datetime="2023-03-13">2023-03-13</time>
    <span itemprop="title">Application filed by Shenzhen Shokz Co Ltd</span>
    <span itemprop="type">filed</span>
    <span itemprop="critical" content="true" bool>Critical</span>
    
    
    
    <span itemprop="assigneeSearch">Shenzhen Shokz Co Ltd</span>
  </dd>
  <dd itemprop="events" itemscope repeat>
    <time itemprop="date" datetime="2023-07-06">2023-07-06</time>
    <span itemprop="title">Publication of US20230210402A1</span>
    <span itemprop="type">publication</span>
    <span itemprop="critical" content="true" bool>Critical</span>
    
    
    <span itemprop="documentId">patent/US20230210402A1/en</span>
    
  </dd>
  <dd itemprop="events" itemscope repeat>
    <time itemprop="date" datetime="2023-09-01">2023-09-01</time>
    <span itemprop="title">Assigned to Shenzhen Shokz Co., Ltd.</span>
    <span itemprop="type">reassignment</span>
    
    
    
    
    <span itemprop="assigneeSearch">Shenzhen Shokz Co., Ltd.</span>
    <span itemprop="description" repeat>ASSIGNMENT OF ASSIGNORS INTEREST (SEE DOCUMENT FOR DETAILS).</span>
    <span itemprop="description" repeat>Assignors: LI, Meiqi, LIAO, Fengyun, SU, Lei, ZHOU, XIN</span>
  </dd>
  <dd itemprop="events" itemscope repeat>
    <time itemprop="date">Status</time>
    <span itemprop="title">Pending</span>
    <span itemprop="type">legal-status</span>
    <span itemprop="critical" content="true" bool>Critical</span>
    <span itemprop="current" content="true" bool>Current</span>
    
    
    
  </dd>

  <h2>Links</h2>
  <ul>
    <li itemprop="links" itemscope repeat>
          <meta itemprop="id" content="usptoLink">
          <a href="https://appft.uspto.gov/netacgi/nph-Parser?Sect1=PTO1&Sect2=HITOFF&p=1&u=/netahtml/PTO/srchnum.html&r=1&f=G&l=50&d=PG01&s1=20230210402.PGNR." itemprop="url" target="_blank"><span itemprop="text">USPTO</span></a>
        </li>
        
        <li itemprop="links" itemscope repeat>
          <meta itemprop="id" content="usptoPatentCenterLink">
          <a href="https://patentcenter.uspto.gov/applications/18182373" itemprop="url" target="_blank"><span itemprop="text">USPTO PatentCenter</span></a>
        </li>
        <li itemprop="links" itemscope repeat>
          <meta itemprop="id" content="usptoAssignmentLink">
          <a href="https://assignment.uspto.gov/patent/index.html#/patent/search/resultFilter?searchInput=20230210402" itemprop="url" target="_blank"><span itemprop="text">USPTO Assignment</span></a>
        </li>

    <li itemprop="links" itemscope repeat>
        <meta itemprop="id" content="espacenetLink">
        <a href="https://worldwide.espacenet.com/publicationDetails/biblio?CC=US&amp;NR=2023210402A1&amp;KC=A1&amp;FT=D" itemprop="url" target="_blank"><span itemprop="text">Espacenet</span></a>
      </li>
      

    

    
      <li itemprop="links" itemscope repeat>
        <meta itemprop="id" content="globalDossierLink">
        <a href="https://globaldossier.uspto.gov/#/result/publication/US/20230210402/1" itemprop="url" target="_blank"><span itemprop="text">Global Dossier</span></a>
      </li>

      

      

      

      <li itemprop="links" itemscope repeat>
        <meta itemprop="id" content="stackexchangeLink">
        <a href="https://patents.stackexchange.com/questions/tagged/US20230210402" itemprop="url"><span itemprop="text">Discuss</span></a>
      </li>
      
  </ul>

  

  <section>
    <h2>Images</h2>
    <ul>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/b1/e4/45/c4e5ee2ca31f75/US20230210402A1-20230706-D00000.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/87/f2/81/ed4e031e5d8e6b/US20230210402A1-20230706-D00000.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="0">
            <meta itemprop="id" content="100">
            <meta itemprop="label" content="motion monitoring system">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="129">
              <meta itemprop="top" content="6">
              <meta itemprop="right" content="222">
              <meta itemprop="bottom" content="51">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="0">
            <meta itemprop="id" content="1000">
            <meta itemprop="label" content="process">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="230">
              <meta itemprop="top" content="645">
              <meta itemprop="right" content="255">
              <meta itemprop="bottom" content="653">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="0">
            <meta itemprop="id" content="1000">
            <meta itemprop="label" content="process">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1546">
              <meta itemprop="top" content="678">
              <meta itemprop="right" content="1573">
              <meta itemprop="bottom" content="685">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="0">
            <meta itemprop="id" content="1000">
            <meta itemprop="label" content="process">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1634">
              <meta itemprop="top" content="677">
              <meta itemprop="right" content="1660">
              <meta itemprop="bottom" content="685">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="0">
            <meta itemprop="id" content="110">
            <meta itemprop="label" content="processing device">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="832">
              <meta itemprop="top" content="57">
              <meta itemprop="right" content="918">
              <meta itemprop="bottom" content="97">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="0">
            <meta itemprop="id" content="120">
            <meta itemprop="label" content="network">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1217">
              <meta itemprop="top" content="879">
              <meta itemprop="right" content="1309">
              <meta itemprop="bottom" content="919">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="0">
            <meta itemprop="id" content="130">
            <meta itemprop="label" content="wearable device">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="322">
              <meta itemprop="top" content="516">
              <meta itemprop="right" content="415">
              <meta itemprop="bottom" content="555">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="0">
            <meta itemprop="id" content="140">
            <meta itemprop="label" content="terminal device">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1579">
              <meta itemprop="top" content="543">
              <meta itemprop="right" content="1671">
              <meta itemprop="bottom" content="586">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="0">
            <meta itemprop="id" content="3">
            <meta itemprop="label" content="movement">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="8">
              <meta itemprop="top" content="701">
              <meta itemprop="right" content="15">
              <meta itemprop="bottom" content="727">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/63/f7/d0/454990c0e53cf4/US20230210402A1-20230706-D00001.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/b9/af/f9/1db2921bfe5df6/US20230210402A1-20230706-D00001.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="1">
            <meta itemprop="id" content="100">
            <meta itemprop="label" content="motion monitoring system">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="141">
              <meta itemprop="top" content="19">
              <meta itemprop="right" content="234">
              <meta itemprop="bottom" content="62">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="1">
            <meta itemprop="id" content="1000">
            <meta itemprop="label" content="process">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1646">
              <meta itemprop="top" content="689">
              <meta itemprop="right" content="1673">
              <meta itemprop="bottom" content="697">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="1">
            <meta itemprop="id" content="110">
            <meta itemprop="label" content="processing device">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="844">
              <meta itemprop="top" content="69">
              <meta itemprop="right" content="931">
              <meta itemprop="bottom" content="109">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="1">
            <meta itemprop="id" content="120">
            <meta itemprop="label" content="network">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1230">
              <meta itemprop="top" content="892">
              <meta itemprop="right" content="1319">
              <meta itemprop="bottom" content="932">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="1">
            <meta itemprop="id" content="130">
            <meta itemprop="label" content="wearable device">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="334">
              <meta itemprop="top" content="528">
              <meta itemprop="right" content="426">
              <meta itemprop="bottom" content="569">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="1">
            <meta itemprop="id" content="140">
            <meta itemprop="label" content="terminal device">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1592">
              <meta itemprop="top" content="557">
              <meta itemprop="right" content="1684">
              <meta itemprop="bottom" content="598">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="1">
            <meta itemprop="id" content="3">
            <meta itemprop="label" content="movement">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="304">
              <meta itemprop="top" content="943">
              <meta itemprop="right" content="368">
              <meta itemprop="bottom" content="1012">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/9e/d8/c1/4476aa279c2a31/US20230210402A1-20230706-D00002.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/c9/29/9f/de8f8daa98059a/US20230210402A1-20230706-D00002.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="2">
            <meta itemprop="id" content="130">
            <meta itemprop="label" content="wearable device">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="50">
              <meta itemprop="top" content="20">
              <meta itemprop="right" content="143">
              <meta itemprop="bottom" content="63">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="2">
            <meta itemprop="id" content="210">
            <meta itemprop="label" content="module">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="517">
              <meta itemprop="top" content="140">
              <meta itemprop="right" content="614">
              <meta itemprop="bottom" content="182">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="2">
            <meta itemprop="id" content="220">
            <meta itemprop="label" content="processing module">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1077">
              <meta itemprop="top" content="136">
              <meta itemprop="right" content="1172">
              <meta itemprop="bottom" content="176">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="2">
            <meta itemprop="id" content="230">
            <meta itemprop="label" content="control module">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1596">
              <meta itemprop="top" content="132">
              <meta itemprop="right" content="1693">
              <meta itemprop="bottom" content="174">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="2">
            <meta itemprop="id" content="240">
            <meta itemprop="label" content="communication module">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="542">
              <meta itemprop="top" content="743">
              <meta itemprop="right" content="634">
              <meta itemprop="bottom" content="784">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="2">
            <meta itemprop="id" content="250">
            <meta itemprop="label" content="power supply module">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1068">
              <meta itemprop="top" content="734">
              <meta itemprop="right" content="1160">
              <meta itemprop="bottom" content="776">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="2">
            <meta itemprop="id" content="260">
            <meta itemprop="label" content="output module">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1709">
              <meta itemprop="top" content="735">
              <meta itemprop="right" content="1800">
              <meta itemprop="bottom" content="776">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="2">
            <meta itemprop="id" content="300">
            <meta itemprop="label" content="computing device">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="193">
              <meta itemprop="top" content="1388">
              <meta itemprop="right" content="289">
              <meta itemprop="bottom" content="1431">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="2">
            <meta itemprop="id" content="310">
            <meta itemprop="label" content="internal communication bus">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="467">
              <meta itemprop="top" content="1984">
              <meta itemprop="right" content="565">
              <meta itemprop="bottom" content="2024">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="2">
            <meta itemprop="id" content="320">
            <meta itemprop="label" content="processor">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="412">
              <meta itemprop="top" content="2142">
              <meta itemprop="right" content="508">
              <meta itemprop="bottom" content="2184">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="2">
            <meta itemprop="id" content="330">
            <meta itemprop="label" content="only memory">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="990">
              <meta itemprop="top" content="2147">
              <meta itemprop="right" content="1087">
              <meta itemprop="bottom" content="2190">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="2">
            <meta itemprop="id" content="340">
            <meta itemprop="label" content="random memory">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1586">
              <meta itemprop="top" content="2138">
              <meta itemprop="right" content="1682">
              <meta itemprop="bottom" content="2185">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="2">
            <meta itemprop="id" content="350">
            <meta itemprop="label" content="communication port">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1425">
              <meta itemprop="top" content="1650">
              <meta itemprop="right" content="1522">
              <meta itemprop="bottom" content="1693">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="2">
            <meta itemprop="id" content="360">
            <meta itemprop="label" content="output interface">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1070">
              <meta itemprop="top" content="1639">
              <meta itemprop="right" content="1166">
              <meta itemprop="bottom" content="1680">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="2">
            <meta itemprop="id" content="370">
            <meta itemprop="label" content="hard disk">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="317">
              <meta itemprop="top" content="1628">
              <meta itemprop="right" content="413">
              <meta itemprop="bottom" content="1671">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="2">
            <meta itemprop="id" content="380">
            <meta itemprop="label" content="user interface">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1035">
              <meta itemprop="top" content="1448">
              <meta itemprop="right" content="1131">
              <meta itemprop="bottom" content="1490">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/f8/6e/f3/441e6ded96b172/US20230210402A1-20230706-D00003.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/7f/ec/3a/caf9a4addc983f/US20230210402A1-20230706-D00003.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="3">
            <meta itemprop="id" content="400">
            <meta itemprop="label" content="wearable device">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="45">
              <meta itemprop="top" content="21">
              <meta itemprop="right" content="141">
              <meta itemprop="bottom" content="63">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="3">
            <meta itemprop="id" content="410">
            <meta itemprop="label" content="upper garment">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="64">
              <meta itemprop="top" content="235">
              <meta itemprop="right" content="161">
              <meta itemprop="bottom" content="277">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="3">
            <meta itemprop="id" content="4110">
            <meta itemprop="label" content="upper garment substrate">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="585">
              <meta itemprop="top" content="196">
              <meta itemprop="right" content="709">
              <meta itemprop="bottom" content="237">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="3">
            <meta itemprop="id" content="4120">
            <meta itemprop="label" content="garment processing module">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="921">
              <meta itemprop="top" content="210">
              <meta itemprop="right" content="1053">
              <meta itemprop="bottom" content="253">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="3">
            <meta itemprop="id" content="4130">
            <meta itemprop="label" content="garment feedback module">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1137">
              <meta itemprop="top" content="389">
              <meta itemprop="right" content="1266">
              <meta itemprop="bottom" content="430">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="3">
            <meta itemprop="id" content="4140">
            <meta itemprop="label" content="garment obtaining module">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1319">
              <meta itemprop="top" content="586">
              <meta itemprop="right" content="1447">
              <meta itemprop="bottom" content="627">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/05/e5/d9/96e1c27147fdc7/US20230210402A1-20230706-D00004.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/de/3b/bd/8f6687e477397e/US20230210402A1-20230706-D00004.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="4">
            <meta itemprop="id" content="500">
            <meta itemprop="label" content="process">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="34">
              <meta itemprop="top" content="20">
              <meta itemprop="right" content="126">
              <meta itemprop="bottom" content="62">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="4">
            <meta itemprop="id" content="510">
            <meta itemprop="label" content="step">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1493">
              <meta itemprop="top" content="232">
              <meta itemprop="right" content="1587">
              <meta itemprop="bottom" content="273">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="4">
            <meta itemprop="id" content="520">
            <meta itemprop="label" content="step">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1482">
              <meta itemprop="top" content="917">
              <meta itemprop="right" content="1577">
              <meta itemprop="bottom" content="960">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="4">
            <meta itemprop="id" content="600">
            <meta itemprop="label" content="process">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="54">
              <meta itemprop="top" content="1523">
              <meta itemprop="right" content="154">
              <meta itemprop="bottom" content="1566">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="4">
            <meta itemprop="id" content="610">
            <meta itemprop="label" content="step">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1471">
              <meta itemprop="top" content="1711">
              <meta itemprop="right" content="1567">
              <meta itemprop="bottom" content="1752">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="4">
            <meta itemprop="id" content="620">
            <meta itemprop="label" content="step">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1470">
              <meta itemprop="top" content="2147">
              <meta itemprop="right" content="1567">
              <meta itemprop="bottom" content="2187">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/de/0c/f7/2427be4a138441/US20230210402A1-20230706-D00005.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/94/dd/0b/76ecbea6ebd0e2/US20230210402A1-20230706-D00005.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="5">
            <meta itemprop="id" content="700">
            <meta itemprop="label" content="process">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="81">
              <meta itemprop="top" content="20">
              <meta itemprop="right" content="179">
              <meta itemprop="bottom" content="63">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="5">
            <meta itemprop="id" content="710">
            <meta itemprop="label" content="step">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1608">
              <meta itemprop="top" content="529">
              <meta itemprop="right" content="1703">
              <meta itemprop="bottom" content="570">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="5">
            <meta itemprop="id" content="720">
            <meta itemprop="label" content="step">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1609">
              <meta itemprop="top" content="1301">
              <meta itemprop="right" content="1706">
              <meta itemprop="bottom" content="1344">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/ba/bf/40/db33c2312fef34/US20230210402A1-20230706-D00006.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/f9/9c/29/8c3b886cfab233/US20230210402A1-20230706-D00006.png">
        <ul>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/2a/77/9f/2e98712b43f2cf/US20230210402A1-20230706-D00007.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/ba/a3/f4/419f876d9c2a09/US20230210402A1-20230706-D00007.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="7">
            <meta itemprop="id" content="900">
            <meta itemprop="label" content="process">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="135">
              <meta itemprop="top" content="21">
              <meta itemprop="right" content="229">
              <meta itemprop="bottom" content="62">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="7">
            <meta itemprop="id" content="910">
            <meta itemprop="label" content="step">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1714">
              <meta itemprop="top" content="626">
              <meta itemprop="right" content="1809">
              <meta itemprop="bottom" content="666">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="7">
            <meta itemprop="id" content="920">
            <meta itemprop="label" content="step">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1714">
              <meta itemprop="top" content="1582">
              <meta itemprop="right" content="1808">
              <meta itemprop="bottom" content="1624">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/26/ae/34/ce9fa6f8c64559/US20230210402A1-20230706-D00008.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/60/15/a2/bc62d48a5ff297/US20230210402A1-20230706-D00008.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="8">
            <meta itemprop="id" content="1000">
            <meta itemprop="label" content="process">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="112">
              <meta itemprop="top" content="20">
              <meta itemprop="right" content="238">
              <meta itemprop="bottom" content="63">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="8">
            <meta itemprop="id" content="1010">
            <meta itemprop="label" content="step">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1513">
              <meta itemprop="top" content="582">
              <meta itemprop="right" content="1637">
              <meta itemprop="bottom" content="622">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="8">
            <meta itemprop="id" content="1020">
            <meta itemprop="label" content="step">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1314">
              <meta itemprop="top" content="1130">
              <meta itemprop="right" content="1436">
              <meta itemprop="bottom" content="1173">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="8">
            <meta itemprop="id" content="1030">
            <meta itemprop="label" content="step">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="938">
              <meta itemprop="top" content="1703">
              <meta itemprop="right" content="1062">
              <meta itemprop="bottom" content="1744">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="8">
            <meta itemprop="id" content="1040">
            <meta itemprop="label" content="step">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1728">
              <meta itemprop="top" content="1696">
              <meta itemprop="right" content="1851">
              <meta itemprop="bottom" content="1738">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/08/0b/4d/c2a0bdd9337b01/US20230210402A1-20230706-D00009.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/e7/06/c7/4ac611393aeb9e/US20230210402A1-20230706-D00009.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="9">
            <meta itemprop="id" content="1100">
            <meta itemprop="label" content="process">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="65">
              <meta itemprop="top" content="18">
              <meta itemprop="right" content="186">
              <meta itemprop="bottom" content="62">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="9">
            <meta itemprop="id" content="1110">
            <meta itemprop="label" content="step">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1523">
              <meta itemprop="top" content="493">
              <meta itemprop="right" content="1637">
              <meta itemprop="bottom" content="533">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="9">
            <meta itemprop="id" content="1120">
            <meta itemprop="label" content="step">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1552">
              <meta itemprop="top" content="1213">
              <meta itemprop="right" content="1673">
              <meta itemprop="bottom" content="1254">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="9">
            <meta itemprop="id" content="1130">
            <meta itemprop="label" content="step">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1552">
              <meta itemprop="top" content="1961">
              <meta itemprop="right" content="1672">
              <meta itemprop="bottom" content="2001">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/f0/fe/5d/d1b470e9a4867c/US20230210402A1-20230706-D00010.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/2f/6d/9a/5a4e74a50c0cf6/US20230210402A1-20230706-D00010.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="10">
            <meta itemprop="id" content="1200">
            <meta itemprop="label" content="process">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="39">
              <meta itemprop="top" content="18">
              <meta itemprop="right" content="163">
              <meta itemprop="bottom" content="62">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="10">
            <meta itemprop="id" content="1210">
            <meta itemprop="label" content="step">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1583">
              <meta itemprop="top" content="700">
              <meta itemprop="right" content="1707">
              <meta itemprop="bottom" content="741">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="10">
            <meta itemprop="id" content="1220">
            <meta itemprop="label" content="step">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1583">
              <meta itemprop="top" content="1630">
              <meta itemprop="right" content="1708">
              <meta itemprop="bottom" content="1672">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/c4/88/06/d07075e7c4110f/US20230210402A1-20230706-D00011.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/86/99/76/d3fe7c8f9e790e/US20230210402A1-20230706-D00011.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="11">
            <meta itemprop="id" content="1300">
            <meta itemprop="label" content="process">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="49">
              <meta itemprop="top" content="20">
              <meta itemprop="right" content="173">
              <meta itemprop="bottom" content="62">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="11">
            <meta itemprop="id" content="1310">
            <meta itemprop="label" content="step">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1688">
              <meta itemprop="top" content="428">
              <meta itemprop="right" content="1816">
              <meta itemprop="bottom" content="469">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="11">
            <meta itemprop="id" content="1320">
            <meta itemprop="label" content="step">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1694">
              <meta itemprop="top" content="1025">
              <meta itemprop="right" content="1818">
              <meta itemprop="bottom" content="1069">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="11">
            <meta itemprop="id" content="1330">
            <meta itemprop="label" content="step">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1714">
              <meta itemprop="top" content="1698">
              <meta itemprop="right" content="1839">
              <meta itemprop="bottom" content="1741">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="11">
            <meta itemprop="id" content="1340">
            <meta itemprop="label" content="step">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1715">
              <meta itemprop="top" content="2318">
              <meta itemprop="right" content="1840">
              <meta itemprop="bottom" content="2362">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/20/80/32/f9ccfef6982904/US20230210402A1-20230706-D00012.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/29/f3/01/f637a0af36e878/US20230210402A1-20230706-D00012.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="12">
            <meta itemprop="id" content="1400">
            <meta itemprop="label" content="process">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="33">
              <meta itemprop="top" content="20">
              <meta itemprop="right" content="157">
              <meta itemprop="bottom" content="62">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="12">
            <meta itemprop="id" content="1410">
            <meta itemprop="label" content="step">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1706">
              <meta itemprop="top" content="626">
              <meta itemprop="right" content="1829">
              <meta itemprop="bottom" content="669">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="12">
            <meta itemprop="id" content="1420">
            <meta itemprop="label" content="step">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1706">
              <meta itemprop="top" content="1783">
              <meta itemprop="right" content="1830">
              <meta itemprop="bottom" content="1824">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/ab/76/76/0584885629cfb9/US20230210402A1-20230706-D00013.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/e9/ae/1b/212fba4c5b097e/US20230210402A1-20230706-D00013.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="13">
            <meta itemprop="id" content="1">
            <meta itemprop="label" content="movement">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1051">
              <meta itemprop="top" content="21">
              <meta itemprop="right" content="1074">
              <meta itemprop="bottom" content="53">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="13">
            <meta itemprop="id" content="1">
            <meta itemprop="label" content="movement">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1105">
              <meta itemprop="top" content="1272">
              <meta itemprop="right" content="1125">
              <meta itemprop="bottom" content="1302">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="13">
            <meta itemprop="id" content="100">
            <meta itemprop="label" content="motion monitoring system">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="54">
              <meta itemprop="top" content="1431">
              <meta itemprop="right" content="120">
              <meta itemprop="bottom" content="1463">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="13">
            <meta itemprop="id" content="100">
            <meta itemprop="label" content="motion monitoring system">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="44">
              <meta itemprop="top" content="1670">
              <meta itemprop="right" content="131">
              <meta itemprop="bottom" content="1705">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="13">
            <meta itemprop="id" content="100">
            <meta itemprop="label" content="motion monitoring system">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="83">
              <meta itemprop="top" content="192">
              <meta itemprop="right" content="150">
              <meta itemprop="bottom" content="222">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="13">
            <meta itemprop="id" content="100">
            <meta itemprop="label" content="motion monitoring system">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="74">
              <meta itemprop="top" content="435">
              <meta itemprop="right" content="167">
              <meta itemprop="bottom" content="471">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/36/fa/3c/d72bb9e409def3/US20230210402A1-20230706-D00014.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/76/e2/d7/9e5d69f3188060/US20230210402A1-20230706-D00014.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="14">
            <meta itemprop="id" content="1">
            <meta itemprop="label" content="movement">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="90">
              <meta itemprop="top" content="59">
              <meta itemprop="right" content="112">
              <meta itemprop="bottom" content="89">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="14">
            <meta itemprop="id" content="1">
            <meta itemprop="label" content="movement">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1065">
              <meta itemprop="top" content="20">
              <meta itemprop="right" content="1086">
              <meta itemprop="bottom" content="49">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="14">
            <meta itemprop="id" content="1">
            <meta itemprop="label" content="movement">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="84">
              <meta itemprop="top" content="588">
              <meta itemprop="right" content="132">
              <meta itemprop="bottom" content="618">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="14">
            <meta itemprop="id" content="1">
            <meta itemprop="label" content="movement">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1074">
              <meta itemprop="top" content="1332">
              <meta itemprop="right" content="1092">
              <meta itemprop="bottom" content="1363">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="14">
            <meta itemprop="id" content="1">
            <meta itemprop="label" content="movement">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="73">
              <meta itemprop="top" content="1935">
              <meta itemprop="right" content="118">
              <meta itemprop="bottom" content="1966">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/b3/01/34/3fb7abb9b13003/US20230210402A1-20230706-D00015.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/14/bc/5f/52bbe75522bb22/US20230210402A1-20230706-D00015.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="15">
            <meta itemprop="id" content="1">
            <meta itemprop="label" content="movement">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="615">
              <meta itemprop="top" content="69">
              <meta itemprop="right" content="631">
              <meta itemprop="bottom" content="98">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="15">
            <meta itemprop="id" content="2">
            <meta itemprop="label" content="movement">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="809">
              <meta itemprop="top" content="70">
              <meta itemprop="right" content="833">
              <meta itemprop="bottom" content="99">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="15">
            <meta itemprop="id" content="3">
            <meta itemprop="label" content="movement">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1009">
              <meta itemprop="top" content="69">
              <meta itemprop="right" content="1034">
              <meta itemprop="bottom" content="100">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="15">
            <meta itemprop="id" content="4">
            <meta itemprop="label" content="movement">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1171">
              <meta itemprop="top" content="109">
              <meta itemprop="right" content="1195">
              <meta itemprop="bottom" content="138">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="15">
            <meta itemprop="id" content="5">
            <meta itemprop="label" content="movement">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1381">
              <meta itemprop="top" content="110">
              <meta itemprop="right" content="1403">
              <meta itemprop="bottom" content="137">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="15">
            <meta itemprop="id" content="6">
            <meta itemprop="label" content="movement">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1597">
              <meta itemprop="top" content="112">
              <meta itemprop="right" content="1620">
              <meta itemprop="bottom" content="142">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/e2/88/46/092f1a2b4b42cb/US20230210402A1-20230706-D00016.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/a0/a8/39/27f057058a42d3/US20230210402A1-20230706-D00016.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="16">
            <meta itemprop="id" content="1">
            <meta itemprop="label" content="movement">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="18">
              <meta itemprop="top" content="471">
              <meta itemprop="right" content="56">
              <meta itemprop="bottom" content="507">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="16">
            <meta itemprop="id" content="2">
            <meta itemprop="label" content="movement">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="32">
              <meta itemprop="top" content="22">
              <meta itemprop="right" content="59">
              <meta itemprop="bottom" content="57">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="16">
            <meta itemprop="id" content="2">
            <meta itemprop="label" content="movement">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="19">
              <meta itemprop="top" content="624">
              <meta itemprop="right" content="61">
              <meta itemprop="bottom" content="658">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="16">
            <meta itemprop="id" content="2">
            <meta itemprop="label" content="movement">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="18">
              <meta itemprop="top" content="1455">
              <meta itemprop="right" content="58">
              <meta itemprop="bottom" content="1489">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="16">
            <meta itemprop="id" content="5">
            <meta itemprop="label" content="movement">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="324">
              <meta itemprop="top" content="1513">
              <meta itemprop="right" content="352">
              <meta itemprop="bottom" content="1550">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/66/b7/c1/6c46166dd26d0c/US20230210402A1-20230706-D00017.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/77/37/fa/4cbb0eee0c6789/US20230210402A1-20230706-D00017.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="17">
            <meta itemprop="id" content="1900">
            <meta itemprop="label" content="process">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="56">
              <meta itemprop="top" content="17">
              <meta itemprop="right" content="183">
              <meta itemprop="bottom" content="64">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="17">
            <meta itemprop="id" content="1910">
            <meta itemprop="label" content="step">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1695">
              <meta itemprop="top" content="577">
              <meta itemprop="right" content="1819">
              <meta itemprop="bottom" content="618">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="17">
            <meta itemprop="id" content="1920">
            <meta itemprop="label" content="step">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1694">
              <meta itemprop="top" content="1667">
              <meta itemprop="right" content="1818">
              <meta itemprop="bottom" content="1711">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/29/55/10/cf3444a35e80ee/US20230210402A1-20230706-D00018.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/95/15/49/0babe648c41009/US20230210402A1-20230706-D00018.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="18">
            <meta itemprop="id" content="2000">
            <meta itemprop="label" content="process">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="81">
              <meta itemprop="top" content="20">
              <meta itemprop="right" content="207">
              <meta itemprop="bottom" content="62">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="18">
            <meta itemprop="id" content="2010">
            <meta itemprop="label" content="step">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="555">
              <meta itemprop="top" content="307">
              <meta itemprop="right" content="684">
              <meta itemprop="bottom" content="351">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="18">
            <meta itemprop="id" content="2020">
            <meta itemprop="label" content="step">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="605">
              <meta itemprop="top" content="1085">
              <meta itemprop="right" content="730">
              <meta itemprop="bottom" content="1128">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="18">
            <meta itemprop="id" content="2030">
            <meta itemprop="label" content="step">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="611">
              <meta itemprop="top" content="1860">
              <meta itemprop="right" content="737">
              <meta itemprop="bottom" content="1903">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="18">
            <meta itemprop="id" content="2040">
            <meta itemprop="label" content="step">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1626">
              <meta itemprop="top" content="298">
              <meta itemprop="right" content="1753">
              <meta itemprop="bottom" content="343">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="18">
            <meta itemprop="id" content="2050">
            <meta itemprop="label" content="step">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1642">
              <meta itemprop="top" content="1071">
              <meta itemprop="right" content="1768">
              <meta itemprop="bottom" content="1112">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="18">
            <meta itemprop="id" content="2060">
            <meta itemprop="label" content="step">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1728">
              <meta itemprop="top" content="1771">
              <meta itemprop="right" content="1855">
              <meta itemprop="bottom" content="1814">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/ff/7d/56/e3c610fb40322a/US20230210402A1-20230706-D00019.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/04/11/ab/4f90326763457c/US20230210402A1-20230706-D00019.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="19">
            <meta itemprop="id" content="2100">
            <meta itemprop="label" content="process">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="21">
              <meta itemprop="top" content="19">
              <meta itemprop="right" content="150">
              <meta itemprop="bottom" content="63">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="19">
            <meta itemprop="id" content="2110">
            <meta itemprop="label" content="step">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1396">
              <meta itemprop="top" content="529">
              <meta itemprop="right" content="1520">
              <meta itemprop="bottom" content="570">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="19">
            <meta itemprop="id" content="2120">
            <meta itemprop="label" content="step">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1394">
              <meta itemprop="top" content="1069">
              <meta itemprop="right" content="1523">
              <meta itemprop="bottom" content="1110">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="19">
            <meta itemprop="id" content="2130">
            <meta itemprop="label" content="step">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1409">
              <meta itemprop="top" content="1632">
              <meta itemprop="right" content="1537">
              <meta itemprop="bottom" content="1675">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/70/3f/46/f674511c4541e8/US20230210402A1-20230706-D00020.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/f3/ef/eb/afa2a1d9f766f0/US20230210402A1-20230706-D00020.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="20">
            <meta itemprop="id" content="2101">
            <meta itemprop="label" content="muscle distribution map">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1011">
              <meta itemprop="top" content="35">
              <meta itemprop="right" content="1133">
              <meta itemprop="bottom" content="76">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="20">
            <meta itemprop="id" content="2102">
            <meta itemprop="label" content="muscle distribution map">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="541">
              <meta itemprop="top" content="21">
              <meta itemprop="right" content="669">
              <meta itemprop="bottom" content="61">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="20">
            <meta itemprop="id" content="2103">
            <meta itemprop="label" content="status bar">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="249">
              <meta itemprop="top" content="34">
              <meta itemprop="right" content="377">
              <meta itemprop="bottom" content="75">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="20">
            <meta itemprop="id" content="2104">
            <meta itemprop="label" content="status bar">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1279">
              <meta itemprop="top" content="30">
              <meta itemprop="right" content="1407">
              <meta itemprop="bottom" content="72">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/d1/f6/10/2853288d65bbd2/US20230210402A1-20230706-D00021.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/2c/51/f2/ec9cfe3a813e52/US20230210402A1-20230706-D00021.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="21">
            <meta itemprop="id" content="2200">
            <meta itemprop="label" content="process">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="20">
              <meta itemprop="top" content="17">
              <meta itemprop="right" content="149">
              <meta itemprop="bottom" content="63">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="21">
            <meta itemprop="id" content="2210">
            <meta itemprop="label" content="step">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1409">
              <meta itemprop="top" content="531">
              <meta itemprop="right" content="1538">
              <meta itemprop="bottom" content="571">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="21">
            <meta itemprop="id" content="2220">
            <meta itemprop="label" content="step">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1410">
              <meta itemprop="top" content="1071">
              <meta itemprop="right" content="1535">
              <meta itemprop="bottom" content="1111">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="21">
            <meta itemprop="id" content="2230">
            <meta itemprop="label" content="step">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1409">
              <meta itemprop="top" content="1633">
              <meta itemprop="right" content="1537">
              <meta itemprop="bottom" content="1674">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/39/eb/65/b4efaf4eac63f7/US20230210402A1-20230706-D00022.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/02/85/c6/986db0d679d863/US20230210402A1-20230706-D00022.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="22">
            <meta itemprop="id" content="010">
            <meta itemprop="label" content="electromyography animation">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="125">
              <meta itemprop="top" content="1356">
              <meta itemprop="right" content="220">
              <meta itemprop="bottom" content="1398">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="22">
            <meta itemprop="id" content="010">
            <meta itemprop="label" content="electromyography animation">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="113">
              <meta itemprop="top" content="29">
              <meta itemprop="right" content="210">
              <meta itemprop="bottom" content="69">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="22">
            <meta itemprop="id" content="011">
            <meta itemprop="label" content="user display area">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="715">
              <meta itemprop="top" content="501">
              <meta itemprop="right" content="798">
              <meta itemprop="bottom" content="541">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="22">
            <meta itemprop="id" content="011">
            <meta itemprop="label" content="user display area">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="725">
              <meta itemprop="top" content="1826">
              <meta itemprop="right" content="811">
              <meta itemprop="bottom" content="1870">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="22">
            <meta itemprop="id" content="012">
            <meta itemprop="label" content="user display area">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="607">
              <meta itemprop="top" content="248">
              <meta itemprop="right" content="702">
              <meta itemprop="bottom" content="289">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="22">
            <meta itemprop="id" content="012">
            <meta itemprop="label" content="user display area">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="619">
              <meta itemprop="top" content="1577">
              <meta itemprop="right" content="713">
              <meta itemprop="bottom" content="1617">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="22">
            <meta itemprop="id" content="013">
            <meta itemprop="label" content="user display area">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="508">
              <meta itemprop="top" content="1520">
              <meta itemprop="right" content="605">
              <meta itemprop="bottom" content="1565">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="22">
            <meta itemprop="id" content="013">
            <meta itemprop="label" content="user display area">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="498">
              <meta itemprop="top" content="193">
              <meta itemprop="right" content="592">
              <meta itemprop="bottom" content="236">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="22">
            <meta itemprop="id" content="014">
            <meta itemprop="label" content="user display area">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="703">
              <meta itemprop="top" content="397">
              <meta itemprop="right" content="797">
              <meta itemprop="bottom" content="439">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="22">
            <meta itemprop="id" content="014">
            <meta itemprop="label" content="user display area">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="715">
              <meta itemprop="top" content="1728">
              <meta itemprop="right" content="811">
              <meta itemprop="bottom" content="1769">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="22">
            <meta itemprop="id" content="020">
            <meta itemprop="label" content="reference electromyography animation">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="857">
              <meta itemprop="top" content="19">
              <meta itemprop="right" content="954">
              <meta itemprop="bottom" content="62">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="22">
            <meta itemprop="id" content="020">
            <meta itemprop="label" content="reference electromyography animation">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="843">
              <meta itemprop="top" content="1350">
              <meta itemprop="right" content="936">
              <meta itemprop="bottom" content="1392">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="22">
            <meta itemprop="id" content="021">
            <meta itemprop="label" content="reference display area">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1443">
              <meta itemprop="top" content="1821">
              <meta itemprop="right" content="1531">
              <meta itemprop="bottom" content="1863">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="22">
            <meta itemprop="id" content="021">
            <meta itemprop="label" content="reference display area">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1458">
              <meta itemprop="top" content="492">
              <meta itemprop="right" content="1546">
              <meta itemprop="bottom" content="534">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="22">
            <meta itemprop="id" content="022">
            <meta itemprop="label" content="user display area">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1354">
              <meta itemprop="top" content="238">
              <meta itemprop="right" content="1448">
              <meta itemprop="bottom" content="280">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="22">
            <meta itemprop="id" content="022">
            <meta itemprop="label" content="user display area">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1337">
              <meta itemprop="top" content="1569">
              <meta itemprop="right" content="1433">
              <meta itemprop="bottom" content="1612">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="22">
            <meta itemprop="id" content="023">
            <meta itemprop="label" content="reference display area">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1242">
              <meta itemprop="top" content="186">
              <meta itemprop="right" content="1336">
              <meta itemprop="bottom" content="226">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="22">
            <meta itemprop="id" content="023">
            <meta itemprop="label" content="reference display area">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1227">
              <meta itemprop="top" content="1516">
              <meta itemprop="right" content="1323">
              <meta itemprop="bottom" content="1558">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="22">
            <meta itemprop="id" content="024">
            <meta itemprop="label" content="user display area">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1433">
              <meta itemprop="top" content="1721">
              <meta itemprop="right" content="1529">
              <meta itemprop="bottom" content="1761">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="22">
            <meta itemprop="id" content="024">
            <meta itemprop="label" content="user display area">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1449">
              <meta itemprop="top" content="389">
              <meta itemprop="right" content="1544">
              <meta itemprop="bottom" content="430">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/dc/67/c4/d13aa67e94365b/US20230210402A1-20230706-D00023.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/34/7c/cb/fe2a7c8cec0a52/US20230210402A1-20230706-D00023.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="23">
            <meta itemprop="id" content="010">
            <meta itemprop="label" content="electromyography animation">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="130">
              <meta itemprop="top" content="16">
              <meta itemprop="right" content="230">
              <meta itemprop="bottom" content="63">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="23">
            <meta itemprop="id" content="011">
            <meta itemprop="label" content="user display area">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="734">
              <meta itemprop="top" content="491">
              <meta itemprop="right" content="817">
              <meta itemprop="bottom" content="533">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="23">
            <meta itemprop="id" content="012">
            <meta itemprop="label" content="user display area">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="626">
              <meta itemprop="top" content="238">
              <meta itemprop="right" content="720">
              <meta itemprop="bottom" content="280">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="23">
            <meta itemprop="id" content="013">
            <meta itemprop="label" content="user display area">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="515">
              <meta itemprop="top" content="186">
              <meta itemprop="right" content="611">
              <meta itemprop="bottom" content="226">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="23">
            <meta itemprop="id" content="014">
            <meta itemprop="label" content="user display area">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="721">
              <meta itemprop="top" content="388">
              <meta itemprop="right" content="817">
              <meta itemprop="bottom" content="430">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="23">
            <meta itemprop="id" content="020">
            <meta itemprop="label" content="reference electromyography animation">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="836">
              <meta itemprop="top" content="26">
              <meta itemprop="right" content="932">
              <meta itemprop="bottom" content="67">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="23">
            <meta itemprop="id" content="021">
            <meta itemprop="label" content="reference display area">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1438">
              <meta itemprop="top" content="497">
              <meta itemprop="right" content="1524">
              <meta itemprop="bottom" content="539">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="23">
            <meta itemprop="id" content="022">
            <meta itemprop="label" content="user display area">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1331">
              <meta itemprop="top" content="244">
              <meta itemprop="right" content="1427">
              <meta itemprop="bottom" content="286">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="23">
            <meta itemprop="id" content="023">
            <meta itemprop="label" content="reference display area">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1221">
              <meta itemprop="top" content="192">
              <meta itemprop="right" content="1316">
              <meta itemprop="bottom" content="232">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="23">
            <meta itemprop="id" content="024">
            <meta itemprop="label" content="user display area">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1427">
              <meta itemprop="top" content="396">
              <meta itemprop="right" content="1521">
              <meta itemprop="bottom" content="436">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/7a/ca/0e/87fe87fd0ec3a2/US20230210402A1-20230706-D00024.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/b9/8c/97/d940440f029f1d/US20230210402A1-20230706-D00024.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="24">
            <meta itemprop="id" content="2400">
            <meta itemprop="label" content="process">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="21">
              <meta itemprop="top" content="20">
              <meta itemprop="right" content="150">
              <meta itemprop="bottom" content="62">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="24">
            <meta itemprop="id" content="2410">
            <meta itemprop="label" content="step">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1438">
              <meta itemprop="top" content="528">
              <meta itemprop="right" content="1567">
              <meta itemprop="bottom" content="570">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="24">
            <meta itemprop="id" content="2420">
            <meta itemprop="label" content="step">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1445">
              <meta itemprop="top" content="972">
              <meta itemprop="right" content="1572">
              <meta itemprop="bottom" content="1014">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="24">
            <meta itemprop="id" content="2430">
            <meta itemprop="label" content="step">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1407">
              <meta itemprop="top" content="1351">
              <meta itemprop="right" content="1534">
              <meta itemprop="bottom" content="1394">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="24">
            <meta itemprop="id" content="2440">
            <meta itemprop="label" content="step">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1419">
              <meta itemprop="top" content="1827">
              <meta itemprop="right" content="1546">
              <meta itemprop="bottom" content="1869">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/58/f8/fb/3e8beac51c72cc/US20230210402A1-20230706-D00025.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/ce/b1/01/dbdb7e70423a47/US20230210402A1-20230706-D00025.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="25">
            <meta itemprop="id" content="110">
            <meta itemprop="label" content="processing device">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="505">
              <meta itemprop="top" content="616">
              <meta itemprop="right" content="579">
              <meta itemprop="bottom" content="665">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="25">
            <meta itemprop="id" content="2500">
            <meta itemprop="label" content="interface">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="61">
              <meta itemprop="top" content="21">
              <meta itemprop="right" content="190">
              <meta itemprop="bottom" content="62">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="25">
            <meta itemprop="id" content="3">
            <meta itemprop="label" content="movement">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1066">
              <meta itemprop="top" content="1187">
              <meta itemprop="right" content="1099">
              <meta itemprop="bottom" content="1232">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="25">
            <meta itemprop="id" content="3">
            <meta itemprop="label" content="movement">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1066">
              <meta itemprop="top" content="1470">
              <meta itemprop="right" content="1099">
              <meta itemprop="bottom" content="1513">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="25">
            <meta itemprop="id" content="4">
            <meta itemprop="label" content="movement">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1062">
              <meta itemprop="top" content="1307">
              <meta itemprop="right" content="1093">
              <meta itemprop="bottom" content="1352">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="25">
            <meta itemprop="id" content="4">
            <meta itemprop="label" content="movement">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1081">
              <meta itemprop="top" content="1650">
              <meta itemprop="right" content="1111">
              <meta itemprop="bottom" content="1693">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/72/53/0e/00a8597897860c/US20230210402A1-20230706-D00026.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/ae/9c/cf/c44a4ff85efda9/US20230210402A1-20230706-D00026.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="26">
            <meta itemprop="id" content="2600">
            <meta itemprop="label" content="interface">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="172">
              <meta itemprop="top" content="20">
              <meta itemprop="right" content="300">
              <meta itemprop="bottom" content="62">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="26">
            <meta itemprop="id" content="2700">
            <meta itemprop="label" content="interface">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="166">
              <meta itemprop="top" content="1353">
              <meta itemprop="right" content="294">
              <meta itemprop="bottom" content="1395">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/66/54/6d/199d577f18a90e/US20230210402A1-20230706-D00027.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/7e/06/d8/fe621b2fa54447/US20230210402A1-20230706-D00027.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="27">
            <meta itemprop="id" content="2800">
            <meta itemprop="label" content="interface">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="79">
              <meta itemprop="top" content="20">
              <meta itemprop="right" content="208">
              <meta itemprop="bottom" content="63">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="27">
            <meta itemprop="id" content="2900">
            <meta itemprop="label" content="interface">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="149">
              <meta itemprop="top" content="1420">
              <meta itemprop="right" content="276">
              <meta itemprop="bottom" content="1463">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/70/a4/dc/9cc620af5f1ed3/US20230210402A1-20230706-D00028.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/e6/37/9f/6d3a90e4563829/US20230210402A1-20230706-D00028.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="28">
            <meta itemprop="id" content="3000">
            <meta itemprop="label" content="interface">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="104">
              <meta itemprop="top" content="21">
              <meta itemprop="right" content="232">
              <meta itemprop="bottom" content="63">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/9d/66/33/ebcf2931a8ec73/US20230210402A1-20230706-D00029.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/31/6c/49/8adcb25583b868/US20230210402A1-20230706-D00029.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="29">
            <meta itemprop="id" content="3100">
            <meta itemprop="label" content="interface">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="135">
              <meta itemprop="top" content="19">
              <meta itemprop="right" content="265">
              <meta itemprop="bottom" content="62">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/6f/ca/45/efb68b37231c92/US20230210402A1-20230706-D00030.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/6d/2b/61/d91578bb55bfbd/US20230210402A1-20230706-D00030.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="30">
            <meta itemprop="id" content="3200">
            <meta itemprop="label" content="interface">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="202">
              <meta itemprop="top" content="17">
              <meta itemprop="right" content="333">
              <meta itemprop="bottom" content="63">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="30">
            <meta itemprop="id" content="3210">
            <meta itemprop="label" content="histogram">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="482">
              <meta itemprop="top" content="53">
              <meta itemprop="right" content="594">
              <meta itemprop="bottom" content="89">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="30">
            <meta itemprop="id" content="3220">
            <meta itemprop="label" content="muscle distribution map">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1555">
              <meta itemprop="top" content="65">
              <meta itemprop="right" content="1670">
              <meta itemprop="bottom" content="106">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="30">
            <meta itemprop="id" content="3300">
            <meta itemprop="label" content="interface">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="157">
              <meta itemprop="top" content="1419">
              <meta itemprop="right" content="285">
              <meta itemprop="bottom" content="1461">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="30">
            <meta itemprop="id" content="3310">
            <meta itemprop="label" content="histogram">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="446">
              <meta itemprop="top" content="1518">
              <meta itemprop="right" content="557">
              <meta itemprop="bottom" content="1555">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="30">
            <meta itemprop="id" content="3320">
            <meta itemprop="label" content="muscle distribution map">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1513">
              <meta itemprop="top" content="1512">
              <meta itemprop="right" content="1624">
              <meta itemprop="bottom" content="1550">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="30">
            <meta itemprop="id" content="3330">
            <meta itemprop="label" content="pectoral muscle">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1761">
              <meta itemprop="top" content="1541">
              <meta itemprop="right" content="1873">
              <meta itemprop="bottom" content="1576">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/02/3b/52/22c9ceea2ed332/US20230210402A1-20230706-D00031.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/5d/ff/6c/6215d752ebf2b5/US20230210402A1-20230706-D00031.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="31">
            <meta itemprop="id" content="3400">
            <meta itemprop="label" content="interface">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="161">
              <meta itemprop="top" content="21">
              <meta itemprop="right" content="288">
              <meta itemprop="bottom" content="62">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="31">
            <meta itemprop="id" content="3410">
            <meta itemprop="label" content="histogram">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="481">
              <meta itemprop="top" content="69">
              <meta itemprop="right" content="594">
              <meta itemprop="bottom" content="105">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="31">
            <meta itemprop="id" content="3420">
            <meta itemprop="label" content="muscle distribution map">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1431">
              <meta itemprop="top" content="70">
              <meta itemprop="right" content="1541">
              <meta itemprop="bottom" content="105">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="31">
            <meta itemprop="id" content="3500">
            <meta itemprop="label" content="interface">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="92">
              <meta itemprop="top" content="1403">
              <meta itemprop="right" content="220">
              <meta itemprop="bottom" content="1445">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="31">
            <meta itemprop="id" content="3510">
            <meta itemprop="label" content="line chart">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="452">
              <meta itemprop="top" content="1454">
              <meta itemprop="right" content="566">
              <meta itemprop="bottom" content="1490">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="31">
            <meta itemprop="id" content="3520">
            <meta itemprop="label" content="muscle distribution map">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1489">
              <meta itemprop="top" content="1492">
              <meta itemprop="right" content="1599">
              <meta itemprop="bottom" content="1530">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="31">
            <meta itemprop="id" content="3530">
            <meta itemprop="label" content="pectoral muscle">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1460">
              <meta itemprop="top" content="1747">
              <meta itemprop="right" content="1568">
              <meta itemprop="bottom" content="1785">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/34/a7/36/e759163a931a41/US20230210402A1-20230706-D00032.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/bc/ea/2c/bc46ac30dee5aa/US20230210402A1-20230706-D00032.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="32">
            <meta itemprop="id" content="3600">
            <meta itemprop="label" content="interface">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="87">
              <meta itemprop="top" content="19">
              <meta itemprop="right" content="214">
              <meta itemprop="bottom" content="64">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="32">
            <meta itemprop="id" content="3610">
            <meta itemprop="label" content="histogram">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="308">
              <meta itemprop="top" content="143">
              <meta itemprop="right" content="419">
              <meta itemprop="bottom" content="180">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="32">
            <meta itemprop="id" content="3620">
            <meta itemprop="label" content="muscle distribution map">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1315">
              <meta itemprop="top" content="93">
              <meta itemprop="right" content="1424">
              <meta itemprop="bottom" content="128">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/9c/cf/29/5cbdfa4f9f74d8/US20230210402A1-20230706-D00033.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/21/21/ac/b1726ef26e490b/US20230210402A1-20230706-D00033.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="33">
            <meta itemprop="id" content="3700">
            <meta itemprop="label" content="interface">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="20">
              <meta itemprop="top" content="21">
              <meta itemprop="right" content="148">
              <meta itemprop="bottom" content="64">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="33">
            <meta itemprop="id" content="3710">
            <meta itemprop="label" content="muscle distribution map">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1158">
              <meta itemprop="top" content="291">
              <meta itemprop="right" content="1287">
              <meta itemprop="bottom" content="335">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="33">
            <meta itemprop="id" content="3720">
            <meta itemprop="label" content="line">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="329">
              <meta itemprop="top" content="408">
              <meta itemprop="right" content="458">
              <meta itemprop="bottom" content="449">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/12/84/d3/004661f146623c/US20230210402A1-20230706-D00034.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/1e/ff/98/4425d3969917fe/US20230210402A1-20230706-D00034.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="34">
            <meta itemprop="id" content="3800">
            <meta itemprop="label" content="interface">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="216">
              <meta itemprop="top" content="19">
              <meta itemprop="right" content="344">
              <meta itemprop="bottom" content="64">
            </span>
          </li>
        </ul>
      </li>
    </ul>
  </section>

  <section>
    <h2>Classifications</h2>
    <ul>
      <li>
        <ul itemprop="classifications" itemscope repeat>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">A</span>&mdash;<span itemprop="Description">HUMAN NECESSITIES</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">A61</span>&mdash;<span itemprop="Description">MEDICAL OR VETERINARY SCIENCE; HYGIENE</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">A61B</span>&mdash;<span itemprop="Description">DIAGNOSIS; SURGERY; IDENTIFICATION</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">A61B5/00</span>&mdash;<span itemprop="Description">Measuring for diagnostic purposes; Identification of persons</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">A61B5/74</span>&mdash;<span itemprop="Description">Details of notification to user or communication with user or patient ; user input means</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">A61B5/7475</span>&mdash;<span itemprop="Description">User input or interface means, e.g. keyboard, pointing device, joystick</span>
            <meta itemprop="Leaf" content="true"><meta itemprop="FirstCode" content="true"><meta itemprop="IsCPC" content="true">
          </li>
        </ul>
      </li>
      <li>
        <ul itemprop="classifications" itemscope repeat>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G</span>&mdash;<span itemprop="Description">PHYSICS</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06</span>&mdash;<span itemprop="Description">COMPUTING; CALCULATING OR COUNTING</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06F</span>&mdash;<span itemprop="Description">ELECTRIC DIGITAL DATA PROCESSING</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06F9/00</span>&mdash;<span itemprop="Description">Arrangements for program control, e.g. control units</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06F9/06</span>&mdash;<span itemprop="Description">Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06F9/44</span>&mdash;<span itemprop="Description">Arrangements for executing specific programs</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06F9/451</span>&mdash;<span itemprop="Description">Execution arrangements for user interfaces</span>
            <meta itemprop="Leaf" content="true"><meta itemprop="FirstCode" content="true"><meta itemprop="IsCPC" content="true">
          </li>
        </ul>
      </li>
      <li>
        <ul itemprop="classifications" itemscope repeat>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">A</span>&mdash;<span itemprop="Description">HUMAN NECESSITIES</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">A61</span>&mdash;<span itemprop="Description">MEDICAL OR VETERINARY SCIENCE; HYGIENE</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">A61B</span>&mdash;<span itemprop="Description">DIAGNOSIS; SURGERY; IDENTIFICATION</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">A61B5/00</span>&mdash;<span itemprop="Description">Measuring for diagnostic purposes; Identification of persons</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">A61B5/103</span>&mdash;<span itemprop="Description">Detecting, measuring or recording devices for testing the shape, pattern, colour, size or movement of the body or parts thereof, for diagnostic purposes</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">A61B5/11</span>&mdash;<span itemprop="Description">Measuring movement of the entire body or parts thereof, e.g. head or hand tremor, mobility of a limb</span>
            <meta itemprop="Leaf" content="true"><meta itemprop="FirstCode" content="true"><meta itemprop="IsCPC" content="true">
          </li>
        </ul>
      </li>
      <li>
        <ul itemprop="classifications" itemscope repeat>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">A</span>&mdash;<span itemprop="Description">HUMAN NECESSITIES</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">A61</span>&mdash;<span itemprop="Description">MEDICAL OR VETERINARY SCIENCE; HYGIENE</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">A61B</span>&mdash;<span itemprop="Description">DIAGNOSIS; SURGERY; IDENTIFICATION</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">A61B5/00</span>&mdash;<span itemprop="Description">Measuring for diagnostic purposes; Identification of persons</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">A61B5/103</span>&mdash;<span itemprop="Description">Detecting, measuring or recording devices for testing the shape, pattern, colour, size or movement of the body or parts thereof, for diagnostic purposes</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">A61B5/11</span>&mdash;<span itemprop="Description">Measuring movement of the entire body or parts thereof, e.g. head or hand tremor, mobility of a limb</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">A61B5/1116</span>&mdash;<span itemprop="Description">Determining posture transitions</span>
            <meta itemprop="Leaf" content="true"><meta itemprop="IsCPC" content="true">
          </li>
        </ul>
      </li>
      <li>
        <ul itemprop="classifications" itemscope repeat>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">A</span>&mdash;<span itemprop="Description">HUMAN NECESSITIES</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">A61</span>&mdash;<span itemprop="Description">MEDICAL OR VETERINARY SCIENCE; HYGIENE</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">A61B</span>&mdash;<span itemprop="Description">DIAGNOSIS; SURGERY; IDENTIFICATION</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">A61B5/00</span>&mdash;<span itemprop="Description">Measuring for diagnostic purposes; Identification of persons</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">A61B5/24</span>&mdash;<span itemprop="Description">Detecting, measuring or recording bioelectric or biomagnetic signals of the body or parts thereof</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">A61B5/316</span>&mdash;<span itemprop="Description">Modalities, i.e. specific diagnostic methods</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">A61B5/389</span>&mdash;<span itemprop="Description">Electromyography [EMG]</span>
            <meta itemprop="Leaf" content="true"><meta itemprop="IsCPC" content="true">
          </li>
        </ul>
      </li>
      <li>
        <ul itemprop="classifications" itemscope repeat>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">A</span>&mdash;<span itemprop="Description">HUMAN NECESSITIES</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">A61</span>&mdash;<span itemprop="Description">MEDICAL OR VETERINARY SCIENCE; HYGIENE</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">A61B</span>&mdash;<span itemprop="Description">DIAGNOSIS; SURGERY; IDENTIFICATION</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">A61B5/00</span>&mdash;<span itemprop="Description">Measuring for diagnostic purposes; Identification of persons</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">A61B5/24</span>&mdash;<span itemprop="Description">Detecting, measuring or recording bioelectric or biomagnetic signals of the body or parts thereof</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">A61B5/316</span>&mdash;<span itemprop="Description">Modalities, i.e. specific diagnostic methods</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">A61B5/389</span>&mdash;<span itemprop="Description">Electromyography [EMG]</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">A61B5/397</span>&mdash;<span itemprop="Description">Analysis of electromyograms</span>
            <meta itemprop="Leaf" content="true"><meta itemprop="IsCPC" content="true">
          </li>
        </ul>
      </li>
      <li>
        <ul itemprop="classifications" itemscope repeat>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">A</span>&mdash;<span itemprop="Description">HUMAN NECESSITIES</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">A61</span>&mdash;<span itemprop="Description">MEDICAL OR VETERINARY SCIENCE; HYGIENE</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">A61B</span>&mdash;<span itemprop="Description">DIAGNOSIS; SURGERY; IDENTIFICATION</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">A61B5/00</span>&mdash;<span itemprop="Description">Measuring for diagnostic purposes; Identification of persons</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">A61B5/48</span>&mdash;<span itemprop="Description">Other medical applications</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">A61B5/486</span>&mdash;<span itemprop="Description">Bio-feedback</span>
            <meta itemprop="Leaf" content="true"><meta itemprop="IsCPC" content="true">
          </li>
        </ul>
      </li>
      <li>
        <ul itemprop="classifications" itemscope repeat>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">A</span>&mdash;<span itemprop="Description">HUMAN NECESSITIES</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">A61</span>&mdash;<span itemprop="Description">MEDICAL OR VETERINARY SCIENCE; HYGIENE</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">A61B</span>&mdash;<span itemprop="Description">DIAGNOSIS; SURGERY; IDENTIFICATION</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">A61B5/00</span>&mdash;<span itemprop="Description">Measuring for diagnostic purposes; Identification of persons</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">A61B5/74</span>&mdash;<span itemprop="Description">Details of notification to user or communication with user or patient ; user input means</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">A61B5/7405</span>&mdash;<span itemprop="Description">Details of notification to user or communication with user or patient ; user input means using sound</span>
            <meta itemprop="Leaf" content="true"><meta itemprop="IsCPC" content="true">
          </li>
        </ul>
      </li>
      <li>
        <ul itemprop="classifications" itemscope repeat>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">A</span>&mdash;<span itemprop="Description">HUMAN NECESSITIES</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">A61</span>&mdash;<span itemprop="Description">MEDICAL OR VETERINARY SCIENCE; HYGIENE</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">A61B</span>&mdash;<span itemprop="Description">DIAGNOSIS; SURGERY; IDENTIFICATION</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">A61B5/00</span>&mdash;<span itemprop="Description">Measuring for diagnostic purposes; Identification of persons</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">A61B5/74</span>&mdash;<span itemprop="Description">Details of notification to user or communication with user or patient ; user input means</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">A61B5/742</span>&mdash;<span itemprop="Description">Details of notification to user or communication with user or patient ; user input means using visual displays</span>
            <meta itemprop="Leaf" content="true"><meta itemprop="IsCPC" content="true">
          </li>
        </ul>
      </li>
      <li>
        <ul itemprop="classifications" itemscope repeat>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G</span>&mdash;<span itemprop="Description">PHYSICS</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06</span>&mdash;<span itemprop="Description">COMPUTING; CALCULATING OR COUNTING</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06F</span>&mdash;<span itemprop="Description">ELECTRIC DIGITAL DATA PROCESSING</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06F3/00</span>&mdash;<span itemprop="Description">Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06F3/01</span>&mdash;<span itemprop="Description">Input arrangements or combined input and output arrangements for interaction between user and computer</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06F3/011</span>&mdash;<span itemprop="Description">Arrangements for interaction with the human body, e.g. for user immersion in virtual reality</span>
            <meta itemprop="Leaf" content="true"><meta itemprop="IsCPC" content="true">
          </li>
        </ul>
      </li>
      <li>
        <ul itemprop="classifications" itemscope repeat>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G</span>&mdash;<span itemprop="Description">PHYSICS</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06</span>&mdash;<span itemprop="Description">COMPUTING; CALCULATING OR COUNTING</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06F</span>&mdash;<span itemprop="Description">ELECTRIC DIGITAL DATA PROCESSING</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06F3/00</span>&mdash;<span itemprop="Description">Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06F3/01</span>&mdash;<span itemprop="Description">Input arrangements or combined input and output arrangements for interaction between user and computer</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06F3/011</span>&mdash;<span itemprop="Description">Arrangements for interaction with the human body, e.g. for user immersion in virtual reality</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06F3/015</span>&mdash;<span itemprop="Description">Input arrangements based on nervous system activity detection, e.g. brain waves [EEG] detection, electromyograms [EMG] detection, electrodermal response detection</span>
            <meta itemprop="Leaf" content="true"><meta itemprop="IsCPC" content="true">
          </li>
        </ul>
      </li>
      <li>
        <ul itemprop="classifications" itemscope repeat>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G</span>&mdash;<span itemprop="Description">PHYSICS</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06</span>&mdash;<span itemprop="Description">COMPUTING; CALCULATING OR COUNTING</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06F</span>&mdash;<span itemprop="Description">ELECTRIC DIGITAL DATA PROCESSING</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06F3/00</span>&mdash;<span itemprop="Description">Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06F3/01</span>&mdash;<span itemprop="Description">Input arrangements or combined input and output arrangements for interaction between user and computer</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06F3/017</span>&mdash;<span itemprop="Description">Gesture based interaction, e.g. based on a set of recognized hand gestures</span>
            <meta itemprop="Leaf" content="true"><meta itemprop="IsCPC" content="true">
          </li>
        </ul>
      </li>
      <li>
        <ul itemprop="classifications" itemscope repeat>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">A</span>&mdash;<span itemprop="Description">HUMAN NECESSITIES</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">A61</span>&mdash;<span itemprop="Description">MEDICAL OR VETERINARY SCIENCE; HYGIENE</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">A61B</span>&mdash;<span itemprop="Description">DIAGNOSIS; SURGERY; IDENTIFICATION</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">A61B2505/00</span>&mdash;<span itemprop="Description">Evaluating, monitoring or diagnosing in the context of a particular type of medical care</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">A61B2505/09</span>&mdash;<span itemprop="Description">Rehabilitation or training</span>
            <meta itemprop="Leaf" content="true"><meta itemprop="Additional" content="true"><meta itemprop="IsCPC" content="true">
          </li>
        </ul>
      </li>
      <li>
        <ul itemprop="classifications" itemscope repeat>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">A</span>&mdash;<span itemprop="Description">HUMAN NECESSITIES</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">A61</span>&mdash;<span itemprop="Description">MEDICAL OR VETERINARY SCIENCE; HYGIENE</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">A61B</span>&mdash;<span itemprop="Description">DIAGNOSIS; SURGERY; IDENTIFICATION</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">A61B2560/00</span>&mdash;<span itemprop="Description">Constructional details of operational features of apparatus; Accessories for medical measuring apparatus</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">A61B2560/02</span>&mdash;<span itemprop="Description">Operational features</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">A61B2560/0266</span>&mdash;<span itemprop="Description">Operational features for monitoring or limiting apparatus function</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">A61B2560/0276</span>&mdash;<span itemprop="Description">Determining malfunction</span>
            <meta itemprop="Leaf" content="true"><meta itemprop="Additional" content="true"><meta itemprop="IsCPC" content="true">
          </li>
        </ul>
      </li>
    </ul>
  </section>

  

  

  <section>
    <h2>Definitions</h2>
    <ul>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the present disclosure</span>
        <span itemprop="definition">relates to a technical field of wearable device, and in particular, to a motion monitoring method and device.</span>
        <meta itemprop="num_attr" content="0002">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the motion monitoring devices</span>
        <span itemprop="definition">mainly monitor some of the physiological parameter information (e.g., a heart rate, a body temperature, a step frequency, a blood oxygen, etc.) of a user during motion, display physiological data to the user, and give exercise suggestions based on the physiological data.</span>
        <meta itemprop="num_attr" content="0003">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">physiological parameter information</span>
        <span itemprop="definition">e.g., a heart rate, a body temperature, a step frequency, a blood oxygen, etc.</span>
        <meta itemprop="num_attr" content="0003">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">motion monitoring devices</span>
        <span itemprop="definition">often cannot display monitoring results of the motion to the user fully and accurately, resulting in the user can not know their own motion situation in time, or the physiological data given by the system is significantly different from the user&#39;s body feeling during motion, which may lead to a decline in the user&#39;s credibility of the motion monitoring devices.</span>
        <meta itemprop="num_attr" content="0003">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">One aspect of the present disclosure</span>
        <span itemprop="definition">may provide a method for displaying a motion monitoring interface.</span>
        <meta itemprop="num_attr" content="0005">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the method</span>
        <span itemprop="definition">may include: obtaining a movement signal during a motion of a user from at least one sensor, wherein the movement signal at least includes an electromyographic signal or an attitude signal; determining information related to the motion of the user by processing the movement signal; and displaying the information related to the motion of the user.</span>
        <meta itemprop="num_attr" content="0005">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the determining information related to the motion of the user by processing the movement signal</span>
        <span itemprop="definition">may include: determining an exertion strength of at least one muscle of the user based on the electromyographic signal.</span>
        <meta itemprop="num_attr" content="0006">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the displaying the information related to the motion the user</span>
        <span itemprop="definition">may include: obtaining a user input regarding a target muscle; and displaying a status bar, wherein a color of the status bar is related to an exertion strength of the target muscle, or making a sound, wherein a volume of the sound is related to the exertion strength of the target muscle.</span>
        <meta itemprop="num_attr" content="0007">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the determining information related to the motion of the user by processing the movement signal</span>
        <span itemprop="definition">may include: generating a user movement model representing a movement of the motion of the user based on the attitude signal.</span>
        <meta itemprop="num_attr" content="0008">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the displaying the information related to the motion of the user</span>
        <span itemprop="definition">may include: obtaining a standard movement model; and displaying the user movement model and the standard movement model.</span>
        <meta itemprop="num_attr" content="0009">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the displaying the information related to the motion of the user</span>
        <span itemprop="definition">may include: determining an exertion strength of at least one muscle of the user based on the electromyographic signal; and displaying the exertion strength of the at least one muscle on the user movement model.</span>
        <meta itemprop="num_attr" content="0010">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the determining information related to the motion of the user by processing the movement signal</span>
        <span itemprop="definition">may include: segmenting the movement signal based on the electromyographic signal or the attitude signal; and determining a monitoring result by monitoring a movement of the motion of the user based on at least one segment of the movement signal.</span>
        <meta itemprop="num_attr" content="0011">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the method</span>
        <span itemprop="definition">may further include: determining a movement feedback mode based on the monitoring result; and performing a movement feedback to the user according to the movement feedback mode.</span>
        <meta itemprop="num_attr" content="0012">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the at least one segment of the movement signal</span>
        <span itemprop="definition">may be a movement signal of the user in at least one training process</span>
        <meta itemprop="num_attr" content="0013">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the monitoring result</span>
        <span itemprop="definition">may include at least one of a movement type, a movement quantity, a movement quality, a movement time, physiological parameter information of the user, or a core stability of the user during the at least one training process.</span>
        <meta itemprop="num_attr" content="0013">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the monitoring result</span>
        <span itemprop="definition">may include muscle information of the user corresponding to at least one time point</span>
        <meta itemprop="num_attr" content="0014">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the muscle information of the user</span>
        <span itemprop="definition">may include at least one of an energy consumption of at least one muscle, a fatigue degree of the at least one muscle, a balance of at least two muscles, or an ability of the at least one muscle</span>
        <meta itemprop="num_attr" content="0014">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the displaying the information related to the motion of the user</span>
        <span itemprop="definition">may include: displaying at least one of the energy consumption of the at least one muscle, the fatigue degree of the at least one muscle, the balance of the at least two muscles, or the ability of the at least one muscle on at least one location in a user model, wherein the at least one location in the user model corresponds to a location of the at least one muscle in the user.</span>
        <meta itemprop="num_attr" content="0014">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">energy consumptions of different muscles, fatigue levels of different muscles, training balances of different muscles, and/or abilities of different muscles</span>
        <span itemprop="definition">may correspond to different display colors.</span>
        <meta itemprop="num_attr" content="0015">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the displaying the information related to the motion of the user</span>
        <span itemprop="definition">may include: obtaining a user input regarding a target muscle; and displaying information of the target muscle.</span>
        <meta itemprop="num_attr" content="0016">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the displaying the information related to the motion of the user</span>
        <span itemprop="definition">may include: displaying the monitoring result in at least one of a text, a chart, a sound, an image, or a video.</span>
        <meta itemprop="num_attr" content="0017">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the method</span>
        <span itemprop="definition">may further include: calibrating the movement signal.</span>
        <meta itemprop="num_attr" content="0018">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the method</span>
        <span itemprop="definition">may further include: determining whether a working state of the at least one sensor is normal based on the movement signal; and in response to determining that the working state of the at least one sensor is abnormal, displaying prompt information.</span>
        <meta itemprop="num_attr" content="0019">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the movement signal</span>
        <span itemprop="definition">may include a signal related to a feature of the user</span>
        <meta itemprop="num_attr" content="0020">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the method</span>
        <span itemprop="definition">may further include: determining body shape information and/or body composition information of the user based on the signal related to the feature of the user; and displaying the body shape information and/or body composition information of the user.</span>
        <meta itemprop="num_attr" content="0020">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the electronic device</span>
        <span itemprop="definition">may include: a display device configured to display content; an input device configured to receive a user input; and at least one sensor configured to detect a movement signal during a motion of a user, wherein the movement signal may at least include an electromyographic signal or an attitude signal; and a processor connected to the display device, the input device, and the at least one sensor, wherein the processor is configured to: obtain the movement signal during the motion of the user from the at least one sensor; determine information related to the motion of the user by processing the movement signal; and control the display device to display the information related to the motion of the user.</span>
        <meta itemprop="num_attr" content="0021">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 1</span>
        <span itemprop="definition">is a schematic diagram of an application scenario of a motion monitoring system according to some embodiments of the present disclosure</span>
        <meta itemprop="num_attr" content="0023">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 2</span>
        <span itemprop="definition">is a schematic diagram of illustrating exemplary hardware and/or software of a wearable device according to some embodiments of the present disclosure</span>
        <meta itemprop="num_attr" content="0024">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 3</span>
        <span itemprop="definition">is a schematic diagram illustrating exemplary hardware and/or software of a computing device according to some embodiments of the present disclosure</span>
        <meta itemprop="num_attr" content="0025">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 4</span>
        <span itemprop="definition">is a structure diagram of an exemplary wearable device according to some embodiments of the present disclosure.</span>
        <meta itemprop="num_attr" content="0026">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 5</span>
        <span itemprop="definition">is a flowchart illustrating an exemplary motion monitoring method according to some embodiments of the present disclosure</span>
        <meta itemprop="num_attr" content="0027">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 6</span>
        <span itemprop="definition">is a flowchart of an exemplary process for monitoring a movement of a motion of a user according to some embodiments of the present disclosure</span>
        <meta itemprop="num_attr" content="0028">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 7</span>
        <span itemprop="definition">is a flowchart of an exemplary process for segmenting a movement signal according to some embodiments of the present disclosure</span>
        <meta itemprop="num_attr" content="0029">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 8</span>
        <span itemprop="definition">is a diagram illustrating exemplary normalized results of segmenting a movement signal according to some embodiments of the present disclosure</span>
        <meta itemprop="num_attr" content="0030">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 9</span>
        <span itemprop="definition">is a flowchart of an exemplary process for pre-processing an electromyographic signal according to some embodiments of the present disclosure.</span>
        <meta itemprop="num_attr" content="0031">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 10</span>
        <span itemprop="definition">is a flow chart illustrating an exemplary burr signal according to some embodiments of the present disclosure.</span>
        <meta itemprop="num_attr" content="0032">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 11</span>
        <span itemprop="definition">is a flowchart of an exemplary process for determining feature information corresponding to an attitude signal according to some embodiments of the present disclosure</span>
        <meta itemprop="num_attr" content="0033">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 12</span>
        <span itemprop="definition">is a flowchart of an exemplary process for determining relative motion between different motion parts of a user according to some embodiments of the present disclosure</span>
        <meta itemprop="num_attr" content="0034">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 13</span>
        <span itemprop="definition">is a flowchart of an exemplary process for determining a conversion relationship between an original coordinate system and a particular coordinate system according to some embodiments of the present disclosure</span>
        <meta itemprop="num_attr" content="0035">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 14</span>
        <span itemprop="definition">is a flowchart of an exemplary process for determining a conversion relationship between an original coordinate system and a target coordinate system according to some embodiments of the present disclosure</span>
        <meta itemprop="num_attr" content="0036">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 15 A</span>
        <span itemprop="definition">is an exemplary vector coordinate diagram illustrating Euler angle data in an original coordinate system at a position of a small arm of a human body according to some embodiments of the present disclosure</span>
        <meta itemprop="num_attr" content="0037">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 15 B</span>
        <span itemprop="definition">is an exemplary vector coordinate diagram illustrating Euler angle data in another original coordinate system at a position of a small arm of a human body according to some embodiments of the present disclosure</span>
        <meta itemprop="num_attr" content="0038">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 16 A</span>
        <span itemprop="definition">is an exemplary vector coordinate diagram of Euler angle data in a target coordinate system at a position of a small arm of a human body according to some embodiments of the present disclosure</span>
        <meta itemprop="num_attr" content="0039">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 16 B</span>
        <span itemprop="definition">is an exemplary vector coordinate diagram of Euler angle data in a target coordinate system at another location of a small arm of a human body according to some embodiments of the present disclosure</span>
        <meta itemprop="num_attr" content="0040">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 17</span>
        <span itemprop="definition">is an exemplary vector coordinate diagram of Euler angle data in a target coordinate system of a multi-sensor according to some embodiments of the present disclosure</span>
        <meta itemprop="num_attr" content="0041">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 18 A</span>
        <span itemprop="definition">is a diagram illustrating exemplary results of an original angular velocity according to some embodiments of the present disclosure</span>
        <meta itemprop="num_attr" content="0042">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 18 B</span>
        <span itemprop="definition">is a diagram illustrating exemplary results of an angular velocity after filtering processing according to some embodiments of the present disclosure</span>
        <meta itemprop="num_attr" content="0043">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 19</span>
        <span itemprop="definition">is a flowchart illustrating an exemplary motion monitoring and feedback method according to some embodiments of the present disclosure.</span>
        <meta itemprop="num_attr" content="0044">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 20</span>
        <span itemprop="definition">is a flowchart illustrating exemplary process for model training according to some embodiments of the present disclosure</span>
        <meta itemprop="num_attr" content="0045">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 21 A</span>
        <span itemprop="definition">is an exemplary flowchart of a process for displaying a motion monitoring interface according to some embodiments of the present disclosure</span>
        <meta itemprop="num_attr" content="0046">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 21 B</span>
        <span itemprop="definition">is an example diagram of a motion monitoring interface according to some embodiments of the present disclosure.</span>
        <meta itemprop="num_attr" content="0047">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 22</span>
        <span itemprop="definition">is an exemplary flowchart of a process for displaying a motion monitoring interface according to some embodiments of the present disclosure</span>
        <meta itemprop="num_attr" content="0048">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 23</span>
        <span itemprop="definition">A a schematic diagram of a motion monitoring interface according to some embodiments of the present disclosure.</span>
        <meta itemprop="num_attr" content="0049">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 23 B</span>
        <span itemprop="definition">is a schematic diagram of a motion monitoring interface according to some embodiments of the present disclosure.</span>
        <meta itemprop="num_attr" content="0050">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 23 C</span>
        <span itemprop="definition">are schematic diagrams of a motion monitoring interface according to some embodiments of the present disclosure.</span>
        <meta itemprop="num_attr" content="0051">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 24</span>
        <span itemprop="definition">is an exemplary flowchart of a process for displaying a motion monitoring interface according to some embodiments of the present disclosure</span>
        <meta itemprop="num_attr" content="0052">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 25</span>
        <span itemprop="definition">is a schematic diagram of a motion monitoring interface according to some embodiments of the present disclosure.</span>
        <meta itemprop="num_attr" content="0053">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 26</span>
        <span itemprop="definition">is a schematic diagram of a motion monitoring interface according to some embodiments of the present disclosure.</span>
        <meta itemprop="num_attr" content="0054">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 27</span>
        <span itemprop="definition">is a schematic diagram of a motion monitoring interface according to some embodiments of the present disclosure.</span>
        <meta itemprop="num_attr" content="0055">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 28</span>
        <span itemprop="definition">is a schematic diagram of a motion monitoring interface according to some embodiments of the present disclosure.</span>
        <meta itemprop="num_attr" content="0056">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 29</span>
        <span itemprop="definition">is a schematic diagram of a motion monitoring interface according to some embodiments of the present disclosure.</span>
        <meta itemprop="num_attr" content="0057">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 30</span>
        <span itemprop="definition">is a schematic diagram of a motion monitoring interface according to some embodiments of the present disclosure.</span>
        <meta itemprop="num_attr" content="0058">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 31</span>
        <span itemprop="definition">is a schematic diagram of a motion monitoring interface according to some embodiments of the present disclosure.</span>
        <meta itemprop="num_attr" content="0059">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 32</span>
        <span itemprop="definition">is a schematic diagram of a motion monitoring interface according to some embodiments of the present disclosure.</span>
        <meta itemprop="num_attr" content="0060">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 33</span>
        <span itemprop="definition">is a schematic diagram of a motion monitoring interface according to some embodiments of the present disclosure.</span>
        <meta itemprop="num_attr" content="0061">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 34</span>
        <span itemprop="definition">is a schematic diagram of a motion monitoring interface according to some embodiments of the present disclosure.</span>
        <meta itemprop="num_attr" content="0062">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 35</span>
        <span itemprop="definition">is a schematic diagram of a motion monitoring interface according to some embodiments of the present disclosure.</span>
        <meta itemprop="num_attr" content="0063">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 36</span>
        <span itemprop="definition">is a schematic diagram of a motion monitoring interface according to some embodiments of the present disclosure.</span>
        <meta itemprop="num_attr" content="0064">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 37</span>
        <span itemprop="definition">is a schematic diagram of a motion monitoring interface according to some embodiments of the present disclosure.</span>
        <meta itemprop="num_attr" content="0065">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 38</span>
        <span itemprop="definition">is a schematic diagram of a motion monitoring interface according to some embodiments of the present disclosure.</span>
        <meta itemprop="num_attr" content="0066">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">system</span>
        <span itemprop="definition">e.g., system, device, unit, and/or module used herein are one method to distinguish different components, elements, parts, sections or assemblies of different levels in ascending order. However, if other words may achieve the same purpose, the words may be replaced by other expressions.</span>
        <meta itemprop="num_attr" content="0068">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the present disclosure</span>
        <span itemprop="definition">may provide a motion monitoring system.</span>
        <meta itemprop="num_attr" content="0071">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the system</span>
        <span itemprop="definition">may obtain a movement signal of a user during motion.</span>
        <meta itemprop="num_attr" content="0071">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the movement signal</span>
        <span itemprop="definition">may include at least an electromyographic signal, an attitude signal, an electro-cardio graphic signal, a respiratory rate signal, and the like.</span>
        <meta itemprop="num_attr" content="0071">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the motion monitoring system</span>
        <span itemprop="definition">may monitor a movement of the user during motion based at least on feature information corresponding to the electromyographic signal or the feature information corresponding to an attitude signal.</span>
        <meta itemprop="num_attr" content="0071">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the system</span>
        <span itemprop="definition">may determine the type of movement of the user, the number of movement, the movement quality, the movement time, or the information of physiological parameters of the user when performing the movement through frequency information and amplitude information corresponding to the electromyographic signal, an angular velocity, an angular velocity direction and an angular velocity value of the angular velocity, an angle, displacement information, and stress, etc., corresponding to the attitude signal.</span>
        <meta itemprop="num_attr" content="0071">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the motion monitoring system</span>
        <span itemprop="definition">may further generate feedback to a user&#39;s fitness movement according to analysis results of the user&#39;s fitness movement to provide guidance to user&#39;s fitness.</span>
        <meta itemprop="num_attr" content="0071">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the motion monitoring system</span>
        <span itemprop="definition">can send a prompt message to the user (e.g., a voice prompt, a vibration prompt, current stimulation, etc.).</span>
        <meta itemprop="num_attr" content="0071">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the motion monitoring system</span>
        <span itemprop="definition">may be applied to a wearable device (e.g., clothing, a wrist guard, a helmet), a medical testing device (e.g., an electromyography tester), a fitness device, etc.</span>
        <meta itemprop="num_attr" content="0071">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the motion monitoring system</span>
        <span itemprop="definition">may accurately monitor and provide feedback on a user&#39;s movement by obtaining the movement signal of the user during motion without professional participation, which can improve the user&#39;s fitness efficiency and reduce a cost of the user fitness.</span>
        <meta itemprop="num_attr" content="0071">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 1</span>
        <span itemprop="definition">is a schematic diagram illustrating an application scenario of a motion monitoring system according to some embodiments of the present disclosure.</span>
        <meta itemprop="num_attr" content="0072">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the motion monitoring system 100</span>
        <span itemprop="definition">may include a processing device 110 , a network 120 , a wearable device 130 , and a mobile terminal device 140 .</span>
        <meta itemprop="num_attr" content="0072">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the motion monitoring system 100</span>
        <span itemprop="definition">may obtain a movement signal (e.g., an electromyographic signal, an attitude signal, an electro-cardio signal, a respiratory rate signal, etc.) representing a movement of user motion, and may monitor and provide feedback on the movement of the user during motion according to a user&#39;s movement signal.</span>
        <meta itemprop="num_attr" content="0072">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a movement signal</span>
        <span itemprop="definition">e.g., an electromyographic signal, an attitude signal, an electro-cardio signal, a respiratory rate signal, etc.</span>
        <meta itemprop="num_attr" content="0072">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the motion monitoring system 100</span>
        <span itemprop="definition">may monitor and provide feedback on the movement of the user during fitness.</span>
        <meta itemprop="num_attr" content="0073">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the wearable device 130</span>
        <span itemprop="definition">may obtain the user&#39;s movement signal.</span>
        <meta itemprop="num_attr" content="0073">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processing device 110 or a mobile terminal device</span>
        <span itemprop="definition">may receive and analyze the user&#39;s movement signal to determine whether the user&#39;s fitness movement is standard, thereby monitoring the user&#39;s movement.</span>
        <meta itemprop="num_attr" content="0073">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the monitoring of the user&#39;s movement</span>
        <span itemprop="definition">may include determining a type of movement, a count of movement, a quality of the movement, and a time of the movement, or information about the physiological parameters of the user at the time the movement is performed.</span>
        <meta itemprop="num_attr" content="0073">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the motion monitoring system 100</span>
        <span itemprop="definition">may generate feedback on the user&#39;s fitness movement according to an analysis result of the user&#39;s fitness movement to provide guidance to the user.</span>
        <meta itemprop="num_attr" content="0073">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the motion monitoring system 100</span>
        <span itemprop="definition">may monitor and provide feedback on the user&#39;s movement while running. For example, when the user wears the wearable device 130 for running exercise, the motion monitoring system 100 may monitor whether the user&#39;s running movement is standard and whether the running time meets a health standard. When a user&#39;s running time is too long or a running movement is incorrect, the fitness device may provide motion state to the user to prompt the user to adjust the running movement or the running time.</span>
        <meta itemprop="num_attr" content="0074">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processing device 110</span>
        <span itemprop="definition">may be configured to process information and/or data related to the user&#39;s movement.</span>
        <meta itemprop="num_attr" content="0075">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processing device 110</span>
        <span itemprop="definition">may receive the movement signal of the user (e.g., an electromyographic signal, an attitude signal, an electro-cardio signal, a respiratory rate signal, etc.) and further extract the feature information corresponding to the movement signal (e.g., the feature information corresponding to the electromyographic signal in the movement signal, the feature information corresponding to the attitude signal).</span>
        <meta itemprop="num_attr" content="0075">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the movement signal of the user</span>
        <span itemprop="definition">e.g., an electromyographic signal, an attitude signal, an electro-cardio signal, a respiratory rate signal, etc.</span>
        <meta itemprop="num_attr" content="0075">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the feature information corresponding to the movement signal</span>
        <span itemprop="definition">e.g., the feature information corresponding to the electromyographic signal in the movement signal, the feature information corresponding to the attitude signal.</span>
        <meta itemprop="num_attr" content="0075">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processing device 110</span>
        <span itemprop="definition">may perform a specific signal processing, such as a signal segmentation, a signal pre-processing (e.g., a signal correction processing, a filtering processing, etc.), etc., on the electromyographic signal or the attitude signal obtained by the wearable device 130 .</span>
        <meta itemprop="num_attr" content="0075">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processing device 110</span>
        <span itemprop="definition">may further determine whether the user movement is correct based on the user&#39;s movement signal. For example, the processing device 110 may determine whether the user movement is correct based on the feature information corresponding to the electromyographic signal (e.g., amplitude information, frequency information, etc.).</span>
        <meta itemprop="num_attr" content="0075">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processing device 110</span>
        <span itemprop="definition">may determine whether the user movement is correct based on the feature information corresponding to the attitude signal (e.g., an angular velocity, a direction of angular velocity, an acceleration of angular velocity, an angle, displacement information, a stress, etc.). Further, for example, the processing device 110 may determine whether the user movement is correct based on the feature information corresponding to the electromyographic signal and the feature information corresponding to the attitude signal. In some embodiments, the processing device 110 may further determine whether information of physiological parameters of the user during motion meets the health standard. In some embodiments, the processing device 110 may further send a corresponding instruction configured to feed the user&#39;s movement back.</span>
        <meta itemprop="num_attr" content="0075">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the feature information corresponding to the attitude signal</span>
        <span itemprop="definition">e.g., an angular velocity, a direction of angular velocity, an acceleration of angular velocity, an angle, displacement information, a stress, etc.</span>
        <meta itemprop="num_attr" content="0075">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processing device 110</span>
        <span itemprop="definition">may determine whether the user movement is correct based on the feature information corresponding to the electromyographic signal and the feature information corresponding to the attitude signal.</span>
        <meta itemprop="num_attr" content="0075">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processing device 110</span>
        <span itemprop="definition">may send the instruction to the mobile terminal device 140 to prompt the user to adjust the running time.</span>
        <meta itemprop="num_attr" content="0075">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the feature information corresponding to the attitude signal</span>
        <span itemprop="definition">is not limited to above angular velocity, the direction of angular velocity, the acceleration of angular velocity, the angle, the displacement information, and the stress, etc., but can also be other feature information.</span>
        <meta itemprop="num_attr" content="0075">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">an attitude sensor</span>
        <span itemprop="definition">is a strain gauge sensor</span>
        <meta itemprop="num_attr" content="0075">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a bending angle and a bending direction at a user&#39;s joint</span>
        <span itemprop="definition">may be obtained by measuring the resistance in a strain gauge sensor that varies with a stretch length.</span>
        <meta itemprop="num_attr" content="0075">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processing device 110</span>
        <span itemprop="definition">may be local or remote.</span>
        <meta itemprop="num_attr" content="0076">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processing device 110</span>
        <span itemprop="definition">may access information and/or materials stored in the wearable device 130 and/or the mobile terminal device 140 through the network 120 .</span>
        <meta itemprop="num_attr" content="0076">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processing device 110</span>
        <span itemprop="definition">may be directly connected to the wearable device 130 and/or the mobile terminal device 140 to access the information and/or materials stored therein.</span>
        <meta itemprop="num_attr" content="0076">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processing device 110</span>
        <span itemprop="definition">may be located in the wearable device 130 and implement the information interact with the mobile terminal device 140 through the network 120 .</span>
        <meta itemprop="num_attr" content="0076">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processing device 110</span>
        <span itemprop="definition">may be located in the mobile terminal device 140 and implement the information interact with the wearable device 130 through a network.</span>
        <meta itemprop="num_attr" content="0076">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processing device 110</span>
        <span itemprop="definition">may be executed on a cloud platform.</span>
        <meta itemprop="num_attr" content="0076">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the cloud platform</span>
        <span itemprop="definition">may include one of a private cloud, a public cloud, a hybrid cloud, a community cloud, a decentralized cloud, an internal cloud, or any combination thereof.</span>
        <meta itemprop="num_attr" content="0076">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processing device 110</span>
        <span itemprop="definition">may process data and/or information related to motion monitoring to perform one or more of functions described in the present disclosure.</span>
        <meta itemprop="num_attr" content="0077">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processing device 110</span>
        <span itemprop="definition">may obtain the movement signal collected by the wearable device 130 while the user is in motion.</span>
        <meta itemprop="num_attr" content="0077">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processing device</span>
        <span itemprop="definition">may send a control instruction to the wearable device 130 or the mobile terminal device 140 .</span>
        <meta itemprop="num_attr" content="0077">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the control instruction</span>
        <span itemprop="definition">may control an on/off state of the wearable device 130 and its respective sensor, and also control the mobile terminal device 140 to send a prompt message.</span>
        <meta itemprop="num_attr" content="0077">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">processing device 110</span>
        <span itemprop="definition">may include one or more sub-processing devices (e.g., a single-core processing device or a multi-core processing device).</span>
        <meta itemprop="num_attr" content="0077">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processing device 110</span>
        <span itemprop="definition">may include a central processing unit (CPU), an application-specific integrated circuit (ASIC), an application-specific instruction processor (ASIP), a graphic processing unit (GPU), a physics processing Unit (PPU), a digital signal processor (DSP), a field-programmable gate array (FPGA), an programmable logic device (PLD), a controller, a microcontroller unit reduced instruction set computer (RISC), and a microprocessor, or the like, or any combination of the above.</span>
        <meta itemprop="num_attr" content="0077">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">CPU</span>
        <span itemprop="definition">central processing unit</span>
        <meta itemprop="num_attr" content="0077">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">ASIC</span>
        <span itemprop="definition">application-specific integrated circuit</span>
        <meta itemprop="num_attr" content="0077">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">ASIP</span>
        <span itemprop="definition">application-specific instruction processor</span>
        <meta itemprop="num_attr" content="0077">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">GPU</span>
        <span itemprop="definition">graphic processing unit</span>
        <meta itemprop="num_attr" content="0077">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">PPU</span>
        <span itemprop="definition">a physics processing Unit</span>
        <meta itemprop="num_attr" content="0077">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">DSP</span>
        <span itemprop="definition">digital signal processor</span>
        <meta itemprop="num_attr" content="0077">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FPGA</span>
        <span itemprop="definition">field-programmable gate array</span>
        <meta itemprop="num_attr" content="0077">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">PLD</span>
        <span itemprop="definition">programmable logic device</span>
        <meta itemprop="num_attr" content="0077">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">controller</span>
        <span itemprop="definition">a microcontroller unit reduced instruction set computer</span>
        <meta itemprop="num_attr" content="0077">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">RISC</span>
        <span itemprop="definition">microcontroller unit reduced instruction set computer</span>
        <meta itemprop="num_attr" content="0077">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the network 120</span>
        <span itemprop="definition">may facilitate the exchange of data and/or information in the motion monitoring system 100 .</span>
        <meta itemprop="num_attr" content="0078">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">one or more components of the motion monitoring system 100</span>
        <span itemprop="definition">e.g., the processing device 110 , the wearable device 130 , the mobile terminal device 140</span>
        <meta itemprop="num_attr" content="0078">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the movement signal collected by the wearable device 130</span>
        <span itemprop="definition">may be transmitted to the processing device 110 through the network 120 .</span>
        <meta itemprop="num_attr" content="0078">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">confirmation results regarding the movement signal in the processing device 110</span>
        <span itemprop="definition">may be transmitted to the mobile terminal device 140 through the network 120 .</span>
        <meta itemprop="num_attr" content="0078">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the network 120</span>
        <span itemprop="definition">may be any type of a wired or wireless network.</span>
        <meta itemprop="num_attr" content="0078">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the network 120</span>
        <span itemprop="definition">may include a cable network, a wired network, a fiber optic network, a telecommunications network, an internal network, an inter-network, a regional network (LAN), a wide area network (WAN), a wireless regional network (WLAN), a metropolitan area network (MAN), a public switched telephone network (PSTN), a BluetoothTM network, a ZigBeeTM network, and a near field communication (NFC) network, or any combination of the above.</span>
        <meta itemprop="num_attr" content="0078">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the network 120</span>
        <span itemprop="definition">may include one or more network entry and exit points.</span>
        <meta itemprop="num_attr" content="0078">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">network 120</span>
        <span itemprop="definition">may include wired or wireless network entry and exit points, such as a base station and/or inter-network exchange points 120 - 1 , 120 - 2 , . . . , through the entry and exit points, one or more components of motion monitoring system 100 may connect to the network 120 to exchange the data and/or the information.</span>
        <meta itemprop="num_attr" content="0078">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the wearable device 130</span>
        <span itemprop="definition">may be a garment or a device that has a wearable function.</span>
        <meta itemprop="num_attr" content="0079">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the wearable device 130</span>
        <span itemprop="definition">may include, but is not limited to, an upper garment device 130 - 1 , a pant device 130 - 2 , a wrist guard device 130 - 3 , and a shoe 130 - 4 , etc.</span>
        <meta itemprop="num_attr" content="0079">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">wearable device 130</span>
        <span itemprop="definition">may include a plurality of sensors. The sensors may obtain various movement signals (e.g., an electromyographic signal, an attitude signal, temperature information, a heart rate, an electro-cardio signal, etc.) from the user during motion.</span>
        <meta itemprop="num_attr" content="0079">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">various movement signals</span>
        <span itemprop="definition">e.g., an electromyographic signal, an attitude signal, temperature information, a heart rate, an electro-cardio signal, etc.</span>
        <meta itemprop="num_attr" content="0079">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the sensors</span>
        <span itemprop="definition">may include, but are not limited to, one or more of an electromyographic sensor, an attitude sensor, a temperature sensor, a humidity sensor, an electro-cardio sensor, an oxygen saturation sensor, a Hall sensor, a Pico electric sensor, a rotation sensor, etc.</span>
        <meta itemprop="num_attr" content="0079">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">an electromyographic sensor</span>
        <span itemprop="definition">may be provided at a human muscle location (e.g., biceps, triceps, latissimus dorsi, trapezius, etc.) in the upper garment device 130 - 1 , and the electromyographic sensor may fit to user&#39;s skin and collect the electromyographic signal from the user during motion.</span>
        <meta itemprop="num_attr" content="0079">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the upper garment device 130 - 1</span>
        <span itemprop="definition">may be provided with an electro-cardio sensor near the left pectoral muscle of the human body, and the electromyographic sensor may collect the electro-cardio signal of the user.</span>
        <meta itemprop="num_attr" content="0079">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the attitude sensor</span>
        <span itemprop="definition">may be provided at a human body muscle location (e.g., gluteus maximus, lateral femoris, medial femoris, gastrocnemius, etc.) in the pant device 130 - 2 , and the attitude sensor may collect a user&#39;s attitude signal.</span>
        <meta itemprop="num_attr" content="0079">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the wearable device 130</span>
        <span itemprop="definition">may further provide feedback on the user&#39;s movement. For example, if the user&#39;s movement of a body part during motion does not meet the standard, the electromyographic sensor corresponding to that part may generate a stimulation signal (e.g., a current stimulation or a strike signal) to prompt the user.</span>
        <meta itemprop="num_attr" content="0079">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a stimulation signal</span>
        <span itemprop="definition">e.g., a current stimulation or a strike signal</span>
        <meta itemprop="num_attr" content="0079">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the wearable device 130</span>
        <span itemprop="definition">is not limited to the upper garment device 130 - 1 , the pant device 130 - 2 , the wrist guard device 130 - 3 , and the shoe device 130 - 4 shown in FIG. 1 , but may further include a device that are applied to other devices that require motion monitoring, such as, for example, a helmet device, a knee pad, etc., which may not be limited herein, and any device that can use the motion monitoring method provided in the disclosure is within the scope of protection of the present disclosure.</span>
        <meta itemprop="num_attr" content="0080">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the mobile terminal device 140</span>
        <span itemprop="definition">may access information or data in the motion monitoring system 100 .</span>
        <meta itemprop="num_attr" content="0081">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the mobile terminal device 140</span>
        <span itemprop="definition">may receive motion data processed by the processing device 110 , and feed motion records back based on processed motion data. Exemplary feedback manners may include, but are not limited to, a voice prompt, an image prompt, a video display, a text prompt, etc.</span>
        <meta itemprop="num_attr" content="0081">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the user</span>
        <span itemprop="definition">may obtain movement records during an own movement through the mobile terminal device 140 .</span>
        <meta itemprop="num_attr" content="0081">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the mobile terminal device 140</span>
        <span itemprop="definition">may be connected to the wearable device 130 through the network 120 (e.g., the wired connection, the wireless connection), and the user may obtain the movement records during the user&#39;s movement through the mobile terminal device 140 , which may be transmitted to the processing device 110 through the mobile terminal device 140 .</span>
        <meta itemprop="num_attr" content="0081">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the mobile terminal device 140</span>
        <span itemprop="definition">may include a mobile device 140 - 1 , a tablet 140 - 2 , a laptop 140 - 3 , or the like, or any combination thereof.</span>
        <meta itemprop="num_attr" content="0081">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the mobile device 140 - 1</span>
        <span itemprop="definition">may include a cell phone, a smart home device, a smart mobility device, a virtual reality device, an augmented reality device, or the like, or any combination thereof.</span>
        <meta itemprop="num_attr" content="0081">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the smart home device</span>
        <span itemprop="definition">may include a control device of a smart appliance, a smart monitoring device, a smart TV, a smart camera, or the like, or any combination thereof.</span>
        <meta itemprop="num_attr" content="0081">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the smart mobility device</span>
        <span itemprop="definition">may include a smart phone, a personal digital assistant (PDA), a gaming device, a navigation device, a POS device, or the like, or any combination thereof.</span>
        <meta itemprop="num_attr" content="0081">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a virtual reality device and/or an augmented reality device</span>
        <span itemprop="definition">may include a virtual reality helmet, virtual reality glasses, a virtual reality eye-mask, an augmented reality helmet, an augmented reality glasses, and an augmented reality eye-mask, or the like, or any combination thereof.</span>
        <meta itemprop="num_attr" content="0081">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the motion monitoring system 100</span>
        <span itemprop="definition">may further include a database.</span>
        <meta itemprop="num_attr" content="0082">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the database</span>
        <span itemprop="definition">may store the information (e.g., a threshold condition of an initially set, etc.) and/or the instruction (e.g., a feedback instruction).</span>
        <meta itemprop="num_attr" content="0082">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the database</span>
        <span itemprop="definition">may store the information obtained from the wearable device 130 and/or the mobile terminal device 140 .</span>
        <meta itemprop="num_attr" content="0082">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the database</span>
        <span itemprop="definition">may store the information and/or the instruction configured for the processing device 110 to execute or use to perform the exemplary methods described in the present disclosure.</span>
        <meta itemprop="num_attr" content="0082">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the database</span>
        <span itemprop="definition">may include a mass storage, a removable memory, a volatile read-write memory (e.g., random access memory RAM), a read-only memory (ROM), or the like, or any combination thereof.</span>
        <meta itemprop="num_attr" content="0082">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the database</span>
        <span itemprop="definition">may be implemented on a cloud platform.</span>
        <meta itemprop="num_attr" content="0082">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the cloud platform</span>
        <span itemprop="definition">may include a private cloud, a public cloud, a hybrid cloud, a community cloud, a decentralized cloud, an internal cloud, or the like, or any combination thereof.</span>
        <meta itemprop="num_attr" content="0082">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the database</span>
        <span itemprop="definition">may be connected to the network 120 to communicate with one or more components of the motion monitoring system 100 (e.g., the processing device 110 , the wearable device 130 , the mobile terminal device 140 , etc.).</span>
        <meta itemprop="num_attr" content="0083">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the one or more components of the motion monitoring system 100</span>
        <span itemprop="definition">may access information or instruction stored in the database through the network 120 .</span>
        <meta itemprop="num_attr" content="0083">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the database</span>
        <span itemprop="definition">may be directly connected or communicate with one or more components of the motion monitoring system 100 (e.g., the processing device 110 , the wearable device 130 , the mobile terminal device 140 ).</span>
        <meta itemprop="num_attr" content="0083">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the database</span>
        <span itemprop="definition">may be a part of the processing device 110</span>
        <meta itemprop="num_attr" content="0083">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 2</span>
        <span itemprop="definition">is a schematic diagram illustrating exemplary hardware and/or software of a wearable device according to some embodiments of the present disclosure.</span>
        <meta itemprop="num_attr" content="0084">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the wearable device 130</span>
        <span itemprop="definition">may include an obtaining module 210 , a processing module 220 (also referred to as a processor), a control module 230 (also referred to as a master, a MCU, a controller), a communication module 240 , a power supply module 250 , and an input/output module 260 .</span>
        <meta itemprop="num_attr" content="0084">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the obtaining module 210</span>
        <span itemprop="definition">may be configured to obtain a movement signal of a user during motion.</span>
        <meta itemprop="num_attr" content="0085">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the obtaining module 210</span>
        <span itemprop="definition">may include a sensor unit.</span>
        <meta itemprop="num_attr" content="0085">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the sensor unit</span>
        <span itemprop="definition">may be configured to obtain one or more movement signals while the user is in motion.</span>
        <meta itemprop="num_attr" content="0085">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the sensor unit</span>
        <span itemprop="definition">may include, but is not limited to, one or more electromyographic sensors, attitude sensors, cardiac sensors, respiration sensors, temperature sensors, humidity sensors, inertial sensors, blood oxygen saturation sensors, Hall sensors, piezoelectric sensors, rotation sensors, or the like.</span>
        <meta itemprop="num_attr" content="0085">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the movement signal</span>
        <span itemprop="definition">may include one or more electromyographic signals, attitude signals, cardiac signals, respiratory rates, temperature signals, humidity signals, etc.</span>
        <meta itemprop="num_attr" content="0085">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the sensor unit</span>
        <span itemprop="definition">may be placed at different locations of the wearable device 130 according to a type of a movement signal to be obtained.</span>
        <meta itemprop="num_attr" content="0085">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the electromyographic sensor</span>
        <span itemprop="definition">(also referred to as an electrode element) may be placed at a human muscle location, and the electromyographic sensor may be configured to collect the electromyographic signal of the user during motion.</span>
        <meta itemprop="num_attr" content="0085">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the electromyographic signal and its corresponding feature information</span>
        <span itemprop="definition">(e.g., frequency information, amplitude information, etc.) may reflect a state of muscle during a user&#39;s movement.</span>
        <meta itemprop="num_attr" content="0085">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the attitude sensor</span>
        <span itemprop="definition">may be provided at different locations on a human body (e.g., locations of the wearable device 130 corresponding to the torso, limbs, and joints), and the attitude sensor may be configured to capture the attitude signal of the user during the user&#39;s movement.</span>
        <meta itemprop="num_attr" content="0085">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the attitude signal and its corresponding feature information</span>
        <span itemprop="definition">may reflect the attitude of the user&#39;s movement.</span>
        <meta itemprop="num_attr" content="0085">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the electromyographic sensor</span>
        <span itemprop="definition">may be set at a location on the circumferential side of the human chest, and the electromyographic sensor may be configured to collect electro cardio data of the user during motion.</span>
        <meta itemprop="num_attr" content="0085">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the respiration sensor</span>
        <span itemprop="definition">may be arranged on a circumferential side of the body&#39;s chest, and the respiration sensor may be configured to collect respiration data (e.g., a respiration rate, a respiration amplitude, etc.) from the user during motion.</span>
        <meta itemprop="num_attr" content="0085">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the temperature sensor</span>
        <span itemprop="definition">may be configured to collect temperature data (e.g., a body surface temperature) of the user during motion.</span>
        <meta itemprop="num_attr" content="0085">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the humidity sensor</span>
        <span itemprop="definition">may be configured to collect humidity data of an external environment of the user during motion.</span>
        <meta itemprop="num_attr" content="0085">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processing module 220</span>
        <span itemprop="definition">may process data from the obtaining module 210 , the control module 230 , the communication module 240 , the power supply module 250 , and/or the input/output module 260 .</span>
        <meta itemprop="num_attr" content="0086">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processing module 220</span>
        <span itemprop="definition">may process the movement signal of the user during a process of motion from the obtaining module 210 .</span>
        <meta itemprop="num_attr" content="0086">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processing module 220</span>
        <span itemprop="definition">may pre-process the movement signal (e.g., the electromyographic signal, the attitude signal) obtained by the obtaining module 210 .</span>
        <meta itemprop="num_attr" content="0086">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processing module 220</span>
        <span itemprop="definition">may segment the electromyographic signal or the attitude signal of the user during motion.</span>
        <meta itemprop="num_attr" content="0086">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processing module 220</span>
        <span itemprop="definition">may perform a pre-processing (e.g., a filtering processing, a signal correction processing) on the electromyographic signal of the user during motion to improve quality of the electromyographic signal. Further, for example, the processing module 220 may determine the feature information corresponding to the attitude signal based on a user&#39;s attitude signal during motion. In some embodiments, the processing module 220 may process an instruction or operation from an input/output module 260 . In some embodiments, processed data may be stored in a memory or a hard disk. In some embodiments, the processing module 220 may transmit its processed data to one or more components in the motion monitoring system 100 through the communication module 240 or the network 120 . For example, the processing module 220 may send monitoring results of the user during motion to the control module 230 , which may execute subsequent operations or instructions according to motion determination results.</span>
        <meta itemprop="num_attr" content="0086">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a pre-processing</span>
        <span itemprop="definition">e.g., a filtering processing, a signal correction processing</span>
        <meta itemprop="num_attr" content="0086">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the control module 230</span>
        <span itemprop="definition">may be connected to other modules in the wearable device 130 .</span>
        <meta itemprop="num_attr" content="0087">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the control module 230</span>
        <span itemprop="definition">may control operation states of other modules (e.g., the communication module 240 , the power supply module 250 , the input/output module 260 ) in the wearable device 130 .</span>
        <meta itemprop="num_attr" content="0087">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the control module 230</span>
        <span itemprop="definition">may control a power supply state (e.g., a normal mode, a power saving mode), a power supply time, or the like, of the power supply module 250 .</span>
        <meta itemprop="num_attr" content="0087">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a certain threshold</span>
        <span itemprop="definition">e.g. 10%</span>
        <meta itemprop="num_attr" content="0087">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the control module 230</span>
        <span itemprop="definition">may control the power supply module 250 to enter a power saving mode or send a prompt message about the replenishment of power.</span>
        <meta itemprop="num_attr" content="0087">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">control module 230</span>
        <span itemprop="definition">may control the input/output module 260 based on user&#39;s movement determination results, and further control the mobile terminal device 140 to send feedback results of the user&#39;s movement.</span>
        <meta itemprop="num_attr" content="0087">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the control module 230</span>
        <span itemprop="definition">may control the input/output module 260 to control the mobile terminal device 140 to provide feedback to the user, allowing the user to understand own motion movement in real time and make some adjustments.</span>
        <meta itemprop="num_attr" content="0087">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the control module 230</span>
        <span itemprop="definition">may also control one or more sensors or other modules in the obtaining module 210 to provide feedback to the human body. For example, when a muscle of the user is exercising too strong during motion, the control module 230 may control an electrode module at a location of the muscle to stimulate the user to prompt the user to adjust the movement in time.</span>
        <meta itemprop="num_attr" content="0087">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the communication module 240</span>
        <span itemprop="definition">may be configured for an exchange of information or data. In some embodiments, the communication module 240 may be configured for communication between components (e.g., the obtaining module 210 , the processing module 220 , the control module 230 , the power supply module 250 , the input/output module 260 ) within a wearable device 130 . For example, the obtaining module 210 may send a movement signal (e.g., the electromyographic signal, the attitude signal, etc.) to the communication module 240 , and the communication module 240 may send the movement signal to the processing module 220 .</span>
        <meta itemprop="num_attr" content="0088">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a movement signal</span>
        <span itemprop="definition">e.g., the electromyographic signal, the attitude signal, etc.</span>
        <meta itemprop="num_attr" content="0088">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the communication module 240</span>
        <span itemprop="definition">may send state information (e.g., a switch state) of the wearable device 130 to the processing device 110 , and the processing device 110 may monitor the wearable device 130 based on the state information.</span>
        <meta itemprop="num_attr" content="0088">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">state information</span>
        <span itemprop="definition">e.g., a switch state</span>
        <meta itemprop="num_attr" content="0088">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the communication module 240</span>
        <span itemprop="definition">may employ wired, wireless, and hybrid wired/wireless technologies.</span>
        <meta itemprop="num_attr" content="0088">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the wired technology</span>
        <span itemprop="definition">may be based on one or more combinations of fiber optic cables such as metallic cables, hybrid cables, fiber optic cables, etc.</span>
        <meta itemprop="num_attr" content="0088">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the wireless technology</span>
        <span itemprop="definition">may include a Bluetooth (BluetoothTM), a wireless network (Wi-Fi), a purple bee (ZigBeeTM) a near field communication (NFC), a radio frequency identification (RFID), a cellular network (including GSM, CDMA, 3G, 4G, 5G, etc.), a cellular-based narrow band internet of things (NBIoT), etc.</span>
        <meta itemprop="num_attr" content="0088">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the communication module 240</span>
        <span itemprop="definition">may use one or more coding methods to encode transmitted information, for example, the coding methods may include a phase coding, a non-zeroing coding, a differential Manchester coding, or the like.</span>
        <meta itemprop="num_attr" content="0088">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the communication module 240</span>
        <span itemprop="definition">may select different transmission and encoding methods according to a type of data or a type of network to be transmitted.</span>
        <meta itemprop="num_attr" content="0088">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the communication module 240</span>
        <span itemprop="definition">may include one or more communication interfaces for different communication methods.</span>
        <meta itemprop="num_attr" content="0088">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">illustrated other modules of the motion monitoring system 100</span>
        <span itemprop="definition">may be dispersed on a plurality of devices, in this case, each of a plurality of other modules may each include one or more communication modules 240 for an inter-module information transmission.</span>
        <meta itemprop="num_attr" content="0088">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the communication module 240</span>
        <span itemprop="definition">may include a receiver and a transmitter. In other embodiments, the communication module 240 may be a transceiver.</span>
        <meta itemprop="num_attr" content="0088">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the power supply module 250</span>
        <span itemprop="definition">may provide power to other components in the motion monitoring system 100 (e.g., the obtaining module 210 , the processing module 220 , the control module 230 , the communication module 240 , the input/output module 260 ).</span>
        <meta itemprop="num_attr" content="0089">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the power supply module 250</span>
        <span itemprop="definition">may receive the control signal from the processing module 220 to control a power output of the wearable device 130 .</span>
        <meta itemprop="num_attr" content="0089">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the wearable device 130</span>
        <span itemprop="definition">does not receive any operation (e.g., no movement signal is detected by the obtaining module 210 ) for a certain period (e.g., 1 s, 2 s, 3 s, or 4 s)</span>
        <meta itemprop="num_attr" content="0089">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the power supply module 250</span>
        <span itemprop="definition">may supply power to the memory merely, putting the wearable device 130 into a standby mode.</span>
        <meta itemprop="num_attr" content="0089">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the power supply module 250</span>
        <span itemprop="definition">may disconnect power to other components and the data in the motion monitoring system 100 may be transmitted to a hard disk, putting the wearable device 130 into the standby mode or a sleeping mode.</span>
        <meta itemprop="num_attr" content="0089">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the power supply module 250</span>
        <span itemprop="definition">may include at least one battery.</span>
        <meta itemprop="num_attr" content="0089">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the battery</span>
        <span itemprop="definition">may include one or more combinations of a dry cell, a lead battery, a lithium battery, a solar cell, a wind energy generation battery, a mechanical energy generation battery, a thermal energy generation battery, etc.</span>
        <meta itemprop="num_attr" content="0089">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Light energy</span>
        <span itemprop="definition">may be converted into electrical energy by the solar battery and stored in the power supply module 250 .</span>
        <meta itemprop="num_attr" content="0089">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Wind energy</span>
        <span itemprop="definition">may be converted into the electrical energy by the wind power generation battery and stored in the power supply module 250 .</span>
        <meta itemprop="num_attr" content="0089">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Mechanical energy</span>
        <span itemprop="definition">may be converted into the electrical energy by the mechanical energy generation battery and stored in the power supply module 250 .</span>
        <meta itemprop="num_attr" content="0089">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the solar cell</span>
        <span itemprop="definition">may include a silicon solar cell, a thin film solar cell, a nanocrystalline chemical solar cell, a fuel sensitized solar cell, a plastic solar cell, etc.</span>
        <meta itemprop="num_attr" content="0089">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the solar cell</span>
        <span itemprop="definition">may be distributed on the wearable device 130 in a form of panel.</span>
        <meta itemprop="num_attr" content="0089">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a user&#39;s body temperature</span>
        <span itemprop="definition">may be converted into the electrical energy by the thermal power cell and stored in the power supply module 250 .</span>
        <meta itemprop="num_attr" content="0089">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processing module 220</span>
        <span itemprop="definition">may send the control signal to the power supply module 250 when the power supply module 250 is less than a power threshold (e.g., 10% of the total power).</span>
        <meta itemprop="num_attr" content="0089">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the control signal</span>
        <span itemprop="definition">may include information that the power supply module 250 is low on power.</span>
        <meta itemprop="num_attr" content="0089">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the power supply module 250</span>
        <span itemprop="definition">may include a backup power source.</span>
        <meta itemprop="num_attr" content="0089">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the power supply module 250</span>
        <span itemprop="definition">may further include a charging interface.</span>
        <meta itemprop="num_attr" content="0089">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the power supply module 250</span>
        <span itemprop="definition">may be temporarily charged by using an electronic device (e.g., a cell phone, a tablet computer) or a rechargeable battery carried by the user to temporarily charge the power supply module 250 in an emergency (e.g., the power supply module 250 is at zero power and an external power system is out of power).</span>
        <meta itemprop="num_attr" content="0089">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the input/output module 260</span>
        <span itemprop="definition">may obtain, transmit, and send a signal.</span>
        <meta itemprop="num_attr" content="0090">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the input/output module 260</span>
        <span itemprop="definition">may connect to or communicate with other components in the motion monitoring system 100 .</span>
        <meta itemprop="num_attr" content="0090">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the other components in the motion monitoring system 100</span>
        <span itemprop="definition">may be connected or communicated through the input/output module 260 .</span>
        <meta itemprop="num_attr" content="0090">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the input/output module 260</span>
        <span itemprop="definition">may be a wired USB interface, a serial communication interface, a parallel communication port, or a wireless Bluetooth, an infrared-frequency identification, a radio-frequency identification (RFID), a WLAN authentication and privacy infrastructure (WAPI), a general packet radio service (GPRS), a code division multiple access (CDMA), or any combination thereof.</span>
        <meta itemprop="num_attr" content="0090">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the input/output module 260</span>
        <span itemprop="definition">may be connected to the network 120 and obtain the information through the network 120 .</span>
        <meta itemprop="num_attr" content="0090">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the input/output module 260</span>
        <span itemprop="definition">may obtain the movement signal from the obtaining module 210 of the user during motion and output user movement information through the network 120 or the communication module 240 .</span>
        <meta itemprop="num_attr" content="0090">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the input/output module 260</span>
        <span itemprop="definition">may include VCC, GND, RS-232, RS-485 (e.g., RS485-A, RS485-B), a universal network interface, or the like, or any combination thereof.</span>
        <meta itemprop="num_attr" content="0090">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the input/output module 260</span>
        <span itemprop="definition">may transmit obtained user motion information to the obtaining module 210 through the network 120 .</span>
        <meta itemprop="num_attr" content="0090">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the encoding methods</span>
        <span itemprop="definition">may include a phase coding, a non-zeroing system encoding, a differential Manchester encoding, or the like, or any combination thereof.</span>
        <meta itemprop="num_attr" content="0090">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">system and its modules shown in FIG. 2</span>
        <span itemprop="definition">may be implemented by using a plurality of methods.</span>
        <meta itemprop="num_attr" content="0091">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the system and its modules</span>
        <span itemprop="definition">may be implemented by hardware, software, or a combination of software and hardware.</span>
        <meta itemprop="num_attr" content="0091">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a hardware portion</span>
        <span itemprop="definition">may be implemented by using dedicated logic.</span>
        <meta itemprop="num_attr" content="0091">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a software portion</span>
        <span itemprop="definition">may be stored in memory and executed by an appropriate instruction execution system, such as a microprocessor or dedicated design hardware.</span>
        <meta itemprop="num_attr" content="0091">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a computer executable instruction and/or contained in a processor control code</span>
        <span itemprop="definition">for example, such encoding provided on a carrier medium such as a disk, a CD or a DVD-ROM, a programmable memory such as a read-only memory (firmware), or a data carrier such as an optical or electronic signal carrier.</span>
        <meta itemprop="num_attr" content="0091">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the system and its modules in one or more embodiments of the present disclosure</span>
        <span itemprop="definition">may be implemented by a hardware circuit, e.g., a ultra-large scale integrated circuit or a gate array, a semiconductor such as a logic chip, a transistor, etc., or a programmable hardcore device such as a field programmable gate array, a programmable logic device, etc., implemented by software executed by various types of processors, or implemented by a combination of above hardware circuit and software (e.g., firmware).</span>
        <meta itemprop="num_attr" content="0091">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a hardware circuit</span>
        <span itemprop="definition">e.g., a ultra-large scale integrated circuit or a gate array, a semiconductor such as a logic chip, a transistor, etc., or a programmable hardcore device such as a field programmable gate array, a programmable logic device, etc.</span>
        <meta itemprop="num_attr" content="0091">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">firmware</span>
        <span itemprop="definition">e.g., firmware</span>
        <meta itemprop="num_attr" content="0091">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the above description of the motion monitoring system and its modules</span>
        <span itemprop="definition">is merely for descriptive convenience and does not limit one or more embodiments of the present disclosure within the scope of the embodiments. Understandably, for those skilled in the art, after understanding a principle of the system, they may make any combination of the modules, or to form a sub-system to connect with other modules, or to omit one or more modules thereof, without departing from this principle.</span>
        <meta itemprop="num_attr" content="0092">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the obtaining module 210 and the processing module 220</span>
        <span itemprop="definition">may be one module that may have a function of obtaining and processing the user movement signal.</span>
        <meta itemprop="num_attr" content="0092">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processing module 220</span>
        <span itemprop="definition">may not be provided in the wearable device 130 , but integrated in the processing device 110 . Variations such as these are within the scope of protection of one or more embodiments of the present disclosure.</span>
        <meta itemprop="num_attr" content="0092">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 3</span>
        <span itemprop="definition">is a schematic diagram illustrating exemplary hardware and/or software of a computing device according to some embodiments of the present disclosure.</span>
        <meta itemprop="num_attr" content="0093">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processing device 110 and/or the mobile terminal device 140</span>
        <span itemprop="definition">may be implemented on a computing device 300 .</span>
        <meta itemprop="num_attr" content="0093">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the computing device 300</span>
        <span itemprop="definition">may include an internal communication bus 310 , a processor 320 , a read-only memory 330 , a random memory 340 , a communication port 350 , an input/output interface 360 , a hard disk 370 , and a user interface 380 .</span>
        <meta itemprop="num_attr" content="0093">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the internal communication bus 310</span>
        <span itemprop="definition">may enable data communication between components in the computing device 300 .</span>
        <meta itemprop="num_attr" content="0094">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processor 320</span>
        <span itemprop="definition">may send data to other hardware such as a memory or the input/output interface 360 through the internal communication bus 310 .</span>
        <meta itemprop="num_attr" content="0094">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the internal communication bus 310</span>
        <span itemprop="definition">may be an industry standard architecture (ISA) bus, an extended industry standard architecture (EISA) bus, a video electronics standard architecture (VESA) bus, a peripheral component interconnect (PCI) bus, etc.</span>
        <meta itemprop="num_attr" content="0094">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the internal communication bus 310</span>
        <span itemprop="definition">may be configured to connect various modules (e.g., the obtaining module 210 , the processing module 220 , the control module 230 , the communication module 240 , the input and output module 260 ) of the motion monitoring system 100 shown in FIG. 1 .</span>
        <meta itemprop="num_attr" content="0094">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processor 320</span>
        <span itemprop="definition">may execute a computing instruction (a program code) and perform functions of the motion monitoring system 100 described in the present disclosure.</span>
        <meta itemprop="num_attr" content="0095">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the computing instruction</span>
        <span itemprop="definition">may include a program, an object, a component, a data structure, a process, a module, and a function (the function may refer to a specific function described in the present disclosure).</span>
        <meta itemprop="num_attr" content="0095">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">processor 320</span>
        <span itemprop="definition">may process the obtained movement signal (e.g., the electromyographic signal, the attitude signal) of a user during motion from the wearable device 130 or/and the mobile terminal device 140 of the motion monitoring system 100 , and monitor the movement of the user during motion based on the movement signal during motion.</span>
        <meta itemprop="num_attr" content="0095">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the obtained movement signal</span>
        <span itemprop="definition">e.g., the electromyographic signal, the attitude signal</span>
        <meta itemprop="num_attr" content="0095">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processor 320</span>
        <span itemprop="definition">may include a microcontroller, a microprocessor, a reduced instruction set computer (RISC), an application-specific integrated circuit (ASIC), an application-specific instruction-set processor (ASIP), a central processing unit (CPU), a graphics processing unit (GPU), a physical processing unit (PPU), a microcontroller unit, a digital signal processor (DSP), a field Programmable Gate Array (FPGA), an advanced RISC machine (ARM), a programmable logic device, and any circuit and processor capable of performing one or more functions, or any combination thereof.</span>
        <meta itemprop="num_attr" content="0095">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the computing device 300 in FIG. 3</span>
        <span itemprop="definition">depicts only one processor, but it should be noted that the computing device 300 in the present disclosure may further include a plurality of processors.</span>
        <meta itemprop="num_attr" content="0095">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a memory of the computing device 300</span>
        <span itemprop="definition">may store data/information obtained from any other components of the motion monitoring system 100 .</span>
        <meta itemprop="num_attr" content="0096">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the memory of the computing device 300</span>
        <span itemprop="definition">may be located in the wearable device 130 or the processing device 110 .</span>
        <meta itemprop="num_attr" content="0096">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Exemplary ROM</span>
        <span itemprop="definition">may include a mask ROM (MROM), a programmable ROM (PROM), an erasable programmable ROM (PEROM), an electrically erasable programmable ROM (EEPROM), a compact disk ROM (CD-ROM), a digital versatile disk ROM, etc.</span>
        <meta itemprop="num_attr" content="0096">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Exemplary RAM</span>
        <span itemprop="definition">may include a dynamic RAM (DRAM), a double-rate synchronous dynamic RAM (DDR SDRAM), a static RAM (SRAM), a thyristor RAM (T-RAM), a zero-capacitor RAM (Z-RAM), etc.</span>
        <meta itemprop="num_attr" content="0096">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">DRAM</span>
        <span itemprop="definition">dynamic RAM</span>
        <meta itemprop="num_attr" content="0096">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">DDR SDRAM</span>
        <span itemprop="definition">double-rate synchronous dynamic RAM</span>
        <meta itemprop="num_attr" content="0096">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">SRAM</span>
        <span itemprop="definition">static RAM</span>
        <meta itemprop="num_attr" content="0096">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">T-RAM</span>
        <span itemprop="definition">thyristor RAM</span>
        <meta itemprop="num_attr" content="0096">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Z-RAM</span>
        <span itemprop="definition">zero-capacitor RAM</span>
        <meta itemprop="num_attr" content="0096">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the input/output interface 360</span>
        <span itemprop="definition">may input or output signals, data, or information.</span>
        <meta itemprop="num_attr" content="0097">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the input/output interface 360</span>
        <span itemprop="definition">may enable a user to interact with the motion monitoring system 100 .</span>
        <meta itemprop="num_attr" content="0097">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the input/output interface 360</span>
        <span itemprop="definition">may include the communication module 240 to enable the communication function of the motion monitoring system 100 .</span>
        <meta itemprop="num_attr" content="0097">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the input/output interface 360</span>
        <span itemprop="definition">may include an input device and an output device.</span>
        <meta itemprop="num_attr" content="0097">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Exemplary input devices</span>
        <span itemprop="definition">may include a keyboard, a mouse, a touch screen, a microphone, or the like, or any combination thereof.</span>
        <meta itemprop="num_attr" content="0097">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Exemplary output devices</span>
        <span itemprop="definition">may include a display device, a loudspeaker, a printer, a projector, or the like, or any combination thereof.</span>
        <meta itemprop="num_attr" content="0097">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Example display devices</span>
        <span itemprop="definition">may include a liquid crystal display (LCD), a light-emitting diode (LED)-based display, a flat panel display, a curved display, a television device, a cathode ray tubes (CRT), or the like, or any combination thereof.</span>
        <meta itemprop="num_attr" content="0097">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the communication port 350</span>
        <span itemprop="definition">may be connected to a network for data communication. Connection may be a wired connection, a wireless connection, or a combination thereof.</span>
        <meta itemprop="num_attr" content="0097">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the wired connection</span>
        <span itemprop="definition">may include a cable, a fiber optic cable, a telephone line, or the like, or any combination thereof.</span>
        <meta itemprop="num_attr" content="0097">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the wireless connection</span>
        <span itemprop="definition">may include BluetoothTM, Wi-Fi, WiMAX, WLAN, ZigBeeTM, a mobile network (e.g., 3G, 4G, or 5G, etc.), or the like, or any combination thereof.</span>
        <meta itemprop="num_attr" content="0097">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the communication port 350</span>
        <span itemprop="definition">may be a standard port, such as RS232, RS485, etc.</span>
        <meta itemprop="num_attr" content="0097">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the communication port 350</span>
        <span itemprop="definition">may be a specially designed port.</span>
        <meta itemprop="num_attr" content="0097">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the hard disk 370</span>
        <span itemprop="definition">may be configured to store information and data generated by or received from the processing device 110 .</span>
        <meta itemprop="num_attr" content="0098">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the hard disk 370</span>
        <span itemprop="definition">may store confirmation information of a user.</span>
        <meta itemprop="num_attr" content="0098">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the hard disk 370</span>
        <span itemprop="definition">may include a hard disk drive (HDD), a solid-state drive (SSD), or a hybrid hard disk (HHD), etc.</span>
        <meta itemprop="num_attr" content="0098">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the hard disk 370</span>
        <span itemprop="definition">may be provided in the processing device 110 or in the wearable device 130 .</span>
        <meta itemprop="num_attr" content="0098">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the user interface 380</span>
        <span itemprop="definition">may enable an interact and information exchange between the computing device 300 and the user.</span>
        <meta itemprop="num_attr" content="0098">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the user interface 380</span>
        <span itemprop="definition">may be configured to present motion recordings generated by the motion monitoring system 100 to the user.</span>
        <meta itemprop="num_attr" content="0098">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the user interface 380</span>
        <span itemprop="definition">may include a physical display such as a display with speakers, an LCD display, an LED display, an OLED display, an electronic ink display (E-Ink), etc.</span>
        <meta itemprop="num_attr" content="0098">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 4</span>
        <span itemprop="definition">is a structure diagram of an exemplary wearable device according to some embodiments of the present disclosure.</span>
        <meta itemprop="num_attr" content="0099">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">an upper garment</span>
        <span itemprop="definition">is illustrated as an example, as shown in FIG. 4 .</span>
        <meta itemprop="num_attr" content="0099">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the wearable device 400</span>
        <span itemprop="definition">may include an upper garment 410 .</span>
        <meta itemprop="num_attr" content="0099">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the upper garment 410</span>
        <span itemprop="definition">may include an upper garment substrate 4110 , at least one upper garment processing module 4120 , at least one upper garment feedback module 4130 , at least one upper garment obtaining module 4140 , etc.</span>
        <meta itemprop="num_attr" content="0099">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the upper garment substrate 4110</span>
        <span itemprop="definition">may refer to clothe worn on an upper body of a human body.</span>
        <meta itemprop="num_attr" content="0099">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the upper garment substrate 4110</span>
        <span itemprop="definition">may include a short sleeve T-shirt, a long sleeve T-shirt, a shirt, a jacket, etc.</span>
        <meta itemprop="num_attr" content="0099">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the at least one upper garment processing module 4120 , the at least one upper garment obtaining module 4140</span>
        <span itemprop="definition">may be located in areas of the upper garment substrate 4110 that fit to different parts of the human body.</span>
        <meta itemprop="num_attr" content="0099">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the at least one upper garment feedback module 4130</span>
        <span itemprop="definition">may be located at any location on the upper garment substrate 4110 , and the at least one upper garment feedback module 4130 may be configured to provide feedback on information about a user&#39;s upper body movement state. Exemplary feedback manners may include, but are not limited to, a voice prompt, a text prompt, a pressure prompt, an electrical stimulation, etc.</span>
        <meta itemprop="num_attr" content="0099">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the at least one upper garment obtaining module 4140</span>
        <span itemprop="definition">may include, but is not limited to, one or more of an attitude sensor, an electro-cardio sensor, an electromyographic sensor, a temperature sensor, a humidity sensor, an inertial sensor, an acid-base sensor, an acoustic transducer, etc.</span>
        <meta itemprop="num_attr" content="0099">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the sensor(s) in the upper garment obtaining module 4140</span>
        <span itemprop="definition">may be placed at different locations on user&#39;s body according to a signal to be measured. For example, when the attitude sensor is configured to obtain the attitude signal of a user during motion, the attitude sensor can be placed in the upper garment substrate 4110 at a location corresponding to the human torso, arms, and joints.</span>
        <meta itemprop="num_attr" content="0099">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the electromyographic sensor</span>
        <span itemprop="definition">when the electromyographic sensor is configured to obtain the electromyographic signal of the user during motion, the electromyographic sensor may be located near the muscles to be measured.</span>
        <meta itemprop="num_attr" content="0099">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the attitude sensor</span>
        <span itemprop="definition">may include, but is not limited to, an acceleration triaxial sensor, an angular velocity triaxial sensor, a magnetic sensor, or the like, or any combination thereof.</span>
        <meta itemprop="num_attr" content="0099">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">an attitude sensor</span>
        <span itemprop="definition">may include an acceleration triaxial sensor, an angular velocity triaxial sensor.</span>
        <meta itemprop="num_attr" content="0099">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">an attitude sensor</span>
        <span itemprop="definition">may further include a strain gauge sensor.</span>
        <meta itemprop="num_attr" content="0099">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a strain gauge sensor</span>
        <span itemprop="definition">may be a sensor based on strain generated by deformation of an object to be measured caused by a force.</span>
        <meta itemprop="num_attr" content="0099">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the strain gauge sensor</span>
        <span itemprop="definition">may include, but is not limited to, one or more of a strain-gauge force sensor, a strain-gauge pressure sensor, a strain-gauge torque sensor, a strain-gauge displacement sensor, a strain-gauge acceleration sensor, etc.</span>
        <meta itemprop="num_attr" content="0099">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the strain gauge sensor</span>
        <span itemprop="definition">may be arranged at a joint location of the user, and a bending angle and a bending direction at the user&#39;s joint can be obtained based on the resistance in the strain gauge sensor that varies with a stretch length at the joint.</span>
        <meta itemprop="num_attr" content="0099">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the upper garment 410</span>
        <span itemprop="definition">may include other modules, such as a power supply module, a communication module, an input/output module, etc., in addition to the upper garment substrate 4110 , the upper garment processing module 4120 , the upper garment feedback module 4130 , and the upper garment obtaining module 4140 described above.</span>
        <meta itemprop="num_attr" content="0099">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the upper garment processing module 4120</span>
        <span itemprop="definition">may be similar to the processing module 220 shown in FIG. 2</span>
        <meta itemprop="num_attr" content="0099">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the upper garment obtaining module 4140</span>
        <span itemprop="definition">may be similar to the obtaining module 210 shown in FIG. 2 .</span>
        <meta itemprop="num_attr" content="0099">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Specific descriptions regarding various modules in the upper garment 410</span>
        <span itemprop="definition">may be found in FIG. 2 and its relevant descriptions of the present disclosure, which may not be repeated herein.</span>
        <meta itemprop="num_attr" content="0099">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 5</span>
        <span itemprop="definition">is a flowchart illustrating an exemplary motion monitoring method according to some embodiments of the present disclosure. As shown in FIG. 5 , process 500 may include the following steps.</span>
        <meta itemprop="num_attr" content="0100">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">step 510</span>
        <span itemprop="definition">a movement signal of a user during motion may be obtained.</span>
        <meta itemprop="num_attr" content="0101">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the step 510</span>
        <span itemprop="definition">may be performed by the obtaining module 210 .</span>
        <meta itemprop="num_attr" content="0102">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the movement signal</span>
        <span itemprop="definition">refers to human body parameter information of the user during motion.</span>
        <meta itemprop="num_attr" content="0102">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the human body parameter information</span>
        <span itemprop="definition">may include, but is not limited to, one or more of an electromyographic signal, an attitude signal, an electro-cardio signal, a temperature signal, a humidity signal, a blood oxygen concentration, a respiration rate, etc.</span>
        <meta itemprop="num_attr" content="0102">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">an electromyographic sensor in the obtaining module 210</span>
        <span itemprop="definition">may collect the electromyographic signal of the user during motion.</span>
        <meta itemprop="num_attr" content="0102">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the electromyographic sensors in a wearable device corresponding to human pectoral muscles, latissimus dorsi, etc.</span>
        <span itemprop="definition">may obtain the electromyographic signals of corresponding muscle positions of the user.</span>
        <meta itemprop="num_attr" content="0102">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the electromyographic sensors in the wearable device corresponding to gluteus maximus and quadriceps</span>
        <span itemprop="definition">may collect the electromyographic signals of the corresponding muscle positions.</span>
        <meta itemprop="num_attr" content="0102">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the electromyographic sensors in the wearable device corresponding to the gastrocnemius muscle and other positions</span>
        <span itemprop="definition">may obtain the electromyographic signals of the corresponding muscle positions.</span>
        <meta itemprop="num_attr" content="0102">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the attitude sensor in the obtaining module 210</span>
        <span itemprop="definition">may obtain an attitude signal of the user during motion.</span>
        <meta itemprop="num_attr" content="0102">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the attitude sensor in the wearable device corresponding to the human triceps, etc.</span>
        <span itemprop="definition">may obtain the attitude signal of the triceps, etc.</span>
        <meta itemprop="num_attr" content="0102">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the attitude sensor set at a position</span>
        <span itemprop="definition">such as a human deltoid muscle may obtain the attitude signal of the corresponding position.</span>
        <meta itemprop="num_attr" content="0102">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a plurality of attitude sensors</span>
        <span itemprop="definition">may obtain attitude signals of a plurality of portions of the user during motion, and the attitude signals of the plurality of portions may reflect a relative movement between different parts of the body.</span>
        <meta itemprop="num_attr" content="0102">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">an attitude signal at an arm and an attitude signal at a torso</span>
        <span itemprop="definition">may reflect a movement condition of the arm relative to the torso.</span>
        <meta itemprop="num_attr" content="0102">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the attitude signal</span>
        <span itemprop="definition">may be associated with a type of the attitude sensor.</span>
        <meta itemprop="num_attr" content="0102">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">an obtained attitude signal</span>
        <span itemprop="definition">may be angular velocity information.</span>
        <meta itemprop="num_attr" content="0102">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the obtained attitude signal</span>
        <span itemprop="definition">may be the angular velocity information and acceleration information.</span>
        <meta itemprop="num_attr" content="0102">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the strain gauge sensor</span>
        <span itemprop="definition">when the attitude sensor is a strain gauge sensor, the strain gauge sensor may be arranged at a user&#39;s joint position, by measuring the resistance in the strain gauge sensor that varies with the stretch length, the obtained attitude signal may be displacement information, stress, etc., and a bending angle and a bending direction at the user&#39;s joint may be represented through these attitude signals.</span>
        <meta itemprop="num_attr" content="0102">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the parameter information configured to reflect the relative motion of the user&#39;s body</span>
        <span itemprop="definition">may be feature information corresponding to the attitude signal, which may be obtained by using different types of attitude sensors according to the type of the feature information.</span>
        <meta itemprop="num_attr" content="0102">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the movement signal</span>
        <span itemprop="definition">may include the electromyographic signal and the attitude signal of a particular part of the user&#39;s body.</span>
        <meta itemprop="num_attr" content="0103">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the electromyographic signal and the attitude signal</span>
        <span itemprop="definition">may reflect a movement state of the particular part of the user&#39;s body from different angles.</span>
        <meta itemprop="num_attr" content="0103">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the attitude signal of a specific part of the user&#39;s body</span>
        <span itemprop="definition">may reflect a type of movement, a movement amplitude, a movement frequency, etc., of the specific part.</span>
        <meta itemprop="num_attr" content="0103">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the electromyographic signal</span>
        <span itemprop="definition">may reflect a muscle state of the particular part during motion. In some embodiments, by measuring the electromyographic signal and/or the attitude signal of the same body part, whether the movement of that part is standard may be better assessed.</span>
        <meta itemprop="num_attr" content="0103">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a movement of the user during motion</span>
        <span itemprop="definition">may be monitored based at least on feature information corresponding to the electromyographic signal or feature information corresponding to the attitude signal.</span>
        <meta itemprop="num_attr" content="0104">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the step 520</span>
        <span itemprop="definition">may be performed by the processing module 220 and/or the processing device 110 .</span>
        <meta itemprop="num_attr" content="0105">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the feature information corresponding to the electromyographic signal</span>
        <span itemprop="definition">may include, but is not limited to, one or more of frequency information, amplitude information, etc.</span>
        <meta itemprop="num_attr" content="0105">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the feature information corresponding to the attitude signal</span>
        <span itemprop="definition">may be parameter information configured to represent a relative motion of the user&#39;s body.</span>
        <meta itemprop="num_attr" content="0105">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the feature information corresponding to the attitude signal</span>
        <span itemprop="definition">may include, but is not limited to, one or more of an angular velocity direction, an angular velocity value, an acceleration value of angular velocity, etc.</span>
        <meta itemprop="num_attr" content="0105">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the feature information corresponding to the attitude signal</span>
        <span itemprop="definition">may further include an angle, displacement information (e.g., a stretch length in a strain gauge sensor), a stress, etc.</span>
        <meta itemprop="num_attr" content="0105">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the strain gauge sensor</span>
        <span itemprop="definition">when the attitude sensor is a strain gauge sensor, the strain gauge sensor may be set at the user&#39;s joint position, and by measuring the resistance in the strain gauge sensor that varies with the stretch length, the obtained attitude signal may be the displacement information, the stress, etc., which may represent the bending angle and the bending direction at the user&#39;s joint.</span>
        <meta itemprop="num_attr" content="0105">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processing module 220 and/or the processing device 110</span>
        <span itemprop="definition">may extract the feature information corresponding to the electromyographic signal (e.g., frequency information, amplitude information) or the feature information corresponding to the attitude signal (e.g., the angular velocity direction, the angular velocity value, the acceleration value of angular velocity, the angle, the displacement information, the stress, etc.), and monitor the movement of the user during motion based on the feature information corresponding to the electromyographic signal or the feature information corresponding to the attitude signal.</span>
        <meta itemprop="num_attr" content="0105">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the monitoring of the movement during motion</span>
        <span itemprop="definition">may include user&#39;s movement-related information.</span>
        <meta itemprop="num_attr" content="0105">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">movement-related information</span>
        <span itemprop="definition">may include one or more of a movement type, a movement quantity, a movement quality (e.g., whether the movement meets a standard), a movement time, etc.</span>
        <meta itemprop="num_attr" content="0105">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the movement type</span>
        <span itemprop="definition">may be a fitness movement performed by the user during motion.</span>
        <meta itemprop="num_attr" content="0105">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the movement type</span>
        <span itemprop="definition">may include, but is not limited to, one or more of seated chest presses, deep squats, hard pulls, plank supports, running, swimming, etc.</span>
        <meta itemprop="num_attr" content="0105">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the movement quantity</span>
        <span itemprop="definition">may refer to the number of times the user performs the movement during motion. For example, if the user performs 10 seated chest clamps during motion, 10 may be the movement quantity.</span>
        <meta itemprop="num_attr" content="0105">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the movement quality</span>
        <span itemprop="definition">may refer to the standard degree of the fitness movement performed by the user related to a standard fitness movement.</span>
        <meta itemprop="num_attr" content="0105">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processing device 110</span>
        <span itemprop="definition">may determine a movement type of the user based on the feature information corresponding to the movement signal (the electromyographic signal and the attitude signal) of a particular specific muscle location (gluteus maximus, quadriceps, etc.), and determine the movement quality of the user during performing the deep squat movement based on the movement signal.</span>
        <meta itemprop="num_attr" content="0105">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the movement time</span>
        <span itemprop="definition">may be the time corresponding to one or more movement types of the user or the total time of the movement process.</span>
        <meta itemprop="num_attr" content="0105">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processing device 110</span>
        <span itemprop="definition">may use one or more movement recognition models to recognize and monitor the movement of the user during motion. For example, the processing device 110 may input the feature information corresponding to the electromyographic signal and/or the feature information corresponding to the attitude signal into the movement recognition model, and the movement recognition model may output information related to the user&#39;s movement.</span>
        <meta itemprop="num_attr" content="0106">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the movement recognition model</span>
        <span itemprop="definition">may include different types of movement recognition models, for example, a model configured to recognize the movement type of the user, or a model configured to identify the movement quality of the user, etc.</span>
        <meta itemprop="num_attr" content="0106">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">process 500</span>
        <span itemprop="definition">is for exemplary and illustrative purpose only, and does not limit the scope of application of the present disclosure.</span>
        <meta itemprop="num_attr" content="0107">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">various amendments and changes</span>
        <span itemprop="definition">can be made to the process 500 under the guidance of the present disclosure.</span>
        <meta itemprop="num_attr" content="0107">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">these amendments and changes</span>
        <span itemprop="definition">are still within the scope of the present disclosure.</span>
        <meta itemprop="num_attr" content="0107">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the extraction of the feature information corresponding to the electromyographic signal or the feature information corresponding to the attitude signal in step 520</span>
        <span itemprop="definition">may be performed by the processing device 110 , or in some embodiments, by the processing module 220 .</span>
        <meta itemprop="num_attr" content="0107">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the user&#39;s movement signal</span>
        <span itemprop="definition">may not be limited to the above electromyographic signal, the attitude signal, the electro-cardio signal, the temperature signal, the humidity signal, the blood oxygen concentration, the respiration rate, but may also include other human physiological parameter signals.</span>
        <meta itemprop="num_attr" content="0107">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the physiological parameter signals involved in human movement</span>
        <span itemprop="definition">may be all considered as the movement signal in the embodiments of the present disclosure.</span>
        <meta itemprop="num_attr" content="0107">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 6</span>
        <span itemprop="definition">is a flowchart of an exemplary process for monitoring a movement of a user during motion according to some embodiments of the present disclosure. As shown in FIG. 6 , process 600 may include the following steps.</span>
        <meta itemprop="num_attr" content="0108">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the movement signal</span>
        <span itemprop="definition">may be segmented based on the feature information corresponding to the electromyographic signal or the feature information corresponding to the attitude signal.</span>
        <meta itemprop="num_attr" content="0109">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the step</span>
        <span itemprop="definition">may be performed by the processing module 220 and/or the processing device 110 .</span>
        <meta itemprop="num_attr" content="0110">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the process of obtaining the movement signal (e.g., the electromyographic signal, the attitude signal) of the user during motion</span>
        <span itemprop="definition">may be continuous, and a movement of the user during motion may be a combination of a plurality of sets of movement or a combination of different movement types.</span>
        <meta itemprop="num_attr" content="0110">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processing module 220</span>
        <span itemprop="definition">may segment the movement signal of the user based on the feature information corresponding to the electromyographic signal or the feature information corresponding to the attitude signal.</span>
        <meta itemprop="num_attr" content="0110">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the segmenting the movement signal of the user</span>
        <span itemprop="definition">herein may refer to dividing the movement signal into signal segments having same or different durations, or extracting one or more signal segments having a specific duration from the movement signal.</span>
        <meta itemprop="num_attr" content="0110">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">each segment of the movement signal</span>
        <span itemprop="definition">may correspond to one or more complete movement of the user. For example, when a user performs a deep squat, the user&#39;s movement from a standing position to a squat position and then getting up to return to the standing position may be considered as completing the deep squat, and the movement signal collected by the obtaining module 210 during this process may be considered as one segment (or one cycle) of the movement signal, after which the movement signal collected by the obtaining module 210 from the next deep squat completed by the user may be considered as another segment of the movement signal.</span>
        <meta itemprop="num_attr" content="0110">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">each movement signal</span>
        <span itemprop="definition">may also correspond to a portion of the user&#39;s movement, and the portion of the movement may be understood as a portion of a complete movement.</span>
        <meta itemprop="num_attr" content="0110">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the user&#39;s movement from a standing position to a squat position</span>
        <span itemprop="definition">may be considered as one segment of the movement, and getting up to return to the standing position may be considered as another segment of the movement.</span>
        <meta itemprop="num_attr" content="0110">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a change in each movement of the user during motion</span>
        <span itemprop="definition">may cause the electromyographic signal and the attitude signal of a corresponding body part to change.</span>
        <meta itemprop="num_attr" content="0110">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the electromyographic signal and the attitude signal of the muscles in the corresponding parts of the user&#39;s body</span>
        <span itemprop="definition">fluctuate less when the user stands; when the user squats from the standing position, the electromyographic signal and the attitude signal of the muscles in the corresponding parts of the user&#39;s body fluctuate more, e.g., amplitude information corresponding to signals of different frequencies of the electromyographic signal becomes greater, or an angular velocity value, a direction of angular velocity, an acceleration value of angular velocity, an angle, displacement information, stress, etc., of the attitude signal may also change.</span>
        <meta itemprop="num_attr" content="0110">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processing module 220</span>
        <span itemprop="definition">may segment, based on the feature information corresponding to the electromyographic signal or the feature information corresponding to the attitude signal, the movement signal. Detailed descriptions for segmenting the movement signal based on the feature information corresponding to the electromyographic signal or the feature information corresponding to the attitude signal may be found in FIG. 7 and FIG. 8 of the present disclosure and their related descriptions.</span>
        <meta itemprop="num_attr" content="0110">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">step 620</span>
        <span itemprop="definition">the movement of the user during motion may be monitored based on at least one segment of the movement signal.</span>
        <meta itemprop="num_attr" content="0111">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">monitoring of the movement of the user based on at least one segment of the movement signal</span>
        <span itemprop="definition">may include matching the at least one segment of the movement signal with at least one segment of a preset movement signal to determine the movement type of the user.</span>
        <meta itemprop="num_attr" content="0112">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the at least one segment of the preset movement signal</span>
        <span itemprop="definition">may be standard movement signals corresponding to different movements that are preset in a database.</span>
        <meta itemprop="num_attr" content="0112">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a movement type of the user during motion</span>
        <span itemprop="definition">may be determined by determining a matching degree of the at least one segment of the movement signal and the at least one segment of the preset movement signal.</span>
        <meta itemprop="num_attr" content="0112">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the movement type of the user</span>
        <span itemprop="definition">may be determined by determining whether the matching degree of the movement signal and the preset movement signal is within a first matching threshold range (e.g., greater than 80%). If so, the movement type of the user during motion may be determined based on the movement type corresponding to the preset movement signal.</span>
        <meta itemprop="num_attr" content="0112">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">monitoring the movement of the user during motion based on the at least one segment of the movement signal</span>
        <span itemprop="definition">may further include determining the movement type of the user during motion by matching the feature information corresponding to the at least one segment of the electromyographic signal with feature information corresponding to an electromyographic signal of the at least one segment of the preset movement signal.</span>
        <meta itemprop="num_attr" content="0112">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">match degree(s) between one or more feature information (e.g., frequency information, amplitude information) of the segment of the electromyographic signal and one or more feature information of the segment of the preset movement signal</span>
        <span itemprop="definition">may be determined respectively, and a determination may be made as to whether a weighted matching degree of the one or more feature information or an average matching degree of the one or more feature information is within a first matching threshold. If so, the movement type of the user during motion may be determined based on the movement type corresponding to the preset movement signal.</span>
        <meta itemprop="num_attr" content="0112">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">feature information</span>
        <span itemprop="definition">e.g., frequency information, amplitude information</span>
        <meta itemprop="num_attr" content="0112">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">monitoring the movement of the user during motion based on the at least one segment of the movement signal</span>
        <span itemprop="definition">may further include determining the movement type of the user during motion by matching the feature information corresponding to the at least one segment of the attitude signal with the feature information corresponding to the attitude signal of the at least one segment of the preset movement signal.</span>
        <meta itemprop="num_attr" content="0112">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the matching degree of the one or more feature information</span>
        <span itemprop="definition">e.g., the angular velocity value, the angular velocity direction and the acceleration value of the angular velocity, the angle, the displacement information, the stress, etc.</span>
        <meta itemprop="num_attr" content="0112">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the one or more feature information</span>
        <span itemprop="definition">may be determined respectively to determine whether the weighted matching degree or the average matching degree of the one or more feature information is within the first matching threshold.</span>
        <meta itemprop="num_attr" content="0112">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the movement type of the user</span>
        <span itemprop="definition">may be determined according to a movement type corresponding to the preset movement signal.</span>
        <meta itemprop="num_attr" content="0112">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">monitoring the movement of the user during motion based on the at least one segment of the movement signal</span>
        <span itemprop="definition">may further include determining the movement type of the user during motion by matching the feature information corresponding to the electromyographic signal and the feature information corresponding to the attitude signal of the at least one segment of the movement signal with the feature information corresponding to the electromyographic signal and the feature information corresponding to the attitude signal of the at least one segment of the preset movement signal.</span>
        <meta itemprop="num_attr" content="0112">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">monitoring the movement of the user during motion based on the at least one segment of the movement signal</span>
        <span itemprop="definition">may include determining the movement quality of the user by matching the at least one segment of the movement signal with the at least one segment of the preset movement signal. Further, if a matching degree of the movement signal and the preset movement signal is within a second matching threshold range (e.g., greater than 90%), the movement quality of the user during motion may meet the standard. In some embodiments, determining the movement of the user during motion based on the movement signal of the at least one segment may include determining the movement quality of the user during motion by matching the one or more feature information of the movement signal of the at least one segment with the one or more feature information of the at least one segment of the preset movement signal.</span>
        <meta itemprop="num_attr" content="0113">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a segment of the movement signal</span>
        <span itemprop="definition">may be a movement signal of a complete movement or a movement signal of a partial of a complete movement.</span>
        <meta itemprop="num_attr" content="0113">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">there may be different ways of force generation at different stages of the complete movement</span>
        <span itemprop="definition">that is, there may be different movement signals at the different stages of the movement, and the user movement may be monitored in real time, and thus, the accuracy of the monitored movement signal at the different stages of the complete movement may be improved.</span>
        <meta itemprop="num_attr" content="0113">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the above description of the process 600</span>
        <span itemprop="definition">is for example and illustration purposes only and does not limit the scope of application of the present disclosure.</span>
        <meta itemprop="num_attr" content="0114">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">various amendments and changes</span>
        <span itemprop="definition">can be made to process 600 under the guidance of the present disclosure.</span>
        <meta itemprop="num_attr" content="0114">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">these amendments and changes</span>
        <span itemprop="definition">are still within the scope of the present disclosure.</span>
        <meta itemprop="num_attr" content="0114">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the user&#39;s movement</span>
        <span itemprop="definition">may also be determined by a movement recognition model or a manually preset model.</span>
        <meta itemprop="num_attr" content="0114">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 7</span>
        <span itemprop="definition">is a flowchart of an exemplary process for segmenting a movement signal according to some embodiments of the present disclosure. As shown in FIG. 7 , process 700 may include the following steps.</span>
        <meta itemprop="num_attr" content="0115">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">At least one target feature point within the time domain window</span>
        <span itemprop="definition">may be determined based on a time domain window of the electromyographic signal or the attitude signal and according to a preset condition.</span>
        <meta itemprop="num_attr" content="0116">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the step</span>
        <span itemprop="definition">may be performed by the processing module 220 and/or the processing device 110 .</span>
        <meta itemprop="num_attr" content="0117">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the time domain window of the electromyographic signal</span>
        <span itemprop="definition">may include an electromyographic signal over a range of time</span>
        <meta itemprop="num_attr" content="0117">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the time domain window of the attitude signal</span>
        <span itemprop="definition">may include an attitude signal over a same range of time.</span>
        <meta itemprop="num_attr" content="0117">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a target feature point</span>
        <span itemprop="definition">refers to a signal of the movement signal with a target feature, which may represent a stage of the user&#39;s movement. For example, when a user performs a seated chest press, at the beginning, the user&#39;s arms are extended outward horizontally, begin to rotate internally, come together, and finally return to the extended state again in the horizontal direction, this process is a complete seated chest press movement.</span>
        <meta itemprop="num_attr" content="0117">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the feature information corresponding to the electromyographic signal or the attitude signal</span>
        <span itemprop="definition">may be different in each stage.</span>
        <meta itemprop="num_attr" content="0117">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the target feature point corresponding to a stage of the user&#39;s movement</span>
        <span itemprop="definition">may be determined.</span>
        <meta itemprop="num_attr" content="0117">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">one or more target feature points</span>
        <span itemprop="definition">may be determined from the time domain window based on the preset condition.</span>
        <meta itemprop="num_attr" content="0117">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the preset condition</span>
        <span itemprop="definition">may include one or more of a change in the direction of the angular velocity corresponding to the attitude signal, the angular velocity corresponding to the attitude signal being greater than or equal to an angular velocity threshold, the angle corresponding to the attitude signal reaching an angular threshold, the change of the angular velocity value corresponding to the attitude signal being the extreme value, and the amplitude information corresponding to the electromyographic signal being greater than or equal to an electromyographic threshold.</span>
        <meta itemprop="num_attr" content="0117">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the target feature points at the different stages of a movement</span>
        <span itemprop="definition">may correspond to different preset conditions.</span>
        <meta itemprop="num_attr" content="0117">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a preset condition for a target feature point when the user&#39;s arms are horizontally extended outward and then start to internally rotate</span>
        <span itemprop="definition">may be different from a preset condition for a target feature point when the arms are brought together.</span>
        <meta itemprop="num_attr" content="0117">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the target feature points of different movements</span>
        <span itemprop="definition">may correspond to different preset conditions.</span>
        <meta itemprop="num_attr" content="0117">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the chest press movement and the bent-over movement</span>
        <span itemprop="definition">may be different, and the preset conditions regarding the respective preset target feature points in these two movements may also be different.</span>
        <meta itemprop="num_attr" content="0117">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Exemplary descriptions of the preset condition</span>
        <span itemprop="definition">may refer to the description of a movement start point, a movement middle point, and a movement end point in the present disclosure.</span>
        <meta itemprop="num_attr" content="0117">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the at least one target feature point</span>
        <span itemprop="definition">may be determined from the time domain windows based on both of the time domain windows of the electromyographic signal and the attitude signal, according to the preset condition.</span>
        <meta itemprop="num_attr" content="0118">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the time domain windows of the electromyographic signal and the attitude signal</span>
        <span itemprop="definition">may include the electromyographic signal and the attitude signal over a range of time.</span>
        <meta itemprop="num_attr" content="0118">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the time of the electromyographic signal</span>
        <span itemprop="definition">may correspond to the time of the attitude signal.</span>
        <meta itemprop="num_attr" content="0118">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a time point of the electromyographic signal when the user starts to move</span>
        <span itemprop="definition">may be the same as a time point of the attitude signal when the user starts to move.</span>
        <meta itemprop="num_attr" content="0118">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the target feature point</span>
        <span itemprop="definition">here may be determined by combining the feature information corresponding to the electromyographic signal (e.g., the amplitude information) and the feature information corresponding to the attitude signal (e.g., the angular velocity value, the direction of angular velocity, the acceleration value of angular velocity, the angle, etc.).</span>
        <meta itemprop="num_attr" content="0118">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the feature information corresponding to the electromyographic signal</span>
        <span itemprop="definition">e.g., the amplitude information</span>
        <meta itemprop="num_attr" content="0118">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the feature information corresponding to the attitude signal</span>
        <span itemprop="definition">e.g., the angular velocity value, the direction of angular velocity, the acceleration value of angular velocity, the angle, etc.</span>
        <meta itemprop="num_attr" content="0118">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the movement signal</span>
        <span itemprop="definition">may be segmented based on the at least one target feature point.</span>
        <meta itemprop="num_attr" content="0119">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the step 720</span>
        <span itemprop="definition">may be performed by the processing module 220 and/or the processing device 110 .</span>
        <meta itemprop="num_attr" content="0120">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the target feature point in the electromyographic signal or the attitude signal</span>
        <span itemprop="definition">may be one or more, and the movement signal may be divided into multiple segments by one or more target feature points.</span>
        <meta itemprop="num_attr" content="0120">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the target feature point</span>
        <span itemprop="definition">may divide the electromyographic signal into two segments, where the two segments may include the electromyographic signal before the target feature point and the electromyographic signal after the target feature point.</span>
        <meta itemprop="num_attr" content="0120">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processing module 220 and/or the processing device 110</span>
        <span itemprop="definition">may extract the electromyographic signal for a certain time range around the target feature point as a segment of the electromyographic signal.</span>
        <meta itemprop="num_attr" content="0120">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the electromyographic signal</span>
        <span itemprop="definition">when the electromyographic signal has a plurality of target feature points (e.g., n-target feature points, and the first target feature point is not a beginning of the time domain window, the n th target feature point is not an end of the time domain window), the electromyographic signal may be divided into (n&#43;1) segments based on the n target feature points.</span>
        <meta itemprop="num_attr" content="0120">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the electromyographic signal</span>
        <span itemprop="definition">when the electromyographic signal has the plurality of target feature points (e.g., n-target feature points, the first target feature point is the beginning of the time domain window, the n th target feature point is not the end of the time domain window), the electromyographic signal may be divided into n segments based on the n target feature points.</span>
        <meta itemprop="num_attr" content="0120">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the electromyographic signal</span>
        <span itemprop="definition">when the electromyographic signal has the plurality of target feature points (e.g., n-target feature points, the first target feature point is the beginning of the time domain window, the n th target feature point is the end of the time domain window), the electromyographic signal may be divided into (n  1) segments based on the n target feature points.</span>
        <meta itemprop="num_attr" content="0120">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the movement stage corresponding to the target feature point</span>
        <span itemprop="definition">may include one or more types.</span>
        <meta itemprop="num_attr" content="0120">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the plurality of target feature points</span>
        <span itemprop="definition">may be used as a benchmark for segmenting the movement signal.</span>
        <meta itemprop="num_attr" content="0120">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the movement stage corresponding to the target feature point</span>
        <span itemprop="definition">may include the movement start point and the movement end point, the movement start point may be before the movement end point, and in this situation, the movement signal between the movement start point and a next movement start point may be considered as a segment of the movement signal.</span>
        <meta itemprop="num_attr" content="0120">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the target feature point</span>
        <span itemprop="definition">may include one or more of the movement start point, the movement middle point, or the movement end point.</span>
        <meta itemprop="num_attr" content="0121">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the movement start point</span>
        <span itemprop="definition">may be considered as a start point of a user movement cycle.</span>
        <meta itemprop="num_attr" content="0122">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">different movements</span>
        <span itemprop="definition">may correspond to different preset conditions.</span>
        <meta itemprop="num_attr" content="0122">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the preset condition</span>
        <span itemprop="definition">may be that the direction of the angular velocity of the movement after the movement start point changes relative to the direction of the angular velocity of the movement before the movement start point, or that the value of the angular velocity at the movement start point is approximately 0 and the acceleration value of the angular velocity at the movement start point is greater than 0.</span>
        <meta itemprop="num_attr" content="0122">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the movement starting point</span>
        <span itemprop="definition">may be set to the point when the arms are extended outward horizontally and start to internally rotate.</span>
        <meta itemprop="num_attr" content="0122">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the preset condition</span>
        <span itemprop="definition">may be that the angle of arm lift is greater than or equal to an angle threshold. Specifically, when the user performs a bent-over movement, the angle of arm lift when the user&#39;s arm is horizontal is 0, the angle of arm lift when the arm is down is negative, and the angle of arm lift when the arm is up is positive. When the user&#39;s arm is raised from the horizontal position, the arm is raised at an angle greater than 0. The point in time when the angle of the arm lift reaches the angle threshold may be considered as the movement start point.</span>
        <meta itemprop="num_attr" content="0122">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the angle threshold</span>
        <span itemprop="definition">may be   70 to   20, or as a preference, the angle threshold may be   50 to   25.</span>
        <meta itemprop="num_attr" content="0122">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the preset condition</span>
        <span itemprop="definition">may also include that the angular velocity of the arm within a specific range of time after the movement start point may be greater than or equal to an angular velocity threshold.</span>
        <meta itemprop="num_attr" content="0122">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the angular velocity threshold</span>
        <span itemprop="definition">may range from 5/s   50/s. According to preference of example, the angular velocity threshold may range from 10/s   30/s.</span>
        <meta itemprop="num_attr" content="0122">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the angular velocity of the arm</span>
        <span itemprop="definition">is continuously greater than the angular velocity threshold for a specific time range (e.g., 0.05 s, 0.1 s, 0.5 s) after an angular threshold is reached and the user&#39;s arm is continuously raised upward.</span>
        <meta itemprop="num_attr" content="0122">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a specific time range</span>
        <span itemprop="definition">e.g., 0.05 s, 0.1 s, 0.5 s</span>
        <meta itemprop="num_attr" content="0122">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the preset condition</span>
        <span itemprop="definition">continues until a movement start point is determined.</span>
        <meta itemprop="num_attr" content="0122">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the movement middle point</span>
        <span itemprop="definition">may be a point within one movement cycle from the start point.</span>
        <meta itemprop="num_attr" content="0123">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a start point of the movement</span>
        <span itemprop="definition">may be set to the time when the arms extend outward horizontally and begin to internally rotate, and the time when the arms come together may be determined as a movement middle point of the user.</span>
        <meta itemprop="num_attr" content="0123">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the preset condition</span>
        <span itemprop="definition">may be that a direction of the angular velocity at the point in time after the movement middle point changes relative to a direction of the angular velocity at the point in time before the movement middle point, and an angular velocity value at the movement middle point is approximately zero, wherein the direction of the angular velocity at the movement middle point is opposite to the direction of the angular velocity at the movement start point.</span>
        <meta itemprop="num_attr" content="0123">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a change of the angular velocity (an acceleration of angular velocity) in a first specific time range after the movement middle point</span>
        <span itemprop="definition">may be greater than an acceleration threshold of angular velocity (e.g., 0.05 rad/s).</span>
        <meta itemprop="num_attr" content="0123">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the amplitude information in the electromyographic signal corresponding to the movement middle point</span>
        <span itemprop="definition">may be greater than the electromyographic threshold while the movement middle point satisfies the preset condition described above. Since the different movements correspond to different electromyographic signals, the electromyographic threshold may be related to the user movement and the target electromyographic signal.</span>
        <meta itemprop="num_attr" content="0123">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the electromyographic signal at the pectoral muscle</span>
        <span itemprop="definition">may be the target electromyographic signal.</span>
        <meta itemprop="num_attr" content="0123">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the position corresponding to the movement middle point</span>
        <span itemprop="definition">also may be called as middle position may be approximated as the maximum point of muscle force, where the electromyographic signal may have a relatively great value.</span>
        <meta itemprop="num_attr" content="0123">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the electromyographic signal at the part of the user&#39;s body when the user performs the movement during motion</span>
        <span itemprop="definition">may be substantially higher than the electromyographic signal at the part of the user&#39;s body when the user does not perform the movement during motion (when the muscle in the particular part may be considered as a resting state).</span>
        <meta itemprop="num_attr" content="0123">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">an amplitude of the electromyographic signal at the part of the user&#39;s body when the user&#39;s movement reaches the middle position</span>
        <span itemprop="definition">may be 10 times higher than that in the resting state.</span>
        <meta itemprop="num_attr" content="0123">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the relationship between the amplitude of the electromyographic signal at the part of the user when the movement position reaches the middle position (the movement middle point) and the amplitude of the electromyographic signal in the resting state</span>
        <span itemprop="definition">may be different according to the different movement types performed by the user, and the relationship between the two may be adapted according to the actual movement.</span>
        <meta itemprop="num_attr" content="0123">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the amplitude corresponding to a second specific time range after the movement middle point</span>
        <span itemprop="definition">may be continuously greater than the electromyographic threshold.</span>
        <meta itemprop="num_attr" content="0123">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a Euler angle</span>
        <span itemprop="definition">also referred to as an angle</span>
        <meta itemprop="num_attr" content="0123">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the Euler angle at the movement middle point relative to the movement start point</span>
        <span itemprop="definition">may be greater than one or more Euler angle thresholds (also referred to as angle thresholds).</span>
        <meta itemprop="num_attr" content="0123">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a Euler angle changed in the X and Y directions</span>
        <span itemprop="definition">may be less than 25, and the Euler angle changed in the Z direction may be greater than 40 (the movement of the seated chest press is mainly related to the rotation at the Z-axis direction, the above parameters are only reference examples).</span>
        <meta itemprop="num_attr" content="0123">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the electromyographic thresholds and/or the Euler angle thresholds</span>
        <span itemprop="definition">may be stored in advance in a storage device or a hard drive of the wearable device 130 , or in the processing device 110 , or may be determined based on an actual condition and adjusted in real time.</span>
        <meta itemprop="num_attr" content="0123">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processing module 220</span>
        <span itemprop="definition">may determine, based on the time domain window of the electromyographic signal or the attitude signal, the movement middle point from a time domain window at a time point after the movement start point according to a preset condition. In some embodiments, after the movement middle point is determined, whether there are other time points that meet the preset condition within the time range from the movement start point to the movement middle point may be re-verified, and if so, a movement start point closest to the movement middle point may be selected as the best movement start point.</span>
        <meta itemprop="num_attr" content="0124">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the movement middle point</span>
        <span itemprop="definition">may be invalid, and the movement start point and movement middle point may be re-determined based on preset condition.</span>
        <meta itemprop="num_attr" content="0124">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the movement end point</span>
        <span itemprop="definition">may be a time point that is after the movement middle point, and within one movement cycle from the movement start point.</span>
        <meta itemprop="num_attr" content="0125">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the movement end point</span>
        <span itemprop="definition">may be set as a point that is one movement cycle from the movement start point, and the movement end point herein may be considered as an end of a movement cycle of the user.</span>
        <meta itemprop="num_attr" content="0125">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the movement start point</span>
        <span itemprop="definition">may be set as a time point when the arms extend horizontally to the left and right and start internal rotation, the time point when the arms close together may be the movement middle point of the user, and the time point when the arms return to the extended state again from the horizontal direction may correspond to the movement end point of the user.</span>
        <meta itemprop="num_attr" content="0125">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the preset condition</span>
        <span itemprop="definition">may be that a changed angular velocity value corresponding to the attitude signal is an extreme value.</span>
        <meta itemprop="num_attr" content="0125">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the change in Euler angle</span>
        <span itemprop="definition">should exceed a certain Euler angle threshold, e.g., 20, in the time range from the movement middle point to the movement end point.</span>
        <meta itemprop="num_attr" content="0125">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processing module 220</span>
        <span itemprop="definition">may determine the movement end point from the time domain window after the movement middle point based on the time domain windows of the electromyographic signal and the attitude signal according to the preset condition.</span>
        <meta itemprop="num_attr" content="0125">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the movement start point and the movement middle point</span>
        <span itemprop="definition">may be invalid, and the movement start point, the movement middle point, and the movement end point may be re-determined based on the preset condition.</span>
        <meta itemprop="num_attr" content="0125">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">At least one set of the movement start point, the movement middle point, and the movement end point in the movement signal</span>
        <span itemprop="definition">may be repeatedly determined, and the movement signal may be segmented based on the at least one set of the movement start point, the movement middle point, and the movement end point as the target feature points.</span>
        <meta itemprop="num_attr" content="0126">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the step</span>
        <span itemprop="definition">may be performed by the processing module 220 and/or the processing device 110 . It should be noted that the segmentation of the movement signal is not limited to be based on the above movement start point, the movement middle point and the movement end point, but may also include other time points.</span>
        <meta itemprop="num_attr" content="0126">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a first time point</span>
        <span itemprop="definition">may be a movement start point</span>
        <meta itemprop="num_attr" content="0126">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a second time point</span>
        <span itemprop="definition">may be a moment of the maximum angular velocity of the internal rotation</span>
        <meta itemprop="num_attr" content="0126">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a third time point</span>
        <span itemprop="definition">may be the movement middle point</span>
        <meta itemprop="num_attr" content="0126">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a fourth time point</span>
        <span itemprop="definition">may be the moment of the maximum angular velocity of external rotation</span>
        <meta itemprop="num_attr" content="0126">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a fifth time point</span>
        <span itemprop="definition">may be the moment when the arms return to extend left and right</span>
        <meta itemprop="num_attr" content="0126">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the angular velocity</span>
        <span itemprop="definition">is 0, that is, the movement end point.</span>
        <meta itemprop="num_attr" content="0126">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the second time point</span>
        <span itemprop="definition">is added as a 1  4 marker point of the movement cycle</span>
        <meta itemprop="num_attr" content="0126">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the movement end point described in the above embodiments</span>
        <span itemprop="definition">is used as the fourth time point for marking the 3  4 position of the movement cycle</span>
        <meta itemprop="num_attr" content="0126">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the fifth time point</span>
        <span itemprop="definition">is added as an end point of the complete movement.</span>
        <meta itemprop="num_attr" content="0126">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a recognition of the movement quality</span>
        <span itemprop="definition">may be done based on the signal of the first 3  4 of the movement cycle (i.e., the recognition of the movement quality for a single cycle does not depend on a complete analysis of the signal of a whole cycle), which may complete the monitoring and feedback of the user&#39;s movement without the end of a current cycle.</span>
        <meta itemprop="num_attr" content="0126">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">all signals of the process of the whole movement</span>
        <span itemprop="definition">may be completely recorded to be easily uploaded to the cloud or the mobile terminal device, thus more methods may be adopted to monitor the user&#39;s movement.</span>
        <meta itemprop="num_attr" content="0126">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the cycle of the movement</span>
        <span itemprop="definition">may be quite long, and each stage may have different force patterns.</span>
        <meta itemprop="num_attr" content="0126">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the above method for determining each time point</span>
        <span itemprop="definition">may be adopted to divide the movement into multiple stages, and the signal for each stage may be recognized and fed back separately to improve timeliness of feedback of the user&#39;s movement.</span>
        <meta itemprop="num_attr" content="0126">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the above segmentation and monitoring of the movement signal based on the movement start point, movement middle point and movement end point as a set of target feature points</span>
        <span itemprop="definition">is only an exemplary illustration.</span>
        <meta itemprop="num_attr" content="0127">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the user&#39;s movement signal</span>
        <span itemprop="definition">may also be segmented and monitored based on any one or more of the movement start point, the movement middle point and the movement end point as the target feature points.</span>
        <meta itemprop="num_attr" content="0127">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the movement signal</span>
        <span itemprop="definition">may be segmented and monitored by using the movement start point as the target feature point.</span>
        <meta itemprop="num_attr" content="0127">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the movement start point and the movement end point</span>
        <span itemprop="definition">may be used as a set of target feature points to segment and monitor the movement signal, and other time points or time ranges that can be used as the target feature points are within the scope of protection of the present disclosure.</span>
        <meta itemprop="num_attr" content="0127">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">step 710 and step 720</span>
        <span itemprop="definition">may be performed simultaneously by the processing module 220 .</span>
        <meta itemprop="num_attr" content="0128">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">step 710 and step 720</span>
        <span itemprop="definition">may be performed simultaneously by the processing module 220 and the processing device 110 , respectively.</span>
        <meta itemprop="num_attr" content="0128">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 8</span>
        <span itemprop="definition">is a diagram illustrating exemplary movement signal segmentation according to some embodiments of the present disclosure.</span>
        <meta itemprop="num_attr" content="0129">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a horizontal coordinate in FIG. 8</span>
        <span itemprop="definition">may indicate a motion time of a user, and a vertical coordinate may indicate amplitude information of an electromyographic signal of a muscle part (e.g., pectoralis major) during seated chest press.</span>
        <meta itemprop="num_attr" content="0129">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 8</span>
        <span itemprop="definition">may also include an angular velocity curve and a Euler angle curve corresponding to an attitude signal of the wrist position of the user during motion.</span>
        <meta itemprop="num_attr" content="0129">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the angular velocity curve</span>
        <span itemprop="definition">is configured to represent a velocity change of the user during motion and the Euler angle curve is configured to represent a position situation of a user&#39;s body part during motion.</span>
        <meta itemprop="num_attr" content="0129">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">point A1</span>
        <span itemprop="definition">is determined as the movement start point according to the preset condition.</span>
        <meta itemprop="num_attr" content="0129">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a direction of the angular velocity at a time point after the user&#39;s movement start point A1</span>
        <span itemprop="definition">changes relative to the direction of the angular velocity at a time point before the movement start point A1.</span>
        <meta itemprop="num_attr" content="0129">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the angular velocity value at the movement start point A1</span>
        <span itemprop="definition">is approximately 0, and an acceleration value of the angular velocity at the movement start point A1 is greater than 0.</span>
        <meta itemprop="num_attr" content="0129">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">point B1</span>
        <span itemprop="definition">is determined as the movement middle point according to the preset condition. Specifically, the direction of the angular velocity at the time point after the user&#39;s movement middle point B1 changes relative to the direction of the angular velocity at the time point before the movement middle point B 1 , and the angular velocity value at the movement middle point B1 is approximately 0. The direction of the angular velocity at the movement middle point B1 is opposite to the direction of the angular velocity at the movement start point A1. In addition, the amplitude of the electromyographic signal (shown as the electromyographic signal in FIG. 8 ) corresponding to the movement middle point B1 is greater than the electromyographic threshold.</span>
        <meta itemprop="num_attr" content="0130">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">point Cl</span>
        <span itemprop="definition">is determined as the movement end point according to the preset condition. Specifically, a changed angular velocity value at the movement end point Cl is the extreme value from the movement start point A1 to the movement end point Cl.</span>
        <meta itemprop="num_attr" content="0131">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the process 700</span>
        <span itemprop="definition">may complete the movement segmentation shown in FIG. 8 , such that the movement signal from the movement start point A1 to the movement end point Cl shown in FIG. 8 may be considered as a segment of the motion.</span>
        <meta itemprop="num_attr" content="0131">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a time interval between the movement middle point and the movement start point</span>
        <span itemprop="definition">is greater than a specific time threshold (e.g., 1  2 of a movement cycle)</span>
        <meta itemprop="num_attr" content="0132">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processing module 220</span>
        <span itemprop="definition">may re-determine the movement start point to improve the accuracy of the movement segmentation.</span>
        <meta itemprop="num_attr" content="0132">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the specific time threshold</span>
        <span itemprop="definition">here may be stored in a storage device or a hard drive of the wearable device 130 , or in the processing device 110 , or may be determined or adjusted based on the actual situation of the user during motion. For example, if the time interval between the movement start point A1 and the movement middle point B1 in FIG. 8 is greater than a specific time threshold, the processing module 220 may re-determine the movement start point, thereby improving the accuracy of the movement segmentation.</span>
        <meta itemprop="num_attr" content="0132">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the segmentation of the movement signal</span>
        <span itemprop="definition">is not limited to be based on the above movement start point A1, the movement middle point B1 and the movement end point Cl, but may also include other time points, and the selection of the time points may be made according to the complexity of the movement.</span>
        <meta itemprop="num_attr" content="0132">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">an abrupt electromyographic signal</span>
        <span itemprop="definition">may be described by using a singularity, and an exemplary singularity may include a burr signal, a discontinuous signal, etc.</span>
        <meta itemprop="num_attr" content="0133">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">monitoring the movement of the user during motion based at least on the feature information corresponding to the electromyographic signal or the feature information corresponding to the attitude signal</span>
        <span itemprop="definition">may further include: pre-processing the electromyographic signal in a frequency domain or a time domain, obtaining, based on the preprocessed electromyographic signal, the feature information corresponding to the electromyographic signal, and monitoring, based on the feature information corresponding to the electromyographic signal or the feature information corresponding to the attitude signal, the movement of the user during motion.</span>
        <meta itemprop="num_attr" content="0133">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">pre-processing the electromyographic signal in the frequency domain or the time domain</span>
        <span itemprop="definition">may include filtering the electromyographic signal in the frequency domain to select or retain components of the electromyographic signal in a particular frequency range in the frequency domain.</span>
        <meta itemprop="num_attr" content="0133">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the obtaining module 210</span>
        <span itemprop="definition">may obtain an electromyographic signal in a frequency range of 1 Hz-1000 Hz, filter the electromyographic signal, and select an electromyographic signal in a specific frequency range (e.g., 30 Hz-150 Hz) for subsequent processing.</span>
        <meta itemprop="num_attr" content="0133">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the specific frequency range</span>
        <span itemprop="definition">may be 10 Hz-500 Hz.</span>
        <meta itemprop="num_attr" content="0133">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the specific frequency range</span>
        <span itemprop="definition">may be 15 Hz-300 Hz or 30 Hz-150 Hz.</span>
        <meta itemprop="num_attr" content="0133">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a filtering process</span>
        <span itemprop="definition">may include a low-pass filter processing.</span>
        <meta itemprop="num_attr" content="0133">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the low-pass filter</span>
        <span itemprop="definition">may include an LC passive filter, an RC passive filter, an RC active filter, a passive filter composed of special elements.</span>
        <meta itemprop="num_attr" content="0133">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the passive filter composed of the special elements</span>
        <span itemprop="definition">may include one or more of a piezoelectric ceramic filter, a crystal filter, an acoustic surface filter.</span>
        <meta itemprop="num_attr" content="0133">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the specific frequency range</span>
        <span itemprop="definition">is not limited to the above range, but may also be other ranges, which may be selected according to the actual situation. More descriptions for monitoring, according to the feature information corresponding to the electromyographic signal or the feature information corresponding to the attitude signal, the movement of the user during motion may be found in FIG. 5 , FIG. 6 of the present disclosure and their relevant descriptions.</span>
        <meta itemprop="num_attr" content="0133">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">pre-processing the electromyographic signal in the frequency domain or the time domain</span>
        <span itemprop="definition">may further include signal correction processing of the electromyographic signal in the time domain.</span>
        <meta itemprop="num_attr" content="0134">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the signal correction processing</span>
        <span itemprop="definition">refers to a correction to the singularity (e.g., the burr signal, the discontinuous signal, etc.) in the electromyographic signal.</span>
        <meta itemprop="num_attr" content="0134">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the signal correction processing of the electromyographic signal in the time domain</span>
        <span itemprop="definition">may include determining the singularity in the electromyographic signal, i.e., determining the abrupt signal in the electromyographic signal.</span>
        <meta itemprop="num_attr" content="0134">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the singularity</span>
        <span itemprop="definition">may be a sudden change in the amplitude of an electromyographic signal within a certain moment, causing a discontinuity in the signal.</span>
        <meta itemprop="num_attr" content="0134">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the electromyographic signal</span>
        <span itemprop="definition">is morphologically smooth and there is no abrupt change in the amplitude of the electromyographic signal, but there is the abrupt change in the first-order differential of the electromyographic signal, and the first-order differential is discontinuous.</span>
        <meta itemprop="num_attr" content="0134">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the method for determining the singularity in the electromyographic signal</span>
        <span itemprop="definition">may include, but is not limited to, one or more of a Fourier transform, a wavelet transform, a fractal dimension, etc.</span>
        <meta itemprop="num_attr" content="0134">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the signal correction processing of the electromyographic signal in the time domain</span>
        <span itemprop="definition">may include removing the singularity in the electromyographic signal, for example, removing signals within a period of time at and near the singularity.</span>
        <meta itemprop="num_attr" content="0134">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the signal correction processing of the electromyographic signal in the time domain</span>
        <span itemprop="definition">may include correcting the singularity of the electromyographic signal according to the feature information of the electromyographic signal in the specific time range, such as adjusting the amplitude of the singularity based on the signals around the singularity.</span>
        <meta itemprop="num_attr" content="0134">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the feature information of the electromyographic signal</span>
        <span itemprop="definition">may include the amplitude information, the statistic information of the amplitude information, etc.</span>
        <meta itemprop="num_attr" content="0134">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the statistic information of amplitude information</span>
        <span itemprop="definition">(also referred to as an amplitude entropy) refers to a distribution of the amplitude information of the electromyographic signal in the time domain.</span>
        <meta itemprop="num_attr" content="0134">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the singularity</span>
        <span itemprop="definition">may be corrected based on the electromyographic signal in the specific time range before or after the location of the singularity.</span>
        <meta itemprop="num_attr" content="0134">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a signal processing algorithm</span>
        <span itemprop="definition">e.g., the Fourier transform, the wavelet transform, the fractal dimension</span>
        <meta itemprop="num_attr" content="0134">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the singularity</span>
        <span itemprop="definition">may be corrected based on the electromyographic signal in the specific time range before or after the location of the singularity.</span>
        <meta itemprop="num_attr" content="0134">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the electromyographic signal at the abrupt trough</span>
        <span itemprop="definition">may be supplemented based on the feature information (e.g., the amplitude information, the statistic information of the amplitude information) of the electromyographic signal in a specific time range (e.g., 5 ms-60 ms) before or after the abrupt trough.</span>
        <meta itemprop="num_attr" content="0134">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 9</span>
        <span itemprop="definition">is a flowchart of an exemplary process for pre-processing an electromyographic signal according to some embodiments of the present disclosure. As shown in FIG. 9 , the process 900 may include following steps.</span>
        <meta itemprop="num_attr" content="0135">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">step 910</span>
        <span itemprop="definition">different time windows may be selected from the time domain window of the electromyographic signal based on the time domain window of the electromyographic signal, wherein the different time windows may cover different time ranges, respectively.</span>
        <meta itemprop="num_attr" content="0136">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the step</span>
        <span itemprop="definition">may be performed by the processing module 220 and/or the processing device 110 .</span>
        <meta itemprop="num_attr" content="0137">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the different windows</span>
        <span itemprop="definition">may include at least one specific window.</span>
        <meta itemprop="num_attr" content="0137">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the specific window</span>
        <span itemprop="definition">refers to a window with a specific time length selected from the time domain window. For example, when the time length of the time domain window of the electromyographic signal is 3 s, a time length of the specific window may be 100 ms.</span>
        <meta itemprop="num_attr" content="0137">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the specific window</span>
        <span itemprop="definition">may include a plurality of different time windows. Merely as way of exemplary illustration, the specific window may include a first time window and a second time window. The first time window may refer to a window corresponding to a partial time length of the specific window.</span>
        <meta itemprop="num_attr" content="0137">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the time length of the first time window</span>
        <span itemprop="definition">may be 80 ms.</span>
        <meta itemprop="num_attr" content="0137">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the second time window</span>
        <span itemprop="definition">may be another window corresponding to the partial time length of the specific window.</span>
        <meta itemprop="num_attr" content="0137">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the first time window and the second time window</span>
        <span itemprop="definition">may be consecutive time windows within a same specific window.</span>
        <meta itemprop="num_attr" content="0137">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the first time window and the second time window</span>
        <span itemprop="definition">may also be two discrete or overlapping time windows within the same specific window.</span>
        <meta itemprop="num_attr" content="0137">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the time length of the specific window</span>
        <span itemprop="definition">is 100 ms</span>
        <meta itemprop="num_attr" content="0137">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the time length of the first time window</span>
        <span itemprop="definition">may be 80 ms and the time length of the second time window may be 25 ms.</span>
        <meta itemprop="num_attr" content="0137">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the second time window</span>
        <span itemprop="definition">may be overlapped with the first time window in 5 ms.</span>
        <meta itemprop="num_attr" content="0137">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processing module 220</span>
        <span itemprop="definition">may slide and update the specific window sequentially from an initially time point of the time domain window of the electromyographic signal according to the specific time length based on the time domain window of the electromyographic signal, and may continue to divide an updated specific window into the first time window and the second time window.</span>
        <meta itemprop="num_attr" content="0137">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the specific time length mentioned here</span>
        <span itemprop="definition">may be less than 1 s, 2 s, 3 s, etc.</span>
        <meta itemprop="num_attr" content="0137">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processing module 220</span>
        <span itemprop="definition">may select a specific window of a specific time length of 100 ms and divide that specific window into a first time window of 80 ms and a second time window of 20 ms.</span>
        <meta itemprop="num_attr" content="0137">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the specific window</span>
        <span itemprop="definition">may be updated by sliding along the time direction.</span>
        <meta itemprop="num_attr" content="0137">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a sliding distance</span>
        <span itemprop="definition">here may be a time length of the second time window (e.g., 20 ms) or other suitable time lengths, e.g., 30 ms, 40 ms, etc.</span>
        <meta itemprop="num_attr" content="0137">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the burr signal</span>
        <span itemprop="definition">may be determined based on the feature information corresponding to the electromyographic signal in the different time windows.</span>
        <meta itemprop="num_attr" content="0138">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the step</span>
        <span itemprop="definition">may be performed by the processing module 220 and/or the processing device 110 .</span>
        <meta itemprop="num_attr" content="0139">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the feature information corresponding to the electromyographic signal</span>
        <span itemprop="definition">may include at least one of the amplitude information, the statistic information of the amplitude information.</span>
        <meta itemprop="num_attr" content="0139">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processing module 220</span>
        <span itemprop="definition">may obtain the amplitude information or the statistic information of the amplitude information corresponding to the electromyographic signal in different time windows (e.g., the first time window, the second time window) to determine the location of the burr signal.</span>
        <meta itemprop="num_attr" content="0139">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">time windows</span>
        <span itemprop="definition">e.g., the first time window, the second time window</span>
        <meta itemprop="num_attr" content="0139">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">process 900</span>
        <span itemprop="definition">is for example and illustration purposes only and does not limit the scope of application of the present disclosure.</span>
        <meta itemprop="num_attr" content="0140">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">various amendments and changes</span>
        <span itemprop="definition">can be made to process 900 under the guidance of the present disclosure.</span>
        <meta itemprop="num_attr" content="0140">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the specific window</span>
        <span itemprop="definition">is not limited to include the first time window and the second time window described above, but may also include other time windows, for example, a third time window, a fourth time window, etc.</span>
        <meta itemprop="num_attr" content="0140">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the specific range of moments before or after the position of the burr signal</span>
        <span itemprop="definition">may be adapted according to the length of the burr signal, which may not be further limited herein.</span>
        <meta itemprop="num_attr" content="0140">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">these amendments and changes</span>
        <span itemprop="definition">are still within the scope of the present disclosure.</span>
        <meta itemprop="num_attr" content="0140">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 10</span>
        <span itemprop="definition">is a flowchart illustrating an exemplary process for determining a burr signal according to some embodiments of the present disclosure. As shown in FIG. 10 , process 1000 may include the following steps.</span>
        <meta itemprop="num_attr" content="0141">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">first amplitude information corresponding to the electromyographic signal within the first time window and second amplitude information corresponding to the electromyographic signal within the second time window</span>
        <span itemprop="definition">may be determined.</span>
        <meta itemprop="num_attr" content="0142">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the step</span>
        <span itemprop="definition">may be performed by the processing module 220 and/or the processing device 110 .</span>
        <meta itemprop="num_attr" content="0143">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processing module 220</span>
        <span itemprop="definition">may select the time lengths of the first time window and the second time window, and extract the first amplitude information corresponding to the electromyographic signal during the time length of the first time window and the second amplitude information corresponding to the electromyographic signal during the time length of the second time window.</span>
        <meta itemprop="num_attr" content="0143">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the first amplitude information</span>
        <span itemprop="definition">may include an average amplitude of the electromyographic signal during the first time window</span>
        <meta itemprop="num_attr" content="0143">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the second amplitude information</span>
        <span itemprop="definition">may include the average amplitude of the electromyographic signal during the second time window.</span>
        <meta itemprop="num_attr" content="0143">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processing module 220</span>
        <span itemprop="definition">may select a time length of a first time window as 80 ms, and extract the first amplitude information corresponding to the electromyographic signal within the first time window.</span>
        <meta itemprop="num_attr" content="0143">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processing module 220</span>
        <span itemprop="definition">may select a time length of a second time window as 20 ms, and extract the second amplitude information corresponding to the electromyographic signal within the second time window.</span>
        <meta itemprop="num_attr" content="0143">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a selection of the time length of the first time window and the time length of the second time window</span>
        <span itemprop="definition">may be related to the shortest burr signal length and amount of computation of the system.</span>
        <meta itemprop="num_attr" content="0144">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the time length of the first time window and the time length of the second time window</span>
        <span itemprop="definition">may be selected according to the feature of the burr signal.</span>
        <meta itemprop="num_attr" content="0144">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the time length of an electro-cardio burr signal</span>
        <span itemprop="definition">is 40 ms-100 ms</span>
        <meta itemprop="num_attr" content="0144">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the time interval between two burr signals in the electro-cardio signal</span>
        <span itemprop="definition">may be about 1 s</span>
        <meta itemprop="num_attr" content="0144">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a peak point of the burr signal</span>
        <span itemprop="definition">is basically symmetrical on both sides</span>
        <meta itemprop="num_attr" content="0144">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">an amplitude distribution of the burr signal</span>
        <span itemprop="definition">is relatively even on both sides, etc.</span>
        <meta itemprop="num_attr" content="0144">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a time length less than the length of the burr signal</span>
        <span itemprop="definition">e.g., a half of the length of the burr signal, may be selected as the time length of the second time window, and the time length of the first time window may be greater than (e.g., four times) the time length of the second time window.</span>
        <meta itemprop="num_attr" content="0144">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the time length of the first time window</span>
        <span itemprop="definition">may be within a range of an interval (about 1 s) between burr signals minus the time length of the second time window.</span>
        <meta itemprop="num_attr" content="0144">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the above selected time length of the first time window and the time length of the second time window</span>
        <span itemprop="definition">are not limited to the above description, as long as a sum of the time length of the second time window and the time length of the first time window is less than a time interval of adjacent two burr signals, or the time length of the second time window is less than a single burr signal length, or an amplitude of the electromyographic signal within the second time window and an amplitude of the electromyographic signal the first time window have a good discrimination.</span>
        <meta itemprop="num_attr" content="0144">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a determination</span>
        <span itemprop="definition">may be made as whether a ratio of the second amplitude information to the first amplitude information is greater than a threshold.</span>
        <meta itemprop="num_attr" content="0145">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the step</span>
        <span itemprop="definition">may be performed by the processing module 220 and/or the processing device 110 .</span>
        <meta itemprop="num_attr" content="0146">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processing module 220</span>
        <span itemprop="definition">may determine whether the ratio of the second amplitude information corresponding to the electromyographic signal in the second time window to the first amplitude information corresponding to the electromyographic signal in the first time window is greater than the threshold.</span>
        <meta itemprop="num_attr" content="0146">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the threshold</span>
        <span itemprop="definition">here may be stored in a storage device or a hard drive of the wearable device 130 , or in the processing device 110 , or may be adjusted according to an actual situation.</span>
        <meta itemprop="num_attr" content="0146">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">step 1020</span>
        <span itemprop="definition">may proceed to step 1030 .</span>
        <meta itemprop="num_attr" content="0146">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">step 1020</span>
        <span itemprop="definition">may proceed to step 1040 .</span>
        <meta itemprop="num_attr" content="0146">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a signal correction processing</span>
        <span itemprop="definition">may be performed on the electromyographic signal within the second time window.</span>
        <meta itemprop="num_attr" content="0147">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the step</span>
        <span itemprop="definition">may be performed by the processing module 220 and/or the processing device 110 .</span>
        <meta itemprop="num_attr" content="0148">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processing module 220</span>
        <span itemprop="definition">may perform the signal correction processing on the electromyographic signal within the second time window based on a comparison result of the ratio of the second amplitude information to the first amplitude information and the threshold in step 1020 . For example, in some embodiments, if the ratio of the second amplitude information to the first amplitude information is greater than the threshold, then the electromyographic signal in the second time window corresponding to the second amplitude information may be a burr signal.</span>
        <meta itemprop="num_attr" content="0148">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">processing the electromyographic signal within the second time window</span>
        <span itemprop="definition">may include performing a signal correction processing on the electromyographic signal within the second time window based on the electromyographic signal within a specific time range before or after the second time window.</span>
        <meta itemprop="num_attr" content="0148">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the signal correction processing of the electromyographic signal within the second time window</span>
        <span itemprop="definition">may include, but is not limited to, a padding, an interpolation, etc.</span>
        <meta itemprop="num_attr" content="0148">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the specific time range herein</span>
        <span itemprop="definition">may be 5 ms-60 ms. According to preference of example, the specific time range may be 10 ms-50 ms or 20 ms-40 ms.</span>
        <meta itemprop="num_attr" content="0148">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the specific time range</span>
        <span itemprop="definition">is not limited to the above range, for example, the specific time range may be greater than 60 ms, less than 5 ms, or other ranges. In practical application scenarios, the specific time range may be adapted based on the duration of the burr signal.</span>
        <meta itemprop="num_attr" content="0148">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">step 1040</span>
        <span itemprop="definition">an electromyographic signal within the second time window may be retained.</span>
        <meta itemprop="num_attr" content="0149">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the step</span>
        <span itemprop="definition">may be performed by the processing module 220 and/or the processing device 110 .</span>
        <meta itemprop="num_attr" content="0150">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processing module 220</span>
        <span itemprop="definition">may perform a retention on the electromyographic signal within the second time window according to the comparison result of the ratio of the second amplitude information to the first amplitude information and the threshold in step 1020 .</span>
        <meta itemprop="num_attr" content="0150">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the ratio of the second amplitude information to the first amplitude information</span>
        <span itemprop="definition">is not greater than the threshold, then the electromyographic signal within the second time window corresponding to the second amplitude information may be a normal electromyographic signal, and the normal electromyographic signal may be retained, i.e., the electromyographic signal within the second time window may be retained.</span>
        <meta itemprop="num_attr" content="0150">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the amplitude of the electromyographic signal</span>
        <span itemprop="definition">is gradually increasing since electrical charges gradually accumulates during muscular exertion, so that the amplitude of the electromyographic signal within two adjacent time windows (e.g., the first time window and the second time window) does not change abruptly in the absence of a burr signal.</span>
        <meta itemprop="num_attr" content="0151">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">whether there is the burr signal in the electromyographic signal</span>
        <span itemprop="definition">may be determined and the burr signal may be removed according to the process 1000 , to realize a real-time processing of the burr signal, thereby enabling the wearable device 130 or the mobile terminal device 140 to provide a real-time feedback of the motion state to the user, and helping the user to perform motion more scientifically.</span>
        <meta itemprop="num_attr" content="0151">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the time length corresponding to the first time window</span>
        <span itemprop="definition">may be greater than the time length corresponding to the second time window.</span>
        <meta itemprop="num_attr" content="0152">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a specific time length corresponding to a specific window</span>
        <span itemprop="definition">may be less than 1 s.</span>
        <meta itemprop="num_attr" content="0152">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the ratio of the time length corresponding to the first time window to the time length corresponding to the second time window</span>
        <span itemprop="definition">may be greater than 2.</span>
        <meta itemprop="num_attr" content="0152">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the time length corresponding to the first time window, the time length corresponding to the second time window, and the specific time length corresponding to the specific window</span>
        <span itemprop="definition">may be selected to ensure that the shortest burr signal (e.g., 40 ms) can be removed, and the system has a high signal-to-noise ratio, the calculation volume of the system may be decreased, repeated calculation of the system may be avoided, and the time complexity may be reduced, thereby improving the calculation efficiency and the calculation accuracy of the system.</span>
        <meta itemprop="num_attr" content="0152">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the shortest burr signal</span>
        <span itemprop="definition">e.g. 40 ms</span>
        <meta itemprop="num_attr" content="0152">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">process 1000</span>
        <span itemprop="definition">is for example and illustration purposes only, and does not limit the scope of application of the present disclosure.</span>
        <meta itemprop="num_attr" content="0153">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">various amendments and changes</span>
        <span itemprop="definition">may be made to process 1000 under the guidance of the present disclosure.</span>
        <meta itemprop="num_attr" content="0153">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the above process 1000</span>
        <span itemprop="definition">is only an example where the singularity is the burr signal, and when the singularity is a trough signal, each of the above steps (e.g., step 1010 , step 1020 , step 1030 , etc.) and the technical schemes may be adjusted or other methods may be used to perform the signal correction processing.</span>
        <meta itemprop="num_attr" content="0153">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">these amendments and changes</span>
        <span itemprop="definition">are still within the scope of the present disclosure.</span>
        <meta itemprop="num_attr" content="0153">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the signal correction processing</span>
        <span itemprop="definition">may further be performed on the singularity of the electromyographic signal by the other methods, e.g., a high-pass method, a low-pass method, a band-pass method, a wavelet transform reconstruction method, etc.</span>
        <meta itemprop="num_attr" content="0154">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a 100 Hz high-pass filter</span>
        <span itemprop="definition">may be used for a removal of the burr signal.</span>
        <meta itemprop="num_attr" content="0154">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the other methods of the signal processing of the electromyographic signal</span>
        <span itemprop="definition">such as a filtering processing, a signal amplification, a phase adjustment, etc., may also be performed.</span>
        <meta itemprop="num_attr" content="0154">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the electromyographic signal of the user collected by the electromyographic sensor</span>
        <span itemprop="definition">may be converted into a digital electromyographic signal by an analog-to-digital converter (ADC), and the converted digital electromyographic signal may be subjected to a filtering process, which may filter out an industrial frequency signal and its harmonic signal, etc.</span>
        <meta itemprop="num_attr" content="0154">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">ADC</span>
        <span itemprop="definition">analog-to-digital converter</span>
        <meta itemprop="num_attr" content="0154">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processing of the electromyographic signal</span>
        <span itemprop="definition">may further include removing motion artifacts of the user.</span>
        <meta itemprop="num_attr" content="0154">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the motion artifacts</span>
        <span itemprop="definition">here refer to signal noises generated by a relative movement of the muscles at the position to be measured relative to the electromyographic module during an obtaining process of the electromyographic signal while the user in motion.</span>
        <meta itemprop="num_attr" content="0154">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the attitude signal</span>
        <span itemprop="definition">may be obtained by the attitude sensor on the wearable device 130 .</span>
        <meta itemprop="num_attr" content="0155">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the attitude sensor on the wearable device 130</span>
        <span itemprop="definition">may be distributed on the limb areas (e.g., the arms, the legs, etc.), the trunk areas (e.g., the chest, the abdomen, the back, the waist, etc.), and the head, etc.</span>
        <meta itemprop="num_attr" content="0155">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the attitude sensor</span>
        <span itemprop="definition">may enable the collection of the attitude signal from other parts of the body such as the limb parts and the trunk parts.</span>
        <meta itemprop="num_attr" content="0155">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the attitude sensor</span>
        <span itemprop="definition">may be a sensor of an attitude and heading reference system (AHRS) with an attitude fusion algorithm.</span>
        <meta itemprop="num_attr" content="0155">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">AHRS</span>
        <span itemprop="definition">attitude and heading reference system</span>
        <meta itemprop="num_attr" content="0155">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the attitude fusion algorithm</span>
        <span itemprop="definition">may fuse data from a nine-axis inertial measurement unit (IMU) with a three-axis acceleration sensor, a three-axis angular velocity sensor, and a three-axis geomagnetic sensor into Euler angles or quaternions to obtain the attitude signal of the user&#39;s body part where the attitude sensor is located.</span>
        <meta itemprop="num_attr" content="0155">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processing module 220 and/or the processing device 110</span>
        <span itemprop="definition">may determine the feature information corresponding to the attitude based on the attitude signal.</span>
        <meta itemprop="num_attr" content="0155">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the feature information corresponding to the attitude signal</span>
        <span itemprop="definition">may include, but is not limited to, the value of angular velocity, the direction of angular velocity, the acceleration value of angular velocity, etc.</span>
        <meta itemprop="num_attr" content="0155">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the attitude sensor</span>
        <span itemprop="definition">may be a strain sensor.</span>
        <meta itemprop="num_attr" content="0155">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the strain sensor</span>
        <span itemprop="definition">may obtain a bending direction and a bending angle at the user&#39;s joints, thereby obtaining the attitude signal during the user&#39;s motion.</span>
        <meta itemprop="num_attr" content="0155">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the strain sensor</span>
        <span itemprop="definition">may be set at the knee joint of the user.</span>
        <meta itemprop="num_attr" content="0155">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the user&#39;s body part</span>
        <span itemprop="definition">acts on the strain sensor, and the bending direction and the bending angle at the knee joint of the user may be determined based on the change in resistance or length of the strain sensor, thereby obtaining the attitude signal of the user&#39;s leg.</span>
        <meta itemprop="num_attr" content="0155">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the attitude sensor</span>
        <span itemprop="definition">may also include a fiber optic sensor, and the attitude signal may be represented by a change in direction after bending of a fiber from the fiber optic sensor.</span>
        <meta itemprop="num_attr" content="0155">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the attitude sensor</span>
        <span itemprop="definition">may also be a magnetic flux sensor, and the attitude signal may be represented by transformation of the magnetic flux.</span>
        <meta itemprop="num_attr" content="0155">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the type of attitude sensor</span>
        <span itemprop="definition">is not limited to the above sensors, but can also be other sensors, the sensors that can obtain the user&#39;s attitude signal are within the scope of the attitude sensor of the present disclosure.</span>
        <meta itemprop="num_attr" content="0155">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 11</span>
        <span itemprop="definition">is a flowchart of an exemplary process for determining feature information corresponding to an attitude signal according to some embodiments of the present disclosure. As shown in FIG. 11 , the process 1100 may include following steps.</span>
        <meta itemprop="num_attr" content="0156">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">step 1110</span>
        <span itemprop="definition">a target coordinate system and a conversion relationship between the target coordinate system and at least one original coordinate system may be obtained.</span>
        <meta itemprop="num_attr" content="0157">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the step</span>
        <span itemprop="definition">may be performed by the processing module 220 and/or the processing device 110 .</span>
        <meta itemprop="num_attr" content="0158">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the original coordinate system</span>
        <span itemprop="definition">may be a coordinate system corresponding to the attitude sensor set on the human body.</span>
        <meta itemprop="num_attr" content="0158">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">each attitude sensor on the wearable device 130</span>
        <span itemprop="definition">is distributed on different parts of the human body, so that installation angles of the attitude sensors are different, and the attitude sensors in different parts use their own coordinate systems as the original coordinate systems, so the attitude sensors in different parts have different original coordinate systems.</span>
        <meta itemprop="num_attr" content="0158">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">an obtained attitude signal of the each attitude sensor</span>
        <span itemprop="definition">may be represented in its corresponding original coordinate system.</span>
        <meta itemprop="num_attr" content="0158">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the target coordinate system</span>
        <span itemprop="definition">refers to a human coordinate system established based on the human body.</span>
        <meta itemprop="num_attr" content="0158">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a length direction of the human torso</span>
        <span itemprop="definition">i.e., a direction perpendicular to a transverse plane of the body</span>
        <meta itemprop="num_attr" content="0158">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">an anterior-posterior direction of the human torso</span>
        <span itemprop="definition">i.e., a direction perpendicular to the coronal plane of the body</span>
        <meta itemprop="num_attr" content="0158">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a left-right direction of the human torso</span>
        <span itemprop="definition">i.e., a direction perpendicular to the sagittal plane of the body</span>
        <meta itemprop="num_attr" content="0158">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the conversion relationship</span>
        <span itemprop="definition">may be expressed as one or more rotation matrices. More descriptions for determining the conversion relationship between the target coordinate system and the original coordinate system may be found in FIG. 13 of the present disclosure and its relevant descriptions.</span>
        <meta itemprop="num_attr" content="0158">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">step 1120</span>
        <span itemprop="definition">coordinate information in the at least one original coordinate system may be converted to coordinate information in the target coordinate system based on the conversion relationship.</span>
        <meta itemprop="num_attr" content="0159">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the step</span>
        <span itemprop="definition">may be performed by the processing module 220 and/or the processing device 110 .</span>
        <meta itemprop="num_attr" content="0160">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the coordinate information in the original coordinate system</span>
        <span itemprop="definition">may be three-dimensional coordinate information in the original coordinate system.</span>
        <meta itemprop="num_attr" content="0160">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the coordinate information in the target coordinate system</span>
        <span itemprop="definition">may be the three-dimensional coordinate information in the target coordinate system.</span>
        <meta itemprop="num_attr" content="0160">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the coordinate information v 1 in the original coordinate system</span>
        <span itemprop="definition">may be converted to the coordinate information v 2 in the target coordinate system according to the conversion relationship.</span>
        <meta itemprop="num_attr" content="0160">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a conversion between the coordinate information v 1 and the coordinate information v 2</span>
        <span itemprop="definition">may be performed by using a rotation matrix.</span>
        <meta itemprop="num_attr" content="0160">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the rotation matrix</span>
        <span itemprop="definition">here may be understood as the conversion relationship between the original coordinate system and the target coordinate system.</span>
        <meta itemprop="num_attr" content="0160">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the coordinate information v 1 in the original coordinate system</span>
        <span itemprop="definition">may be converted to coordinate information v 1   1 using a first rotation matrix</span>
        <meta itemprop="num_attr" content="0160">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the coordinate information v 1   1</span>
        <span itemprop="definition">may be converted to coordinate information v 1   2 using a second rotation matrix</span>
        <meta itemprop="num_attr" content="0160">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the coordinate information v 1   2</span>
        <span itemprop="definition">may be converted to coordinate information v 1   3 using a third rotation matrix.</span>
        <meta itemprop="num_attr" content="0160">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the coordinate information v 1   3</span>
        <span itemprop="definition">may be the coordinate information v 2 in the target coordinate system.</span>
        <meta itemprop="num_attr" content="0160">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the rotation matrices</span>
        <span itemprop="definition">are not limited to the above first rotation matrix, the second rotation matrix and the third rotation matrix, but may also include fewer or more rotation matrices.</span>
        <meta itemprop="num_attr" content="0160">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the rotation matrix</span>
        <span itemprop="definition">may be a rotation matrix or a combination of a plurality of rotation matrices.</span>
        <meta itemprop="num_attr" content="0160">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the feature information corresponding to the attitude signal</span>
        <span itemprop="definition">may be determined based on the coordinate information in the target coordinate system.</span>
        <meta itemprop="num_attr" content="0161">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">determining, based on the coordinate information in the target coordinate system, the feature information corresponding to the attitude signal</span>
        <span itemprop="definition">may include determining, based on a plurality of coordinate information in the target coordinate system of the user during motion, the feature information corresponding to the attitude signal of the user. For example, when the user performs a seated chest press, the user&#39;s arm may correspond to the first coordinate information in the target coordinate system when the user&#39;s arm is held forward, and the user&#39;s arm may correspond to the second coordinate information in the target coordinate system when the user&#39;s arm is opened in a same plane as the torso. Based on the first coordinate information and the second coordinate information, the feature information, e.g., the angular velocity, the angular velocity direction, and the acceleration value of the angular velocity, corresponding to the attitude signal may be determined.</span>
        <meta itemprop="num_attr" content="0162">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the feature information</span>
        <span itemprop="definition">e.g., the angular velocity, the angular velocity direction, and the acceleration value of the angular velocity</span>
        <meta itemprop="num_attr" content="0162">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">process 1100</span>
        <span itemprop="definition">is for example and illustration purposes only and does not limit the scope of application of the present disclosure.</span>
        <meta itemprop="num_attr" content="0163">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">various amendments and changes</span>
        <span itemprop="definition">can be made to process 1100 under the guidance of the present disclosure. However, these amendments and changes are still within the scope of the present disclosure.</span>
        <meta itemprop="num_attr" content="0163">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the relative motion between different motion parts of the user&#39;s body</span>
        <span itemprop="definition">may be determined based on the feature information corresponding to the attitude sensors located at the different motion parts of the user&#39;s body. For example, by using the feature information corresponding to the attitude sensor at the user&#39;s arm and the feature information corresponding to the attitude sensor at the user&#39;s torso, the relative motion between the user&#39;s arm and torso during motion may be determined.</span>
        <meta itemprop="num_attr" content="0164">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 12</span>
        <span itemprop="definition">is a flowchart of an exemplary process for determining relative motion between different motion parts of a user according to some embodiments of the present disclosure. As shown in FIG. 12 , the process 1200 may include following steps.</span>
        <meta itemprop="num_attr" content="0164">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">step 1210</span>
        <span itemprop="definition">feature information corresponding to at least two sensors respectively may be determined based on conversion relationships between different original coordinate systems and a target coordinate system.</span>
        <meta itemprop="num_attr" content="0165">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the step</span>
        <span itemprop="definition">may be performed by the processing module 220 and/or the processing device 110 .</span>
        <meta itemprop="num_attr" content="0166">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processing device 110</span>
        <span itemprop="definition">may convert the coordinate information in the original coordinate systems corresponding to the sensors at different parts of the user (e.g., small arm, large arm, torso, etc.) to the coordinate information in the target coordinate system, respectively, so that the feature information corresponding to at least two sensors may be determined respectively. More descriptions of the conversion of the coordinate information in the original coordinate system to coordinate information in the target coordinate system may be found elsewhere in the present disclosure, e.g., FIG. 11 , which may not be repeated herein.</span>
        <meta itemprop="num_attr" content="0166">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a relative motion between different motion parts of a user</span>
        <span itemprop="definition">may be determined based on the feature information corresponding to the at least two sensors respectively.</span>
        <meta itemprop="num_attr" content="0167">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a motion part</span>
        <span itemprop="definition">may refer to a limb on the human body that can move independently, for example, a small arm, a large arm, a small leg, a thigh, etc.</span>
        <meta itemprop="num_attr" content="0168">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the coordinate information in the target coordinate system corresponding to the sensor set at the small arm part and the coordinate information in the target coordinate system corresponding to the sensor set at the large arm part</span>
        <span itemprop="definition">may be combined to determine the relative motion between the small arm and the large arm of the user, thereby determining the arm lifting dumbbell movement of the user.</span>
        <meta itemprop="num_attr" content="0168">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a same motion part of the user</span>
        <span itemprop="definition">may be arranged with a plurality of sensors of the same or different types, and the coordinate information in the original coordinate systems corresponding to a plurality of sensors of same or different types may be converted to the coordinate information in the target coordinate system, respectively.</span>
        <meta itemprop="num_attr" content="0169">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a plurality of sensors of the same or different types</span>
        <span itemprop="definition">may be arranged at different locations of the user&#39;s small arm part, and a plurality of coordinates in the target coordinate systems corresponding to a plurality of sensors of the same or different types may simultaneously represent the movement of the user&#39;s small arm part.</span>
        <meta itemprop="num_attr" content="0169">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the coordinate information in the target coordinate systems corresponding to a plurality of sensors of the same type</span>
        <span itemprop="definition">may be averaged, thereby improving the accuracy of the coordinate information of the motion parts during the user&#39;s motion.</span>
        <meta itemprop="num_attr" content="0169">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the coordinate information in the target coordinate system</span>
        <span itemprop="definition">may be obtained by performing a fusion algorithm (e.g., Kalman filtering, etc.) on the coordinate information in coordinate systems corresponding to a plurality sensors of different types.</span>
        <meta itemprop="num_attr" content="0169">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">process 1100</span>
        <span itemprop="definition">is for example and illustration purposes only and does not limit the scope of application of the present disclosure.</span>
        <meta itemprop="num_attr" content="0170">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">various amendments and changes</span>
        <span itemprop="definition">can be made to process 1100 under the guidance of the present disclosure. However, these amendments and changes are still within the scope of the present disclosure.</span>
        <meta itemprop="num_attr" content="0170">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 13</span>
        <span itemprop="definition">is a flowchart of an exemplary process for determining a conversion relationship between an original coordinate system and a specific coordinate system according to some embodiments of the present disclosure.</span>
        <meta itemprop="num_attr" content="0171">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the process for determining the conversion relationship between the original coordinate system and the specific coordinate system</span>
        <span itemprop="definition">may also be referred to as a calibration process.</span>
        <meta itemprop="num_attr" content="0171">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the process 1300</span>
        <span itemprop="definition">may include following steps.</span>
        <meta itemprop="num_attr" content="0171">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a specific coordinate system</span>
        <span itemprop="definition">may be constructed.</span>
        <meta itemprop="num_attr" content="0172">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the step</span>
        <span itemprop="definition">may be performed by the processing module 220 and/or the processing device 110 .</span>
        <meta itemprop="num_attr" content="0173">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the conversion relationship between at least one original coordinate system and the target coordinate system</span>
        <span itemprop="definition">may be obtained by the calibration process.</span>
        <meta itemprop="num_attr" content="0173">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the specific coordinate system</span>
        <span itemprop="definition">may refer to a reference coordinate system configured to determine the conversion relationship between the original coordinate system and the target coordinate system during the calibration process.</span>
        <meta itemprop="num_attr" content="0173">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a length direction of the torso when the human body is standing</span>
        <span itemprop="definition">may be determined as the Z-axis</span>
        <meta itemprop="num_attr" content="0173">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a front-to-back direction of the human body</span>
        <span itemprop="definition">may be determined as the X-axis</span>
        <meta itemprop="num_attr" content="0173">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">z left-to-right direction of the human torso</span>
        <span itemprop="definition">may be determined as the Y-axis.</span>
        <meta itemprop="num_attr" content="0173">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the specific coordinate system</span>
        <span itemprop="definition">may be related to the orientation of the user during the calibration process. For example, if the user&#39;s body is facing a fixed direction (e.g., north) during the calibration process, the front (north) direction of the body may be the X-axis. In the calibration process, the X axis direction may be fixed.</span>
        <meta itemprop="num_attr" content="0173">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">step 1320</span>
        <span itemprop="definition">first coordinate information in at least one original coordinate system when a user is in a first pose may be obtained.</span>
        <meta itemprop="num_attr" content="0174">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the step</span>
        <span itemprop="definition">may be performed by the obtaining module 210 .</span>
        <meta itemprop="num_attr" content="0175">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the first pose</span>
        <span itemprop="definition">may be a pose that the user approximately remains standing.</span>
        <meta itemprop="num_attr" content="0175">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the obtaining module 210</span>
        <span itemprop="definition">e.g., the sensor</span>
        <meta itemprop="num_attr" content="0175">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the obtaining module 210</span>
        <span itemprop="definition">may obtain the first coordinate information in the original coordinate system based on the user&#39;s first pose.</span>
        <meta itemprop="num_attr" content="0175">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">step 1330</span>
        <span itemprop="definition">second coordinate information in the at least one original coordinate system when the user is in a second pose may be obtained.</span>
        <meta itemprop="num_attr" content="0176">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the step</span>
        <span itemprop="definition">may be performed by the obtaining module 210 .</span>
        <meta itemprop="num_attr" content="0177">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the second pose</span>
        <span itemprop="definition">may be a pose that the user&#39;s body part (e.g., the arm) where the sensor is located is tilted forward.</span>
        <meta itemprop="num_attr" content="0177">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the obtaining module 210</span>
        <span itemprop="definition">e.g., the sensor</span>
        <meta itemprop="num_attr" content="0177">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a relationship between the at least one original coordinate system and the specific coordinate system</span>
        <span itemprop="definition">may be determined based on the first coordinate information, the second coordinate information, and the specific coordinate system.</span>
        <meta itemprop="num_attr" content="0178">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a first rotation matrix</span>
        <span itemprop="definition">may be determined based on the first coordinate information corresponding to the first pose.</span>
        <meta itemprop="num_attr" content="0179">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the first rotation matrix</span>
        <span itemprop="definition">is the rotation matrix obtained by rotating the original coordinate system in the reverse direction around the X-axis and then around the Y-axis.</span>
        <meta itemprop="num_attr" content="0179">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a second rotation matrix</span>
        <span itemprop="definition">may be determined based on the second coordinate information of the second pose (e.g., the body part where the sensor is located is tilted forward).</span>
        <meta itemprop="num_attr" content="0179">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the second rotation matrix</span>
        <span itemprop="definition">is the rotation matrix obtained by rotating the original coordinate system in the reverse direction around the Y direction and then around the Z 3 direction.</span>
        <meta itemprop="num_attr" content="0179">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the conversion relationship between the original coordinate system and the specific coordinate system</span>
        <span itemprop="definition">may be determined based on the first rotation matrix and the second rotation matrix. In some embodiments, when there are a plurality of original coordinate systems (sensors), the conversion relationship between each original coordinate system and the specific coordinate system may be determined according to the above method.</span>
        <meta itemprop="num_attr" content="0179">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the first pose</span>
        <span itemprop="definition">is not limited to an approximately standing pose</span>
        <meta itemprop="num_attr" content="0180">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the second pose</span>
        <span itemprop="definition">is not limited to the pose that the user&#39;s body part (e.g., the arm) where the sensor is located is tilted forward.</span>
        <meta itemprop="num_attr" content="0180">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the first and second poses herein</span>
        <span itemprop="definition">may be approximated as being stationary during the calibration process.</span>
        <meta itemprop="num_attr" content="0180">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the first pose and/or the second pose</span>
        <span itemprop="definition">may also be a dynamic pose during the calibration process.</span>
        <meta itemprop="num_attr" content="0180">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the user&#39;s walking attitude</span>
        <span itemprop="definition">may be a relatively fixed attitude, an angle and an angular velocity of the arms, the legs and the feet during walking may be extracted to recognize a movement, such as a forward stride, a forward arm swing, or the like.</span>
        <meta itemprop="num_attr" content="0180">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the user&#39;s forward walking attitude</span>
        <span itemprop="definition">may be used as the second pose in the calibration process.</span>
        <meta itemprop="num_attr" content="0180">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the second pose</span>
        <span itemprop="definition">is not limited to one movement, and a plurality of movements may also be extracted as the second pose. For example, coordinate information of a plurality of movements may be fused to obtain a more accurate rotation matrix.</span>
        <meta itemprop="num_attr" content="0180">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the rotation matrix</span>
        <span itemprop="definition">may be dynamically corrected during the calibration process using one or more signal processing algorithms (e.g., using a Kalman filtering algorithm) to obtain a better transformation matrix in the whole calibration process.</span>
        <meta itemprop="num_attr" content="0181">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">one or more signal processing algorithms</span>
        <span itemprop="definition">e.g., using a Kalman filtering algorithm</span>
        <meta itemprop="num_attr" content="0181">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a machine learning algorithm</span>
        <span itemprop="definition">may be used for automatic recognition of specific movements to update the rotation matrix in real time. For example, if the machine learning algorithm recognizes that a current user is walking, or standing, the calibration process may be automatically started. In this case, the wearable device no longer need an explicit calibration process, and the rotation matrix may be dynamically updated when the user uses the wearable device.</span>
        <meta itemprop="num_attr" content="0182">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">an installation position of the attitude sensor</span>
        <span itemprop="definition">may be relatively fixed and a rotation matrix may be preset, which may make the recognition process of the specific movement more accurate. Further, the rotation matrix may continue to be corrected during the user&#39;s use of the wearable device to make the obtained rotation matrix closer to the real situation.</span>
        <meta itemprop="num_attr" content="0183">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">process 1300</span>
        <span itemprop="definition">is for example and illustration purposes only, and does not limit the scope of application of the present disclosure.</span>
        <meta itemprop="num_attr" content="0184">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">various amendments and changes</span>
        <span itemprop="definition">can be made to process 1300 under the guidance of the present disclosure. However, these amendments and changes are still within the scope of the present disclosure.</span>
        <meta itemprop="num_attr" content="0184">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 14</span>
        <span itemprop="definition">is a flowchart of an exemplary process for determining a conversion relationship between an original coordinate system and a target coordinate system according to some embodiments of the present disclosure. As shown in FIG. 14 , the process 1400 may include following steps.</span>
        <meta itemprop="num_attr" content="0185">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">step 1410</span>
        <span itemprop="definition">a conversion relationship between a specific coordinate system and a target coordinate system may be obtained.</span>
        <meta itemprop="num_attr" content="0186">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the step</span>
        <span itemprop="definition">may be performed by the processing module 220 and/or the processing device 110 .</span>
        <meta itemprop="num_attr" content="0187">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a length direction of the human torso</span>
        <span itemprop="definition">may be determined as the Z-axis. Therefore, the conversion relationship between the specific coordinate relationship and the target coordinate system may be obtained based on a conversion relationship between the X-axis of the specific coordinate system and the X-axis of the target coordinate system and a conversion relationship between the Y-axis of the specific coordinate system and the Y-axis of the target coordinate system.</span>
        <meta itemprop="num_attr" content="0187">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the principle of obtaining the conversion relationship between the specific coordinate relationship and the target coordinate system</span>
        <span itemprop="definition">may be found in FIG. 13 and its relevant descriptions.</span>
        <meta itemprop="num_attr" content="0187">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the length direction of the human torso</span>
        <span itemprop="definition">may be determined as the Z-axis and a front-to-back direction of the human body may be determined as a calibrated X-axis. Since the front-to-back direction of the user&#39;s body changes during motion (e.g., a turning motion) and cannot be fixed in the calibrated coordinate system, it is necessary to determine a coordinate system that can rotate with the body, i.e., the target coordinate system. In some embodiments, the target coordinate system may change with the user&#39;s orientation, and the X-axis of the target coordinate system is always in front of the human torso.</span>
        <meta itemprop="num_attr" content="0188">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a conversion relationship between at least one original coordinate system and the target coordinate system</span>
        <span itemprop="definition">may be determined according to a conversion relationship between the at least one original coordinate system and the specific coordinate system, and the conversion relationship between the specific coordinate system and the target coordinate system.</span>
        <meta itemprop="num_attr" content="0189">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the step</span>
        <span itemprop="definition">may be performed by the processing module 220 and/or the processing device 110 .</span>
        <meta itemprop="num_attr" content="0190">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processing device 110</span>
        <span itemprop="definition">may determine the conversion relationship between the at least one original coordinate system and the target coordinate system according to the conversion relationship between the at least one original coordinate system and the specific coordinate system determined in the process 1300 and the conversion relationship between the specific coordinate system and the target coordinate system determined in step 1410 , such that the coordinate information in the original coordinate system can be converted to the coordinate information in the target coordinate system.</span>
        <meta itemprop="num_attr" content="0190">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the position of the attitude sensor set on the wearable device 130</span>
        <span itemprop="definition">may change and/or the installation angle of the attitude sensor on the human body may be different, then the user performs the same motion, and the attitude data returned by the attitude sensor may have great differences.</span>
        <meta itemprop="num_attr" content="0192">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 15 A</span>
        <span itemprop="definition">is an exemplary vector coordinate diagram illustrating Euler angle data in an original coordinate system at a position of a small arm of a human body according to some embodiments of the present disclosure.</span>
        <meta itemprop="num_attr" content="0193">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a boxed part</span>
        <span itemprop="definition">may represent the Euler angle data (the coordinate information) in the original coordinate system corresponding to the position of the small arm when the user performs the same movement.</span>
        <meta itemprop="num_attr" content="0193">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the result of the Euler angle vector in the Z-axis direction (shown as Z in FIG. 15 A ) in the boxed part</span>
        <span itemprop="definition">are approximately in a range of   180 to (  80).</span>
        <meta itemprop="num_attr" content="0193">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the result of the Euler angle vector in the Y-axis direction</span>
        <span itemprop="definition">(shown as Y in FIG. 15 A ) fluctuate approximately around 0.</span>
        <meta itemprop="num_attr" content="0193">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the result of the Euler angle vector in the X-axis direction</span>
        <span itemprop="definition">(shown as X in FIG. 15 A ) fluctuate approximately around   80.</span>
        <meta itemprop="num_attr" content="0193">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a fluctuation range here</span>
        <span itemprop="definition">may be 20.</span>
        <meta itemprop="num_attr" content="0193">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 15 B</span>
        <span itemprop="definition">is an exemplary vector coordinate diagram illustrating Euler angle data in another original coordinate system at a position of a small arm of a human body according to some embodiments of the present disclosure.</span>
        <meta itemprop="num_attr" content="0194">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the boxed part</span>
        <span itemprop="definition">may represent the Euler angle data in the original coordinate system corresponding to the other position of the small arm when the user performs the same movement (the same movement as shown in FIG. 15 A ).</span>
        <meta itemprop="num_attr" content="0194">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the result of the Euler angle vector in the Z-axis direction (shown as Z in FIG. 15 B ) in the boxed part</span>
        <span itemprop="definition">is approximately in a range of   180 to 180.</span>
        <meta itemprop="num_attr" content="0194">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the result of the Euler angle vector in the Y-axis direction</span>
        <span itemprop="definition">(shown as Y in FIG. 15 B ) fluctuate approximately around 0.</span>
        <meta itemprop="num_attr" content="0194">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the result of the Euler angle vector in the X-axis direction</span>
        <span itemprop="definition">(shown as X in FIG. 15 B ) fluctuate approximately around   150.</span>
        <meta itemprop="num_attr" content="0194">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the fluctuation range here</span>
        <span itemprop="definition">may be 20.</span>
        <meta itemprop="num_attr" content="0194">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the Euler angle data shown in FIG. 15 A and FIG. 15 B</span>
        <span itemprop="definition">are the Euler angle data (the coordinate information) respectively obtained in the original coordinate system when the user performs the same movement at different positions of the human small arm (it can also be understood that the installation angle of the attitude sensor at the position of the human small arm is different).</span>
        <meta itemprop="num_attr" content="0195">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the installation angle of the attitude sensor on the human body</span>
        <span itemprop="definition">is different, when the user performs the same movement, the Euler angle data in the original coordinate system returned by the attitude sensor may vary greatly.</span>
        <meta itemprop="num_attr" content="0195">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the result of the Euler angle vector in the Z-axis direction in FIG. 15 A</span>
        <span itemprop="definition">is approximately in the range of   180-(  80)</span>
        <meta itemprop="num_attr" content="0195">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the result of the Euler angle vector in the Z-axis direction in FIG. 15 B</span>
        <span itemprop="definition">is approximately in the range of   180-180, which are quite different from each other.</span>
        <meta itemprop="num_attr" content="0195">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the Euler angle data in the original coordinate system corresponding to sensors with different installation angles</span>
        <span itemprop="definition">may be converted to the Euler angle data in the target coordinate system, thereby facilitating the analysis of the attitude signal of the sensors at different positions.</span>
        <meta itemprop="num_attr" content="0196">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a line where the left arm is located</span>
        <span itemprop="definition">may be abstracted as a unit vector pointing from the elbow to the wrist.</span>
        <meta itemprop="num_attr" content="0196">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">T unit vector</span>
        <span itemprop="definition">may be a coordinate value in the target coordinate system.</span>
        <meta itemprop="num_attr" content="0196">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">an axis pointing to the rear of the body</span>
        <span itemprop="definition">may be determined as the X-axis</span>
        <meta itemprop="num_attr" content="0196">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">an axis pointing to the right side of the body</span>
        <span itemprop="definition">may be determined as the Y-axis</span>
        <meta itemprop="num_attr" content="0196">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">an axis pointing to the top of the body</span>
        <span itemprop="definition">may be determined as the Z-axis, which conforms to the right-handed coordinate system.</span>
        <meta itemprop="num_attr" content="0196">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a coordinate value [  1, 0, 0] in the target coordinate system</span>
        <span itemprop="definition">indicates that the arm is held forward flat.</span>
        <meta itemprop="num_attr" content="0196">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a coordinate value [0,   1, 0] in the target coordinate system</span>
        <span itemprop="definition">indicates that the arm is held flat to the left.</span>
        <meta itemprop="num_attr" content="0196">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 16 A</span>
        <span itemprop="definition">is an exemplary vector coordinate diagram of Euler angle data in a target coordinate system at a position of a small arm of a human body according to some embodiments of the present disclosure.</span>
        <meta itemprop="num_attr" content="0196">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">16 A</span>
        <span itemprop="definition">is a curve obtained after the Euler angle data of the small arm in the original coordinate in FIG. 15 A is converted into vector coordinates in the target coordinate system.</span>
        <meta itemprop="num_attr" content="0196">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the boxed part</span>
        <span itemprop="definition">may represent the Euler angle data in the target coordinate system at the position of the small arm when the user performs the same movement.</span>
        <meta itemprop="num_attr" content="0196">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a small arm vector [x, y, z] in the boxed part</span>
        <span itemprop="definition">moves reciprocally between a first position and a second position, wherein the first position is [0.2,   0.9,   0.38] and the second position is [0.1,   0.95,   0.3]. It should be noted that for each reciprocal movement of the small arm, there may be a small deviation between the first position and the second position.</span>
        <meta itemprop="num_attr" content="0196">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 16 B</span>
        <span itemprop="definition">is an exemplary vector coordinate diagram of Euler angle data in a target coordinate system at another location of a small arm of a human body according to some embodiments of the present disclosure.</span>
        <meta itemprop="num_attr" content="0197">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 16 B</span>
        <span itemprop="definition">is a curve obtained after the Euler angle data of the small arm in the original coordinate in FIG. 15 B is converted into vector coordinates in the target coordinate system.</span>
        <meta itemprop="num_attr" content="0197">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the boxed part</span>
        <span itemprop="definition">may represent the Euler angle data in the target coordinate system at another location of the small arm when the user performs the same movement (the same movement as the movement shown in FIG. 16 A ).</span>
        <meta itemprop="num_attr" content="0197">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a small arm vector [x, y, z]</span>
        <span itemprop="definition">reciprocates between the first position and the second position similarly, wherein the first position is [ 0 . 2 ,   0.9,   0.38] and the second position is [0.1,   0.95,   0.3].</span>
        <meta itemprop="num_attr" content="0197">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 15 A to FIG. 16 B</span>
        <span itemprop="definition">it can be seen from FIGS. 15 A and 15 B that the Euler angles in the original coordinate system have a great difference in the range of values and the fluctuation form due to the different installation positions of the two attitude sensors.</span>
        <meta itemprop="num_attr" content="0198">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the vector coordinates corresponding to the target coordinate system</span>
        <span itemprop="definition">e.g., the vector coordinates in FIGS. 16 A and 16 B</span>
        <meta itemprop="num_attr" content="0198">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">two approximately same vector coordinates</span>
        <span itemprop="definition">may be obtained. That is, the method can make the feature information corresponding to the attitude signal not affected by the sensor installation position.</span>
        <meta itemprop="num_attr" content="0198">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the two attitude sensors</span>
        <span itemprop="definition">are installed at different positions on the small arm, and after the coordinate conversion, the same vector coordinates may be obtained, i.e., it can represent the process of the arm switching back and forth between two states of state 1 (arm held flat to the right) and state 2 (arm held flat to the front) during the process of the seated chest press.</span>
        <meta itemprop="num_attr" content="0198">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 17</span>
        <span itemprop="definition">is an exemplary vector coordinate diagram of a limb vector in a target coordinate system according to some embodiments of the present disclosure.</span>
        <meta itemprop="num_attr" content="0199">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">vector coordinates of attitude sensors in a target coordinate system at positions of the left small arm ( 17 - 1 ), the right small arm ( 17 - 2 ), the left large arm ( 17 - 3 ), the right large arm ( 17 - 4 ), and the torso ( 17 - 5 ) of the human body</span>
        <span itemprop="definition">may be represented from top to bottom, respectively.</span>
        <meta itemprop="num_attr" content="0199">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the vector coordinates of each position (e.g., 17 - 1 , 17 - 2 , 17 - 3 , 17 - 4 , 17 - 5 ) in the target coordinate system during motion of the human</span>
        <span itemprop="definition">are illustrated in FIG. 17 .</span>
        <meta itemprop="num_attr" content="0199">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the first 4200 points in FIG. 17</span>
        <span itemprop="definition">may be calibration movements required for limb calibration, such as standing, torso forward, arm forward, arm side planks, etc.</span>
        <meta itemprop="num_attr" content="0199">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">raw data collected by the attitude sensors</span>
        <span itemprop="definition">may be converted to the Euler angles in the target coordinate system.</span>
        <meta itemprop="num_attr" content="0199">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">it</span>
        <span itemprop="definition">may further be converted into the coordinate vector of the arm vector in the target coordinate system.</span>
        <meta itemprop="num_attr" content="0199">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the X-axis</span>
        <span itemprop="definition">may point to the front of the torso</span>
        <meta itemprop="num_attr" content="0199">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the Y-axis</span>
        <span itemprop="definition">may point to the left of the torso</span>
        <meta itemprop="num_attr" content="0199">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the Z-axis</span>
        <span itemprop="definition">may point to the top of the torso.</span>
        <meta itemprop="num_attr" content="0199">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">movement 1 , movement 2 , movement 3 , movement 4 , movement 5 , and movement 6</span>
        <span itemprop="definition">which are seated chest press, high pull-down, seated chest thrust, seated shoulder thrust, barbell dip head curl, and seated chest press, respectively.</span>
        <meta itemprop="num_attr" content="0199">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">different movements</span>
        <span itemprop="definition">have different movement patterns, which may be clearly recognized by using the limb vectors.</span>
        <meta itemprop="num_attr" content="0199">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the same movement</span>
        <span itemprop="definition">also has good repeatability.</span>
        <meta itemprop="num_attr" content="0199">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the movement 1 and the movement 6</span>
        <span itemprop="definition">both represent the seated chest press, and the curves of these two movements have good repeatability.</span>
        <meta itemprop="num_attr" content="0199">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the attitude data</span>
        <span itemprop="definition">(e.g., the Euler angle, the angular velocity, etc.) directly output by a module of the original coordinate system may be converted to the attitude data in the target coordinate system according to process 1300 and process 1400 , so that highly consistent attitude data (e.g., the Euler angle, the angular velocity, the limb vector coordinate, etc.) may be obtained.</span>
        <meta itemprop="num_attr" content="0200">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">highly consistent attitude data</span>
        <span itemprop="definition">e.g., the Euler angle, the angular velocity, the limb vector coordinate, etc.</span>
        <meta itemprop="num_attr" content="0200">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 18 A</span>
        <span itemprop="definition">is a diagram illustrating an exemplary coordinate vector of an original angular velocity according to some embodiments of the present disclosure.</span>
        <meta itemprop="num_attr" content="0201">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the original angular velocity</span>
        <span itemprop="definition">may be understood as the conversion of the Euler angle data in the original coordinate systems corresponding to the sensors with different installation angles to the Euler angle data in the target coordinate system.</span>
        <meta itemprop="num_attr" content="0201">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">factors</span>
        <span itemprop="definition">such as jitter during the motion of the user may affect the result of the angular velocity in the attitude data.</span>
        <meta itemprop="num_attr" content="0201">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the original angular velocity</span>
        <span itemprop="definition">shows a more obvious unsmooth curve in its vector coordinate curve under an influence of jitter, etc. For example, a presence of an abrupt signal in the vector coordinate curve of the original angular velocity makes the vector coordinate curve of the original angular velocity unsmooth.</span>
        <meta itemprop="num_attr" content="0201">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 18 B</span>
        <span itemprop="definition">is a diagram illustrating exemplary results of an angular velocity after filtering processing according to some embodiments of the present disclosure. As shown in FIG. 18 B , after performing the 1 Hz-3 Hz low-pass filtering on the original angular velocity, the effect of jitter and other effects on the angular velocity (e.g., abrupt signals) may be eliminated, so that the vector coordinate curve corresponding to the angular velocity may be displayed smoother.</span>
        <meta itemprop="num_attr" content="0201">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">performing the low-pass filtering from 1 Hz to 3 Hz on the angular velocity</span>
        <span itemprop="definition">may effectively prevent the effect of jitter, etc., on the attitude data (e.g., the Euler angle, the angular velocity, etc.), so as to facilitate the subsequent signal segmentation process.</span>
        <meta itemprop="num_attr" content="0201">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the filtering process</span>
        <span itemprop="definition">may also filter out an industrial frequency signal and its harmonic wave signal, burr signal, etc., from the movement signal. It should be noted that low-pass filtering at 1 Hz-3 Hz introduces time delay, which makes a movement point of the attitude signal and a movement point of a real electromyographic signal misaligned in time.</span>
        <meta itemprop="num_attr" content="0201">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the time delay generated during the low-pass filtering process</span>
        <span itemprop="definition">may be subtracted from the vector coordinate curve after the low-pass filtering processing, to ensure the synchronization of the attitude signal and the electromyographic signal in time.</span>
        <meta itemprop="num_attr" content="0201">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the time delay</span>
        <span itemprop="definition">may be associated with a center frequency of the filter.</span>
        <meta itemprop="num_attr" content="0201">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the time delay</span>
        <span itemprop="definition">may be adjusted adaptively according to the center frequency of the filter.</span>
        <meta itemprop="num_attr" content="0201">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the angular range of the Euler angle</span>
        <span itemprop="definition">is [480, &#43;180]</span>
        <meta itemprop="num_attr" content="0201">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">an obtained Euler angle</span>
        <span itemprop="definition">may have a change of   180 to &#43;180 or &#43;180 to   180 when an actual Euler angle is not in this angular range. For example, when the angle is   181, the Euler angle changes to 179. In the practical application, the angle change may affect the determination of the angle difference, and it is necessary to correct the angle change first.</span>
        <meta itemprop="num_attr" content="0201">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a movement recognition model</span>
        <span itemprop="definition">may also be used to analyze the user&#39;s movement signal or the feature information corresponding to the movement signal, so as to recognize the user&#39;s movement.</span>
        <meta itemprop="num_attr" content="0202">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the movement recognition model</span>
        <span itemprop="definition">may include a trained machine learning model configured to recognize the user&#39;s movement.</span>
        <meta itemprop="num_attr" content="0202">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the movement recognition model</span>
        <span itemprop="definition">may include one or more machine learning models.</span>
        <meta itemprop="num_attr" content="0202">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the movement recognition model</span>
        <span itemprop="definition">may include, but is not limited to, one or more of a machine learning model that classifies the user&#39;s movement signal, a machine learning model that recognizes the movement quality of the user, a machine learning model that recognizes the number of movements of the user, and a machine learning model that recognizes a fatigue index of the user performing the movement.</span>
        <meta itemprop="num_attr" content="0202">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the machine learning model</span>
        <span itemprop="definition">may include one or more of a linear classification model (LR), a support vector machine model (SVM), a plain Bayesian model (NB), a K-nearest neighbor model (KNN), a decision tree model (DT), a random forest/a gradient boosting decision tree (RF/GDBT, etc.), etc. More descriptions regarding the movement recognition model may be found elsewhere in the present disclosure, such as FIG. 20 and its relevant descriptions.</span>
        <meta itemprop="num_attr" content="0202">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">LR</span>
        <span itemprop="definition">linear classification model</span>
        <meta itemprop="num_attr" content="0202">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">SVM</span>
        <span itemprop="definition">support vector machine model</span>
        <meta itemprop="num_attr" content="0202">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">NB</span>
        <span itemprop="definition">plain Bayesian model</span>
        <meta itemprop="num_attr" content="0202">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">KNN</span>
        <span itemprop="definition">K-nearest neighbor model</span>
        <meta itemprop="num_attr" content="0202">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">DT</span>
        <span itemprop="definition">decision tree model</span>
        <meta itemprop="num_attr" content="0202">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">RF/GDBT</span>
        <span itemprop="definition">gradient boosting decision tree</span>
        <meta itemprop="num_attr" content="0202">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 19</span>
        <span itemprop="definition">is a flowchart illustrating an exemplary motion monitoring and feedback method according to some embodiments of the present disclosure. As shown in FIG. 19 , the process 1900 may include the following steps.</span>
        <meta itemprop="num_attr" content="0203">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">step 1910</span>
        <span itemprop="definition">a movement signal during a motion of a user may be obtained.</span>
        <meta itemprop="num_attr" content="0204">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the step</span>
        <span itemprop="definition">may be performed by the obtaining module 210 .</span>
        <meta itemprop="num_attr" content="0205">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the movement signal</span>
        <span itemprop="definition">may at least include feature information corresponding to an electromyographic signal and feature information corresponding to an attitude signal.</span>
        <meta itemprop="num_attr" content="0205">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the movement signal</span>
        <span itemprop="definition">may refer to human body parameter information during the motion of the user.</span>
        <meta itemprop="num_attr" content="0205">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the human body parameter information</span>
        <span itemprop="definition">may include, but is not limited to, the electromyographic signal, the attitude signal, a heart rate signal, a temperature signal, a humidity signal, a blood oxygen concentration, or the like, or any combination thereof.</span>
        <meta itemprop="num_attr" content="0205">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the movement signal</span>
        <span itemprop="definition">may at least include the electromyographic signal and the attitude signal.</span>
        <meta itemprop="num_attr" content="0205">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">an electromyographic sensor in the obtaining module 210</span>
        <span itemprop="definition">may collect the electromyographic signal during the motion of the user, and an attitude sensor in the obtaining module 210 may collect the attitude signal during the motion of the user.</span>
        <meta itemprop="num_attr" content="0205">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a movement of the motion of the user</span>
        <span itemprop="definition">may be monitored based on the movement signal through a movement recognition model and a movement feedback may be performed based on an output result of the movement recognition model.</span>
        <meta itemprop="num_attr" content="0206">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the step</span>
        <span itemprop="definition">may be performed by the processing module 220 and/or the processing device 110 .</span>
        <meta itemprop="num_attr" content="0207">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the output result of the movement recognition model</span>
        <span itemprop="definition">may include, but is not limited to, a movement type, a movement quality, a movement quantity, a fatigue index, or the like, or any combination thereof.</span>
        <meta itemprop="num_attr" content="0207">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the movement recognition model</span>
        <span itemprop="definition">may recognize the movement type of the user as the seated chest press based on the movement signal.</span>
        <meta itemprop="num_attr" content="0207">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">one machine learning model of the movement recognition model</span>
        <span itemprop="definition">may first recognize the movement type of the user as the seated chest press based on the movement signal, and another machine learning model of the movement recognition model may output the movement quality of the user as a standard movement or an incorrect movement according to the movement signal (e.g., amplitude information, the frequency information of the electromyographic signal, and/or an angular velocity, an angular velocity direction, and an acceleration value of angular velocity of the attitude signal).</span>
        <meta itemprop="num_attr" content="0207">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the movement feedback</span>
        <span itemprop="definition">may include sending prompt information.</span>
        <meta itemprop="num_attr" content="0207">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the prompt information</span>
        <span itemprop="definition">may include, but is not limited to, a voice prompt, a text prompt, an image prompt, a video prompt, etc.</span>
        <meta itemprop="num_attr" content="0207">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processing device 110</span>
        <span itemprop="definition">may control the wearable device 130 or the mobile terminal device 140 to send the voice prompt (e.g., information such as nonstandard movement) to the user to remind the user to adjust a fitness movement in time.</span>
        <meta itemprop="num_attr" content="0207">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the wearable device 130 or the mobile terminal device 140</span>
        <span itemprop="definition">may not send the prompt information, or send prompt information such as standard movement.</span>
        <meta itemprop="num_attr" content="0207">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the motion feedback</span>
        <span itemprop="definition">may also include the wearable device 130 stimulating a corresponding part of the motion of the user.</span>
        <meta itemprop="num_attr" content="0207">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a component of the wearable device 130</span>
        <span itemprop="definition">may stimulate the corresponding part of the motion of the user through a manner such as a vibration feedback, an electrical stimulation feedback, a pressure feedback, etc.</span>
        <meta itemprop="num_attr" content="0207">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processing device 110</span>
        <span itemprop="definition">may control the component of the wearable device 130 to stimulate the corresponding part of the motion of the user.</span>
        <meta itemprop="num_attr" content="0207">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the movement feedback</span>
        <span itemprop="definition">may also include outputting a motion record during the motion of the user.</span>
        <meta itemprop="num_attr" content="0207">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the motion record</span>
        <span itemprop="definition">here may refer to the movement type, a movement time, the movement quantity, the movement quality, the fatigue index, physiological parameter information during the motion of the user, or the like, or any combination thereof. Further description regarding the movement recognition model may be found elsewhere in the present disclosure and will not be repeated herein.</span>
        <meta itemprop="num_attr" content="0207">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 20</span>
        <span itemprop="definition">is a flowchart illustrating an exemplary process for model training according to some embodiments of the present disclosure.</span>
        <meta itemprop="num_attr" content="0209">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">sample information</span>
        <span itemprop="definition">may be obtained.</span>
        <meta itemprop="num_attr" content="0210">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the step</span>
        <span itemprop="definition">may be performed by the obtaining module 210 .</span>
        <meta itemprop="num_attr" content="0211">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the sample information</span>
        <span itemprop="definition">may include a movement signal during a motion of a professional (e.g., a fitness instructor) and/or a non-professional.</span>
        <meta itemprop="num_attr" content="0211">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the sample information</span>
        <span itemprop="definition">may include an electromyographic signal and/or an attitude signal generated by the professional and/or the non-professional while performing a same type of movement (e.g., the seated chest press).</span>
        <meta itemprop="num_attr" content="0211">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the electromyographic signal and/or the attitude signal in the sample information</span>
        <span itemprop="definition">may be subjected to a segmentation processing of the process 700 , a burr processing of the process 900 , and a conversion processing of the process 1300 , etc., to form at least one segment of the electromyographic signal and/or the attitude signal.</span>
        <meta itemprop="num_attr" content="0211">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the at least one segment of the electromyographic signal and/or the attitude signal</span>
        <span itemprop="definition">may be used as an input of a machine learning model to train the machine learning model.</span>
        <meta itemprop="num_attr" content="0211">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">feature information corresponding to the at least one segment of the electromyographic signal and/or feature information corresponding to the attitude signal</span>
        <span itemprop="definition">may also be used as the input of the machine learning model to train the machine learning model.</span>
        <meta itemprop="num_attr" content="0211">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">frequency information and amplitude information of the electromyographic signal</span>
        <span itemprop="definition">may be used as the input of the machine learning model.</span>
        <meta itemprop="num_attr" content="0211">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">an angular velocity, an angular velocity direction, and an acceleration value of angular velocity of the attitude signal</span>
        <span itemprop="definition">may be used as the input of the machine learning model.</span>
        <meta itemprop="num_attr" content="0211">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a movement start point, a movement middle point, and a movement end point of the movement signal</span>
        <span itemprop="definition">may be used as the input of the machine learning model.</span>
        <meta itemprop="num_attr" content="0211">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the sample information</span>
        <span itemprop="definition">may be obtained from a storage device of the processing device 110 .</span>
        <meta itemprop="num_attr" content="0211">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the sample information</span>
        <span itemprop="definition">may be obtained from the obtaining module 210 .</span>
        <meta itemprop="num_attr" content="0211">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a movement recognition model</span>
        <span itemprop="definition">may be trained.</span>
        <meta itemprop="num_attr" content="0212">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the movement recognition model</span>
        <span itemprop="definition">may include one or more machine learning models.</span>
        <meta itemprop="num_attr" content="0213">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the movement recognition model</span>
        <span itemprop="definition">may include, but is not limited to, a machine learning model that classifies the movement signal of the user, a machine learning model that recognizes a movement quality of the user, a machine learning model that recognizes a movement quantity of the user, a machine learning model that recognizes a fatigue degree of the user performing the movement, or any combination thereof.</span>
        <meta itemprop="num_attr" content="0213">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the machine learning model</span>
        <span itemprop="definition">may include a linear classification model (LR), a support vector machine model (SVM), a Naive Bayesian model (NB), a K-nearest neighbor model (KNN), a decision tree model (DT), a random forest/a gradient boosting decision tree (RF/GDBT, etc.), etc.</span>
        <meta itemprop="num_attr" content="0213">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">LR</span>
        <span itemprop="definition">linear classification model</span>
        <meta itemprop="num_attr" content="0213">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">SVM</span>
        <span itemprop="definition">support vector machine model</span>
        <meta itemprop="num_attr" content="0213">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">NB</span>
        <span itemprop="definition">Naive Bayesian model</span>
        <meta itemprop="num_attr" content="0213">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">KNN</span>
        <span itemprop="definition">K-nearest neighbor model</span>
        <meta itemprop="num_attr" content="0213">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">DT</span>
        <span itemprop="definition">decision tree model</span>
        <meta itemprop="num_attr" content="0213">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">RF/GDBT</span>
        <span itemprop="definition">gradient boosting decision tree</span>
        <meta itemprop="num_attr" content="0213">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">training of the machine learning model</span>
        <span itemprop="definition">may include obtaining the sample information.</span>
        <meta itemprop="num_attr" content="0214">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the sample information</span>
        <span itemprop="definition">may include the movement signal during the motion of the professional (e.g., the fitness instructor) and/or the non-professional.</span>
        <meta itemprop="num_attr" content="0214">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the sample information</span>
        <span itemprop="definition">may include the electromyographic signal and/or the attitude signal generated by professional and/or the non-professional while performing the same type of movement (e.g., the seated chest press).</span>
        <meta itemprop="num_attr" content="0214">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the electromyographic signal and/or the attitude signal in the sample information</span>
        <span itemprop="definition">may be subjected to the segmentation processing of the process 700 , the burr processing of the process 900 , and the conversion processing of the process 1300 , etc., to form at least one segment of the electromyographic signal and/or the attitude signal.</span>
        <meta itemprop="num_attr" content="0214">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the at least one segment of the electromyographic signal and/or the attitude signal</span>
        <span itemprop="definition">may be used as the input to the machine learning model to train the machine learning model.</span>
        <meta itemprop="num_attr" content="0214">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the feature information corresponding to the at least one segment of the electromyographic signal and/or the feature information corresponding to the attitude signal</span>
        <span itemprop="definition">may also be used as the input of the machine learning model to train the machine learning model.</span>
        <meta itemprop="num_attr" content="0214">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the frequency information and the amplitude information of the electromyographic signal</span>
        <span itemprop="definition">may be used as the input of the machine learning model.</span>
        <meta itemprop="num_attr" content="0214">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the angular velocity, the angular velocity direction, and the acceleration value of angular velocity of the attitude signal</span>
        <span itemprop="definition">may be used as the input of the machine learning model.</span>
        <meta itemprop="num_attr" content="0214">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the movement start point, the movement middle point, and/or the movement end point signal (including the electromyographic signal and/or the attitude signal) corresponding to the signal</span>
        <span itemprop="definition">may be used as the input of the machine learning model.</span>
        <meta itemprop="num_attr" content="0214">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the sample information from different movement types</span>
        <span itemprop="definition">may be labelled.</span>
        <meta itemprop="num_attr" content="0215">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the sample information from the electromyographic signal and/or the attitude signal generated when the user performs the seated chest press</span>
        <span itemprop="definition">may be labelled 1, where 1 is configured to represent the seated chest press.</span>
        <meta itemprop="num_attr" content="0215">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the sample information from the electromyographic signal and/or the attitude signal generated when the user performs a bicep curl</span>
        <span itemprop="definition">may be marked as 2, where 2 is configured to represent the bicep curl.</span>
        <meta itemprop="num_attr" content="0215">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the feature information</span>
        <span itemprop="definition">e.g., the frequency information, the amplitude information</span>
        <meta itemprop="num_attr" content="0215">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the feature information</span>
        <span itemprop="definition">e.g., the angular velocity, the angular velocity direction, the acceleration value of angular velocity</span>
        <meta itemprop="num_attr" content="0215">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the attitude signals corresponding to the different movement types</span>
        <span itemprop="definition">may be different.</span>
        <meta itemprop="num_attr" content="0215">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the labelled sample information</span>
        <span itemprop="definition">(e.g., the feature information corresponding to the electromyographic signal and/or the attitude signal in the sample information) may be used as the input of the machine learning model to train the machine learning model, so that the movement recognition model configured to recognize the movement type may be obtained, and by inputting the movement signal in the machine learning model, a movement type corresponding to the movement signal may be output.</span>
        <meta itemprop="num_attr" content="0215">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the movement recognition model</span>
        <span itemprop="definition">may further include the machine learning model for determining the movement quality of the user.</span>
        <meta itemprop="num_attr" content="0216">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the sample information</span>
        <span itemprop="definition">here may include both a standard movement signal (also known as a positive sample) and a non-standard movement signal (also known as a negative sample).</span>
        <meta itemprop="num_attr" content="0216">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the standard movement signal</span>
        <span itemprop="definition">may include a movement signal generated when the professional performs a standard movement.</span>
        <meta itemprop="num_attr" content="0216">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a movement signal generated when the professional performs the seated chest press</span>
        <span itemprop="definition">standardly may be the standard movement signal.</span>
        <meta itemprop="num_attr" content="0216">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the non-standard movement signal</span>
        <span itemprop="definition">may include a movement signal generated when the user performs a non-standard movement (e.g., an incorrect movement).</span>
        <meta itemprop="num_attr" content="0216">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the electromyographic signal and/or the attitude signal in the sample information</span>
        <span itemprop="definition">may be subjected to the segmentation processing of the process 700 , the burr processing of the process 900 , and the conversion processing of the process 1300 , etc., to form at least one segment of the electromyographic signal and/or the attitude signal.</span>
        <meta itemprop="num_attr" content="0216">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the at least one segment of the electromyographic signal and/or the attitude signal</span>
        <span itemprop="definition">may be used as the input of the machine learning model to train the machine learning model.</span>
        <meta itemprop="num_attr" content="0216">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the positive sample and the negative sample of the sample information</span>
        <span itemprop="definition">(each segment of the electromyographic signal or/the attitude signal) may be labelled.</span>
        <meta itemprop="num_attr" content="0216">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the positive sample</span>
        <span itemprop="definition">may be labelled 1 and the negative sample may be labelled 0.</span>
        <meta itemprop="num_attr" content="0216">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the 1 here</span>
        <span itemprop="definition">may be configured to characterize a movement of the user as a standard movement, and the 0 here may be configured to characterize a movement of the user as an incorrect movement.</span>
        <meta itemprop="num_attr" content="0216">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a trained machine learning model</span>
        <span itemprop="definition">may output different labels based on the input sample information (e.g., the positive sample, the negative sample).</span>
        <meta itemprop="num_attr" content="0216">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the movement recognition model</span>
        <span itemprop="definition">may include one or more machine learning models for analyzing and recognizing the movement quality of the user. Different machine learning models may analyze and recognize the sample information from the different movement types, respectively.</span>
        <meta itemprop="num_attr" content="0216">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the movement recognition model</span>
        <span itemprop="definition">may also include a model that recognizes the movement quantity of fitness movements of the user.</span>
        <meta itemprop="num_attr" content="0217">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a model</span>
        <span itemprop="definition">that recognizes the movement quantity of fitness movements of the user.</span>
        <meta itemprop="num_attr" content="0217">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the movement signal</span>
        <span itemprop="definition">e.g., the electromyographic signal and/or the attitude signal</span>
        <meta itemprop="num_attr" content="0217">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">each set of the movement start point, the movement middle point, and the movement end point</span>
        <span itemprop="definition">may be labelled, respectively (e.g., the movement start point may be labeled 1 , the movement middle point may be labeled 2 , and the movement end point may be labeled 3 ), and the labels may be used as the input of the machine learning model.</span>
        <meta itemprop="num_attr" content="0217">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">one movement</span>
        <span itemprop="definition">may be output. For example, if three consecutive sets of 1, 2, and 3 are input into the machine learning model, three movements may be output.</span>
        <meta itemprop="num_attr" content="0217">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the movement recognition model</span>
        <span itemprop="definition">may also include the machine learning model for recognizing a fatigue index of the user.</span>
        <meta itemprop="num_attr" content="0218">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the sample information</span>
        <span itemprop="definition">here may also include a physiological parameter signal such as an electro-cardio signal, a respiratory rate, a temperature signal, a humidity signal, etc.</span>
        <meta itemprop="num_attr" content="0218">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a physiological parameter signal</span>
        <span itemprop="definition">such as an electro-cardio signal, a respiratory rate, a temperature signal, a humidity signal, etc.</span>
        <meta itemprop="num_attr" content="0218">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">different frequency ranges of the electro-cardio signal</span>
        <span itemprop="definition">may be used as input data of the machine learning model.</span>
        <meta itemprop="num_attr" content="0218">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the frequency range of the electro-cardio signal from 60 beats/min to 100 beats/min</span>
        <span itemprop="definition">may be labelled 1 (normal).</span>
        <meta itemprop="num_attr" content="0218">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the frequency range of the electro-cardio signal less than 60 beats/min or more than 100 beats/min</span>
        <span itemprop="definition">may be labelled 2 (abnormal).</span>
        <meta itemprop="num_attr" content="0218">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a further segmentation</span>
        <span itemprop="definition">may be performed and different indices may be labeled as the input data based on the frequency of the electro-cardio signal of the user, and the trained machine learning model may output a corresponding fatigue index according to the frequency of the electro-cardio signal.</span>
        <meta itemprop="num_attr" content="0218">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the machine learning model</span>
        <span itemprop="definition">may also be trained in combination with the physiological parameter signal such as the respiratory rate, the temperature signal, etc.</span>
        <meta itemprop="num_attr" content="0218">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the sample information</span>
        <span itemprop="definition">may be obtained from the storage device of the processing device 110 .</span>
        <meta itemprop="num_attr" content="0218">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the sample information</span>
        <span itemprop="definition">may be obtained from the obtaining module 210 .</span>
        <meta itemprop="num_attr" content="0218">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the movement recognition model</span>
        <span itemprop="definition">may be any one of the machine learning models or a combination of the plurality of machine learning models, or include other machine learning models, which may be selected according to an actual situation.</span>
        <meta itemprop="num_attr" content="0218">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the input of the training of the machine learning model</span>
        <span itemprop="definition">is not limited to one segment (one cycle) of the movement signal, but may also be part of a segment of the movement signal, or a plurality of segments of the movement signal, etc.</span>
        <meta itemprop="num_attr" content="0218">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">step 2030</span>
        <span itemprop="definition">the movement recognition model may be extracted.</span>
        <meta itemprop="num_attr" content="0219">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the step</span>
        <span itemprop="definition">may be performed by the processing device 110 .</span>
        <meta itemprop="num_attr" content="0220">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processing device 110 and/or the processing module 220</span>
        <span itemprop="definition">may extract the movement recognition model.</span>
        <meta itemprop="num_attr" content="0220">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the movement recognition model</span>
        <span itemprop="definition">may be stored to the processing device 110 , the processing module 220 , or a mobile terminal.</span>
        <meta itemprop="num_attr" content="0220">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">step 2040</span>
        <span itemprop="definition">the movement signal of the user may be obtained.</span>
        <meta itemprop="num_attr" content="0221">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the step</span>
        <span itemprop="definition">may be performed by the obtaining module 210 .</span>
        <meta itemprop="num_attr" content="0222">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">an electromyographic sensor in the obtaining module 210</span>
        <span itemprop="definition">may obtain the electromyographic signal of the user</span>
        <meta itemprop="num_attr" content="0222">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">an attitude sensor in the obtaining module 210</span>
        <span itemprop="definition">may obtain the attitude signal of the user.</span>
        <meta itemprop="num_attr" content="0222">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the user movement signal</span>
        <span itemprop="definition">may also include other physiological parameter signals such as the electro-cardio signal, the respiration signal, the temperature signal, the humidity signal, etc. during the motion of the user.</span>
        <meta itemprop="num_attr" content="0222">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the obtained movement signal</span>
        <span itemprop="definition">(e.g., the electromyographic signal and/or the attitude signal) may be subjected to the segmentation processing of the process 700 , the burr processing of process the 900 , and the conversion processing of the process 1300 , etc., to form at least one segment of the electromyographic signal and/or the attitude signal.</span>
        <meta itemprop="num_attr" content="0222">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the movement of the user</span>
        <span itemprop="definition">may be determined based on the movement signal of the user through the movement recognition model.</span>
        <meta itemprop="num_attr" content="0223">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the step</span>
        <span itemprop="definition">may be performed by the processing device 110 and/or the processing module 220 .</span>
        <meta itemprop="num_attr" content="0224">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processing device 110 and/or the processing module 220</span>
        <span itemprop="definition">may determine the movement of the user based on the movement recognition model.</span>
        <meta itemprop="num_attr" content="0224">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the trained movement recognition model</span>
        <span itemprop="definition">may include one or more machine learning models.</span>
        <meta itemprop="num_attr" content="0224">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the movement recognition model</span>
        <span itemprop="definition">may include, but is not limited to, the machine learning model that classifies the movement signal of the user, the machine learning model that recognizes the movement quality of the user, the machine learning model that recognizes the movement quantity of user, the machine learning model that recognizes the fatigue index of the user performing the movement, or any combination thereof.</span>
        <meta itemprop="num_attr" content="0224">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the different machine learning models</span>
        <span itemprop="definition">may have different recognition effects.</span>
        <meta itemprop="num_attr" content="0224">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the machine learning model that classifies the movement signal</span>
        <span itemprop="definition">may use the movement signal of the user as input data and output a corresponding movement type.</span>
        <meta itemprop="num_attr" content="0224">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the machine learning model that recognizes the movement quality of the user</span>
        <span itemprop="definition">may use the movement signal of the user as input data and output the movement quality (e.g., a standard movement, an incorrect movement).</span>
        <meta itemprop="num_attr" content="0224">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the machine learning model that recognizes the fatigue index of the user performing the movement</span>
        <span itemprop="definition">may use the movement signal (e.g., the frequency of the electro-cardio signal) of the user as input data and output the fatigue index of the user.</span>
        <meta itemprop="num_attr" content="0224">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the movement signal of the user and the determination result (output) of the machine learning model</span>
        <span itemprop="definition">may also be used as the sample information of training the movement recognition model, and the movement recognition model may be trained to optimize relevant parameters of the movement recognition model.</span>
        <meta itemprop="num_attr" content="0224">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the movement recognition model</span>
        <span itemprop="definition">is not limited to the trained machine learning model described above, but can also be a preset model, for example, a manually preset conditional judgment algorithm or manually adding parameters (e.g., a confidence level) to the trained machine learning model, etc.</span>
        <meta itemprop="num_attr" content="0224">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">step 2060</span>
        <span itemprop="definition">feedback may be performed on the movement of the user based on the determination result.</span>
        <meta itemprop="num_attr" content="0225">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the step</span>
        <span itemprop="definition">may be performed by the wearable device 130 and/or the mobile terminal device 140 .</span>
        <meta itemprop="num_attr" content="0226">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processing device 110 and/or the processing module 220</span>
        <span itemprop="definition">may send a feedback instruction to the wearable device 130 and/or the mobile terminal device 140 based on the determination result of the movement of the user.</span>
        <meta itemprop="num_attr" content="0226">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the wearable device 130 and/or the mobile terminal device 140</span>
        <span itemprop="definition">may perform feedback to the user based on the feedback instruction.</span>
        <meta itemprop="num_attr" content="0226">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the feedback</span>
        <span itemprop="definition">may include sending prompt information (e.g., text information, image information, video information, voice information, indicator information, etc.) and/or stimulating the body of the user by performing a corresponding movement (a manner such as a current stimulation, a vibration, a pressure change, a heat change, etc.).</span>
        <meta itemprop="num_attr" content="0226">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the input/output module 260</span>
        <span itemprop="definition">e.g., a vibration prompter</span>
        <meta itemprop="num_attr" content="0226">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the wearable device 130 and the mobile terminal device 140</span>
        <span itemprop="definition">may perform a corresponding feedback movement (e.g., applying the vibration to the user&#39;s body part, sending the voice prompt, etc.) to prompt the user to adjust an exertion part in time.</span>
        <meta itemprop="num_attr" content="0226">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the movement type, the movement quality, and the movement quantity during the motion of the user</span>
        <span itemprop="definition">may be determined by monitoring the movement signal during the motion of the user, and the mobile terminal device 140 may output corresponding movement records, so that the user can understand his/her motion situation during the motion.</span>
        <meta itemprop="num_attr" content="0226">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the feedback</span>
        <span itemprop="definition">when the feedback is performed to the user, the feedback may be matched to perception of the user. For example, when the movement of the user is not standard, the vibration stimulation may be performed on an area corresponding to the movement of the user, and the user may know that the movement is not standard based on the vibration stimulation. The vibration stimulation is within an acceptable range of the user. Further, a matching model may be constructed based on the movement signal of the user and the perception of the user to find a best balance between the user perception and a real feedback.</span>
        <meta itemprop="num_attr" content="0227">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the movement recognition model</span>
        <span itemprop="definition">may further be trained based on the movement signal of the user.</span>
        <meta itemprop="num_attr" content="0228">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">training the movement recognition model according to the movement signal of the user</span>
        <span itemprop="definition">may include determining a confidence level of the movement signal of the user by evaluating the movement signal of the user.</span>
        <meta itemprop="num_attr" content="0228">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the confidence level</span>
        <span itemprop="definition">may indicate a quality of the movement signal of the user. For example, the higher the confidence level, the better the quality of the movement signal of the user.</span>
        <meta itemprop="num_attr" content="0228">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">evaluating the movement signal of the user</span>
        <span itemprop="definition">may be performed at a stage such as movement signal obtaining, pre-processing, segmentation, and/or recognition.</span>
        <meta itemprop="num_attr" content="0228">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">training the movement recognition model according to the movement signal of the user</span>
        <span itemprop="definition">may further include determining whether the confidence level is greater than a confidence level threshold (e.g., 80 ). If the confidence level is greater than or equal to the confidence level threshold, the movement recognition model may be trained by using the movement signal of the user corresponding to the confidence level as sample data. If the confidence level is smaller than the confidence level threshold, the movement signal of the user corresponding to the confidence level may not be used as sample data to train the movement recognition model.</span>
        <meta itemprop="num_attr" content="0229">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the confidence level</span>
        <span itemprop="definition">may include, but is not limited to, a confidence level of any stage of the movement signal obtaining, the movement signal pre-processing, the movement signal segmentation, or the movement signal recognition.</span>
        <meta itemprop="num_attr" content="0229">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the confidence level of the movement signal collected by the obtaining module 210</span>
        <span itemprop="definition">may be used as a determination criterion.</span>
        <meta itemprop="num_attr" content="0229">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the confidence level</span>
        <span itemprop="definition">may further include a joint confidence level of several stages such as the movement signal obtaining, the movement signal pre-processing, the movement signal segmentation, or the movement signal recognition.</span>
        <meta itemprop="num_attr" content="0229">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the joint confidence level</span>
        <span itemprop="definition">may be obtained by averaging or weighting the confidence level of each stage, etc.</span>
        <meta itemprop="num_attr" content="0229">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the movement recognition model</span>
        <span itemprop="definition">may be trained in real time, periodically (e.g., a day, a week, a month, etc.), or when a certain data volume is met according to the movement signal of the user.</span>
        <meta itemprop="num_attr" content="0229">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processing device 110 and/or the processing module 220</span>
        <span itemprop="definition">may send the feedback instruction to the wearable device 130 and/or the mobile terminal 140 based on the determination result of the movement of the user.</span>
        <meta itemprop="num_attr" content="0231">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the wearable device 130 and/or the mobile terminal 140</span>
        <span itemprop="definition">may perform feedback to the user based on the feedback instruction.</span>
        <meta itemprop="num_attr" content="0231">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the input/output module 260</span>
        <span itemprop="definition">e.g., a vibration prompter</span>
        <meta itemprop="num_attr" content="0231">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the mobile terminal device 140</span>
        <span itemprop="definition">e.g., a smartwatch, a smart phone, etc.</span>
        <meta itemprop="num_attr" content="0231">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the corresponding feedback movement</span>
        <span itemprop="definition">e.g., applying the vibration to the user&#39;s body part, sending the voice prompt, etc.</span>
        <meta itemprop="num_attr" content="0231">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the user</span>
        <span itemprop="definition">may be unable to identify a reason for the non-standard movement according to the feedback movement, such as a non-standard posture, an incorrect exertion position of a muscle, an incorrect exertion strength of a muscle, etc.</span>
        <meta itemprop="num_attr" content="0231">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a reason for the non-standard movement</span>
        <span itemprop="definition">such as a non-standard posture, an incorrect exertion position of a muscle, an incorrect exertion strength of a muscle, etc.</span>
        <meta itemprop="num_attr" content="0231">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the user&#39;s credibility of the motion monitoring system 100</span>
        <span itemprop="definition">may also decrease. For example, when a user performs the bicep curl, a standard posture of the movement may be that shoulders needs to be relaxed.</span>
        <meta itemprop="num_attr" content="0231">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the embodiments of the present disclosure</span>
        <span itemprop="definition">may also provide a method for displaying a motion monitoring interface.</span>
        <meta itemprop="num_attr" content="0231">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the method</span>
        <span itemprop="definition">may display information related to the motion of the user (e.g., the exertion position of the muscle, the exertion strength of the muscle, and the user&#39;s movement model) by using a display device.</span>
        <meta itemprop="num_attr" content="0231">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the user</span>
        <span itemprop="definition">can intuitively observe a problem in the motion according to display content, and timely adjust the movement for a scientific motion.</span>
        <meta itemprop="num_attr" content="0231">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 21 A</span>
        <span itemprop="definition">is a flowchart illustrating an exemplary process of a method for displaying a motion monitoring interface according to some embodiments of the present disclosure. As shown in FIG. 21 A , the process 2100 may include the following steps.</span>
        <meta itemprop="num_attr" content="0232">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a movement signal during a motion of a user</span>
        <span itemprop="definition">may be obtained from at least one sensor.</span>
        <meta itemprop="num_attr" content="0233">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the step 2110</span>
        <span itemprop="definition">may be performed by the obtaining module 210 .</span>
        <meta itemprop="num_attr" content="0234">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the movement signal during the motion of the user</span>
        <span itemprop="definition">may refer to human body parameter information during the motion of the user.</span>
        <meta itemprop="num_attr" content="0234">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the human body parameter information</span>
        <span itemprop="definition">may include, but is not limited to, an electromyographic signal, an attitude signal, an electro-cardio signal, a temperature signal, a humidity signal, a blood oxygen concentration, a respiratory rate, or the like, or any combination thereof.</span>
        <meta itemprop="num_attr" content="0234">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a sensor in the obtaining module 210</span>
        <span itemprop="definition">may obtain the movement signal during the motion of the user.</span>
        <meta itemprop="num_attr" content="0234">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">an electromyography sensor in the obtaining module 210</span>
        <span itemprop="definition">may collect the electromyographic signal during the motion of the user.</span>
        <meta itemprop="num_attr" content="0234">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the electromyography sensor in the wearable device corresponding to a position of a human pectoral muscle, a latissimus dorsi, etc.</span>
        <span itemprop="definition">may collect the electromyographic signal corresponding to the muscle position of the user.</span>
        <meta itemprop="num_attr" content="0234">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">an attitude sensor in the obtaining module 210</span>
        <span itemprop="definition">may collect the attitude signal during the motion of the user.</span>
        <meta itemprop="num_attr" content="0234">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the attitude sensor in the wearable device corresponding to a position of a human triceps brachii muscle</span>
        <span itemprop="definition">may collect the attitude signal of the position of the user&#39;s triceps brachii muscle.</span>
        <meta itemprop="num_attr" content="0234">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the at least one sensor</span>
        <span itemprop="definition">may include, but is not limited to, an attitude sensor, an electro-cardio sensor, an electromyography sensor, a temperature sensor, a humidity sensor, an inertial sensor, an acid-base sensor, an acoustic transducer, or the like, or any combination thereof.</span>
        <meta itemprop="num_attr" content="0234">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Different types of sensors</span>
        <span itemprop="definition">may be placed at different positions of the user&#39;s body according to different signals to be measured, so that different types of sensors and/or sensors at different positions can collect different movement signals.</span>
        <meta itemprop="num_attr" content="0234">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the movement signal</span>
        <span itemprop="definition">may be a movement signal formed after the movement signal collected by a plurality of sensors in the obtaining module 210 during the motion of the user is subject to a signal processing process such as filtering, rectification, and/or wavelet transform, a segmentation processing of the process 700 , a burr processing of the process 900 , or permutation and combination of any one or more of the above processing processes.</span>
        <meta itemprop="num_attr" content="0235">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a signal processing process</span>
        <span itemprop="definition">such as filtering, rectification, and/or wavelet transform, the segmentation processing of process 700 , and the burr processing of process 900 may be performed by the processing module 220 and/or the processing device 110 .</span>
        <meta itemprop="num_attr" content="0235">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the obtaining module 210</span>
        <span itemprop="definition">may obtain the processed movement signal from the processing module 220 and/or the processing device 110 .</span>
        <meta itemprop="num_attr" content="0235">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">step 2120</span>
        <span itemprop="definition">information related to the motion of the user may be determined by processing the movement signal.</span>
        <meta itemprop="num_attr" content="0236">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the step 2120</span>
        <span itemprop="definition">may be performed by the processing module 220 .</span>
        <meta itemprop="num_attr" content="0237">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the information related to the motion of the user</span>
        <span itemprop="definition">may include a movement type, a movement frequency, a movement intensity, a movement model of the user, or the like, or any combination thereof.</span>
        <meta itemprop="num_attr" content="0237">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processing module 220</span>
        <span itemprop="definition">may determine feature information of the movement signal (e.g., amplitude information, frequency information of the electromyographic signal, and/or an angular velocity, an angular velocity direction, and an acceleration value of angular velocity of the attitude signal) by analyzing and processing the movement signal of the user, and determine the information related to the motion of the user according to the feature information of the movement signal.</span>
        <meta itemprop="num_attr" content="0237">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">feature information of the movement signal</span>
        <span itemprop="definition">e.g., amplitude information, frequency information of the electromyographic signal, and/or an angular velocity, an angular velocity direction, and an acceleration value of angular velocity of the attitude signal</span>
        <meta itemprop="num_attr" content="0237">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the information related to the motion of the user</span>
        <span itemprop="definition">may include an exertion strength of at least one muscle during the motion of the user.</span>
        <meta itemprop="num_attr" content="0238">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processing module 220</span>
        <span itemprop="definition">may determine the exertion strength of the at least one muscle of the user according to the electromyographic signal collected by the electromyography sensor. For example, when a user performs a deep squat movement, the electromyography sensor set at a position of a human gluteus maximus, a quadriceps femoris muscle, etc.</span>
        <meta itemprop="num_attr" content="0238">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processing module 220</span>
        <span itemprop="definition">may collect the electromyographic signal corresponding to the muscle position of the user, and the processing module 220 may determine the exertion strength of the gluteus maximus and quadriceps femoris muscle of the user based on a signal strength of the obtained electromyographic signal.</span>
        <meta itemprop="num_attr" content="0238">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processing module 220</span>
        <span itemprop="definition">may determine the movement type of the user based on the movement signal. For example, the processing module 220 may determine the movement type based on the movement signal and a movement recognition model (e. g., the movement recognition model described in FIG. 20 ) of the user. For example, the movement type may be manually input. Further, the processing module 220 may determine a muscle located at an exercise position (also called a muscle of the exercise position) of the user and a muscle located at a non-exercise position (also called a muscle of the non-exercise position) of the user according to the movement type of the user.</span>
        <meta itemprop="num_attr" content="0239">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a movement recognition model</span>
        <span itemprop="definition">e. g., the movement recognition model described in FIG. 20</span>
        <meta itemprop="num_attr" content="0239">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processing module 220</span>
        <span itemprop="definition">may determine a muscle located at an exercise position (also called a muscle of the exercise position) of the user and a muscle located at a non-exercise position (also called a muscle of the non-exercise position) of the user according to the movement type of the user.</span>
        <meta itemprop="num_attr" content="0239">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the muscle of the non-exercise position</span>
        <span itemprop="definition">may be a muscle of a position where an incorrect exertion easily occurs or a muscle at a part that is easy to be injured when the user perform a certain movement.</span>
        <meta itemprop="num_attr" content="0239">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Different movement types</span>
        <span itemprop="definition">may correspond to different muscles of exercise positions and different muscles of non-exercise positions.</span>
        <meta itemprop="num_attr" content="0239">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the user</span>
        <span itemprop="definition">may preset the muscle of the exercise position and the muscle of the non-exercise position corresponding to each movement type.</span>
        <meta itemprop="num_attr" content="0239">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processing module 220</span>
        <span itemprop="definition">may determine whether an exertion part of the user is correct and whether the movement posture is standard when a corresponding movement is performed according to the exertion strengths of the muscle of the exercise position and/or the muscle of the non-exercise position of the user.</span>
        <meta itemprop="num_attr" content="0239">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the input/output module 260</span>
        <span itemprop="definition">may send a feedback signal to the user to prompt the user to adjust the movement in time.</span>
        <meta itemprop="num_attr" content="0239">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the information related to the motion of the user</span>
        <span itemprop="definition">may include a user movement model representing a movement of the motion of the user.</span>
        <meta itemprop="num_attr" content="0240">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the attitude sensor set at a position</span>
        <span itemprop="definition">such as a human deltoid muscle, an upper limb joint (e.g., an arm elbow joint), etc. may collect the attitude signal of the deltoid muscle and the upper limb joint of the user.</span>
        <meta itemprop="num_attr" content="0240">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processing module 220</span>
        <span itemprop="definition">may process each attitude signal to obtain the feature information corresponding to each attitude signal (e.g., angular velocity information, acceleration information, stress information, displacement information), and the processing module 220 may generate the movement model of the dumbbell flying bird movement according to the feature information. Further description regarding generating the user movement model during the motion of the user based on the attitude signal may be found in FIG. 22 and related description thereof.</span>
        <meta itemprop="num_attr" content="0240">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">step 2130</span>
        <span itemprop="definition">the information related to the motion of the user may be displayed.</span>
        <meta itemprop="num_attr" content="0241">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the step 2130</span>
        <span itemprop="definition">may be performed by the input/output module 260 .</span>
        <meta itemprop="num_attr" content="0242">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the information related to the motion of the user</span>
        <span itemprop="definition">may be displayed on a display device (e.g., a display screen) of the wearable device 130 or the mobile terminal device 140 , so that the user can intuitively observe a motion situation during the motion.</span>
        <meta itemprop="num_attr" content="0242">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">an interface of the display device</span>
        <span itemprop="definition">may display a front muscle distribution map 2101 and a back muscle distribution diagram 2102 of a human body.</span>
        <meta itemprop="num_attr" content="0243">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a color of a muscle corresponding to an exertion part of the user in the human muscle distribution map</span>
        <span itemprop="definition">(e.g., the front muscle distribution map 2101 and the back muscle distribution map 2102 ) may change, so that the user can intuitively feel the exertion strength of the muscle according to the color change corresponding to the muscle in the human muscle distribution map.</span>
        <meta itemprop="num_attr" content="0243">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">an exertion strength of a muscle</span>
        <span itemprop="definition">such as a rectus abdominis muscle, an external oblique muscle, an internal oblique muscle, and a transverse muscle of abdomen of the user&#39;s abdomen, and a trapezius muscle of the user&#39;s shoulder may be displayed in the human muscle distribution map.</span>
        <meta itemprop="num_attr" content="0243">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the greater the exertion strength of a certain muscle of the user</span>
        <span itemprop="definition">the darker the color corresponding to the muscle in the human muscle distribution map (e.g., the closer to red).</span>
        <meta itemprop="num_attr" content="0243">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processing module 220 and/or the user</span>
        <span itemprop="definition">may determine whether the sit-up movement is standard or not according to the exertion strength of muscles of different positions. For example, if the exertion strength of the rectus abdominis muscle, the external oblique muscle, the internal oblique muscle, and the transverse muscle of the user&#39;s abdomen is greater than a first strength threshold (the first strength threshold may be set according to the exertion strength of the corresponding muscle when a professional performs a standard sit-up movement), and when the exertion strength of the trapezius muscle of the user&#39;s shoulder is smaller than a second strength threshold (the second strength threshold may be set according to the exertion strength of the corresponding muscle when the professional performs the standard sit-up movement), the processing module 220 may determine that the sit-up movement of the user is standard. Otherwise, the processing module 220 may determine that the sit-up movement of the user is non-standard.</span>
        <meta itemprop="num_attr" content="0244">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a first strength threshold</span>
        <span itemprop="definition">may be set according to the exertion strength of the corresponding muscle when a professional performs</span>
        <meta itemprop="num_attr" content="0244">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">front muscle distribution map 2101 and the back muscle distribution map 2102 of the human body shown in FIG. 21 B</span>
        <span itemprop="definition">are only examples.</span>
        <meta itemprop="num_attr" content="0245">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the front muscle distribution map 2101 and the back muscle distribution map 2102 of the human body</span>
        <span itemprop="definition">may be arranged up and down, left and right, or in other arrangement modes easy to observe in the interface.</span>
        <meta itemprop="num_attr" content="0245">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the input/output module 260</span>
        <span itemprop="definition">may obtain a user input regarding a target muscle.</span>
        <meta itemprop="num_attr" content="0246">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the target muscle</span>
        <span itemprop="definition">may refer to a muscle that the user pays more attention to during the motion.</span>
        <meta itemprop="num_attr" content="0246">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the target muscle</span>
        <span itemprop="definition">may be a muscle that the user focuses on during an exercise.</span>
        <meta itemprop="num_attr" content="0246">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a position of the target muscle and/or a count of target muscles</span>
        <span itemprop="definition">may be related to the movement type of the user.</span>
        <meta itemprop="num_attr" content="0246">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the target muscle</span>
        <span itemprop="definition">may include the gluteus maximus, the quadriceps femoris muscle, a tibialis anterior muscle, or the like, or any combination thereof.</span>
        <meta itemprop="num_attr" content="0246">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the target muscle</span>
        <span itemprop="definition">may include the rectus abdominis muscle, the external oblique muscle, the internal oblique muscle, the transverse muscle of abdomen, the trapezius muscle, or the like, or any combination thereof.</span>
        <meta itemprop="num_attr" content="0246">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processing module 220</span>
        <span itemprop="definition">may determine the movement type of the user based on the movement signal, and determine the target muscle according to the movement type of the user automatically.</span>
        <meta itemprop="num_attr" content="0246">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the user</span>
        <span itemprop="definition">may determine the movement type manually, and the processing module 220 may determine the target muscle according to the movement type input by the user based on a corresponding relationship between the movement type and the target muscle.</span>
        <meta itemprop="num_attr" content="0246">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the user</span>
        <span itemprop="definition">may determine the target muscle manually. For example, the user may set a specific muscle as the target muscle by clicking the specific muscle in the human muscle distribution map. As another example, the user may set a specific muscle as the target muscle by inputting a name of the specific muscle in the interface of the display device.</span>
        <meta itemprop="num_attr" content="0246">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the interface of the display device</span>
        <span itemprop="definition">may include a status bar (e.g., a status bar 2103 and a status bar 2104 shown in FIG. 21 B ).</span>
        <meta itemprop="num_attr" content="0247">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the status bar</span>
        <span itemprop="definition">may be configured to display information of the target muscle (e.g., an exertion strength of the target muscle). For example, when the target muscle input by the user is a pectoralis major muscle, the exertion strength of the pectoralis major muscle may be displayed through the status bar.</span>
        <meta itemprop="num_attr" content="0247">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a color of the status bar</span>
        <span itemprop="definition">may be related to the exertion strength of the target muscle. For example, the darker the color of the status bar, the greater the exertion strength of the target muscle.</span>
        <meta itemprop="num_attr" content="0247">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the status bar</span>
        <span itemprop="definition">may display a proportional relationship between the exertion strength of the target muscle and a standard exertion strength (or the maximum exertion strength).</span>
        <meta itemprop="num_attr" content="0247">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the standard exertion strength</span>
        <span itemprop="definition">may be set according to an exertion strength corresponding to a muscle when the professional performs a standard movement.</span>
        <meta itemprop="num_attr" content="0247">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the maximum exertion strength</span>
        <span itemprop="definition">may be set according to an exertion strength limit of a human muscle. For example, if the status bar is full, it may indicate that the exertion strength of the target muscle of the user is consistent with the standard exertion strength. The user may more intuitively feel a difference between his/her exertion strength of muscle and the standard exertion strength of muscle through the status bar displayed in the interface, so that the user can timely adjust his/her exertion strength of muscle.</span>
        <meta itemprop="num_attr" content="0247">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a count of status bars</span>
        <span itemprop="definition">may be related to a count of target muscles. For example, when the user sets a triceps brachii muscle as the target muscle, two status bars may be displayed on left and right sides of the interface, respectively.</span>
        <meta itemprop="num_attr" content="0248">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the left status bar</span>
        <span itemprop="definition">e.g., the status bar 2103 shown in FIG. 21 B</span>
        <meta itemprop="num_attr" content="0248">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the right status bar</span>
        <span itemprop="definition">e.g., the status bar 2104 shown in FIG. 21 B</span>
        <meta itemprop="num_attr" content="0248">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the exertion strengths of the target muscles on the left and right sides of the user</span>
        <span itemprop="definition">may be displayed through two status bars, which may help the user determine whether the exertion strengths of the muscles on the left and right sides of the body are balanced during the motion, so as to avoid physical damage caused by uneven force on the left and right sides of the body.</span>
        <meta itemprop="num_attr" content="0248">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the status bars shown in FIG. 21 B</span>
        <span itemprop="definition">are only examples.</span>
        <meta itemprop="num_attr" content="0248">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the count of the status bars</span>
        <span itemprop="definition">may be any numeric value.</span>
        <meta itemprop="num_attr" content="0248">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the status bar</span>
        <span itemprop="definition">may be set at any position of the interface.</span>
        <meta itemprop="num_attr" content="0248">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the input/output module 260</span>
        <span itemprop="definition">may include a sound output device (e. g., a speaker).</span>
        <meta itemprop="num_attr" content="0249">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the sound output device</span>
        <span itemprop="definition">may make a sound (e.g., a sound of flame burning, bells, water flow), and a volume of the sound may be related to the exertion strength of the target muscle.</span>
        <meta itemprop="num_attr" content="0249">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the volume of the sound</span>
        <span itemprop="definition">may be positively related to the exertion strength of the target muscle, that is, the greater the exertion strength of the target muscle, the greater the volume of the sound; and the weaker the exertion strength of the target muscle, the smaller the volume of the sound.</span>
        <meta itemprop="num_attr" content="0249">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the sound output device</span>
        <span itemprop="definition">may include a left channel and a right channel, and different channels may correspond to the exertion strengths of different target muscles.</span>
        <meta itemprop="num_attr" content="0249">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the sound from the left channel</span>
        <span itemprop="definition">may correspond to the exertion strength of the target muscle on the left side of the user&#39;s body (e.g., the triceps brachii muscle on the left arm), and the sound from the right channel may correspond to the exertion strength of the target muscle on the right side of the user&#39;s body (e.g., the triceps brachii muscle on the right arm).</span>
        <meta itemprop="num_attr" content="0249">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the user</span>
        <span itemprop="definition">may feel the exertion strengths of the muscles in different parts of the body. The user may determine whether the exertion strengths of the muscles on the left and right sides of the body are balanced during the motion only by hearing, which can further improve the user&#39;s sense of experience.</span>
        <meta itemprop="num_attr" content="0249">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the above description regarding the process 2100</span>
        <span itemprop="definition">is merely provided for the purpose of illustration, and not intended to limit the scope of the present disclosure.</span>
        <meta itemprop="num_attr" content="0250">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">various amendments and changes</span>
        <span itemprop="definition">can be made to the process 2100 under the guidance of the present disclosure.</span>
        <meta itemprop="num_attr" content="0250">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the step 2120</span>
        <span itemprop="definition">may be divided into a plurality of steps to perform processing and determination of the movement signal, respectively.</span>
        <meta itemprop="num_attr" content="0250">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">these amendments and changes</span>
        <span itemprop="definition">are still within the scope of the present disclosure.</span>
        <meta itemprop="num_attr" content="0250">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 22</span>
        <span itemprop="definition">is a flowchart illustrating an exemplary process for displaying a motion monitoring interface according to some embodiments of the present disclosure. As shown in FIG. 22 , the process 2200 may include the following steps.</span>
        <meta itemprop="num_attr" content="0251">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a user movement model representing a movement of the motion of the user</span>
        <span itemprop="definition">may be generated based on an attitude signal.</span>
        <meta itemprop="num_attr" content="0252">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the step 2210</span>
        <span itemprop="definition">may be performed by the processing module 220 .</span>
        <meta itemprop="num_attr" content="0253">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the user movement model</span>
        <span itemprop="definition">may include a user three-dimensional (3D) movement model, a user three-dimensional (2D) movement model, etc.</span>
        <meta itemprop="num_attr" content="0253">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the user 3D movement model and/or the user 2D movement model</span>
        <span itemprop="definition">may reproduce the movement of the motion of the user. It may be understood that the movement reproduction of the motion of the user may reflect a posture of the motion of the user to a certain extent, without requiring the reproduced movement to be completely consistent with the real movement of the user.</span>
        <meta itemprop="num_attr" content="0253">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processing module 220</span>
        <span itemprop="definition">may generate the user movement model representing the movement of the motion of the user based on the attitude signal collected by an attitude sensor.</span>
        <meta itemprop="num_attr" content="0254">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a plurality of attitude sensors</span>
        <span itemprop="definition">may be placed at different positions of the wearable device 130 (e.g., positions of the wearable device 130 corresponding to a trunk, limbs and joints) according to an attitude signal required to be obtained to measure the attitude signals corresponding to different parts of a human body.</span>
        <meta itemprop="num_attr" content="0254">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the attitude signals corresponding to the different parts</span>
        <span itemprop="definition">may reflect a relative motion situation between different parts of the human body.</span>
        <meta itemprop="num_attr" content="0254">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the attitude signal</span>
        <span itemprop="definition">may be associated with a type of attitude sensor. For example, when the attitude sensor is an angular velocity triaxial sensor, the obtained attitude signal may be angular velocity information.</span>
        <meta itemprop="num_attr" content="0254">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the obtained attitude signal</span>
        <span itemprop="definition">may be the angular velocity information and acceleration information.</span>
        <meta itemprop="num_attr" content="0254">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the attitude sensor</span>
        <span itemprop="definition">when the attitude sensor is a strain gauge sensor, the strain gauge sensor may be set at a joint position of the user. By measuring a magnitude of a resistance in the strain gauge sensor that changes with a tensile length, the obtained attitude signals may include displacement information, stress, etc.</span>
        <meta itemprop="num_attr" content="0254">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the attitude signals</span>
        <span itemprop="definition">may characterize a bending angle and a bending direction at the joint of the user.</span>
        <meta itemprop="num_attr" content="0254">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the attitude sensor</span>
        <span itemprop="definition">may be an ultrasonic sensor that is set at a fixed position of the joint or the limb of the user.</span>
        <meta itemprop="num_attr" content="0254">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a position of the sensor</span>
        <span itemprop="definition">may be determined by measuring the time of flight (TOF) of an acoustic wave, so as to determine an attitude of the user.</span>
        <meta itemprop="num_attr" content="0254">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the attitude signal obtained by the attitude sensor and feature information corresponding to the attitude sensor</span>
        <span itemprop="definition">e.g., an angular velocity direction, an angular velocity value, an acceleration value of angular velocity, angle, displacement information, stress, etc.</span>
        <meta itemprop="num_attr" content="0254">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processing module 220</span>
        <span itemprop="definition">may generate the user movement model representing the movement of the motion of the user based on the posture of the motion of the user.</span>
        <meta itemprop="num_attr" content="0254">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processing module 220</span>
        <span itemprop="definition">may generate a virtual character (e. g., a 3D or 2D animation model) to display the posture of the motion of the user.</span>
        <meta itemprop="num_attr" content="0254">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processing module 220</span>
        <span itemprop="definition">may determine other types of information related to the motion of the user (e.g., muscle information) based on other types of movement signals (e.g., an electromyographic signal), and display the other types of information related to the motion of the user on the user movement model.</span>
        <meta itemprop="num_attr" content="0255">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processing module 220</span>
        <span itemprop="definition">may determine an exertion strength of at least one muscle of the user based on the electromyographic signal, and the processing module 220 may display the exertion strength of the at least one muscle of the user on a corresponding position of the user movement model.</span>
        <meta itemprop="num_attr" content="0255">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processing module 220</span>
        <span itemprop="definition">may obtain the electromyographic signal from an electromyography sensor set at a position such as a gluteus maximus, a quadriceps femoris muscle, a tibialis anterior muscle, etc.</span>
        <meta itemprop="num_attr" content="0255">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processing module 220</span>
        <span itemprop="definition">may determine the exertion strength of the muscle such as the gluteus maximus, the quadriceps femoris muscle, and the tibialis anterior muscle, respectively, according to the electromyographic signal, and display the exertion strength of the muscle of the gluteus maximus, the quadriceps femoris muscle, and the tibialis anterior muscle at the position corresponding to the gluteus maximus, the quadriceps femoris muscle, and the tibialis anterior muscle in the user movement model.</span>
        <meta itemprop="num_attr" content="0255">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">different muscle strengths</span>
        <span itemprop="definition">may correspond to different display colors.</span>
        <meta itemprop="num_attr" content="0255">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a standard movement model</span>
        <span itemprop="definition">may be obtained.</span>
        <meta itemprop="num_attr" content="0256">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the step 2220</span>
        <span itemprop="definition">may be performed by the obtaining module 210 .</span>
        <meta itemprop="num_attr" content="0257">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the standard movement model</span>
        <span itemprop="definition">may be a movement model generated based on standard movement information (e.g., standard attitude information, standard electromyography information) during a motion of a professional (e.g., a fitness instructor).</span>
        <meta itemprop="num_attr" content="0257">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the standard movement model</span>
        <span itemprop="definition">may include a standard 3D movement model, a standard 2D movement model, etc.</span>
        <meta itemprop="num_attr" content="0257">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the standard 3D movement model and/or the standard 2D movement model</span>
        <span itemprop="definition">may reproduce the movement of the professional. It may be understood that the movement reproduction of the standard movement may reflect a posture of the motion of the professional to a certain extent, without requiring the reproduced movement to be completely consistent with the real movement of the professional.</span>
        <meta itemprop="num_attr" content="0257">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the standard movement model</span>
        <span itemprop="definition">may display a plurality of types of information related to the motion (e.g., muscle information) during the motion of the professional.</span>
        <meta itemprop="num_attr" content="0257">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">different types of movements</span>
        <span itemprop="definition">may correspond to different standard movement models.</span>
        <meta itemprop="num_attr" content="0258">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a sit-up movement</span>
        <span itemprop="definition">may correspond to a sit-up standard movement model</span>
        <meta itemprop="num_attr" content="0258">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a dumbbell flying bird movement</span>
        <span itemprop="definition">may correspond to a dumbbell flying bird standard movement model.</span>
        <meta itemprop="num_attr" content="0258">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a plurality of standard movement models corresponding to a plurality of motion types</span>
        <span itemprop="definition">may be stored in a storage device of the motion monitoring system 100 in advance.</span>
        <meta itemprop="num_attr" content="0258">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the obtaining module 210</span>
        <span itemprop="definition">may obtain, according to the movement type of the user, the standard movement model corresponding to the movement type of the user from the storage device.</span>
        <meta itemprop="num_attr" content="0258">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">step 2230</span>
        <span itemprop="definition">the user movement model and the standard movement model may be displayed.</span>
        <meta itemprop="num_attr" content="0259">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the step 2230</span>
        <span itemprop="definition">may be performed by the input/output module 260 .</span>
        <meta itemprop="num_attr" content="0260">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the display device</span>
        <span itemprop="definition">may display the user movement model and the standard movement model simultaneously. For example, the user movement model and the standard movement model may be displayed on top of each other or side by side. By observing and comparing the user movement model and the standard movement model, the user may determine whether the movement of the motion is standard more intuitively and quickly, so as to adjust the movement of the motion in time.</span>
        <meta itemprop="num_attr" content="0260">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a determination</span>
        <span itemprop="definition">may be made as whether the movement of the user needs to be adjusted by comparing a degree of coincidence between a contour of the user movement model and a contour of the standard movement model. For example, if the degree of coincidence between the contour of the user movement model and the contour of the standard movement model is greater than a threshold (e.g., 90%, 95%, 98%), it may be determined that the movement of the user is standard and does not need to be adjusted. If the degree of coincidence between the contour of the user movement model and the contour of the standard movement model is smaller than a threshold (e.g., 90%, 95%, 98%), it may be determined that the movement of the user is non-standard.</span>
        <meta itemprop="num_attr" content="0261">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the input/output module 260</span>
        <span itemprop="definition">may prompt the user to adjust the movement of the motion.</span>
        <meta itemprop="num_attr" content="0261">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a determination</span>
        <span itemprop="definition">may be made as whether the movement of the user needs to be adjusted by comparing the muscle information displayed on the user movement model with the muscle information displayed on the standard movement model.</span>
        <meta itemprop="num_attr" content="0262">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a bicep curl movement of a left arm</span>
        <span itemprop="definition">may be taken as an example.</span>
        <meta itemprop="num_attr" content="0262">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">muscles mainly involved in the movement</span>
        <span itemprop="definition">may include a biceps brachii muscle, a deltoid muscle, a trapezius muscle, and a pectoral muscle.</span>
        <meta itemprop="num_attr" content="0262">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIGS. 23 A to 23 C</span>
        <span itemprop="definition">are schematic diagrams illustrating motion monitoring interfaces according to some embodiments of the present disclosure. FIGS.</span>
        <meta itemprop="num_attr" content="0262">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIGS. 23 A to 23 C</span>
        <span itemprop="definition">are a user movement model 010 (also referred to as an electromyography animation 010 of a virtual user character) and a standard movement model 020 (also referred to as a reference electromyography animation 020 of a virtual reference character) displayed on the display device, respectively.</span>
        <meta itemprop="num_attr" content="0262">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the electromyography animation 010 of the virtual user character</span>
        <span itemprop="definition">may be displayed in a left half of the motion monitoring interface</span>
        <meta itemprop="num_attr" content="0262">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the reference electromyography animation 020 of the virtual reference character</span>
        <span itemprop="definition">may be displayed in a right half of the motion monitoring interface.</span>
        <meta itemprop="num_attr" content="0262">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the motion monitoring interface shown in FIG. 23 A</span>
        <span itemprop="definition">may correspond to the electromyography animation at a moment before the movement starts. As shown in FIG.</span>
        <meta itemprop="num_attr" content="0262">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a user display area 011 corresponding to the biceps brachii muscle, a user display area 012 corresponding to the deltoid muscle, a user display area 013 corresponding to the trapezius muscle, and a user display area 014 corresponding to the pectoral muscle in the electromyography animation 010 of the virtual user character</span>
        <span itemprop="definition">may have no color display.</span>
        <meta itemprop="num_attr" content="0262">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a user display area 021 corresponding to the biceps brachii muscle, a user display area 022 corresponding to the deltoid muscle, a user display area 023 corresponding to the trapezius, and a user display area 024 corresponding to the pectoral muscle in the reference electromyography animation 020 of the virtual reference character</span>
        <span itemprop="definition">may also have no color display.</span>
        <meta itemprop="num_attr" content="0262">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the motion monitoring interface shown in FIG. 23 B</span>
        <span itemprop="definition">may correspond to an electromyography animation at a certain moment in a process of the bicep curl movement.</span>
        <meta itemprop="num_attr" content="0263">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a main exertion point</span>
        <span itemprop="definition">may be the biceps brachii muscle.</span>
        <meta itemprop="num_attr" content="0263">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the pectoral muscle</span>
        <span itemprop="definition">may also exert slightly, for example, when the user does not chin up and chest out.</span>
        <meta itemprop="num_attr" content="0263">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the trapezius muscle</span>
        <span itemprop="definition">may not need to be involved in exertion or may exert slightly. As shown in FIG.</span>
        <meta itemprop="num_attr" content="0263">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a color displayed in the user display area 013 corresponding to the trapezius muscle in the electromyography animation 010 of the virtual user character</span>
        <span itemprop="definition">is darker than a color displayed in the reference display area 023 corresponding to the trapezius muscle in the electromyography animation 020 of the virtual reference character, which may indicate that the trapezius muscle exerts a relatively large force when the user performs the bicep curl movement, and the exertion strength exceeds an exertion strength of the trapezius muscle in the standard bicep curl movement.</span>
        <meta itemprop="num_attr" content="0263">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the motion monitoring interface shown in FIG. 23 C</span>
        <span itemprop="definition">may correspond to an electromyographic animation at a certain moment from an end of the bicep curl movement to a beginning of a next movement cycle.</span>
        <meta itemprop="num_attr" content="0264">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the user</span>
        <span itemprop="definition">may not be in a completely relaxed state from the end of a complete movement cycle to the beginning of a next complete movement cycle. That is, when a barbell reaches the bottom, the biceps muscle cannot be completely relaxed, but may need to maintain a certain amount of exertion strength, so as to achieve the best exercise effect.</span>
        <meta itemprop="num_attr" content="0264">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 23 C</span>
        <span itemprop="definition">may correspond to an electromyographic animation at a certain moment from an end of the bicep curl movement to a beginning of a next movement cycle.</span>
        <meta itemprop="num_attr" content="0264">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the user display area 011 corresponding to the biceps brachii muscle</span>
        <span itemprop="definition">has no color display, which may indicate that the user is in a completely relaxed state.</span>
        <meta itemprop="num_attr" content="0264">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the color of the reference display area 021 corresponding to the biceps brachii muscle</span>
        <span itemprop="definition">is darker.</span>
        <meta itemprop="num_attr" content="0264">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the user</span>
        <span itemprop="definition">may clearly and intuitively view a difference between the exertion strength of the muscle of the user in the electromyography animation 010 of the virtual user character and the exertion strength of the standard muscle in the reference electromyography animation 020 of the virtual reference character, find problems in the current movement, and adjust the movement in time. Further description regarding displaying the user movement model and the standard movement model may be found in the priority of International Application No. PCT/CN2021/093302, filed on May 12, 2021, the entire contents of which are hereby incorporated by reference.</span>
        <meta itemprop="num_attr" content="0265">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 24</span>
        <span itemprop="definition">is a flowchart illustrating an exemplary process for displaying a motion monitoring interface according to some embodiments of the present disclosure. As shown in FIG. 24 , the process 2400 may include the following steps.</span>
        <meta itemprop="num_attr" content="0267">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a movement signal</span>
        <span itemprop="definition">may be segmented based on an electromyographic signal or an attitude signal.</span>
        <meta itemprop="num_attr" content="0268">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the step 2410</span>
        <span itemprop="definition">may be performed by the processing module 220 .</span>
        <meta itemprop="num_attr" content="0269">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">an obtaining process of the movement signal</span>
        <span itemprop="definition">e.g., the electromyographic signal, the attitude signal</span>
        <meta itemprop="num_attr" content="0269">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a movement during the motion of the user</span>
        <span itemprop="definition">may be a combination of a plurality of sets of movements or a combination of movements of different movement types.</span>
        <meta itemprop="num_attr" content="0269">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processing module 220</span>
        <span itemprop="definition">may segment the movement signal of the user based on the electromyographic signal or the attitude signal during the motion of the user.</span>
        <meta itemprop="num_attr" content="0269">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">segmenting the movement signal</span>
        <span itemprop="definition">may refer to dividing the movement signal into signal segments with a same time duration or different time durations, or extracting one or more signal segments with a specific time duration from the movement signal.</span>
        <meta itemprop="num_attr" content="0269">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">each segment of the movement signal</span>
        <span itemprop="definition">may correspond to one or more complete movements of the user. For example, when the user performs a deep squat movement, the user goes from a standing posture to a squatting posture, gets up, and returns to the standing posture, which may be regarded as completing the deep squat movement.</span>
        <meta itemprop="num_attr" content="0269">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the movement signal collected by the obtaining module 210 in the process</span>
        <span itemprop="definition">may be regarded as a segment (or a cycle) of movement signal.</span>
        <meta itemprop="num_attr" content="0269">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the movement signal collected by the obtaining module 210 that the user completes a next squat movement</span>
        <span itemprop="definition">may be regarded as another segment of movement signal.</span>
        <meta itemprop="num_attr" content="0269">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a change of each movement step during the motion of the user</span>
        <span itemprop="definition">may cause the electromyographic signal and the attitude signal of a corresponding part to change.</span>
        <meta itemprop="num_attr" content="0269">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processing module 220</span>
        <span itemprop="definition">may segment the movement signal of the user based on the electromyographic signal or the attitude signal.</span>
        <meta itemprop="num_attr" content="0269">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processing module 220</span>
        <span itemprop="definition">may segment the movement signal of the user based on feature information corresponding to the electromyographic signal or feature information corresponding to the attitude signal.</span>
        <meta itemprop="num_attr" content="0269">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIGS. 6 to 8 of the present disclosure and related description thereof</span>
        <span itemprop="definition">may be found in FIGS. 6 to 8 of the present disclosure and related description thereof.</span>
        <meta itemprop="num_attr" content="0269">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a monitoring result</span>
        <span itemprop="definition">may be determined by monitoring a movement of the motion of the user based on at least one segment of the movement signal.</span>
        <meta itemprop="num_attr" content="0270">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the step 2420</span>
        <span itemprop="definition">may be performed by the processing module 220 .</span>
        <meta itemprop="num_attr" content="0271">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the at least one segment of the movement signal</span>
        <span itemprop="definition">may be a movement signal of the user in at least one training process.</span>
        <meta itemprop="num_attr" content="0271">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the training process</span>
        <span itemprop="definition">may refer to a process in which a user completes a training movement.</span>
        <meta itemprop="num_attr" content="0271">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the user completing a deep squat movement</span>
        <span itemprop="definition">may be the training process.</span>
        <meta itemprop="num_attr" content="0271">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the training process</span>
        <span itemprop="definition">may also refer to a process in which the user completes a plurality of same or different training movements.</span>
        <meta itemprop="num_attr" content="0271">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the user completing a plurality of deep squat movements successively</span>
        <span itemprop="definition">may be a training process.</span>
        <meta itemprop="num_attr" content="0271">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the user completing the deep squat movement and a jumping movement in situ successively</span>
        <span itemprop="definition">may be a training process.</span>
        <meta itemprop="num_attr" content="0271">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the training process</span>
        <span itemprop="definition">may refer to a process in which the user completes training movements within a certain period of time.</span>
        <meta itemprop="num_attr" content="0271">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the training process</span>
        <span itemprop="definition">may be a process of training movements completed within a day, a week, a month, or a year.</span>
        <meta itemprop="num_attr" content="0271">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a segment of movement signal</span>
        <span itemprop="definition">may be a movement signal of a complete training process or a movement signal of a part of the training process in a complete training process.</span>
        <meta itemprop="num_attr" content="0272">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">there may be different exertion modes and different exertion strengths of muscles at different stages of the complete training process</span>
        <span itemprop="definition">that is, there may be different movement signals at different stages of the training process.</span>
        <meta itemprop="num_attr" content="0272">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the real-time performance of monitoring of the movement of the user</span>
        <span itemprop="definition">may be improved by monitoring the movement signals at the different stages of the complete training process.</span>
        <meta itemprop="num_attr" content="0272">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the monitoring result</span>
        <span itemprop="definition">may include a movement type, a movement quantity, a movement quality, a movement time, physiological parameter information, a core stability, an interval time, an expected recovery time of the user, or the like, or any combination thereof, during the at least one training process.</span>
        <meta itemprop="num_attr" content="0273">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the physiological parameter information of the user</span>
        <span itemprop="definition">may include, but is not limited to, a heart rate (e.g., an average heart rate, the maximum heart rate), a blood pressure, a body temperature, an energy consumption during the motion, or the like, or any combination thereof.</span>
        <meta itemprop="num_attr" content="0273">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a heart rate</span>
        <span itemprop="definition">e.g., an average heart rate, the maximum heart rate</span>
        <meta itemprop="num_attr" content="0273">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the interval time</span>
        <span itemprop="definition">may refer to a time interval between two consecutive movements. For example, when a user performs a deep squat movement, the interval time may refer to the time interval between a first deep squat movement and a second deep squat movement.</span>
        <meta itemprop="num_attr" content="0273">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the expected recovery time</span>
        <span itemprop="definition">may refer to a time it takes for each part of the body (e.g., muscle) to recover from a motion state to a normal state after the user completes the motion. For example, the expected recovery time may be the time it takes for the muscle of the user to recover from a fatigue state to a relaxed state after the user completes the motion.</span>
        <meta itemprop="num_attr" content="0273">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the monitoring result</span>
        <span itemprop="definition">may be determined by monitoring the motion of the user based on the at least one segment of movement signal.</span>
        <meta itemprop="num_attr" content="0274">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the monitoring result</span>
        <span itemprop="definition">e.g., the movement type, the movement quality</span>
        <meta itemprop="num_attr" content="0274">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the at least one segment of movement signal</span>
        <span itemprop="definition">e.g., the electromyographic signal, the attitude signal</span>
        <meta itemprop="num_attr" content="0274">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">at least one segment of preset movement signal</span>
        <span itemprop="definition">e.g., a preset electromyographic signal, a preset attitude signal.</span>
        <meta itemprop="num_attr" content="0274">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the at least one preset movement signal</span>
        <span itemprop="definition">may be a standard movement signal collected by a sensor when a professional performs a standard movement.</span>
        <meta itemprop="num_attr" content="0274">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the preset movement signal</span>
        <span itemprop="definition">may be stored in a database in advance.</span>
        <meta itemprop="num_attr" content="0274">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the movement type or the movement quality during the motion of the user</span>
        <span itemprop="definition">may be determined by determining a matching degree between feature information corresponding to the at least one segment of movement signal and feature information corresponding to the at least one segment of preset movement signal. For example, if it is determined that the matching degree between the feature information corresponding to a segment of movement signal of the user and the feature information corresponding to a segment of the preset movement signal is higher than a certain threshold (e.g., 95%), it may be determined that the movement type during the motion of the user is consistent with the movement type of the preset movement signal.</span>
        <meta itemprop="num_attr" content="0274">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a certain threshold</span>
        <span itemprop="definition">e.g., 95%</span>
        <meta itemprop="num_attr" content="0274">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the monitoring result</span>
        <span itemprop="definition">e.g., the heart rate and the energy consumption</span>
        <meta itemprop="num_attr" content="0274">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the monitoring result</span>
        <span itemprop="definition">e.g., the heart rate and the energy consumption</span>
        <meta itemprop="num_attr" content="0274">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the feature information</span>
        <span itemprop="definition">corresponding to physiological signals of the user (e.g., electro-cardio signals and respiratory signals) collected by different types of sensors. Further description regarding determining the motion type, the movement type, the movement quantity, the movement quality, the movement time, the physiological parameter information, etc. of the user may be found in FIGS. 19 - 20 of the present disclosure and related descriptions thereof.</span>
        <meta itemprop="num_attr" content="0274">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the method for determining the monitoring result by monitoring the user based on the at least one segment of movement signal</span>
        <span itemprop="definition">may be an algorithm not based on another segment of movement signal.</span>
        <meta itemprop="num_attr" content="0275">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the algorithm</span>
        <span itemprop="definition">may be based on a machine learning model.</span>
        <meta itemprop="num_attr" content="0275">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the movement signal</span>
        <span itemprop="definition">may be input into the machine learning model, and the movement type, the movement quantity, the movement quality, or an error point of the movement may be given through a neural network model or a traditional machine learning model.</span>
        <meta itemprop="num_attr" content="0275">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the algorithm</span>
        <span itemprop="definition">may be based on an algorithm based on state machine transition. When the movement experiences a series of states, the movement type, movement quantity, the movement quality, or the error point of the movement may be output.</span>
        <meta itemprop="num_attr" content="0275">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the algorithm</span>
        <span itemprop="definition">may be a combination of threshold judgments. The movement type, the movement quantity, the movement quality, or the error point of the movement may be given by judging whether the movement signal meets a series of conditions.</span>
        <meta itemprop="num_attr" content="0275">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the core stability of the user</span>
        <span itemprop="definition">may be determined based on the electromyographic signal obtained by an electromyography sensor. For example, the core stability of the user may be determined based on a proportion of an exertion time of an abdominal muscle of the use during a training process. In the training process, the greater the proportion of the exertion time of the abdominal muscle of the user, the better the core stability of the user.</span>
        <meta itemprop="num_attr" content="0276">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the core stability of the user</span>
        <span itemprop="definition">may be determined based on the attitude signal obtained by an attitude sensor. For example, the core stability of the user may be determined based on a motion amplitude of the trunk of the user during a training process.</span>
        <meta itemprop="num_attr" content="0276">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the core stability of the user</span>
        <span itemprop="definition">may be determined based on the electromyographic signal and the attitude signal. For example, the core stability of the user may be determined based on the proportion of the exertion time of the abdominal muscle of the user and the motion amplitude of the trunk of the user in the training process.</span>
        <meta itemprop="num_attr" content="0276">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the monitoring result</span>
        <span itemprop="definition">may include muscle information of the user.</span>
        <meta itemprop="num_attr" content="0277">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the muscle information of the user</span>
        <span itemprop="definition">may include, but is not limited to, a participation degree of at least one muscle, an energy consumption of the at least one muscle, a fatigue degree of the at least one muscle, a balance of at least two muscles, an ability of the at least one muscle, or the like, or any combination thereof.</span>
        <meta itemprop="num_attr" content="0277">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the participation degree (also referred to as a contribution degree) and the fatigue degree of muscle</span>
        <span itemprop="definition">may indicate whether a target training muscle (e.g., a key training muscle) has been effectively exercised during the motion, and whether other non-target training muscles have exertion compensation, so that the movement quality of the user may be evaluated.</span>
        <meta itemprop="num_attr" content="0278">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the energy consumption of muscle</span>
        <span itemprop="definition">may be determined based on the electromyographic signal of the muscle of the user and a training time.</span>
        <meta itemprop="num_attr" content="0278">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the participation degree of each muscle</span>
        <span itemprop="definition">may be determined based on a proportion of an energy consumption of each muscle to an energy consumption of all muscles during the motion of the user.</span>
        <meta itemprop="num_attr" content="0278">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the participation degree (the contribution degree) of the pectoral muscles</span>
        <span itemprop="definition">may be determined as 50%.</span>
        <meta itemprop="num_attr" content="0278">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the participation degree of muscle</span>
        <span itemprop="definition">may be determined based on the feature information of the electromyographic signal.</span>
        <meta itemprop="num_attr" content="0278">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the feature information of the electromyographic signal</span>
        <span itemprop="definition">may include amplitude information (e.g., a mean square amplitude, an integrated electromyogram, an amplitude envelope) and/or frequency information (e.g., an average power frequency, a median frequency, a short-term zero crossing rate) of the electromyographic signal.</span>
        <meta itemprop="num_attr" content="0278">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the participation degree of muscle</span>
        <span itemprop="definition">may be determined based on a percentage of integrated electromyogram of the muscle during a training process (or during a movement).</span>
        <meta itemprop="num_attr" content="0278">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the electromyographic signal</span>
        <span itemprop="definition">may be preprocessed, and the participation degree of muscle may be determined based on the amplitude information and/or the frequency information of the preprocessed electromyographic signal.</span>
        <meta itemprop="num_attr" content="0279">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the participation degree of muscle</span>
        <span itemprop="definition">may be determined based on the amplitude information and/or the frequency information of the preprocessed electromyographic signal.</span>
        <meta itemprop="num_attr" content="0279">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">magnitudes of electromyographic signals that the different muscles can emit</span>
        <span itemprop="definition">may be also different. For example, under a same degree of subjective effort, a muscle group such as the biceps brachii muscle, etc. may be more likely to emit a relatively large electromyographic signal, while a muscle group such as the pectoral muscle, etc. may emit a relatively small electromyographic signal.</span>
        <meta itemprop="num_attr" content="0279">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the electromyographic signal</span>
        <span itemprop="definition">may be normalized to eliminate or weaken a difference in the magnitude of the electromyographic signal emitted from the different muscle groups.</span>
        <meta itemprop="num_attr" content="0279">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the fatigue degree of muscle</span>
        <span itemprop="definition">may be configured to evaluate the maximum capacity and a growth capacity of the muscle of the user, which may reflect whether the muscle of the user has been adequately exercised.</span>
        <meta itemprop="num_attr" content="0280">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the motion</span>
        <span itemprop="definition">may make the muscle enter a fatigue state, and an excessive recovery may be formed using natural repair of a body, resulting in an increase in strength, volume, endurance and explosive power of the muscle. Therefore, it is necessary to evaluate the fatigue degree of the muscle of the user after the motion.</span>
        <meta itemprop="num_attr" content="0280">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the fatigue degree of muscle</span>
        <span itemprop="definition">may be determined based on the feature information of the electromyographic signal.</span>
        <meta itemprop="num_attr" content="0280">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the fatigue degree of muscle</span>
        <span itemprop="definition">may be determined based on a degree of change (e.g., a degree of decline) of a feature value (e.g., an average power frequency, a median frequency, a short-term zero crossing rate) of the electromyographic signal during at least one training process (e.g., between a plurality of movements).</span>
        <meta itemprop="num_attr" content="0280">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a degree of change</span>
        <span itemprop="definition">e.g., a degree of decline</span>
        <meta itemprop="num_attr" content="0280">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a feature value</span>
        <span itemprop="definition">e.g., an average power frequency, a median frequency, a short-term zero crossing rate</span>
        <meta itemprop="num_attr" content="0280">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the fatigue degree of muscle</span>
        <span itemprop="definition">may be determined based on a degree of stability of the electromyography amplitude envelope. The lower the degree of stability of the electromyography amplitude envelope, the higher the fatigue degree of muscle.</span>
        <meta itemprop="num_attr" content="0280">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the fatigue degree of muscle</span>
        <span itemprop="definition">may be determined based on the feature information of the attitude signal (e.g., an angular velocity, an angular velocity direction, an acceleration of angular velocity, an angle, displacement information, and stress). For example, if it is detected that the attitude signal has a high degree of jitter, and the movement of the user is jittered or severely deformed, it may indicate that the muscle is in the fatigue state.</span>
        <meta itemprop="num_attr" content="0280">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the fatigue degree of muscle</span>
        <span itemprop="definition">may be determined using a trained machine learning model.</span>
        <meta itemprop="num_attr" content="0281">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the trained machine learning model</span>
        <span itemprop="definition">may be generated by training an initial model based on sample information.</span>
        <meta itemprop="num_attr" content="0281">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the sample information</span>
        <span itemprop="definition">may include sample movement signals and sample fatigue degrees of muscles of a plurality of users.</span>
        <meta itemprop="num_attr" content="0281">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the sample fatigue degree</span>
        <span itemprop="definition">may be determined based on the sample movement signal.</span>
        <meta itemprop="num_attr" content="0281">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the initial model</span>
        <span itemprop="definition">may be trained based on the sample information using a training algorithm to generate the trained machine learning model.</span>
        <meta itemprop="num_attr" content="0281">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Exemplary training algorithms</span>
        <span itemprop="definition">may include a gradient descent algorithm, a Newton algorithm, a quasi-Newton algorithm, a conjugate gradient algorithm, a generation adversarial learning algorithm, etc.</span>
        <meta itemprop="num_attr" content="0281">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the trained machine learning model</span>
        <span itemprop="definition">may be used to determine the fatigue degree of the muscle of the user based on the movement signal of the user. For example, the movement signal of the user may be input into the trained machine learning model, and the trained machine learning model may output the fatigue degree of the muscle of the user.</span>
        <meta itemprop="num_attr" content="0281">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a determination</span>
        <span itemprop="definition">may be made as whether a current motion exceeds a load of the user according to the fatigue degree of the muscle of the user. For example, when it is determined that the fatigue degree of a certain muscle of the user exceeds a first fatigue threshold, it may be determined that the current amount of motion has exceeded the load of the user. At this time, a prompt may be sent to the user to remind the user to reduce the amount of motion or stop the motion to prevent injury. As another example, when it is determined that the fatigue degree of a certain muscle of the user is lower than a second fatigue threshold, it may be determined that the current amount of motion of the user is insufficient to achieve an expected training effect, or it may indicate that the user still has more spare energy.</span>
        <meta itemprop="num_attr" content="0282">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a prompt</span>
        <span itemprop="definition">may be sent to the user to remind the user to increase the amount of motion to ensure the training effect.</span>
        <meta itemprop="num_attr" content="0282">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the recovery time</span>
        <span itemprop="definition">may be estimated according to the fatigue degree of the user and fed back to the user to help the user plan a next motion in advance.</span>
        <meta itemprop="num_attr" content="0282">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the balance of at least two muscles</span>
        <span itemprop="definition">may be a motion balance of left and right muscles in a same muscle group of the user&#39;s body.</span>
        <meta itemprop="num_attr" content="0283">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the balance of at least two muscles</span>
        <span itemprop="definition">may refer to a balance of the left pectoralis major muscle and the right pectoralis major muscle of the user.</span>
        <meta itemprop="num_attr" content="0283">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the balance of muscles</span>
        <span itemprop="definition">may include a balance of exertion strengths of muscles, a balance of fatigue degrees of muscles, a balance of energy consumptions of muscles, etc.</span>
        <meta itemprop="num_attr" content="0283">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the balance of at least two muscles</span>
        <span itemprop="definition">may be determined based on the feature information of the movement signal (e.g., the electromyographic signal, the attitude signal). In some embodiments, a determination may be made as whether the exertion strengths of the two muscles is balanced by comparing the amplitude information of the electromyographic signals of the two muscles (e.g., the root mean square amplitude, the integral electromyogram, the amplitude envelope). For example, if a difference between the amplitude information of the electromyographic signals of the two muscles is within a threshold range, it may be considered that the exertion strengths of the two muscles are substantially the same.</span>
        <meta itemprop="num_attr" content="0284">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the amplitude information of the electromyographic signals of the two muscles</span>
        <span itemprop="definition">e.g., the root mean square amplitude, the integral electromyogram, the amplitude envelope</span>
        <meta itemprop="num_attr" content="0284">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a determination</span>
        <span itemprop="definition">may be made as whether the fatigue degrees of the two muscles are the same by comparing the frequency information of the electromyographic signals of two muscles (e.g., the average power frequency, the median frequency, the short-term zero crossing rate). For example, if a difference between the frequency information of the electromyographic signals of the two muscles is within a threshold range, it may be considered that the fatigue degrees of the two muscles are substantially the same.</span>
        <meta itemprop="num_attr" content="0284">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a determination</span>
        <span itemprop="definition">may be made as whether motion speeds and motion angles of left and right limbs of the user&#39;s body are consistent by comparing the feature information of the attitude signals of the two muscles (e.g., the acceleration and the angular velocity), so as to determine the balance of the posture of the movement of the user.</span>
        <meta itemprop="num_attr" content="0284">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the balance degree of left and right muscles of the user&#39;s body</span>
        <span itemprop="definition">may be comprehensively determined based on the balance of the exertion strengths of the at least two muscles, the balance of the fatigue degrees of the at least two muscles, and the balance of the movement posture of the motion of the user.</span>
        <meta itemprop="num_attr" content="0284">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a prompt</span>
        <span itemprop="definition">may be sent to the user to remind the user to strengthen exercise of some muscle groups or improve the posture of the current exercise to ensure the effect of the motion.</span>
        <meta itemprop="num_attr" content="0284">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the ability of muscle</span>
        <span itemprop="definition">may be a training amount when the user reaches exhaustion during training.</span>
        <meta itemprop="num_attr" content="0285">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the ability of muscle</span>
        <span itemprop="definition">may be represented by a characteristic amount determined by one or more of characteristics such as an energy consumption, a count of groups of motion, a count of motion times, a weight, a time, etc.</span>
        <meta itemprop="num_attr" content="0285">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the ability of muscle</span>
        <span itemprop="definition">may be expressed by a total work obtained by multiplying a total count of times of motion by a total weight, or expressed by a power obtained by multiplying the total count of times of motion by the total weight and dividing by the time.</span>
        <meta itemprop="num_attr" content="0285">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the fatigue degree of muscle of the user</span>
        <span itemprop="definition">may be determined based on the electromyographic signal and/or the attitude signal, the training amount (e.g., an energy consumption amount) of the user when the fatigue degree of muscle of the user is relatively high (e.g., higher than a fatigue threshold) may be determined, and the training amount (e.g., the energy consumption amount) of the user at this time may be used as the ability of muscle of the user.</span>
        <meta itemprop="num_attr" content="0285">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the training amount</span>
        <span itemprop="definition">e.g., an energy consumption amount</span>
        <meta itemprop="num_attr" content="0285">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a movement feedback mode</span>
        <span itemprop="definition">may be determined based on the monitoring result.</span>
        <meta itemprop="num_attr" content="0286">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the step 2430</span>
        <span itemprop="definition">may be performed by the processing module 220 .</span>
        <meta itemprop="num_attr" content="0287">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the movement feedback mode</span>
        <span itemprop="definition">may include a feedback manner, a feedback priority, a feedback content, or the like, or any combination thereof.</span>
        <meta itemprop="num_attr" content="0288">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the feedback mode</span>
        <span itemprop="definition">may include, but is not limited to, a text prompt, a voice prompt, an image prompt, a video prompt, a vibration prompt, a pressure prompt, or the like, or any combination thereof.</span>
        <meta itemprop="num_attr" content="0288">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the text prompt</span>
        <span itemprop="definition">may be displayed through a display of the input/output module 260 .</span>
        <meta itemprop="num_attr" content="0288">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the voice prompt</span>
        <span itemprop="definition">may be realized by playing sound through a speaker in the input/output module 260 and/or the wearable device 130 .</span>
        <meta itemprop="num_attr" content="0288">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the image prompt and the video prompt</span>
        <span itemprop="definition">may be realized by the display of the input/output module 260 and/or the wearable device 130 .</span>
        <meta itemprop="num_attr" content="0288">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the vibration prompt</span>
        <span itemprop="definition">may be realized by a vibration of a vibration module in the input/output module 260 and/or the wearable device 130 .</span>
        <meta itemprop="num_attr" content="0288">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the pressure prompt</span>
        <span itemprop="definition">may be realized through electrodes in the wearable device 130 .</span>
        <meta itemprop="num_attr" content="0288">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the movement feedback mode</span>
        <span itemprop="definition">may be determined according to the movement type of the motion of the user. For example, when the user is running, since the text prompt is not easy to be received by the user, the voice prompt, the vibration prompt, or the pressure prompt may be selected to feedback the monitoring result to the user.</span>
        <meta itemprop="num_attr" content="0288">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the feedback priority</span>
        <span itemprop="definition">may include immediate feedback, feedback after a movement is completed, feedback after a training is completed, etc.</span>
        <meta itemprop="num_attr" content="0289">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the immediate feedback</span>
        <span itemprop="definition">may refer to that the input/output module 260 immediately performs feedback to the user according to the corresponding feedback mode when the user has a problem (e.g., an exertion strength of the muscle is relatively high) during the motion.</span>
        <meta itemprop="num_attr" content="0289">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the feedback after a movement/training is completed</span>
        <span itemprop="definition">may refer to that the input/output module 260 performs feedback to the user in a form of a training suggestion after the user completes a movement/training.</span>
        <meta itemprop="num_attr" content="0289">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the feedback priority of the movement</span>
        <span itemprop="definition">may be determined based on the movement type of the user.</span>
        <meta itemprop="num_attr" content="0289">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the priority of the movement feedback mode</span>
        <span itemprop="definition">may be relatively high, and a more eye-catching feedback mode (e.g., a text prompt with signs) may be used to perform feedback, so that the user may receive the feedback and adjust the movement posture in time.</span>
        <meta itemprop="num_attr" content="0289">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a more eye-catching feedback mode</span>
        <span itemprop="definition">e.g., a text prompt with signs</span>
        <meta itemprop="num_attr" content="0289">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the priority of the movement feedback mode</span>
        <span itemprop="definition">may be relatively low, for example, the feedback may be performed through the text prompt after the user completes the training.</span>
        <meta itemprop="num_attr" content="0289">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a determination</span>
        <span itemprop="definition">may be made as whether an error occurs in the movement of the motion of the user based on the monitoring result, and the feedback priority of the movement may be determined according to a type of movement error of the motion of the user.</span>
        <meta itemprop="num_attr" content="0290">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the type of movement error</span>
        <span itemprop="definition">may reflect a degree of damage to the user&#39;s body when the user makes the movement error.</span>
        <meta itemprop="num_attr" content="0290">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the type of movement error</span>
        <span itemprop="definition">may be divided into a type of primary movement error, a type of secondary movement error, and a type of tertiary movement error.</span>
        <meta itemprop="num_attr" content="0290">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the type of primary movement error</span>
        <span itemprop="definition">may be a type of movement error that is easy to cause injury (e.g., knee buckle during the deep squat movement) to the user.</span>
        <meta itemprop="num_attr" content="0290">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the type of secondary movement error</span>
        <span itemprop="definition">may be a type of movement error in which a target training muscle has not been effectively exercised (e.g., arms are bent to exert when the user performs the seated chest press, so that the biceps brachii muscle is exercised but the pectoral muscles are not exercised).</span>
        <meta itemprop="num_attr" content="0290">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the type of tertiary movement error</span>
        <span itemprop="definition">may be a type of movement error that leads to a relatively low training efficiency (e.g., running too slow).</span>
        <meta itemprop="num_attr" content="0290">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the feedback priority</span>
        <span itemprop="definition">when the type of movement error is the type of primary movement error, the feedback priority may be the immediate feedback.</span>
        <meta itemprop="num_attr" content="0290">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the type of movement error</span>
        <span itemprop="definition">is the type of secondary movement error</span>
        <meta itemprop="num_attr" content="0290">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the feedback priority</span>
        <span itemprop="definition">may be the feedback after a movement is completed.</span>
        <meta itemprop="num_attr" content="0290">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the type of movement error</span>
        <span itemprop="definition">is the tertiary movement error</span>
        <meta itemprop="num_attr" content="0290">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the feedback priority</span>
        <span itemprop="definition">may be the feedback after a training is completed.</span>
        <meta itemprop="num_attr" content="0290">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the feedback content</span>
        <span itemprop="definition">may include the monitoring result (e.g., the movement type, the movement quantity, the movement quality, the movement time), the type of movement error, a degree of movement completion, the training suggestion, or the like, or any combination thereof.</span>
        <meta itemprop="num_attr" content="0291">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processing module 220</span>
        <span itemprop="definition">may determine the feedback content according to the motion monitoring result such as the movement type and the type of movement error of the motion of the user. For example, after the user completes a training, the input/output module 260 may feedback training information (e.g., the movement type, the movement quantity, the movement quality, the movement time) during the training process to the user, so as to help the user fully understand the training process.</span>
        <meta itemprop="num_attr" content="0291">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the input/output module 260</span>
        <span itemprop="definition">may prompt the user of the current movement error to help the user adjust the movement in time.</span>
        <meta itemprop="num_attr" content="0291">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the error of the user</span>
        <span itemprop="definition">may be displayed at a position corresponding to the certain muscle in the user movement model. For example, a manner such as an edge flicker, a sign, a word, a symbol (e.g., an exclamation mark), etc. may be used at the position corresponding to the certain muscle in the user movement model to prompt the user that the exertion of the certain muscle at the position is wrong.</span>
        <meta itemprop="num_attr" content="0291">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a movement feedback</span>
        <span itemprop="definition">may be performed to the user according to the movement feedback mode.</span>
        <meta itemprop="num_attr" content="0292">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the step 2440</span>
        <span itemprop="definition">may be performed by the input/output module 260 .</span>
        <meta itemprop="num_attr" content="0293">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the input/output module 260</span>
        <span itemprop="definition">may display the monitoring result to the user in a form of a text, a chart (e.g., a line chart, a bar chart, a pie chart, a histogram), a sound, an image, a video, or the like, or any combination thereof.</span>
        <meta itemprop="num_attr" content="0294">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a chart</span>
        <span itemprop="definition">e.g., a line chart, a bar chart, a pie chart, a histogram</span>
        <meta itemprop="num_attr" content="0294">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 25</span>
        <span itemprop="definition">is a schematic diagram illustrating a motion monitoring interface according to some embodiments of the present disclosure.</span>
        <meta itemprop="num_attr" content="0295">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">basic training information and exercise counts after a user completes a training</span>
        <span itemprop="definition">is displayed in the form of a text in an interface 2500 .</span>
        <meta itemprop="num_attr" content="0295">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the user</span>
        <span itemprop="definition">may formulate a training plan in advance before the training starts. After the training, the user may compare the basic training information after the training with the training plan to help the user determine a degree of completion of the training plan.</span>
        <meta itemprop="num_attr" content="0295">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 26</span>
        <span itemprop="definition">is a schematic diagram illustrating a motion monitoring interface according to some embodiments of the present disclosure.</span>
        <meta itemprop="num_attr" content="0296">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">an energy consumption of each muscle after a user completes a training</span>
        <span itemprop="definition">is displayed in the form of a pie chart and a text in an interface 2600 .</span>
        <meta itemprop="num_attr" content="0296">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the energy consumption of each muscle of the user</span>
        <span itemprop="definition">is arranged in descending order of a pectoral muscle, a biceps brachii muscle, a latissimus dorsi muscle and other muscles.</span>
        <meta itemprop="num_attr" content="0296">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the user</span>
        <span itemprop="definition">may intuitively observe a proportion of energy consumption of each muscle through the pie chart.</span>
        <meta itemprop="num_attr" content="0296">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 27</span>
        <span itemprop="definition">is a schematic diagram illustrating a motion monitoring interface according to some embodiments of the present disclosure.</span>
        <meta itemprop="num_attr" content="0297">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a fatigue degree of muscle, an evaluation of the fatigue degree, and an evaluation of the maximum ability of muscle after a user completes a training</span>
        <span itemprop="definition">is displayed in the form of a pattern and a text in an interface 2700 .</span>
        <meta itemprop="num_attr" content="0297">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">different fatigue degrees of muscle</span>
        <span itemprop="definition">may be represented by circular patterns of different colors, and the fatigue degree of each muscle may be evaluated according to the degree fatigue of muscle and the maximum ability of muscle (e.g., exhausted, with remaining strength, relaxed).</span>
        <meta itemprop="num_attr" content="0297">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 28</span>
        <span itemprop="definition">is a schematic diagram illustrating a motion monitoring interface according to some embodiments of the present disclosure.</span>
        <meta itemprop="num_attr" content="0298">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a balance of left and right muscles of a body after a user completes a training</span>
        <span itemprop="definition">is displayed in the form of a histogram in an interface 2800 .</span>
        <meta itemprop="num_attr" content="0298">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Each kind of muscle</span>
        <span itemprop="definition">may correspond to a columnar strip.</span>
        <meta itemprop="num_attr" content="0298">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a position, a length, and/or a color of the columnar strip</span>
        <span itemprop="definition">may indicate the balance of the kind of muscle corresponding to the columnar strip. For example, the longer the length and/or the darker the color of the columnar strip corresponding to the muscle, the poorer the balance of the muscle.</span>
        <meta itemprop="num_attr" content="0298">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 28</span>
        <span itemprop="definition">a balance of left and right muscles of a body after a user completes a training is displayed in the form of a histogram in an interface 2800 .</span>
        <meta itemprop="num_attr" content="0298">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Each kind of muscle</span>
        <span itemprop="definition">may correspond to a columnar strip.</span>
        <meta itemprop="num_attr" content="0298">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a position, a length, and/or a color of the columnar strip</span>
        <span itemprop="definition">may indicate the balance of the kind of muscle corresponding to the columnar strip. For example, the longer the</span>
        <meta itemprop="num_attr" content="0298">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the columnar strips corresponding to a pectoral muscle and a biceps brachii muscle</span>
        <span itemprop="definition">are located on the right, which may indicate that the right pectoral muscle and the right biceps brachii muscle have a relatively high energy.</span>
        <meta itemprop="num_attr" content="0298">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the columnar strip corresponding a latissimus dorsi muscle</span>
        <span itemprop="definition">is on the left, which may indicate that the left latissimus dorsi has a relatively high energy.</span>
        <meta itemprop="num_attr" content="0298">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a length of the columnar strip corresponding to the pectoral muscle</span>
        <span itemprop="definition">is longer (or darker) than a length of the columnar strip corresponding to the biceps brachii muscle, which may indicate that the balance of the pectoral muscle is lower than the balance of the latissimus dorsi muscle.</span>
        <meta itemprop="num_attr" content="0298">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 29</span>
        <span itemprop="definition">is a schematic diagram illustrating a motion monitoring interface according to some embodiments of the present disclosure.</span>
        <meta itemprop="num_attr" content="0299">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a proportion of an exertion time of an abdominal muscle during a training process of a user</span>
        <span itemprop="definition">is displayed in the form of a status bar in an interface 2900 , which may reflect a core stability of the user.</span>
        <meta itemprop="num_attr" content="0299">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the proportion of the exertion time of the abdominal muscle during the training process (e.g., sit-ups) of the user</span>
        <span itemprop="definition">is 70%, which may reflect that the core stability of the user is good.</span>
        <meta itemprop="num_attr" content="0299">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the monitoring result</span>
        <span itemprop="definition">may be displayed in a user model (e.g., the front muscle distribution map 2101 shown in FIG. 21 B , the back muscle distribution model 2102 , and the user movement model 010 shown in FIGS. 23 A to 23 C ).</span>
        <meta itemprop="num_attr" content="0300">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a user model</span>
        <span itemprop="definition">e.g., the front muscle distribution map 2101 shown in FIG. 21 B , the back muscle distribution model 2102 , and the user movement model 010 shown in FIGS. 23 A to 23 C .</span>
        <meta itemprop="num_attr" content="0300">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">an energy consumption of at least one muscle, a fatigue degree of the at least one muscle, a training balance of at least two muscles, an ability of the at least one muscle of the user, or the like, or any combination thereof</span>
        <span itemprop="definition">may be displayed at least one specific location in the user model.</span>
        <meta itemprop="num_attr" content="0300">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the at least one specific location in the user model</span>
        <span itemprop="definition">may correspond to a location of at least one muscle in the user.</span>
        <meta itemprop="num_attr" content="0300">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">energy consumptions of different muscles, fatigue degrees of different muscles, training balances of different muscles, and/or abilities of different muscles</span>
        <span itemprop="definition">may correspond to different display colors, so that the user may feel the training result more intuitively.</span>
        <meta itemprop="num_attr" content="0300">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the input/output module 260</span>
        <span itemprop="definition">may obtain a user input regarding a target muscle and display information of the target muscle in the display interface.</span>
        <meta itemprop="num_attr" content="0300">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 30</span>
        <span itemprop="definition">is a schematic diagram illustrating a motion monitoring interface according to some embodiments of the present disclosure.</span>
        <meta itemprop="num_attr" content="0301">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">contribution degrees of muscles</span>
        <span itemprop="definition">e.g., percentages of energy consumptions of muscles</span>
        <meta itemprop="num_attr" content="0301">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">contribution degrees of muscles</span>
        <span itemprop="definition">e.g., percentages of energy consumptions of muscles</span>
        <meta itemprop="num_attr" content="0301">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the contribution degree of a left pectoralis major muscle of the user</span>
        <span itemprop="definition">is 20%</span>
        <meta itemprop="num_attr" content="0301">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the contribution degree of a right pectoralis major muscle</span>
        <span itemprop="definition">is 30%</span>
        <meta itemprop="num_attr" content="0301">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the contribution degrees of a left biceps brachii muscle and a right biceps muscle brachii muscle</span>
        <span itemprop="definition">are both 20%.</span>
        <meta itemprop="num_attr" content="0301">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the higher the contribution degree of the muscle</span>
        <span itemprop="definition">the darker the color of the muscle at a corresponding position in the muscle distribution map.</span>
        <meta itemprop="num_attr" content="0301">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 31</span>
        <span itemprop="definition">is a schematic diagram illustrating a motion monitoring interface according to some embodiments of the present disclosure.</span>
        <meta itemprop="num_attr" content="0302">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a fatigue degree of muscle during a training process of the user</span>
        <span itemprop="definition">is displayed in the form of human muscle distribution map in an interface 3100 .</span>
        <meta itemprop="num_attr" content="0302">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the higher the fatigue degree of the muscle</span>
        <span itemprop="definition">the darker the color of the muscle at a corresponding position in the muscle distribution map.</span>
        <meta itemprop="num_attr" content="0302">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the interface display modes shown in FIGS. 25 - 31</span>
        <span itemprop="definition">are only examples.</span>
        <meta itemprop="num_attr" content="0303">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the balance of at least two muscles and/or the ability of muscle</span>
        <span itemprop="definition">may be displayed in the interface in the form of human muscle distribution map.</span>
        <meta itemprop="num_attr" content="0303">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a plurality of monitoring results</span>
        <span itemprop="definition">may be displayed in a plurality of ways in one interface. For example, the contribution degree of muscle and the fatigue degree of muscle of the user during a training process may be displayed simultaneously in the human muscle distribution map.</span>
        <meta itemprop="num_attr" content="0303">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the energy consumption of each muscle after the user completes the training</span>
        <span itemprop="definition">may be displayed in the form of the pie chart in the interface, and the energy consumption of each muscle during the training process of the user may be displayed in the human muscle distribution map at the same time.</span>
        <meta itemprop="num_attr" content="0303">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the motion monitoring system 100</span>
        <span itemprop="definition">may count motion data during a plurality of training processes of the user and generate a motion record, thereby helping the user understand changes in physical performance and physical quality during long-term exercise and helping the user maintain good exercise habits.</span>
        <meta itemprop="num_attr" content="0304">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 32</span>
        <span itemprop="definition">is a schematic diagram illustrating a motion monitoring interface according to some embodiments of the present disclosure.</span>
        <meta itemprop="num_attr" content="0305">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a contribution degree (or an energy consumption) of each muscle of a user in different training cycles</span>
        <span itemprop="definition">e.g., training cycles in a unit of day, week, month, and year</span>
        <meta itemprop="num_attr" content="0305">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">contribution degrees of different muscles</span>
        <span itemprop="definition">may be displayed in different colors in columnar bars.</span>
        <meta itemprop="num_attr" content="0305">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the user</span>
        <span itemprop="definition">may select a target muscle in a muscle distribution map 3220 in the interface 3200 .</span>
        <meta itemprop="num_attr" content="0305">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the user</span>
        <span itemprop="definition">may click a muscle in the muscle distribution map 3220 as the target muscle.</span>
        <meta itemprop="num_attr" content="0305">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 32</span>
        <span itemprop="definition">is a schematic diagram illustrating a motion monitoring interface according to some embodiments of the present disclosure.</span>
        <meta itemprop="num_attr" content="0305">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a contribution degree (or an energy consumption) of each muscle of a user in different training cycles</span>
        <span itemprop="definition">e.g., training cycles in a unit of day, week, month, and year</span>
        <meta itemprop="num_attr" content="0305">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">contribution degrees of different muscles</span>
        <span itemprop="definition">may be displayed in different colors in columnar bars.</span>
        <meta itemprop="num_attr" content="0305">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the user</span>
        <span itemprop="definition">may select a target muscle in a muscle distribution map 3220 in the interface 3200 .</span>
        <meta itemprop="num_attr" content="0305">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the user</span>
        <span itemprop="definition">may click</span>
        <meta itemprop="num_attr" content="0305">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the contribution degree of the pectoral muscle in the different training cycles</span>
        <span itemprop="definition">is displayed through a histogram 3310 in an interface 3300 .</span>
        <meta itemprop="num_attr" content="0305">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the user</span>
        <span itemprop="definition">can understand his/her training preferences and training history, for example, which muscles are often exercised and which muscles have not been exercised for a long time, so as to help the user better develop a training plan.</span>
        <meta itemprop="num_attr" content="0305">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 34</span>
        <span itemprop="definition">is a schematic diagram illustrating a motion monitoring interface according to some embodiments of the present disclosure.</span>
        <meta itemprop="num_attr" content="0306">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the maximum energy consumption of each muscle during a training process of a user</span>
        <span itemprop="definition">is displayed through a histogram 3410 in an interface 3400 , thereby reflecting an ability of each muscle.</span>
        <meta itemprop="num_attr" content="0306">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the user</span>
        <span itemprop="definition">may select a target muscle in a muscle distribution map 3420 in the interface 3400 .</span>
        <meta itemprop="num_attr" content="0306">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the user</span>
        <span itemprop="definition">may click a muscle in the muscle distribution map 3420 as the target muscle.</span>
        <meta itemprop="num_attr" content="0306">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 35</span>
        <span itemprop="definition">when the user selects a pectoral muscle 3530 in a muscle distribution map 3520 as the target muscle, the maximum energy consumption of the pectoral muscle in different training cycles is displayed through a line chart 3510 in an interface 3500 .</span>
        <meta itemprop="num_attr" content="0306">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the user</span>
        <span itemprop="definition">can understand the growth of his/her ability, so as to help the user better develop a training plan.</span>
        <meta itemprop="num_attr" content="0306">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 36</span>
        <span itemprop="definition">is a schematic diagram illustrating a motion monitoring interface according to some embodiments of the present disclosure.</span>
        <meta itemprop="num_attr" content="0307">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a balance of muscle of the user</span>
        <span itemprop="definition">is displayed through a histogram 3610 in an interface 3600 .</span>
        <meta itemprop="num_attr" content="0307">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the user</span>
        <span itemprop="definition">may select a target muscle in a muscle distribution map 3620 in the interface 3600 .</span>
        <meta itemprop="num_attr" content="0307">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the user</span>
        <span itemprop="definition">may click a muscle in the muscle distribution map 3620 as the target muscle.</span>
        <meta itemprop="num_attr" content="0307">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the interface</span>
        <span itemprop="definition">may show the balance of the target muscle in different training cycles.</span>
        <meta itemprop="num_attr" content="0307">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">process 2400</span>
        <span itemprop="definition">is merely provided for the purpose of illustration, and not intended to limit the scope of the present disclosure.</span>
        <meta itemprop="num_attr" content="0308">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">process 2400</span>
        <span itemprop="definition">under the guidance of the present disclosure.</span>
        <meta itemprop="num_attr" content="0308">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">amendments and changes</span>
        <span itemprop="definition">are still within the scope of the present disclosure.</span>
        <meta itemprop="num_attr" content="0308">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the motion monitoring system 100</span>
        <span itemprop="definition">may calibrate the movement signal of the user obtained by the sensor.</span>
        <meta itemprop="num_attr" content="0309">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the electromyographic signal collected by the electromyography sensor</span>
        <span itemprop="definition">may be vulnerable to a plurality of factors (e.g., an individual user difference, a user skin status, an installation position of the electromyography sensor, an exertion strength of muscle, a fatigue degree of muscle).</span>
        <meta itemprop="num_attr" content="0309">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the factor</span>
        <span itemprop="definition">such as the individual user difference, the user skin status, the installation position of the electromyography sensor, etc. may make it impossible to directly compare the obtained electromyographic signals for different users. Therefore, it is necessary to calibrate the electromyographic signal, so as to eliminate or weaken the influence of the factor such as the individual user difference, the user skin status, the installation position of the electromyography sensor, etc.</span>
        <meta itemprop="num_attr" content="0309">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the motion monitoring system 100</span>
        <span itemprop="definition">may guide the user to perform a series of calibration movements (e.g., movements such as push-ups, etc. that can mobilize a large number of muscle groups to exert) to activate most of the muscle groups to be detected before the motion starts (e.g., a warm-up phase).</span>
        <meta itemprop="num_attr" content="0309">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a display device</span>
        <span itemprop="definition">e.g., a screen</span>
        <meta itemprop="num_attr" content="0309">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processing module 220</span>
        <span itemprop="definition">may determine an electromyographic signal collected by the electromyography sensor when the user performs the calibration movement as a reference value, and calibrate all the electromyographic signals collected by the user in the movement.</span>
        <meta itemprop="num_attr" content="0309">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the motion monitoring system 100</span>
        <span itemprop="definition">may guide the user to perform a plurality of sets of push-ups (e.g., 3 - 5 push-ups), and collect electromyographic signals of activated muscles such as the pectoral muscle, the biceps brachii muscle, the triceps brachii muscle, the rectus abdominis muscle of the user, etc. through the electromyography sensor, and determine a specific multiple of the electromyography amplitude of the muscle activated by the push up movement as the reference value.</span>
        <meta itemprop="num_attr" content="0309">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a range of the multiple</span>
        <span itemprop="definition">may be between 1.2-5 times.</span>
        <meta itemprop="num_attr" content="0309">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the multiple</span>
        <span itemprop="definition">may be between 1.2-3 times.</span>
        <meta itemprop="num_attr" content="0309">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">each muscle</span>
        <span itemprop="definition">may correspond to different multiples.</span>
        <meta itemprop="num_attr" content="0309">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the multiple</span>
        <span itemprop="definition">may be a value preset by the user or the motion monitoring system 100 , or a value determined by analyzing a feature of the electromyographic signal.</span>
        <meta itemprop="num_attr" content="0309">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the reference value of the electromyographic signal of a target user in the motion</span>
        <span itemprop="definition">may be determined based on a plurality of historical electromyographic signals collected when the target user performs a calibration movement during a plurality of historical motions.</span>
        <meta itemprop="num_attr" content="0309">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the reference value of the electromyographic signal of the target user in the motion</span>
        <span itemprop="definition">may be determined based on a plurality of electromyographic signals collected when a plurality of users perform a calibration movement.</span>
        <meta itemprop="num_attr" content="0309">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the accuracy and rationality of the reference value of the electromyographic signal in the movement</span>
        <span itemprop="definition">may be improved.</span>
        <meta itemprop="num_attr" content="0309">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the motion monitoring system 100</span>
        <span itemprop="definition">may guide the user to warm up and display a warm-up result of the user.</span>
        <meta itemprop="num_attr" content="0310">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the warm-up exercise before the motion</span>
        <span itemprop="definition">can improve the motion performance of the user, prevent the user from muscle twitching during the motion, and reduce the risk of injury.</span>
        <meta itemprop="num_attr" content="0310">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the display device</span>
        <span itemprop="definition">e.g., the screen</span>
        <meta itemprop="num_attr" content="0310">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processing module 220</span>
        <span itemprop="definition">may determine the warm-up result of the user based on physiological information of the user.</span>
        <meta itemprop="num_attr" content="0310">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the sensor</span>
        <span itemprop="definition">e.g., an electrode</span>
        <meta itemprop="num_attr" content="0310">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the sensor</span>
        <span itemprop="definition">may detect a contact impedance generated by the contact between the electrode and the human body, thus determining a sweating state of the human body, and determining whether the warm-up exercise of the user is sufficient according to the sweating state of the human body.</span>
        <meta itemprop="num_attr" content="0310">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a determination</span>
        <span itemprop="definition">may be made as whether the warm-up exercise of the user is sufficient based on the fatigue degree of muscle of the user.</span>
        <meta itemprop="num_attr" content="0310">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a determination</span>
        <span itemprop="definition">may be made as whether the warm-up exercise of the user is sufficient based on information such as an exercise volume, the heart rate, the body temperature, etc. of the user.</span>
        <meta itemprop="num_attr" content="0310">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a warm-up suggestion</span>
        <span itemprop="definition">may be provided to the user according to the warm-up result, for example, to prompt the user that the warm-up exercise is sufficient to start a formal exercise, or prompt the user to continue the warm-up exercise.</span>
        <meta itemprop="num_attr" content="0310">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processing module 220</span>
        <span itemprop="definition">may determine whether a working state of the sensor is normal based on the movement signal collected by the sensor.</span>
        <meta itemprop="num_attr" content="0311">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the working state of the sensor</span>
        <span itemprop="definition">may include a contact state between the and the skin.</span>
        <meta itemprop="num_attr" content="0311">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the contact state between the sensor and the skin</span>
        <span itemprop="definition">may include a degree of fit between the sensor and the skin, the contact impedance between the sensor and the skin, etc.</span>
        <meta itemprop="num_attr" content="0311">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the quality of the movement signal collected by the sensor set on the user&#39;s skin</span>
        <span itemprop="definition">may be related to the contact state between the sensor and the skin. For example, when the degree of fit between the sensor and the skin is poor, there may be more noise in the movement signal collected by the sensor, resulting in that the movement signal cannot reflect a real motion state of the user.</span>
        <meta itemprop="num_attr" content="0311">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the degree of fit between the sensor and the skin</span>
        <span itemprop="definition">may be determined according to the quality of the movement signal (e.g., an amount of noise in the movement signal) and/or the contact impedance between the sensor and the skin. If the degree of fit between the sensor and the skin is lower than a certain threshold, it may be determined that the working state of the sensor is abnormal. At this time, prompt information may be sent to the user to remind the user to check the state of the sensor.</span>
        <meta itemprop="num_attr" content="0311">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 37</span>
        <span itemprop="definition">is a schematic diagram illustrating a motion monitoring interface according to some embodiments of the present disclosure. As shown in FIG.</span>
        <meta itemprop="num_attr" content="0311">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">an interface 3700</span>
        <span itemprop="definition">displays a human muscle distribution map 3710 , and a dotted line 3720 indicates that the degree of fit between the sensor at a position of the right pectoral muscle and the user&#39;s skin is relatively low.</span>
        <meta itemprop="num_attr" content="0311">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the position with low degree of fit between the sensor and the user&#39;s skin</span>
        <span itemprop="definition">may be marked by other ways (e.g., mark using different colors).</span>
        <meta itemprop="num_attr" content="0311">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the movement signal of the user</span>
        <span itemprop="definition">may include a signal related to a feature of the user.</span>
        <meta itemprop="num_attr" content="0312">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processing module 220</span>
        <span itemprop="definition">may determine feature information of the user based on the signal related to the feature of the user.</span>
        <meta itemprop="num_attr" content="0312">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the feature information of the user</span>
        <span itemprop="definition">may include body shape information, body composition information, etc.</span>
        <meta itemprop="num_attr" content="0312">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the body shape information</span>
        <span itemprop="definition">may include a waist circumference, a chest circumference, a hip circumference, an arm length, a leg length, a shoulder width, etc.</span>
        <meta itemprop="num_attr" content="0312">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the body composition information</span>
        <span itemprop="definition">may include a body weight, a body fat percentage, a fat distribution, a fat thickness, a muscle distribution, a bone density, etc.</span>
        <meta itemprop="num_attr" content="0312">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a plurality of strain gauge sensors</span>
        <span itemprop="definition">may be set at a plurality of parts of the user&#39;s body.</span>
        <meta itemprop="num_attr" content="0312">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the movement signals obtained</span>
        <span itemprop="definition">may include displacement information, stress, etc.</span>
        <meta itemprop="num_attr" content="0312">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the movement signals</span>
        <span itemprop="definition">may indicate the body shape information of the user.</span>
        <meta itemprop="num_attr" content="0312">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">electrical signals</span>
        <span itemprop="definition">may be applied to electrodes set at a plurality of parts of the user&#39;s body, and information of the conductivity characteristics inside the human body may be extracted by measuring a body surface potential, so as to perform a positioning measurement on the body composition of the user.</span>
        <meta itemprop="num_attr" content="0312">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the motion monitoring system 100</span>
        <span itemprop="definition">may monitor the feature information of the user for a long time, and display a statistical analysis result to the user to help the user better understand a physical condition and develop a more reasonable exercise plan. For example, the motion monitoring system 100 may recommend an appropriate exercise to the user, such as a muscle building exercise, a fat loss exercise, a stretching sport, etc., according to a change (e.g., a fat distribution of each part of the user, a muscle distribution of each part of the user) of the feature information of the user over a period of time.</span>
        <meta itemprop="num_attr" content="0313">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a change</span>
        <span itemprop="definition">e.g., a fat distribution of each part of the user, a muscle distribution of each part of the user</span>
        <meta itemprop="num_attr" content="0313">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the wearable device of appropriate size</span>
        <span itemprop="definition">may be recommended to the user according to the body shape information. For example, if the user becomes thinner after a long period of exercise, a prompt may be sent to the user to remind the user to replace with a new wearable device. As another example, when the user select other types of wearable devices, appropriate sizes may be recommended to the user according to the body shape information.</span>
        <meta itemprop="num_attr" content="0314">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the user</span>
        <span itemprop="definition">when the user wears the wearable device 130 to exercise, the user may select a perceptual training mode.</span>
        <meta itemprop="num_attr" content="0315">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the perceptual training mode</span>
        <span itemprop="definition">when the user&#39;s muscle (e.g., the target muscle) exerts, the display device (e.g., the screen) of the wearable device 130 or the mobile terminal device 140 may display the exertion strength of the muscle.</span>
        <meta itemprop="num_attr" content="0315">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the exertion strength of the target muscle</span>
        <span itemprop="definition">may be displayed through a status bar (e.g., the status bars 2103 and 2104 shown in FIG. 21 B ).</span>
        <meta itemprop="num_attr" content="0315">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the exertion strength of the target muscle</span>
        <span itemprop="definition">may be displayed by the amount of the sound emitted by a sound output device (e.g., a speaker).</span>
        <meta itemprop="num_attr" content="0315">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a brightness and a color of a corresponding muscle position</span>
        <span itemprop="definition">may be changed in a user model to show a change of the exertion strength of the target muscle.</span>
        <meta itemprop="num_attr" content="0315">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the user</span>
        <span itemprop="definition">may be prompted (e.g., by the voice prompt, the text prompt, etc.) to help the user strengthen the feeling of controlling muscles.</span>
        <meta itemprop="num_attr" content="0315">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the perceptual training mode</span>
        <span itemprop="definition">it can help the user learn to control limbs and muscles, increase an ability of the brain and the nervous system to control muscles, effectively improve a motion performance, improve a movement pattern, and even correct a posture.</span>
        <meta itemprop="num_attr" content="0315">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the motion monitoring system 100</span>
        <span itemprop="definition">may formulate a motion plan of the user based on information related to the user.</span>
        <meta itemprop="num_attr" content="0316">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the information related to the user</span>
        <span itemprop="definition">may include feature information (e.g., the gender, the body shape information, the body composition information), an exercise history, an injury history, a health status, an expected training objective (e.g., a muscle building training, a fat loss training, a cardio pulmonary enhancement training, a posture correction training), an expected training intensity (e.g., a high-intensity training, a medium intensity training, a low-intensity training), a training type preference (e.g., an equipment training, a body weight training, an anaerobic training, an aerobic training), etc. of the user.</span>
        <meta itemprop="num_attr" content="0316">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">feature information</span>
        <span itemprop="definition">e.g., the gender, the body shape information, the body composition information</span>
        <meta itemprop="num_attr" content="0316">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">an exercise history</span>
        <span itemprop="definition">e.g., a muscle building training, a fat loss training, a cardio pulmonary enhancement training, a posture correction training</span>
        <meta itemprop="num_attr" content="0316">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">an expected training intensity</span>
        <span itemprop="definition">e.g., a high-inten</span>
        <meta itemprop="num_attr" content="0316">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a professional</span>
        <span itemprop="definition">e.g., a fitness instructor</span>
        <meta itemprop="num_attr" content="0316">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the user</span>
        <span itemprop="definition">may modify and adjust the motion plan according to an actual situation.</span>
        <meta itemprop="num_attr" content="0316">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 38</span>
        <span itemprop="definition">is a schematic diagram illustrating a motion monitoring interface according to some embodiments of the present disclosure. As shown in FIG.</span>
        <meta itemprop="num_attr" content="0316">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a user</span>
        <span itemprop="definition">may enter or select a training objective (e.g., a muscle to be strengthened, an enhancement objective), a training intensity (e.g., the high-intensity training, the medium intensity training, the low-intensity training), a training type preference (e.g., the equipment training, the body weight training, the anaerobic training, the aerobic training), a training time, a planning cycle, etc. in an interface 3800 .</span>
        <meta itemprop="num_attr" content="0316">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the motion monitoring system 100</span>
        <span itemprop="definition">may specify an appropriate motion plan for the user according to the input and the selection of the user.</span>
        <meta itemprop="num_attr" content="0316">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the motion monitoring system 100</span>
        <span itemprop="definition">may estimate a service life of the wearable device (e.g., a remaining usable time, a remaining count of cleanable times, a remaining count of usable times).</span>
        <meta itemprop="num_attr" content="0317">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the wearable device</span>
        <span itemprop="definition">may include a clothing life analysis module.</span>
        <meta itemprop="num_attr" content="0317">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the clothing life analysis module</span>
        <span itemprop="definition">may determine a wear degree of the wearable device according to the contact impedance between the and the user, the quality of the movement signal (e.g., an electromyography sensor signal, an inertial sensor signal, a stress sensor signal) collected by the sensor, and the status of the wearable device (e.g., a count of times cleaned, a used time, a count of times used), and estimate the service life according to the wear degree of the wearable device.</span>
        <meta itemprop="num_attr" content="0317">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a prompt</span>
        <span itemprop="definition">may be sent to the user to remind the user to replace with a new wearable device in time.</span>
        <meta itemprop="num_attr" content="0317">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">aspects of the present disclosure</span>
        <span itemprop="definition">may be illustrated and described herein in any of a number of patentable classes or context including any new and useful process, machine, manufacture, or composition of matter, or any new and useful improvement thereof. Accordingly, aspects of the present disclosure may be implemented entirely hardware, entirely software (including firmware, resident software, micro-code, etc.) or combining software and hardware implementation that may all generally be referred to herein as a data block, module, engine, unit, component, or system. Furthermore, aspects of the present disclosure may take the form of a computer program product embodied in one or more computer-readable media having computer-readable program code embodied thereon.</span>
        <meta itemprop="num_attr" content="0320">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a computer storage medium</span>
        <span itemprop="definition">may include a propagated data signal with computer readable program code embodied therein, for example, in baseband or as part of a carrier wave. Such a propagated signal may take any of a variety of forms, including electro-magnetic, optical, or the like, or any suitable combination thereof.</span>
        <meta itemprop="num_attr" content="0321">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a computer storage medium</span>
        <span itemprop="definition">may be any computer-readable medium that is not a computer-readable storage medium and that may communicate, propagate, or transport a program for use by or in connection with an instruction execution system, apparatus, or device.</span>
        <meta itemprop="num_attr" content="0321">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Program code embodied on a computer-readable signal medium</span>
        <span itemprop="definition">may be transmitted using any appropriate medium, including wireless, wireline, optical fiber cable, RF, or the like, or any suitable combination of the foregoing.</span>
        <meta itemprop="num_attr" content="0321">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Computer program code for carrying out operations for aspects of the present disclosure</span>
        <span itemprop="definition">may be written in any combination of one or more programming languages, including an object-oriented programming language such as Java, Scala, Smalltalk, Eiffel, JADE, Emerald, C&#43;&#43;, C #, VB. NET, Python or the like, conventional procedural programming languages, such as the C programming language, Visual Basic, Fortran 2003, Perl, COBOL 2002, PHP, ABAP, dynamic programming languages such as Python, Ruby, and Groovy, or other programming languages.</span>
        <meta itemprop="num_attr" content="0322">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the program code</span>
        <span itemprop="definition">may execute entirely on the user&#39;s computer, partly on the user&#39;s computer, as a stand-alone software package, partly on the user&#39;s computer and partly on a remote computer or entirely on the remote computer or server.</span>
        <meta itemprop="num_attr" content="0322">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the remote computer</span>
        <span itemprop="definition">may be connected to the user&#39;s computer through any type of network, including a local area network (LAN) or a wide area network (WAN), or the connection may be made to an external computer (for example, through the Internet) or in a cloud computing environment or offered as a service such as a Software as a Service (SaaS).</span>
        <meta itemprop="num_attr" content="0322">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">LAN</span>
        <span itemprop="definition">local area network</span>
        <meta itemprop="num_attr" content="0322">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">WAN</span>
        <span itemprop="definition">wide area network</span>
        <meta itemprop="num_attr" content="0322">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">SaaS</span>
        <span itemprop="definition">Software as a Service</span>
        <meta itemprop="num_attr" content="0322">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the numbers expressing quantities, properties, and so forth, used to describe and claim certain embodiments of the application</span>
        <span itemprop="definition">are to be understood as being modified in some instances by the term about, approximate, or substantially. For example, about, approximate, or substantially may indicate   20% variation of the value it describes, unless otherwise stated. Accordingly, in some embodiments, the numerical parameters set forth in the written description and attached claims are approximations that may vary depending upon the desired properties sought to be obtained by a particular embodiment. In some embodiments, the numerical parameters should be construed in light of the number of reported significant digits and by applying ordinary rounding techniques. Notwithstanding that the numerical ranges and parameters setting forth the broad scope of some embodiments of the application are approximations, the numerical values set forth in the specific examples are reported as precisely as practicable.</span>
        <meta itemprop="num_attr" content="0325">
      </li>
    </ul>
  </section>

  


  <section itemprop="abstract" itemscope>
    <h2>Abstract</h2>
    
    <div itemprop="content" html><abstract mxw-id="PA604957619" lang="EN" source="national office" load-source="docdb">
    <div class="abstract">The present disclosure discloses a method for displaying a motion monitoring interface. The method includes: obtaining a movement signal during a motion of a user from at least one sensor, wherein the movement signal at least includes an electromyographic signal or an attitude signal; determining information related to the motion of the user by processing the movement signal; and displaying the information related to the motion of the user.</div>
  </abstract>
  </div>
  </section>

  <section itemprop="description" itemscope>
    <h2>Description</h2>
    
    <div itemprop="content" html><ul mxw-id="PDES421917812" lang="EN" load-source="patent-office" class="description">
    
    <heading id="h-0001">CROSS-REFERENCE TO RELATED APPLICATIONS</heading>
    <li> <para-num num="[0001]"> </para-num> <div id="p-0002" num="0001" class="description-line">The present disclosure is a continuation of International Application No. PCT/CN2022/081718, filed on Mar. 18, 2022, which claims priority of International Application No. PCT/CN2021/081931, filed on Mar. 19, 2021, and International Application No. PCT/CN2021/093302, filed on May 12, 2021, the content of each of which are hereby incorporated by reference.</div>
    
    
    </li> <heading id="h-0002">TECHNICAL FIELD</heading>
    <li> <para-num num="[0002]"> </para-num> <div id="p-0003" num="0002" class="description-line">The present disclosure relates to a technical field of wearable device, and in particular, to a motion monitoring method and device.</div>
    </li> <heading id="h-0003">BACKGROUND</heading>
    <li> <para-num num="[0003]"> </para-num> <div id="p-0004" num="0003" class="description-line">With people concerned about scientific exercise and physical health, motion monitoring devices are developing tremendously. At present, the motion monitoring devices mainly monitor some of the physiological parameter information (e.g., a heart rate, a body temperature, a step frequency, a blood oxygen, etc.) of a user during motion, display physiological data to the user, and give exercise suggestions based on the physiological data. In practical scenarios, motion monitoring devices often cannot display monitoring results of the motion to the user fully and accurately, resulting in the user can not know their own motion situation in time, or the physiological data given by the system is significantly different from the user&#39;s body feeling during motion, which may lead to a decline in the user&#39;s credibility of the motion monitoring devices.</div>
    </li> <li> <para-num num="[0004]"> </para-num> <div id="p-0005" num="0004" class="description-line">Therefore, it is desired to provide a motion monitoring method and device to monitor and display motion data of a user during motion comprehensively and accurately.</div>
    </li> <heading id="h-0004">SUMMARY</heading>
    <li> <para-num num="[0005]"> </para-num> <div id="p-0006" num="0005" class="description-line">One aspect of the present disclosure may provide a method for displaying a motion monitoring interface. The method may include: obtaining a movement signal during a motion of a user from at least one sensor, wherein the movement signal at least includes an electromyographic signal or an attitude signal; determining information related to the motion of the user by processing the movement signal; and displaying the information related to the motion of the user.</div>
    </li> <li> <para-num num="[0006]"> </para-num> <div id="p-0007" num="0006" class="description-line">In some embodiments, the determining information related to the motion of the user by processing the movement signal may include: determining an exertion strength of at least one muscle of the user based on the electromyographic signal.</div>
    </li> <li> <para-num num="[0007]"> </para-num> <div id="p-0008" num="0007" class="description-line">In some embodiments, the displaying the information related to the motion the user may include: obtaining a user input regarding a target muscle; and displaying a status bar, wherein a color of the status bar is related to an exertion strength of the target muscle, or making a sound, wherein a volume of the sound is related to the exertion strength of the target muscle.</div>
    </li> <li> <para-num num="[0008]"> </para-num> <div id="p-0009" num="0008" class="description-line">In some embodiments, the determining information related to the motion of the user by processing the movement signal may include: generating a user movement model representing a movement of the motion of the user based on the attitude signal.</div>
    </li> <li> <para-num num="[0009]"> </para-num> <div id="p-0010" num="0009" class="description-line">In some embodiments, the displaying the information related to the motion of the user may include: obtaining a standard movement model; and displaying the user movement model and the standard movement model.</div>
    </li> <li> <para-num num="[0010]"> </para-num> <div id="p-0011" num="0010" class="description-line">In some embodiments, the displaying the information related to the motion of the user may include: determining an exertion strength of at least one muscle of the user based on the electromyographic signal; and displaying the exertion strength of the at least one muscle on the user movement model.</div>
    </li> <li> <para-num num="[0011]"> </para-num> <div id="p-0012" num="0011" class="description-line">In some embodiments, the determining information related to the motion of the user by processing the movement signal may include: segmenting the movement signal based on the electromyographic signal or the attitude signal; and determining a monitoring result by monitoring a movement of the motion of the user based on at least one segment of the movement signal.</div>
    </li> <li> <para-num num="[0012]"> </para-num> <div id="p-0013" num="0012" class="description-line">In some embodiments, the method may further include: determining a movement feedback mode based on the monitoring result; and performing a movement feedback to the user according to the movement feedback mode.</div>
    </li> <li> <para-num num="[0013]"> </para-num> <div id="p-0014" num="0013" class="description-line">In some embodiments, the at least one segment of the movement signal may be a movement signal of the user in at least one training process, and the monitoring result may include at least one of a movement type, a movement quantity, a movement quality, a movement time, physiological parameter information of the user, or a core stability of the user during the at least one training process.</div>
    </li> <li> <para-num num="[0014]"> </para-num> <div id="p-0015" num="0014" class="description-line">In some embodiments, the monitoring result may include muscle information of the user corresponding to at least one time point, the muscle information of the user may include at least one of an energy consumption of at least one muscle, a fatigue degree of the at least one muscle, a balance of at least two muscles, or an ability of the at least one muscle, and the displaying the information related to the motion of the user may include: displaying at least one of the energy consumption of the at least one muscle, the fatigue degree of the at least one muscle, the balance of the at least two muscles, or the ability of the at least one muscle on at least one location in a user model, wherein the at least one location in the user model corresponds to a location of the at least one muscle in the user.</div>
    </li> <li> <para-num num="[0015]"> </para-num> <div id="p-0016" num="0015" class="description-line">In some embodiments, energy consumptions of different muscles, fatigue levels of different muscles, training balances of different muscles, and/or abilities of different muscles may correspond to different display colors.</div>
    </li> <li> <para-num num="[0016]"> </para-num> <div id="p-0017" num="0016" class="description-line">In some embodiments, the displaying the information related to the motion of the user may include: obtaining a user input regarding a target muscle; and displaying information of the target muscle.</div>
    </li> <li> <para-num num="[0017]"> </para-num> <div id="p-0018" num="0017" class="description-line">In some embodiments, the displaying the information related to the motion of the user may include: displaying the monitoring result in at least one of a text, a chart, a sound, an image, or a video.</div>
    </li> <li> <para-num num="[0018]"> </para-num> <div id="p-0019" num="0018" class="description-line">In some embodiments, the method may further include: calibrating the movement signal.</div>
    </li> <li> <para-num num="[0019]"> </para-num> <div id="p-0020" num="0019" class="description-line">In some embodiments, the method may further include: determining whether a working state of the at least one sensor is normal based on the movement signal; and in response to determining that the working state of the at least one sensor is abnormal, displaying prompt information.</div>
    </li> <li> <para-num num="[0020]"> </para-num> <div id="p-0021" num="0020" class="description-line">In some embodiments, the movement signal may include a signal related to a feature of the user, and the method may further include: determining body shape information and/or body composition information of the user based on the signal related to the feature of the user; and displaying the body shape information and/or body composition information of the user.</div>
    </li> <li> <para-num num="[0021]"> </para-num> <div id="p-0022" num="0021" class="description-line">Some embodiments of the present disclosure may also provide an electronic device. The electronic device may include: a display device configured to display content; an input device configured to receive a user input; and at least one sensor configured to detect a movement signal during a motion of a user, wherein the movement signal may at least include an electromyographic signal or an attitude signal; and a processor connected to the display device, the input device, and the at least one sensor, wherein the processor is configured to: obtain the movement signal during the motion of the user from the at least one sensor; determine information related to the motion of the user by processing the movement signal; and control the display device to display the information related to the motion of the user.</div>
    
    
    </li> <description-of-drawings>
      <heading id="h-0005">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
      <li> <para-num num="[0022]"> </para-num> <div id="p-0023" num="0022" class="description-line">The present disclosure will be further described in the form of exemplary embodiments, which will be described in detail by the accompanying drawings. These embodiments are not limiting. In these embodiments, the same number represents the same structure, wherein:</div>
      </li> <li> <para-num num="[0023]"> </para-num> <div id="p-0024" num="0023" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>1</b> </figref> is a schematic diagram of an application scenario of a motion monitoring system according to some embodiments of the present disclosure;</div>
      </li> <li> <para-num num="[0024]"> </para-num> <div id="p-0025" num="0024" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>2</b> </figref> is a schematic diagram of illustrating exemplary hardware and/or software of a wearable device according to some embodiments of the present disclosure;</div>
      </li> <li> <para-num num="[0025]"> </para-num> <div id="p-0026" num="0025" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>3</b> </figref> is a schematic diagram illustrating exemplary hardware and/or software of a computing device according to some embodiments of the present disclosure;</div>
      </li> <li> <para-num num="[0026]"> </para-num> <div id="p-0027" num="0026" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>4</b> </figref> is a structure diagram of an exemplary wearable device according to some embodiments of the present disclosure;</div>
      </li> <li> <para-num num="[0027]"> </para-num> <div id="p-0028" num="0027" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>5</b> </figref> is a flowchart illustrating an exemplary motion monitoring method according to some embodiments of the present disclosure;</div>
      </li> <li> <para-num num="[0028]"> </para-num> <div id="p-0029" num="0028" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>6</b> </figref> is a flowchart of an exemplary process for monitoring a movement of a motion of a user according to some embodiments of the present disclosure;</div>
      </li> <li> <para-num num="[0029]"> </para-num> <div id="p-0030" num="0029" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>7</b> </figref> is a flowchart of an exemplary process for segmenting a movement signal according to some embodiments of the present disclosure;</div>
      </li> <li> <para-num num="[0030]"> </para-num> <div id="p-0031" num="0030" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>8</b> </figref> is a diagram illustrating exemplary normalized results of segmenting a movement signal according to some embodiments of the present disclosure;</div>
      </li> <li> <para-num num="[0031]"> </para-num> <div id="p-0032" num="0031" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>9</b> </figref> is a flowchart of an exemplary process for pre-processing an electromyographic signal according to some embodiments of the present disclosure;</div>
      </li> <li> <para-num num="[0032]"> </para-num> <div id="p-0033" num="0032" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>10</b> </figref> is a flow chart illustrating an exemplary burr signal according to some embodiments of the present disclosure;</div>
      </li> <li> <para-num num="[0033]"> </para-num> <div id="p-0034" num="0033" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>11</b> </figref> is a flowchart of an exemplary process for determining feature information corresponding to an attitude signal according to some embodiments of the present disclosure;</div>
      </li> <li> <para-num num="[0034]"> </para-num> <div id="p-0035" num="0034" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>12</b> </figref> is a flowchart of an exemplary process for determining relative motion between different motion parts of a user according to some embodiments of the present disclosure;</div>
      </li> <li> <para-num num="[0035]"> </para-num> <div id="p-0036" num="0035" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>13</b> </figref> is a flowchart of an exemplary process for determining a conversion relationship between an original coordinate system and a particular coordinate system according to some embodiments of the present disclosure;</div>
      </li> <li> <para-num num="[0036]"> </para-num> <div id="p-0037" num="0036" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>14</b> </figref> is a flowchart of an exemplary process for determining a conversion relationship between an original coordinate system and a target coordinate system according to some embodiments of the present disclosure;</div>
      </li> <li> <para-num num="[0037]"> </para-num> <div id="p-0038" num="0037" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>15</b>A</figref> is an exemplary vector coordinate diagram illustrating Euler angle data in an original coordinate system at a position of a small arm of a human body according to some embodiments of the present disclosure;</div>
      </li> <li> <para-num num="[0038]"> </para-num> <div id="p-0039" num="0038" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>15</b>B</figref> is an exemplary vector coordinate diagram illustrating Euler angle data in another original coordinate system at a position of a small arm of a human body according to some embodiments of the present disclosure;</div>
      </li> <li> <para-num num="[0039]"> </para-num> <div id="p-0040" num="0039" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>16</b>A</figref> is an exemplary vector coordinate diagram of Euler angle data in a target coordinate system at a position of a small arm of a human body according to some embodiments of the present disclosure;</div>
      </li> <li> <para-num num="[0040]"> </para-num> <div id="p-0041" num="0040" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>16</b>B</figref> is an exemplary vector coordinate diagram of Euler angle data in a target coordinate system at another location of a small arm of a human body according to some embodiments of the present disclosure;</div>
      </li> <li> <para-num num="[0041]"> </para-num> <div id="p-0042" num="0041" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>17</b> </figref> is an exemplary vector coordinate diagram of Euler angle data in a target coordinate system of a multi-sensor according to some embodiments of the present disclosure;</div>
      </li> <li> <para-num num="[0042]"> </para-num> <div id="p-0043" num="0042" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>18</b>A</figref> is a diagram illustrating exemplary results of an original angular velocity according to some embodiments of the present disclosure;</div>
      </li> <li> <para-num num="[0043]"> </para-num> <div id="p-0044" num="0043" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>18</b>B</figref> is a diagram illustrating exemplary results of an angular velocity after filtering processing according to some embodiments of the present disclosure;</div>
      </li> <li> <para-num num="[0044]"> </para-num> <div id="p-0045" num="0044" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>19</b> </figref> is a flowchart illustrating an exemplary motion monitoring and feedback method according to some embodiments of the present disclosure;</div>
      </li> <li> <para-num num="[0045]"> </para-num> <div id="p-0046" num="0045" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>20</b> </figref> is a flowchart illustrating exemplary process for model training according to some embodiments of the present disclosure</div>
      </li> <li> <para-num num="[0046]"> </para-num> <div id="p-0047" num="0046" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>21</b>A</figref> is an exemplary flowchart of a process for displaying a motion monitoring interface according to some embodiments of the present disclosure;</div>
      </li> <li> <para-num num="[0047]"> </para-num> <div id="p-0048" num="0047" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>21</b>B</figref> is an example diagram of a motion monitoring interface according to some embodiments of the present disclosure;</div>
      </li> <li> <para-num num="[0048]"> </para-num> <div id="p-0049" num="0048" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>22</b> </figref> is an exemplary flowchart of a process for displaying a motion monitoring interface according to some embodiments of the present disclosure;</div>
      </li> <li> <para-num num="[0049]"> </para-num> <div id="p-0050" num="0049" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>23</b>A</figref> a schematic diagram of a motion monitoring interface according to some embodiments of the present disclosure;</div>
      </li> <li> <para-num num="[0050]"> </para-num> <div id="p-0051" num="0050" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>23</b>B</figref> is a schematic diagram of a motion monitoring interface according to some embodiments of the present disclosure;</div>
      </li> <li> <para-num num="[0051]"> </para-num> <div id="p-0052" num="0051" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>23</b>C</figref> are schematic diagrams of a motion monitoring interface according to some embodiments of the present disclosure;</div>
      </li> <li> <para-num num="[0052]"> </para-num> <div id="p-0053" num="0052" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>24</b> </figref> is an exemplary flowchart of a process for displaying a motion monitoring interface according to some embodiments of the present disclosure;</div>
      </li> <li> <para-num num="[0053]"> </para-num> <div id="p-0054" num="0053" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>25</b> </figref> is a schematic diagram of a motion monitoring interface according to some embodiments of the present disclosure;</div>
      </li> <li> <para-num num="[0054]"> </para-num> <div id="p-0055" num="0054" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>26</b> </figref> is a schematic diagram of a motion monitoring interface according to some embodiments of the present disclosure;</div>
      </li> <li> <para-num num="[0055]"> </para-num> <div id="p-0056" num="0055" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>27</b> </figref> is a schematic diagram of a motion monitoring interface according to some embodiments of the present disclosure;</div>
      </li> <li> <para-num num="[0056]"> </para-num> <div id="p-0057" num="0056" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>28</b> </figref> is a schematic diagram of a motion monitoring interface according to some embodiments of the present disclosure;</div>
      </li> <li> <para-num num="[0057]"> </para-num> <div id="p-0058" num="0057" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>29</b> </figref> is a schematic diagram of a motion monitoring interface according to some embodiments of the present disclosure;</div>
      </li> <li> <para-num num="[0058]"> </para-num> <div id="p-0059" num="0058" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>30</b> </figref> is a schematic diagram of a motion monitoring interface according to some embodiments of the present disclosure;</div>
      </li> <li> <para-num num="[0059]"> </para-num> <div id="p-0060" num="0059" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>31</b> </figref> is a schematic diagram of a motion monitoring interface according to some embodiments of the present disclosure;</div>
      </li> <li> <para-num num="[0060]"> </para-num> <div id="p-0061" num="0060" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>32</b> </figref> is a schematic diagram of a motion monitoring interface according to some embodiments of the present disclosure;</div>
      </li> <li> <para-num num="[0061]"> </para-num> <div id="p-0062" num="0061" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>33</b> </figref> is a schematic diagram of a motion monitoring interface according to some embodiments of the present disclosure;</div>
      </li> <li> <para-num num="[0062]"> </para-num> <div id="p-0063" num="0062" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>34</b> </figref> is a schematic diagram of a motion monitoring interface according to some embodiments of the present disclosure;</div>
      </li> <li> <para-num num="[0063]"> </para-num> <div id="p-0064" num="0063" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>35</b> </figref> is a schematic diagram of a motion monitoring interface according to some embodiments of the present disclosure;</div>
      </li> <li> <para-num num="[0064]"> </para-num> <div id="p-0065" num="0064" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>36</b> </figref> is a schematic diagram of a motion monitoring interface according to some embodiments of the present disclosure;</div>
      </li> <li> <para-num num="[0065]"> </para-num> <div id="p-0066" num="0065" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>37</b> </figref> is a schematic diagram of a motion monitoring interface according to some embodiments of the present disclosure;</div>
      </li> <li> <para-num num="[0066]"> </para-num> <div id="p-0067" num="0066" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>38</b> </figref> is a schematic diagram of a motion monitoring interface according to some embodiments of the present disclosure.</div>
    </li> </description-of-drawings>
    
    
    <heading id="h-0006">DETAILED DESCRIPTION</heading>
    <li> <para-num num="[0067]"> </para-num> <div id="p-0068" num="0067" class="description-line">In order to more clearly explain the technical scheme of the embodiments of the present disclosure, the following will briefly introduce the drawings that need to be used in the description of the embodiments. Obviously, the drawings in the following description are only some examples or embodiments of the present disclosure. For those skilled in the art, the present disclosure may also be applied to other similar scenarios according to these drawings without creative work. Unless it is obvious from the language environment or otherwise stated, the same label in the figure represents the same structure or operation.</div>
    </li> <li> <para-num num="[0068]"> </para-num> <div id="p-0069" num="0068" class="description-line">It will be understood that the term system, device, unit, and/or module used herein are one method to distinguish different components, elements, parts, sections or assemblies of different levels in ascending order. However, if other words may achieve the same purpose, the words may be replaced by other expressions.</div>
    </li> <li> <para-num num="[0069]"> </para-num> <div id="p-0070" num="0069" class="description-line">As used in the disclosure and the appended claims, the singular forms a, an, and the include plural referents unless the content clearly dictates otherwise. Generally speaking, the terms comprise, comprises, and/or comprising, include, includes, and/or including, only imply that the clearly identified steps and elements are included, these steps and elements may not constitute an exclusive list, and the method or device may further include other steps or elements.</div>
    </li> <li> <para-num num="[0070]"> </para-num> <div id="p-0071" num="0070" class="description-line">Flowcharts are used throughout the present disclosure to illustrate the operations performed by the system according to embodiments of the present disclosure. It should be understood that the preceding or following operations are not necessarily performed in precise order. Instead, the individual steps may be processed in reverse order or simultaneously. Other operations may be added to these processes or a step or steps of operations may be removed from these processes.</div>
    </li> <li> <para-num num="[0071]"> </para-num> <div id="p-0072" num="0071" class="description-line">The present disclosure may provide a motion monitoring system. The system may obtain a movement signal of a user during motion. The movement signal may include at least an electromyographic signal, an attitude signal, an electro-cardio graphic signal, a respiratory rate signal, and the like. The motion monitoring system may monitor a movement of the user during motion based at least on feature information corresponding to the electromyographic signal or the feature information corresponding to an attitude signal. For example, the system may determine the type of movement of the user, the number of movement, the movement quality, the movement time, or the information of physiological parameters of the user when performing the movement through frequency information and amplitude information corresponding to the electromyographic signal, an angular velocity, an angular velocity direction and an angular velocity value of the angular velocity, an angle, displacement information, and stress, etc., corresponding to the attitude signal. In some embodiments, the motion monitoring system may further generate feedback to a user&#39;s fitness movement according to analysis results of the user&#39;s fitness movement to provide guidance to user&#39;s fitness. For example, when the user&#39;s fitness movement is not standard, the motion monitoring system can send a prompt message to the user (e.g., a voice prompt, a vibration prompt, current stimulation, etc.). The motion monitoring system may be applied to a wearable device (e.g., clothing, a wrist guard, a helmet), a medical testing device (e.g., an electromyography tester), a fitness device, etc. The motion monitoring system may accurately monitor and provide feedback on a user&#39;s movement by obtaining the movement signal of the user during motion without professional participation, which can improve the user&#39;s fitness efficiency and reduce a cost of the user fitness.</div>
    </li> <li> <para-num num="[0072]"> </para-num> <div id="p-0073" num="0072" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>1</b> </figref> is a schematic diagram illustrating an application scenario of a motion monitoring system according to some embodiments of the present disclosure. As shown in <figref idrefs="DRAWINGS">FIG. <b>1</b> </figref>, the <figure-callout id="100" label="motion monitoring system" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">motion monitoring system</figure-callout> <b>100</b> may include a <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b>, a <figure-callout id="120" label="network" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">network</figure-callout> <b>120</b>, a <figure-callout id="130" label="wearable device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">wearable device</figure-callout> <b>130</b>, and a mobile <figure-callout id="140" label="terminal device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">terminal device</figure-callout> <b>140</b>. The <figure-callout id="100" label="motion monitoring system" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">motion monitoring system</figure-callout> <b>100</b> may obtain a movement signal (e.g., an electromyographic signal, an attitude signal, an electro-cardio signal, a respiratory rate signal, etc.) representing a movement of user motion, and may monitor and provide feedback on the movement of the user during motion according to a user&#39;s movement signal.</div>
    </li> <li> <para-num num="[0073]"> </para-num> <div id="p-0074" num="0073" class="description-line">For example, the <figure-callout id="100" label="motion monitoring system" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">motion monitoring system</figure-callout> <b>100</b> may monitor and provide feedback on the movement of the user during fitness. When the user wears the <figure-callout id="130" label="wearable device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">wearable device</figure-callout> <b>130</b> for fitness, the <figure-callout id="130" label="wearable device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">wearable device</figure-callout> <b>130</b> may obtain the user&#39;s movement signal. The <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b> or a mobile terminal device may receive and analyze the user&#39;s movement signal to determine whether the user&#39;s fitness movement is standard, thereby monitoring the user&#39;s movement. Specifically, the monitoring of the user&#39;s movement may include determining a type of movement, a count of movement, a quality of the movement, and a time of the movement, or information about the physiological parameters of the user at the time the movement is performed. Further, the <figure-callout id="100" label="motion monitoring system" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">motion monitoring system</figure-callout> <b>100</b> may generate feedback on the user&#39;s fitness movement according to an analysis result of the user&#39;s fitness movement to provide guidance to the user.</div>
    </li> <li> <para-num num="[0074]"> </para-num> <div id="p-0075" num="0074" class="description-line">Further, for example, the <figure-callout id="100" label="motion monitoring system" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">motion monitoring system</figure-callout> <b>100</b> may monitor and provide feedback on the user&#39;s movement while running. For example, when the user wears the <figure-callout id="130" label="wearable device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">wearable device</figure-callout> <b>130</b> for running exercise, the <figure-callout id="100" label="motion monitoring system" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">motion monitoring system</figure-callout> <b>100</b> may monitor whether the user&#39;s running movement is standard and whether the running time meets a health standard. When a user&#39;s running time is too long or a running movement is incorrect, the fitness device may provide motion state to the user to prompt the user to adjust the running movement or the running time.</div>
    </li> <li> <para-num num="[0075]"> </para-num> <div id="p-0076" num="0075" class="description-line">In some embodiments, the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b> may be configured to process information and/or data related to the user&#39;s movement. For example, the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b> may receive the movement signal of the user (e.g., an electromyographic signal, an attitude signal, an electro-cardio signal, a respiratory rate signal, etc.) and further extract the feature information corresponding to the movement signal (e.g., the feature information corresponding to the electromyographic signal in the movement signal, the feature information corresponding to the attitude signal). In some embodiments, the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b> may perform a specific signal processing, such as a signal segmentation, a signal pre-processing (e.g., a signal correction processing, a filtering processing, etc.), etc., on the electromyographic signal or the attitude signal obtained by the <figure-callout id="130" label="wearable device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">wearable device</figure-callout> <b>130</b>. In some embodiments, the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b> may further determine whether the user movement is correct based on the user&#39;s movement signal. For example, the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b> may determine whether the user movement is correct based on the feature information corresponding to the electromyographic signal (e.g., amplitude information, frequency information, etc.). As another example, the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b> may determine whether the user movement is correct based on the feature information corresponding to the attitude signal (e.g., an angular velocity, a direction of angular velocity, an acceleration of angular velocity, an angle, displacement information, a stress, etc.). Further, for example, the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b> may determine whether the user movement is correct based on the feature information corresponding to the electromyographic signal and the feature information corresponding to the attitude signal. In some embodiments, the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b> may further determine whether information of physiological parameters of the user during motion meets the health standard. In some embodiments, the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b> may further send a corresponding instruction configured to feed the user&#39;s movement back. For example, when the user is running and the <figure-callout id="100" label="motion monitoring system" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">motion monitoring system</figure-callout> <b>100</b> monitors that the user&#39;s running time is too long, the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b> may send the instruction to the mobile <figure-callout id="140" label="terminal device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">terminal device</figure-callout> <b>140</b> to prompt the user to adjust the running time. It should be noted that the feature information corresponding to the attitude signal is not limited to above angular velocity, the direction of angular velocity, the acceleration of angular velocity, the angle, the displacement information, and the stress, etc., but can also be other feature information. For example, when an attitude sensor is a strain gauge sensor, a bending angle and a bending direction at a user&#39;s joint may be obtained by measuring the resistance in a strain gauge sensor that varies with a stretch length.</div>
    </li> <li> <para-num num="[0076]"> </para-num> <div id="p-0077" num="0076" class="description-line">In some embodiments, the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b> may be local or remote. For example, the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b> may access information and/or materials stored in the <figure-callout id="130" label="wearable device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">wearable device</figure-callout> <b>130</b> and/or the mobile <figure-callout id="140" label="terminal device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">terminal device</figure-callout> <b>140</b> through the <figure-callout id="120" label="network" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">network</figure-callout> <b>120</b>. In some embodiments, the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b> may be directly connected to the <figure-callout id="130" label="wearable device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">wearable device</figure-callout> <b>130</b> and/or the mobile <figure-callout id="140" label="terminal device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">terminal device</figure-callout> <b>140</b> to access the information and/or materials stored therein. For example, the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b> may be located in the <figure-callout id="130" label="wearable device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">wearable device</figure-callout> <b>130</b> and implement the information interact with the mobile <figure-callout id="140" label="terminal device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">terminal device</figure-callout> <b>140</b> through the <figure-callout id="120" label="network" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">network</figure-callout> <b>120</b>. Further, for example, the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b> may be located in the mobile <figure-callout id="140" label="terminal device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">terminal device</figure-callout> <b>140</b> and implement the information interact with the <figure-callout id="130" label="wearable device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">wearable device</figure-callout> <b>130</b> through a network. In some embodiments, the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b> may be executed on a cloud platform. For example, the cloud platform may include one of a private cloud, a public cloud, a hybrid cloud, a community cloud, a decentralized cloud, an internal cloud, or any combination thereof.</div>
    </li> <li> <para-num num="[0077]"> </para-num> <div id="p-0078" num="0077" class="description-line">In some embodiments, the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b> may process data and/or information related to motion monitoring to perform one or more of functions described in the present disclosure. In some embodiments, the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b> may obtain the movement signal collected by the <figure-callout id="130" label="wearable device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">wearable device</figure-callout> <b>130</b> while the user is in motion. In some embodiments, the processing device may send a control instruction to the <figure-callout id="130" label="wearable device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">wearable device</figure-callout> <b>130</b> or the mobile <figure-callout id="140" label="terminal device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">terminal device</figure-callout> <b>140</b>. The control instruction may control an on/off state of the <figure-callout id="130" label="wearable device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">wearable device</figure-callout> <b>130</b> and its respective sensor, and also control the mobile <figure-callout id="140" label="terminal device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">terminal device</figure-callout> <b>140</b> to send a prompt message. In some embodiments, <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b> may include one or more sub-processing devices (e.g., a single-core processing device or a multi-core processing device). Merely by way of example, the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b> may include a central processing unit (CPU), an application-specific integrated circuit (ASIC), an application-specific instruction processor (ASIP), a graphic processing unit (GPU), a physics processing Unit (PPU), a digital signal processor (DSP), a field-programmable gate array (FPGA), an programmable logic device (PLD), a controller, a microcontroller unit reduced instruction set computer (RISC), and a microprocessor, or the like, or any combination of the above.</div>
    </li> <li> <para-num num="[0078]"> </para-num> <div id="p-0079" num="0078" class="description-line">The <figure-callout id="120" label="network" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">network</figure-callout> <b>120</b> may facilitate the exchange of data and/or information in the <figure-callout id="100" label="motion monitoring system" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">motion monitoring system</figure-callout> <b>100</b>. In some embodiments, one or more components of the motion monitoring system <b>100</b> (e.g., the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b>, the <figure-callout id="130" label="wearable device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">wearable device</figure-callout> <b>130</b>, the mobile terminal device <b>140</b>) may send the data and/or the information to other components of the <figure-callout id="100" label="motion monitoring system" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">motion monitoring system</figure-callout> <b>100</b> through <figure-callout id="120" label="network" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">network</figure-callout> <b>120</b>. For example, the movement signal collected by the <figure-callout id="130" label="wearable device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">wearable device</figure-callout> <b>130</b> may be transmitted to the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b> through the <figure-callout id="120" label="network" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">network</figure-callout> <b>120</b>. As another example, confirmation results regarding the movement signal in the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b> may be transmitted to the mobile <figure-callout id="140" label="terminal device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">terminal device</figure-callout> <b>140</b> through the <figure-callout id="120" label="network" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">network</figure-callout> <b>120</b>. In some embodiments, the <figure-callout id="120" label="network" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">network</figure-callout> <b>120</b> may be any type of a wired or wireless network. For example, the <figure-callout id="120" label="network" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">network</figure-callout> <b>120</b> may include a cable network, a wired network, a fiber optic network, a telecommunications network, an internal network, an inter-network, a regional network (LAN), a wide area network (WAN), a wireless regional network (WLAN), a metropolitan area network (MAN), a public switched telephone network (PSTN), a Bluetooth network, a ZigBee network, and a near field communication (NFC) network, or any combination of the above. In some embodiments, the <figure-callout id="120" label="network" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">network</figure-callout> <b>120</b> may include one or more network entry and exit points. For example, <figure-callout id="120" label="network" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">network</figure-callout> <b>120</b> may include wired or wireless network entry and exit points, such as a base station and/or inter-network exchange points <b>120</b>-<b>1</b>, <b>120</b>-<b>2</b>, . . . , through the entry and exit points, one or more components of <figure-callout id="100" label="motion monitoring system" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">motion monitoring system</figure-callout> <b>100</b> may connect to the <figure-callout id="120" label="network" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">network</figure-callout> <b>120</b> to exchange the data and/or the information.</div>
    </li> <li> <para-num num="[0079]"> </para-num> <div id="p-0080" num="0079" class="description-line">The <figure-callout id="130" label="wearable device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">wearable device</figure-callout> <b>130</b> may be a garment or a device that has a wearable function. In some embodiments, the <figure-callout id="130" label="wearable device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">wearable device</figure-callout> <b>130</b> may include, but is not limited to, an upper garment device <b>130</b>-<b>1</b>, a pant device <b>130</b>-<b>2</b>, a wrist guard device <b>130</b>-<b>3</b>, and a shoe <b>130</b>-<b>4</b>, etc. In some embodiments, <figure-callout id="130" label="wearable device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">wearable device</figure-callout> <b>130</b> may include a plurality of sensors. The sensors may obtain various movement signals (e.g., an electromyographic signal, an attitude signal, temperature information, a heart rate, an electro-cardio signal, etc.) from the user during motion. In some embodiments, the sensors may include, but are not limited to, one or more of an electromyographic sensor, an attitude sensor, a temperature sensor, a humidity sensor, an electro-cardio sensor, an oxygen saturation sensor, a Hall sensor, a Pico electric sensor, a rotation sensor, etc. For example, an electromyographic sensor may be provided at a human muscle location (e.g., biceps, triceps, latissimus dorsi, trapezius, etc.) in the upper garment device <b>130</b>-<b>1</b>, and the electromyographic sensor may fit to user&#39;s skin and collect the electromyographic signal from the user during motion. For example, the upper garment device <b>130</b>-<b>1</b> may be provided with an electro-cardio sensor near the left pectoral muscle of the human body, and the electromyographic sensor may collect the electro-cardio signal of the user. Further, for example, the attitude sensor may be provided at a human body muscle location (e.g., gluteus maximus, lateral femoris, medial femoris, gastrocnemius, etc.) in the pant device <b>130</b>-<b>2</b>, and the attitude sensor may collect a user&#39;s attitude signal. In some embodiments, the <figure-callout id="130" label="wearable device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">wearable device</figure-callout> <b>130</b> may further provide feedback on the user&#39;s movement. For example, if the user&#39;s movement of a body part during motion does not meet the standard, the electromyographic sensor corresponding to that part may generate a stimulation signal (e.g., a current stimulation or a strike signal) to prompt the user.</div>
    </li> <li> <para-num num="[0080]"> </para-num> <div id="p-0081" num="0080" class="description-line">It should be noted that the <figure-callout id="130" label="wearable device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">wearable device</figure-callout> <b>130</b> is not limited to the upper garment device <b>130</b>-<b>1</b>, the pant device <b>130</b>-<b>2</b>, the wrist guard device <b>130</b>-<b>3</b>, and the shoe device <b>130</b>-<b>4</b> shown in <figref idrefs="DRAWINGS">FIG. <b>1</b> </figref>, but may further include a device that are applied to other devices that require motion monitoring, such as, for example, a helmet device, a knee pad, etc., which may not be limited herein, and any device that can use the motion monitoring method provided in the disclosure is within the scope of protection of the present disclosure.</div>
    </li> <li> <para-num num="[0081]"> </para-num> <div id="p-0082" num="0081" class="description-line">In some embodiments, the mobile <figure-callout id="140" label="terminal device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">terminal device</figure-callout> <b>140</b> may access information or data in the <figure-callout id="100" label="motion monitoring system" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">motion monitoring system</figure-callout> <b>100</b>. In some embodiments, the mobile <figure-callout id="140" label="terminal device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">terminal device</figure-callout> <b>140</b> may receive motion data processed by the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b>, and feed motion records back based on processed motion data. Exemplary feedback manners may include, but are not limited to, a voice prompt, an image prompt, a video display, a text prompt, etc. In some embodiments, the user may obtain movement records during an own movement through the mobile <figure-callout id="140" label="terminal device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">terminal device</figure-callout> <b>140</b>. For example, the mobile <figure-callout id="140" label="terminal device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">terminal device</figure-callout> <b>140</b> may be connected to the <figure-callout id="130" label="wearable device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">wearable device</figure-callout> <b>130</b> through the network <b>120</b> (e.g., the wired connection, the wireless connection), and the user may obtain the movement records during the user&#39;s movement through the mobile <figure-callout id="140" label="terminal device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">terminal device</figure-callout> <b>140</b>, which may be transmitted to the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b> through the mobile <figure-callout id="140" label="terminal device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">terminal device</figure-callout> <b>140</b>. In some embodiments, the mobile <figure-callout id="140" label="terminal device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">terminal device</figure-callout> <b>140</b> may include a mobile device <b>140</b>-<b>1</b>, a tablet <b>140</b>-<b>2</b>, a laptop <b>140</b>-<b>3</b>, or the like, or any combination thereof. In some embodiments, the mobile device <b>140</b>-<b>1</b> may include a cell phone, a smart home device, a smart mobility device, a virtual reality device, an augmented reality device, or the like, or any combination thereof. In some embodiments, the smart home device may include a control device of a smart appliance, a smart monitoring device, a smart TV, a smart camera, or the like, or any combination thereof. In some embodiments, the smart mobility device may include a smart phone, a personal digital assistant (PDA), a gaming device, a navigation device, a POS device, or the like, or any combination thereof. In some embodiments, a virtual reality device and/or an augmented reality device may include a virtual reality helmet, virtual reality glasses, a virtual reality eye-mask, an augmented reality helmet, an augmented reality glasses, and an augmented reality eye-mask, or the like, or any combination thereof.</div>
    </li> <li> <para-num num="[0082]"> </para-num> <div id="p-0083" num="0082" class="description-line">In some embodiments, the <figure-callout id="100" label="motion monitoring system" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">motion monitoring system</figure-callout> <b>100</b> may further include a database. The database may store the information (e.g., a threshold condition of an initially set, etc.) and/or the instruction (e.g., a feedback instruction). In some embodiments, the database may store the information obtained from the <figure-callout id="130" label="wearable device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">wearable device</figure-callout> <b>130</b> and/or the mobile <figure-callout id="140" label="terminal device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">terminal device</figure-callout> <b>140</b>. In some embodiments, the database may store the information and/or the instruction configured for the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b> to execute or use to perform the exemplary methods described in the present disclosure. In some embodiments, the database may include a mass storage, a removable memory, a volatile read-write memory (e.g., random access memory RAM), a read-only memory (ROM), or the like, or any combination thereof. In some embodiments, the database may be implemented on a cloud platform. For example, the cloud platform may include a private cloud, a public cloud, a hybrid cloud, a community cloud, a decentralized cloud, an internal cloud, or the like, or any combination thereof.</div>
    </li> <li> <para-num num="[0083]"> </para-num> <div id="p-0084" num="0083" class="description-line">In some embodiments, the database may be connected to the <figure-callout id="120" label="network" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">network</figure-callout> <b>120</b> to communicate with one or more components of the motion monitoring system <b>100</b> (e.g., the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b>, the <figure-callout id="130" label="wearable device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">wearable device</figure-callout> <b>130</b>, the mobile <figure-callout id="140" label="terminal device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">terminal device</figure-callout> <b>140</b>, etc.). The one or more components of the <figure-callout id="100" label="motion monitoring system" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">motion monitoring system</figure-callout> <b>100</b> may access information or instruction stored in the database through the <figure-callout id="120" label="network" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">network</figure-callout> <b>120</b>. In some embodiments, the database may be directly connected or communicate with one or more components of the motion monitoring system <b>100</b> (e.g., the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b>, the <figure-callout id="130" label="wearable device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">wearable device</figure-callout> <b>130</b>, the mobile terminal device <b>140</b>). In some embodiments, the database may be a part of the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b> </div>
    </li> <li> <para-num num="[0084]"> </para-num> <div id="p-0085" num="0084" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>2</b> </figref> is a schematic diagram illustrating exemplary hardware and/or software of a wearable device according to some embodiments of the present disclosure. As shown in <figref idrefs="DRAWINGS">FIG. <b>2</b> </figref>, the <figure-callout id="130" label="wearable device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">wearable device</figure-callout> <b>130</b> may include an obtaining <figure-callout id="210" label="module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">module</figure-callout> <b>210</b>, a processing module <b>220</b> (also referred to as a processor), a control module <b>230</b> (also referred to as a master, a MCU, a controller), a <figure-callout id="240" label="communication module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">communication module</figure-callout> <b>240</b>, a <figure-callout id="250" label="power supply module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">power supply module</figure-callout> <b>250</b>, and an input/<figure-callout id="260" label="output module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">output module</figure-callout> <b>260</b>.</div>
    </li> <li> <para-num num="[0085]"> </para-num> <div id="p-0086" num="0085" class="description-line">The obtaining <figure-callout id="210" label="module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">module</figure-callout> <b>210</b> may be configured to obtain a movement signal of a user during motion. In some embodiments, the obtaining <figure-callout id="210" label="module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">module</figure-callout> <b>210</b> may include a sensor unit. The sensor unit may be configured to obtain one or more movement signals while the user is in motion. In some embodiments, the sensor unit may include, but is not limited to, one or more electromyographic sensors, attitude sensors, cardiac sensors, respiration sensors, temperature sensors, humidity sensors, inertial sensors, blood oxygen saturation sensors, Hall sensors, piezoelectric sensors, rotation sensors, or the like. In some embodiments, the movement signal may include one or more electromyographic signals, attitude signals, cardiac signals, respiratory rates, temperature signals, humidity signals, etc. The sensor unit may be placed at different locations of the <figure-callout id="130" label="wearable device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">wearable device</figure-callout> <b>130</b> according to a type of a movement signal to be obtained. For example, in some embodiments, the electromyographic sensor (also referred to as an electrode element) may be placed at a human muscle location, and the electromyographic sensor may be configured to collect the electromyographic signal of the user during motion. The electromyographic signal and its corresponding feature information (e.g., frequency information, amplitude information, etc.) may reflect a state of muscle during a user&#39;s movement. The attitude sensor may be provided at different locations on a human body (e.g., locations of the <figure-callout id="130" label="wearable device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">wearable device</figure-callout> <b>130</b> corresponding to the torso, limbs, and joints), and the attitude sensor may be configured to capture the attitude signal of the user during the user&#39;s movement. The attitude signal and its corresponding feature information (e.g., an angular velocity direction, an angular velocity value, an acceleration value of an angular velocity, an angle, a displacement information, a stress, etc.) may reflect the attitude of the user&#39;s movement. The electromyographic sensor may be set at a location on the circumferential side of the human chest, and the electromyographic sensor may be configured to collect electro cardio data of the user during motion. The respiration sensor may be arranged on a circumferential side of the body&#39;s chest, and the respiration sensor may be configured to collect respiration data (e.g., a respiration rate, a respiration amplitude, etc.) from the user during motion. The temperature sensor may be configured to collect temperature data (e.g., a body surface temperature) of the user during motion. The humidity sensor may be configured to collect humidity data of an external environment of the user during motion.</div>
    </li> <li> <para-num num="[0086]"> </para-num> <div id="p-0087" num="0086" class="description-line">The <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> may process data from the obtaining <figure-callout id="210" label="module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">module</figure-callout> <b>210</b>, the <figure-callout id="230" label="control module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">control module</figure-callout> <b>230</b>, the <figure-callout id="240" label="communication module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">communication module</figure-callout> <b>240</b>, the <figure-callout id="250" label="power supply module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">power supply module</figure-callout> <b>250</b>, and/or the input/<figure-callout id="260" label="output module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">output module</figure-callout> <b>260</b>. For example, the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> may process the movement signal of the user during a process of motion from the obtaining <figure-callout id="210" label="module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">module</figure-callout> <b>210</b>. In some embodiments, the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> may pre-process the movement signal (e.g., the electromyographic signal, the attitude signal) obtained by the obtaining <figure-callout id="210" label="module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">module</figure-callout> <b>210</b>. For example, the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> may segment the electromyographic signal or the attitude signal of the user during motion. As another example, the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> may perform a pre-processing (e.g., a filtering processing, a signal correction processing) on the electromyographic signal of the user during motion to improve quality of the electromyographic signal. Further, for example, the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> may determine the feature information corresponding to the attitude signal based on a user&#39;s attitude signal during motion. In some embodiments, the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> may process an instruction or operation from an input/<figure-callout id="260" label="output module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">output module</figure-callout> <b>260</b>. In some embodiments, processed data may be stored in a memory or a hard disk. In some embodiments, the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> may transmit its processed data to one or more components in the <figure-callout id="100" label="motion monitoring system" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">motion monitoring system</figure-callout> <b>100</b> through the <figure-callout id="240" label="communication module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">communication module</figure-callout> <b>240</b> or the <figure-callout id="120" label="network" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">network</figure-callout> <b>120</b>. For example, the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> may send monitoring results of the user during motion to the <figure-callout id="230" label="control module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">control module</figure-callout> <b>230</b>, which may execute subsequent operations or instructions according to motion determination results.</div>
    </li> <li> <para-num num="[0087]"> </para-num> <div id="p-0088" num="0087" class="description-line">The <figure-callout id="230" label="control module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">control module</figure-callout> <b>230</b> may be connected to other modules in the <figure-callout id="130" label="wearable device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">wearable device</figure-callout> <b>130</b>. In some embodiments, the <figure-callout id="230" label="control module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">control module</figure-callout> <b>230</b> may control operation states of other modules (e.g., the <figure-callout id="240" label="communication module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">communication module</figure-callout> <b>240</b>, the <figure-callout id="250" label="power supply module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">power supply module</figure-callout> <b>250</b>, the input/output module <b>260</b>) in the <figure-callout id="130" label="wearable device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">wearable device</figure-callout> <b>130</b>. For example, the <figure-callout id="230" label="control module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">control module</figure-callout> <b>230</b> may control a power supply state (e.g., a normal mode, a power saving mode), a power supply time, or the like, of the <figure-callout id="250" label="power supply module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">power supply module</figure-callout> <b>250</b>. When the remaining power of the <figure-callout id="250" label="power supply module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">power supply module</figure-callout> <b>250</b> reaches a certain threshold (e.g., 10%) or less, the <figure-callout id="230" label="control module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">control module</figure-callout> <b>230</b> may control the <figure-callout id="250" label="power supply module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">power supply module</figure-callout> <b>250</b> to enter a power saving mode or send a prompt message about the replenishment of power. As another example, the <figure-callout id="230" label="control module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">control module</figure-callout> <b>230</b> may control the input/<figure-callout id="260" label="output module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">output module</figure-callout> <b>260</b> based on user&#39;s movement determination results, and further control the mobile <figure-callout id="140" label="terminal device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">terminal device</figure-callout> <b>140</b> to send feedback results of the user&#39;s movement. When there is a problem with the user&#39;s movement (e.g., movement not meeting the standard), the <figure-callout id="230" label="control module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">control module</figure-callout> <b>230</b> may control the input/<figure-callout id="260" label="output module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">output module</figure-callout> <b>260</b> to control the mobile <figure-callout id="140" label="terminal device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">terminal device</figure-callout> <b>140</b> to provide feedback to the user, allowing the user to understand own motion movement in real time and make some adjustments. In some embodiments, the <figure-callout id="230" label="control module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">control module</figure-callout> <b>230</b> may also control one or more sensors or other modules in the obtaining <figure-callout id="210" label="module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">module</figure-callout> <b>210</b> to provide feedback to the human body. For example, when a muscle of the user is exercising too strong during motion, the <figure-callout id="230" label="control module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">control module</figure-callout> <b>230</b> may control an electrode module at a location of the muscle to stimulate the user to prompt the user to adjust the movement in time.</div>
    </li> <li> <para-num num="[0088]"> </para-num> <div id="p-0089" num="0088" class="description-line">In some embodiments, the <figure-callout id="240" label="communication module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">communication module</figure-callout> <b>240</b> may be configured for an exchange of information or data. In some embodiments, the <figure-callout id="240" label="communication module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">communication module</figure-callout> <b>240</b> may be configured for communication between components (e.g., the obtaining <figure-callout id="210" label="module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">module</figure-callout> <b>210</b>, the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b>, the <figure-callout id="230" label="control module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">control module</figure-callout> <b>230</b>, the <figure-callout id="250" label="power supply module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">power supply module</figure-callout> <b>250</b>, the input/output module <b>260</b>) within a <figure-callout id="130" label="wearable device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">wearable device</figure-callout> <b>130</b>. For example, the obtaining <figure-callout id="210" label="module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">module</figure-callout> <b>210</b> may send a movement signal (e.g., the electromyographic signal, the attitude signal, etc.) to the <figure-callout id="240" label="communication module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">communication module</figure-callout> <b>240</b>, and the <figure-callout id="240" label="communication module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">communication module</figure-callout> <b>240</b> may send the movement signal to the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b>. For example, the <figure-callout id="240" label="communication module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">communication module</figure-callout> <b>240</b> may send state information (e.g., a switch state) of the <figure-callout id="130" label="wearable device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">wearable device</figure-callout> <b>130</b> to the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b>, and the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b> may monitor the <figure-callout id="130" label="wearable device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">wearable device</figure-callout> <b>130</b> based on the state information. The <figure-callout id="240" label="communication module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">communication module</figure-callout> <b>240</b> may employ wired, wireless, and hybrid wired/wireless technologies. The wired technology may be based on one or more combinations of fiber optic cables such as metallic cables, hybrid cables, fiber optic cables, etc. The wireless technology may include a Bluetooth (Bluetooth), a wireless network (Wi-Fi), a purple bee (ZigBee) a near field communication (NFC), a radio frequency identification (RFID), a cellular network (including GSM, CDMA, 3G, 4G, 5G, etc.), a cellular-based narrow band internet of things (NBIoT), etc. In some embodiments, the <figure-callout id="240" label="communication module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">communication module</figure-callout> <b>240</b> may use one or more coding methods to encode transmitted information, for example, the coding methods may include a phase coding, a non-zeroing coding, a differential Manchester coding, or the like. In some embodiments, the <figure-callout id="240" label="communication module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">communication module</figure-callout> <b>240</b> may select different transmission and encoding methods according to a type of data or a type of network to be transmitted. In some embodiments, the <figure-callout id="240" label="communication module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">communication module</figure-callout> <b>240</b> may include one or more communication interfaces for different communication methods. In some embodiments, illustrated other modules of the <figure-callout id="100" label="motion monitoring system" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">motion monitoring system</figure-callout> <b>100</b> may be dispersed on a plurality of devices, in this case, each of a plurality of other modules may each include one or <figure-callout id="240" label="more communication modules" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">more communication modules</figure-callout> <b>240</b> for an inter-module information transmission. In some embodiments, the <figure-callout id="240" label="communication module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">communication module</figure-callout> <b>240</b> may include a receiver and a transmitter. In other embodiments, the <figure-callout id="240" label="communication module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">communication module</figure-callout> <b>240</b> may be a transceiver.</div>
    </li> <li> <para-num num="[0089]"> </para-num> <div id="p-0090" num="0089" class="description-line">In some embodiments, the <figure-callout id="250" label="power supply module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">power supply module</figure-callout> <b>250</b> may provide power to other components in the motion monitoring system <b>100</b> (e.g., the obtaining <figure-callout id="210" label="module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">module</figure-callout> <b>210</b>, the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b>, the <figure-callout id="230" label="control module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">control module</figure-callout> <b>230</b>, the <figure-callout id="240" label="communication module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">communication module</figure-callout> <b>240</b>, the input/output module <b>260</b>). The <figure-callout id="250" label="power supply module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">power supply module</figure-callout> <b>250</b> may receive the control signal from the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> to control a power output of the <figure-callout id="130" label="wearable device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">wearable device</figure-callout> <b>130</b>. For example, if the <figure-callout id="130" label="wearable device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">wearable device</figure-callout> <b>130</b> does not receive any operation (e.g., no movement signal is detected by the obtaining module <b>210</b>) for a certain period (e.g., 1 s, 2 s, 3 s, or 4 s), the <figure-callout id="250" label="power supply module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">power supply module</figure-callout> <b>250</b> may supply power to the memory merely, putting the <figure-callout id="130" label="wearable device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">wearable device</figure-callout> <b>130</b> into a standby mode. For example, if the <figure-callout id="130" label="wearable device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">wearable device</figure-callout> <b>130</b> does not receive any operation (e.g., no movement signal is detected by the obtaining module <b>210</b>) for a certain period (e.g., 1 s, 2 s, 3 s, or 4 s), the <figure-callout id="250" label="power supply module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">power supply module</figure-callout> <b>250</b> may disconnect power to other components and the data in the <figure-callout id="100" label="motion monitoring system" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">motion monitoring system</figure-callout> <b>100</b> may be transmitted to a hard disk, putting the <figure-callout id="130" label="wearable device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">wearable device</figure-callout> <b>130</b> into the standby mode or a sleeping mode. In some embodiments, the <figure-callout id="250" label="power supply module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">power supply module</figure-callout> <b>250</b> may include at least one battery. The battery may include one or more combinations of a dry cell, a lead battery, a lithium battery, a solar cell, a wind energy generation battery, a mechanical energy generation battery, a thermal energy generation battery, etc. Light energy may be converted into electrical energy by the solar battery and stored in the <figure-callout id="250" label="power supply module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">power supply module</figure-callout> <b>250</b>. Wind energy may be converted into the electrical energy by the wind power generation battery and stored in the <figure-callout id="250" label="power supply module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">power supply module</figure-callout> <b>250</b>. Mechanical energy may be converted into the electrical energy by the mechanical energy generation battery and stored in the <figure-callout id="250" label="power supply module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">power supply module</figure-callout> <b>250</b>. The solar cell may include a silicon solar cell, a thin film solar cell, a nanocrystalline chemical solar cell, a fuel sensitized solar cell, a plastic solar cell, etc. The solar cell may be distributed on the <figure-callout id="130" label="wearable device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">wearable device</figure-callout> <b>130</b> in a form of panel. A user&#39;s body temperature may be converted into the electrical energy by the thermal power cell and stored in the <figure-callout id="250" label="power supply module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">power supply module</figure-callout> <b>250</b>. In some embodiments, the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> may send the control signal to the <figure-callout id="250" label="power supply module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">power supply module</figure-callout> <b>250</b> when the <figure-callout id="250" label="power supply module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">power supply module</figure-callout> <b>250</b> is less than a power threshold (e.g., 10% of the total power). The control signal may include information that the <figure-callout id="250" label="power supply module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">power supply module</figure-callout> <b>250</b> is low on power. In some embodiments, the <figure-callout id="250" label="power supply module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">power supply module</figure-callout> <b>250</b> may include a backup power source. In some embodiments, the <figure-callout id="250" label="power supply module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">power supply module</figure-callout> <b>250</b> may further include a charging interface. For example, the <figure-callout id="250" label="power supply module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">power supply module</figure-callout> <b>250</b> may be temporarily charged by using an electronic device (e.g., a cell phone, a tablet computer) or a rechargeable battery carried by the user to temporarily charge the <figure-callout id="250" label="power supply module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">power supply module</figure-callout> <b>250</b> in an emergency (e.g., the <figure-callout id="250" label="power supply module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">power supply module</figure-callout> <b>250</b> is at zero power and an external power system is out of power).</div>
    </li> <li> <para-num num="[0090]"> </para-num> <div id="p-0091" num="0090" class="description-line">The input/<figure-callout id="260" label="output module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">output module</figure-callout> <b>260</b> may obtain, transmit, and send a signal. The input/<figure-callout id="260" label="output module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">output module</figure-callout> <b>260</b> may connect to or communicate with other components in the <figure-callout id="100" label="motion monitoring system" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">motion monitoring system</figure-callout> <b>100</b>. The other components in the <figure-callout id="100" label="motion monitoring system" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">motion monitoring system</figure-callout> <b>100</b> may be connected or communicated through the input/<figure-callout id="260" label="output module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">output module</figure-callout> <b>260</b>. The input/<figure-callout id="260" label="output module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">output module</figure-callout> <b>260</b> may be a wired USB interface, a serial communication interface, a parallel communication port, or a wireless Bluetooth, an infrared-frequency identification, a radio-frequency identification (RFID), a WLAN authentication and privacy infrastructure (WAPI), a general packet radio service (GPRS), a code division multiple access (CDMA), or any combination thereof. In some embodiments, the input/<figure-callout id="260" label="output module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">output module</figure-callout> <b>260</b> may be connected to the <figure-callout id="120" label="network" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">network</figure-callout> <b>120</b> and obtain the information through the <figure-callout id="120" label="network" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">network</figure-callout> <b>120</b>. For example, the input/<figure-callout id="260" label="output module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">output module</figure-callout> <b>260</b> may obtain the movement signal from the obtaining <figure-callout id="210" label="module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">module</figure-callout> <b>210</b> of the user during motion and output user movement information through the <figure-callout id="120" label="network" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">network</figure-callout> <b>120</b> or the <figure-callout id="240" label="communication module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">communication module</figure-callout> <b>240</b>. In some embodiments, the input/<figure-callout id="260" label="output module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">output module</figure-callout> <b>260</b> may include VCC, GND, RS-232, RS-485 (e.g., RS485-A, RS485-B), a universal network interface, or the like, or any combination thereof. In some embodiments, the input/<figure-callout id="260" label="output module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">output module</figure-callout> <b>260</b> may transmit obtained user motion information to the obtaining <figure-callout id="210" label="module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">module</figure-callout> <b>210</b> through the <figure-callout id="120" label="network" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">network</figure-callout> <b>120</b>. The encoding methods may include a phase coding, a non-zeroing system encoding, a differential Manchester encoding, or the like, or any combination thereof.</div>
    </li> <li> <para-num num="[0091]"> </para-num> <div id="p-0092" num="0091" class="description-line">It should be understood that the system and its modules shown in <figref idrefs="DRAWINGS">FIG. <b>2</b> </figref> may be implemented by using a plurality of methods. For example, in some embodiments, the system and its modules may be implemented by hardware, software, or a combination of software and hardware. In particular, a hardware portion may be implemented by using dedicated logic. A software portion may be stored in memory and executed by an appropriate instruction execution system, such as a microprocessor or dedicated design hardware. Those skilled in the art may understand that the above methods and the system can be implemented by using a computer executable instruction and/or contained in a processor control code, for example, such encoding provided on a carrier medium such as a disk, a CD or a DVD-ROM, a programmable memory such as a read-only memory (firmware), or a data carrier such as an optical or electronic signal carrier. The system and its modules in one or more embodiments of the present disclosure may be implemented by a hardware circuit, e.g., a ultra-large scale integrated circuit or a gate array, a semiconductor such as a logic chip, a transistor, etc., or a programmable hardcore device such as a field programmable gate array, a programmable logic device, etc., implemented by software executed by various types of processors, or implemented by a combination of above hardware circuit and software (e.g., firmware).</div>
    </li> <li> <para-num num="[0092]"> </para-num> <div id="p-0093" num="0092" class="description-line">It should be noted that the above description of the motion monitoring system and its modules is merely for descriptive convenience and does not limit one or more embodiments of the present disclosure within the scope of the embodiments. Understandably, for those skilled in the art, after understanding a principle of the system, they may make any combination of the modules, or to form a sub-system to connect with other modules, or to omit one or more modules thereof, without departing from this principle. For example, the obtaining <figure-callout id="210" label="module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">module</figure-callout> <b>210</b> and the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> may be one module that may have a function of obtaining and processing the user movement signal. As another example, the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> may not be provided in the <figure-callout id="130" label="wearable device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">wearable device</figure-callout> <b>130</b>, but integrated in the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b>. Variations such as these are within the scope of protection of one or more embodiments of the present disclosure.</div>
    </li> <li> <para-num num="[0093]"> </para-num> <div id="p-0094" num="0093" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>3</b> </figref> is a schematic diagram illustrating exemplary hardware and/or software of a computing device according to some embodiments of the present disclosure. In some embodiments, the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b> and/or the mobile <figure-callout id="140" label="terminal device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">terminal device</figure-callout> <b>140</b> may be implemented on a <figure-callout id="300" label="computing device" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">computing device</figure-callout> <b>300</b>. As shown in <figref idrefs="DRAWINGS">FIG. <b>3</b> </figref>, the <figure-callout id="300" label="computing device" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">computing device</figure-callout> <b>300</b> may include an <figure-callout id="310" label="internal communication bus" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">internal communication bus</figure-callout> <b>310</b>, a <figure-callout id="320" label="processor" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processor</figure-callout> <b>320</b>, a read-<figure-callout id="330" label="only memory" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">only memory</figure-callout> <b>330</b>, a <figure-callout id="340" label="random memory" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">random memory</figure-callout> <b>340</b>, a <figure-callout id="350" label="communication port" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">communication port</figure-callout> <b>350</b>, an input/<figure-callout id="360" label="output interface" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">output interface</figure-callout> <b>360</b>, a <figure-callout id="370" label="hard disk" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">hard disk</figure-callout> <b>370</b>, and a <figure-callout id="380" label="user interface" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">user interface</figure-callout> <b>380</b>.</div>
    </li> <li> <para-num num="[0094]"> </para-num> <div id="p-0095" num="0094" class="description-line">The <figure-callout id="310" label="internal communication bus" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">internal communication bus</figure-callout> <b>310</b> may enable data communication between components in the <figure-callout id="300" label="computing device" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">computing device</figure-callout> <b>300</b>. For example, the <figure-callout id="320" label="processor" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processor</figure-callout> <b>320</b> may send data to other hardware such as a memory or the input/<figure-callout id="360" label="output interface" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">output interface</figure-callout> <b>360</b> through the <figure-callout id="310" label="internal communication bus" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">internal communication bus</figure-callout> <b>310</b>. In some embodiments, the <figure-callout id="310" label="internal communication bus" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">internal communication bus</figure-callout> <b>310</b> may be an industry standard architecture (ISA) bus, an extended industry standard architecture (EISA) bus, a video electronics standard architecture (VESA) bus, a peripheral component interconnect (PCI) bus, etc. In some embodiments, the <figure-callout id="310" label="internal communication bus" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">internal communication bus</figure-callout> <b>310</b> may be configured to connect various modules (e.g., the obtaining <figure-callout id="210" label="module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">module</figure-callout> <b>210</b>, the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b>, the <figure-callout id="230" label="control module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">control module</figure-callout> <b>230</b>, the <figure-callout id="240" label="communication module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">communication module</figure-callout> <b>240</b>, the input and output module <b>260</b>) of the <figure-callout id="100" label="motion monitoring system" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">motion monitoring system</figure-callout> <b>100</b> shown in <figref idrefs="DRAWINGS">FIG. <b>1</b> </figref>.</div>
    </li> <li> <para-num num="[0095]"> </para-num> <div id="p-0096" num="0095" class="description-line">The <figure-callout id="320" label="processor" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processor</figure-callout> <b>320</b> may execute a computing instruction (a program code) and perform functions of the <figure-callout id="100" label="motion monitoring system" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">motion monitoring system</figure-callout> <b>100</b> described in the present disclosure. The computing instruction may include a program, an object, a component, a data structure, a process, a module, and a function (the function may refer to a specific function described in the present disclosure). For example, <figure-callout id="320" label="processor" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processor</figure-callout> <b>320</b> may process the obtained movement signal (e.g., the electromyographic signal, the attitude signal) of a user during motion from the <figure-callout id="130" label="wearable device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">wearable device</figure-callout> <b>130</b> or/and the mobile <figure-callout id="140" label="terminal device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">terminal device</figure-callout> <b>140</b> of the <figure-callout id="100" label="motion monitoring system" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">motion monitoring system</figure-callout> <b>100</b>, and monitor the movement of the user during motion based on the movement signal during motion. In some embodiments, the <figure-callout id="320" label="processor" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processor</figure-callout> <b>320</b> may include a microcontroller, a microprocessor, a reduced instruction set computer (RISC), an application-specific integrated circuit (ASIC), an application-specific instruction-set processor (ASIP), a central processing unit (CPU), a graphics processing unit (GPU), a physical processing unit (PPU), a microcontroller unit, a digital signal processor (DSP), a field Programmable Gate Array (FPGA), an advanced RISC machine (ARM), a programmable logic device, and any circuit and processor capable of performing one or more functions, or any combination thereof. For illustrative purposes only, the <figure-callout id="300" label="computing device" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">computing device</figure-callout> <b>300</b> in <figref idrefs="DRAWINGS">FIG. <b>3</b> </figref> depicts only one processor, but it should be noted that the <figure-callout id="300" label="computing device" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">computing device</figure-callout> <b>300</b> in the present disclosure may further include a plurality of processors.</div>
    </li> <li> <para-num num="[0096]"> </para-num> <div id="p-0097" num="0096" class="description-line">A memory of the computing device <b>300</b> (e.g., a read-only memory (ROM) <b>330</b>, a random access memory (RAM) <b>340</b>, a <figure-callout id="370" label="hard disk" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">hard disk</figure-callout> <b>370</b>, etc.) may store data/information obtained from any other components of the <figure-callout id="100" label="motion monitoring system" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">motion monitoring system</figure-callout> <b>100</b>. In some embodiments, the memory of the <figure-callout id="300" label="computing device" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">computing device</figure-callout> <b>300</b> may be located in the <figure-callout id="130" label="wearable device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">wearable device</figure-callout> <b>130</b> or the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b>. Exemplary ROM may include a mask ROM (MROM), a programmable ROM (PROM), an erasable programmable ROM (PEROM), an electrically erasable programmable ROM (EEPROM), a compact disk ROM (CD-ROM), a digital versatile disk ROM, etc. Exemplary RAM may include a dynamic RAM (DRAM), a double-rate synchronous dynamic RAM (DDR SDRAM), a static RAM (SRAM), a thyristor RAM (T-RAM), a zero-capacitor RAM (Z-RAM), etc.</div>
    </li> <li> <para-num num="[0097]"> </para-num> <div id="p-0098" num="0097" class="description-line">The input/<figure-callout id="360" label="output interface" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">output interface</figure-callout> <b>360</b> may input or output signals, data, or information. In some embodiments, the input/<figure-callout id="360" label="output interface" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">output interface</figure-callout> <b>360</b> may enable a user to interact with the <figure-callout id="100" label="motion monitoring system" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">motion monitoring system</figure-callout> <b>100</b>. For example, the input/<figure-callout id="360" label="output interface" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">output interface</figure-callout> <b>360</b> may include the <figure-callout id="240" label="communication module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">communication module</figure-callout> <b>240</b> to enable the communication function of the <figure-callout id="100" label="motion monitoring system" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">motion monitoring system</figure-callout> <b>100</b>. In some embodiments, the input/<figure-callout id="360" label="output interface" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">output interface</figure-callout> <b>360</b> may include an input device and an output device. Exemplary input devices may include a keyboard, a mouse, a touch screen, a microphone, or the like, or any combination thereof. Exemplary output devices may include a display device, a loudspeaker, a printer, a projector, or the like, or any combination thereof. Example display devices may include a liquid crystal display (LCD), a light-emitting diode (LED)-based display, a flat panel display, a curved display, a television device, a cathode ray tubes (CRT), or the like, or any combination thereof. The <figure-callout id="350" label="communication port" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">communication port</figure-callout> <b>350</b> may be connected to a network for data communication. Connection may be a wired connection, a wireless connection, or a combination thereof. The wired connection may include a cable, a fiber optic cable, a telephone line, or the like, or any combination thereof. The wireless connection may include Bluetooth, Wi-Fi, WiMAX, WLAN, ZigBee, a mobile network (e.g., 3G, 4G, or 5G, etc.), or the like, or any combination thereof. In some embodiments, the <figure-callout id="350" label="communication port" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">communication port</figure-callout> <b>350</b> may be a standard port, such as RS232, RS485, etc. In some embodiments, the <figure-callout id="350" label="communication port" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">communication port</figure-callout> <b>350</b> may be a specially designed port.</div>
    </li> <li> <para-num num="[0098]"> </para-num> <div id="p-0099" num="0098" class="description-line">The <figure-callout id="370" label="hard disk" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">hard disk</figure-callout> <b>370</b> may be configured to store information and data generated by or received from the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b>. For example, the <figure-callout id="370" label="hard disk" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">hard disk</figure-callout> <b>370</b> may store confirmation information of a user. In some embodiments, the <figure-callout id="370" label="hard disk" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">hard disk</figure-callout> <b>370</b> may include a hard disk drive (HDD), a solid-state drive (SSD), or a hybrid hard disk (HHD), etc. In some embodiments, the <figure-callout id="370" label="hard disk" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">hard disk</figure-callout> <b>370</b> may be provided in the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b> or in the <figure-callout id="130" label="wearable device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">wearable device</figure-callout> <b>130</b>. The <figure-callout id="380" label="user interface" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">user interface</figure-callout> <b>380</b> may enable an interact and information exchange between the <figure-callout id="300" label="computing device" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">computing device</figure-callout> <b>300</b> and the user. In some embodiments, the <figure-callout id="380" label="user interface" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">user interface</figure-callout> <b>380</b> may be configured to present motion recordings generated by the <figure-callout id="100" label="motion monitoring system" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">motion monitoring system</figure-callout> <b>100</b> to the user. In some embodiments, the <figure-callout id="380" label="user interface" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">user interface</figure-callout> <b>380</b> may include a physical display such as a display with speakers, an LCD display, an LED display, an OLED display, an electronic ink display (E-Ink), etc.</div>
    </li> <li> <para-num num="[0099]"> </para-num> <div id="p-0100" num="0099" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>4</b> </figref> is a structure diagram of an exemplary wearable device according to some embodiments of the present disclosure. To further describe the wearable device, an upper garment is illustrated as an example, as shown in <figref idrefs="DRAWINGS">FIG. <b>4</b> </figref>. The <figure-callout id="400" label="wearable device" filenames="US20230210402A1-20230706-D00003.png" state="{{state}}">wearable device</figure-callout> <b>400</b> may include an <figure-callout id="410" label="upper garment" filenames="US20230210402A1-20230706-D00003.png" state="{{state}}">upper garment</figure-callout> <b>410</b>. The <figure-callout id="410" label="upper garment" filenames="US20230210402A1-20230706-D00003.png" state="{{state}}">upper garment</figure-callout> <b>410</b> may include an <figure-callout id="4110" label="upper garment substrate" filenames="US20230210402A1-20230706-D00003.png" state="{{state}}">upper garment substrate</figure-callout> <b>4110</b>, at least one upper <figure-callout id="4120" label="garment processing module" filenames="US20230210402A1-20230706-D00003.png" state="{{state}}">garment processing module</figure-callout> <b>4120</b>, at least one upper <figure-callout id="4130" label="garment feedback module" filenames="US20230210402A1-20230706-D00003.png" state="{{state}}">garment feedback module</figure-callout> <b>4130</b>, at least one upper <figure-callout id="4140" label="garment obtaining module" filenames="US20230210402A1-20230706-D00003.png" state="{{state}}">garment obtaining module</figure-callout> <b>4140</b>, etc. The <figure-callout id="4110" label="upper garment substrate" filenames="US20230210402A1-20230706-D00003.png" state="{{state}}">upper garment substrate</figure-callout> <b>4110</b> may refer to clothe worn on an upper body of a human body. In some embodiments, the <figure-callout id="4110" label="upper garment substrate" filenames="US20230210402A1-20230706-D00003.png" state="{{state}}">upper garment substrate</figure-callout> <b>4110</b> may include a short sleeve T-shirt, a long sleeve T-shirt, a shirt, a jacket, etc. The at least one upper <figure-callout id="4120" label="garment processing module" filenames="US20230210402A1-20230706-D00003.png" state="{{state}}">garment processing module</figure-callout> <b>4120</b>, the at least one upper <figure-callout id="4140" label="garment obtaining module" filenames="US20230210402A1-20230706-D00003.png" state="{{state}}">garment obtaining module</figure-callout> <b>4140</b> may be located in areas of the <figure-callout id="4110" label="upper garment substrate" filenames="US20230210402A1-20230706-D00003.png" state="{{state}}">upper garment substrate</figure-callout> <b>4110</b> that fit to different parts of the human body. The at least one upper <figure-callout id="4130" label="garment feedback module" filenames="US20230210402A1-20230706-D00003.png" state="{{state}}">garment feedback module</figure-callout> <b>4130</b> may be located at any location on the <figure-callout id="4110" label="upper garment substrate" filenames="US20230210402A1-20230706-D00003.png" state="{{state}}">upper garment substrate</figure-callout> <b>4110</b>, and the at least one upper <figure-callout id="4130" label="garment feedback module" filenames="US20230210402A1-20230706-D00003.png" state="{{state}}">garment feedback module</figure-callout> <b>4130</b> may be configured to provide feedback on information about a user&#39;s upper body movement state. Exemplary feedback manners may include, but are not limited to, a voice prompt, a text prompt, a pressure prompt, an electrical stimulation, etc. In some embodiments, the at least one upper <figure-callout id="4140" label="garment obtaining module" filenames="US20230210402A1-20230706-D00003.png" state="{{state}}">garment obtaining module</figure-callout> <b>4140</b> may include, but is not limited to, one or more of an attitude sensor, an electro-cardio sensor, an electromyographic sensor, a temperature sensor, a humidity sensor, an inertial sensor, an acid-base sensor, an acoustic transducer, etc. The sensor(s) in the upper <figure-callout id="4140" label="garment obtaining module" filenames="US20230210402A1-20230706-D00003.png" state="{{state}}">garment obtaining module</figure-callout> <b>4140</b> may be placed at different locations on user&#39;s body according to a signal to be measured. For example, when the attitude sensor is configured to obtain the attitude signal of a user during motion, the attitude sensor can be placed in the <figure-callout id="4110" label="upper garment substrate" filenames="US20230210402A1-20230706-D00003.png" state="{{state}}">upper garment substrate</figure-callout> <b>4110</b> at a location corresponding to the human torso, arms, and joints. As another example, when the electromyographic sensor is configured to obtain the electromyographic signal of the user during motion, the electromyographic sensor may be located near the muscles to be measured. In some embodiments, the attitude sensor may include, but is not limited to, an acceleration triaxial sensor, an angular velocity triaxial sensor, a magnetic sensor, or the like, or any combination thereof. For example, an attitude sensor may include an acceleration triaxial sensor, an angular velocity triaxial sensor. In some embodiments, an attitude sensor may further include a strain gauge sensor. A strain gauge sensor may be a sensor based on strain generated by deformation of an object to be measured caused by a force. In some embodiments, the strain gauge sensor may include, but is not limited to, one or more of a strain-gauge force sensor, a strain-gauge pressure sensor, a strain-gauge torque sensor, a strain-gauge displacement sensor, a strain-gauge acceleration sensor, etc. For example, the strain gauge sensor may be arranged at a joint location of the user, and a bending angle and a bending direction at the user&#39;s joint can be obtained based on the resistance in the strain gauge sensor that varies with a stretch length at the joint. It should be understood that the <figure-callout id="410" label="upper garment" filenames="US20230210402A1-20230706-D00003.png" state="{{state}}">upper garment</figure-callout> <b>410</b> may include other modules, such as a power supply module, a communication module, an input/output module, etc., in addition to the <figure-callout id="4110" label="upper garment substrate" filenames="US20230210402A1-20230706-D00003.png" state="{{state}}">upper garment substrate</figure-callout> <b>4110</b>, the upper <figure-callout id="4120" label="garment processing module" filenames="US20230210402A1-20230706-D00003.png" state="{{state}}">garment processing module</figure-callout> <b>4120</b>, the upper <figure-callout id="4130" label="garment feedback module" filenames="US20230210402A1-20230706-D00003.png" state="{{state}}">garment feedback module</figure-callout> <b>4130</b>, and the upper <figure-callout id="4140" label="garment obtaining module" filenames="US20230210402A1-20230706-D00003.png" state="{{state}}">garment obtaining module</figure-callout> <b>4140</b> described above. The upper <figure-callout id="4120" label="garment processing module" filenames="US20230210402A1-20230706-D00003.png" state="{{state}}">garment processing module</figure-callout> <b>4120</b> may be similar to the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> shown in <figref idrefs="DRAWINGS">FIG. <b>2</b> </figref>, and the upper <figure-callout id="4140" label="garment obtaining module" filenames="US20230210402A1-20230706-D00003.png" state="{{state}}">garment obtaining module</figure-callout> <b>4140</b> may be similar to the obtaining <figure-callout id="210" label="module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">module</figure-callout> <b>210</b> shown in <figref idrefs="DRAWINGS">FIG. <b>2</b> </figref>. Specific descriptions regarding various modules in the <figure-callout id="410" label="upper garment" filenames="US20230210402A1-20230706-D00003.png" state="{{state}}">upper garment</figure-callout> <b>410</b> may be found in <figref idrefs="DRAWINGS">FIG. <b>2</b> </figref> and its relevant descriptions of the present disclosure, which may not be repeated herein.</div>
    </li> <li> <para-num num="[0100]"> </para-num> <div id="p-0101" num="0100" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>5</b> </figref> is a flowchart illustrating an exemplary motion monitoring method according to some embodiments of the present disclosure. As shown in <figref idrefs="DRAWINGS">FIG. <b>5</b> </figref>, <figure-callout id="500" label="process" filenames="US20230210402A1-20230706-D00004.png" state="{{state}}">process</figure-callout> <b>500</b> may include the following steps.</div>
    </li> <li> <para-num num="[0101]"> </para-num> <div id="p-0102" num="0101" class="description-line">In <figure-callout id="510" label="step" filenames="US20230210402A1-20230706-D00004.png" state="{{state}}">step</figure-callout> <b>510</b>, a movement signal of a user during motion may be obtained.</div>
    </li> <li> <para-num num="[0102]"> </para-num> <div id="p-0103" num="0102" class="description-line">In some embodiments, the <figure-callout id="510" label="step" filenames="US20230210402A1-20230706-D00004.png" state="{{state}}">step</figure-callout> <b>510</b> may be performed by the obtaining <figure-callout id="210" label="module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">module</figure-callout> <b>210</b>. The movement signal refers to human body parameter information of the user during motion. In some embodiments, the human body parameter information may include, but is not limited to, one or more of an electromyographic signal, an attitude signal, an electro-cardio signal, a temperature signal, a humidity signal, a blood oxygen concentration, a respiration rate, etc. In some embodiments, an electromyographic sensor in the obtaining <figure-callout id="210" label="module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">module</figure-callout> <b>210</b> may collect the electromyographic signal of the user during motion. For example, when the user performs a seated chest press, the electromyographic sensors in a wearable device corresponding to human pectoral muscles, latissimus dorsi, etc., may obtain the electromyographic signals of corresponding muscle positions of the user. As another example, when a user performs a deep squat, the electromyographic sensors in the wearable device corresponding to gluteus maximus and quadriceps may collect the electromyographic signals of the corresponding muscle positions. As another example, when the user is running, the electromyographic sensors in the wearable device corresponding to the gastrocnemius muscle and other positions may obtain the electromyographic signals of the corresponding muscle positions. In some embodiments, the attitude sensor in the obtaining <figure-callout id="210" label="module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">module</figure-callout> <b>210</b> may obtain an attitude signal of the user during motion. For example, when the user performs a barbell bench press, the attitude sensor in the wearable device corresponding to the human triceps, etc., may obtain the attitude signal of the triceps, etc. For example, when the user performs a dumbbell flyover, the attitude sensor set at a position such as a human deltoid muscle may obtain the attitude signal of the corresponding position. In some embodiments, a plurality of attitude sensors may obtain attitude signals of a plurality of portions of the user during motion, and the attitude signals of the plurality of portions may reflect a relative movement between different parts of the body. For example, an attitude signal at an arm and an attitude signal at a torso may reflect a movement condition of the arm relative to the torso. In some embodiments, the attitude signal may be associated with a type of the attitude sensor. For example, when the attitude sensor is an angular velocity tri-axis sensor, an obtained attitude signal may be angular velocity information. As another example, when the attitude sensor is the angular velocity tri-axis sensor and an acceleration tri-axis sensor, the obtained attitude signal may be the angular velocity information and acceleration information. For example, when the attitude sensor is a strain gauge sensor, the strain gauge sensor may be arranged at a user&#39;s joint position, by measuring the resistance in the strain gauge sensor that varies with the stretch length, the obtained attitude signal may be displacement information, stress, etc., and a bending angle and a bending direction at the user&#39;s joint may be represented through these attitude signals. It should be noted that the parameter information configured to reflect the relative motion of the user&#39;s body may be feature information corresponding to the attitude signal, which may be obtained by using different types of attitude sensors according to the type of the feature information.</div>
    </li> <li> <para-num num="[0103]"> </para-num> <div id="p-0104" num="0103" class="description-line">In some embodiments, the movement signal may include the electromyographic signal and the attitude signal of a particular part of the user&#39;s body. The electromyographic signal and the attitude signal may reflect a movement state of the particular part of the user&#39;s body from different angles. In simple terms, the attitude signal of a specific part of the user&#39;s body may reflect a type of movement, a movement amplitude, a movement frequency, etc., of the specific part. The electromyographic signal may reflect a muscle state of the particular part during motion. In some embodiments, by measuring the electromyographic signal and/or the attitude signal of the same body part, whether the movement of that part is standard may be better assessed.</div>
    </li> <li> <para-num num="[0104]"> </para-num> <div id="p-0105" num="0104" class="description-line">In <figure-callout id="520" label="step" filenames="US20230210402A1-20230706-D00004.png" state="{{state}}">step</figure-callout> <b>520</b>, a movement of the user during motion may be monitored based at least on feature information corresponding to the electromyographic signal or feature information corresponding to the attitude signal.</div>
    </li> <li> <para-num num="[0105]"> </para-num> <div id="p-0106" num="0105" class="description-line">In some embodiments, the <figure-callout id="520" label="step" filenames="US20230210402A1-20230706-D00004.png" state="{{state}}">step</figure-callout> <b>520</b> may be performed by the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> and/or the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b>. In some embodiments, the feature information corresponding to the electromyographic signal may include, but is not limited to, one or more of frequency information, amplitude information, etc. The feature information corresponding to the attitude signal may be parameter information configured to represent a relative motion of the user&#39;s body. In some embodiments, the feature information corresponding to the attitude signal may include, but is not limited to, one or more of an angular velocity direction, an angular velocity value, an acceleration value of angular velocity, etc. In some embodiments, the feature information corresponding to the attitude signal may further include an angle, displacement information (e.g., a stretch length in a strain gauge sensor), a stress, etc. For example, when the attitude sensor is a strain gauge sensor, the strain gauge sensor may be set at the user&#39;s joint position, and by measuring the resistance in the strain gauge sensor that varies with the stretch length, the obtained attitude signal may be the displacement information, the stress, etc., which may represent the bending angle and the bending direction at the user&#39;s joint. In some embodiments, the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> and/or the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b> may extract the feature information corresponding to the electromyographic signal (e.g., frequency information, amplitude information) or the feature information corresponding to the attitude signal (e.g., the angular velocity direction, the angular velocity value, the acceleration value of angular velocity, the angle, the displacement information, the stress, etc.), and monitor the movement of the user during motion based on the feature information corresponding to the electromyographic signal or the feature information corresponding to the attitude signal. The monitoring of the movement during motion may include user&#39;s movement-related information. In some embodiments, movement-related information may include one or more of a movement type, a movement quantity, a movement quality (e.g., whether the movement meets a standard), a movement time, etc. The movement type may be a fitness movement performed by the user during motion. In some embodiments, the movement type may include, but is not limited to, one or more of seated chest presses, deep squats, hard pulls, plank supports, running, swimming, etc. The movement quantity may refer to the number of times the user performs the movement during motion. For example, if the user performs 10 seated chest clamps during motion, 10 may be the movement quantity. The movement quality may refer to the standard degree of the fitness movement performed by the user related to a standard fitness movement. For example, when the user performs a deep squat movement, the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b> may determine a movement type of the user based on the feature information corresponding to the movement signal (the electromyographic signal and the attitude signal) of a particular specific muscle location (gluteus maximus, quadriceps, etc.), and determine the movement quality of the user during performing the deep squat movement based on the movement signal. The movement time may be the time corresponding to one or more movement types of the user or the total time of the movement process. Detailed descriptions for monitoring the movement of the user during motion based on the feature information corresponding to the electromyographic signal and/or the feature information corresponding to the attitude signal may be found in <figref idrefs="DRAWINGS">FIG. <b>6</b> </figref> and its relevant descriptions of the present disclosure.</div>
    </li> <li> <para-num num="[0106]"> </para-num> <div id="p-0107" num="0106" class="description-line">In some embodiments, the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b> may use one or more movement recognition models to recognize and monitor the movement of the user during motion. For example, the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b> may input the feature information corresponding to the electromyographic signal and/or the feature information corresponding to the attitude signal into the movement recognition model, and the movement recognition model may output information related to the user&#39;s movement. In some embodiments, the movement recognition model may include different types of movement recognition models, for example, a model configured to recognize the movement type of the user, or a model configured to identify the movement quality of the user, etc.</div>
    </li> <li> <para-num num="[0107]"> </para-num> <div id="p-0108" num="0107" class="description-line">It should be noted that the above <figure-callout id="500" label="description regarding process" filenames="US20230210402A1-20230706-D00004.png" state="{{state}}">description regarding process</figure-callout> <b>500</b> is for exemplary and illustrative purpose only, and does not limit the scope of application of the present disclosure. For those skilled in the art, various amendments and changes can be made to the <figure-callout id="500" label="process" filenames="US20230210402A1-20230706-D00004.png" state="{{state}}">process</figure-callout> <b>500</b> under the guidance of the present disclosure. However, these amendments and changes are still within the scope of the present disclosure. For example, the extraction of the feature information corresponding to the electromyographic signal or the feature information corresponding to the attitude signal in <figure-callout id="520" label="step" filenames="US20230210402A1-20230706-D00004.png" state="{{state}}">step</figure-callout> <b>520</b> may be performed by the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b>, or in some embodiments, by the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b>. As another example, the user&#39;s movement signal may not be limited to the above electromyographic signal, the attitude signal, the electro-cardio signal, the temperature signal, the humidity signal, the blood oxygen concentration, the respiration rate, but may also include other human physiological parameter signals. The physiological parameter signals involved in human movement may be all considered as the movement signal in the embodiments of the present disclosure.</div>
    </li> <li> <para-num num="[0108]"> </para-num> <div id="p-0109" num="0108" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>6</b> </figref> is a flowchart of an exemplary process for monitoring a movement of a user during motion according to some embodiments of the present disclosure. As shown in <figref idrefs="DRAWINGS">FIG. <b>6</b> </figref>, <figure-callout id="600" label="process" filenames="US20230210402A1-20230706-D00004.png" state="{{state}}">process</figure-callout> <b>600</b> may include the following steps.</div>
    </li> <li> <para-num num="[0109]"> </para-num> <div id="p-0110" num="0109" class="description-line">In <figure-callout id="610" label="step" filenames="US20230210402A1-20230706-D00004.png" state="{{state}}">step</figure-callout> <b>610</b>, the movement signal may be segmented based on the feature information corresponding to the electromyographic signal or the feature information corresponding to the attitude signal.</div>
    </li> <li> <para-num num="[0110]"> </para-num> <div id="p-0111" num="0110" class="description-line">In some embodiments, the step may be performed by the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> and/or the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b>. The process of obtaining the movement signal (e.g., the electromyographic signal, the attitude signal) of the user during motion may be continuous, and a movement of the user during motion may be a combination of a plurality of sets of movement or a combination of different movement types. To analyze each movement of the user during motion, the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> may segment the movement signal of the user based on the feature information corresponding to the electromyographic signal or the feature information corresponding to the attitude signal. The segmenting the movement signal of the user herein may refer to dividing the movement signal into signal segments having same or different durations, or extracting one or more signal segments having a specific duration from the movement signal. In some embodiments, each segment of the movement signal may correspond to one or more complete movement of the user. For example, when a user performs a deep squat, the user&#39;s movement from a standing position to a squat position and then getting up to return to the standing position may be considered as completing the deep squat, and the movement signal collected by the obtaining <figure-callout id="210" label="module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">module</figure-callout> <b>210</b> during this process may be considered as one segment (or one cycle) of the movement signal, after which the movement signal collected by the obtaining <figure-callout id="210" label="module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">module</figure-callout> <b>210</b> from the next deep squat completed by the user may be considered as another segment of the movement signal. In some embodiments, each movement signal may also correspond to a portion of the user&#39;s movement, and the portion of the movement may be understood as a portion of a complete movement. For example, when a user performs a deep squat, the user&#39;s movement from a standing position to a squat position may be considered as one segment of the movement, and getting up to return to the standing position may be considered as another segment of the movement. A change in each movement of the user during motion may cause the electromyographic signal and the attitude signal of a corresponding body part to change. For example, when the user performs a squat, the electromyographic signal and the attitude signal of the muscles in the corresponding parts of the user&#39;s body (e.g., arms, legs, hips, abdomen) fluctuate less when the user stands; when the user squats from the standing position, the electromyographic signal and the attitude signal of the muscles in the corresponding parts of the user&#39;s body fluctuate more, e.g., amplitude information corresponding to signals of different frequencies of the electromyographic signal becomes greater, or an angular velocity value, a direction of angular velocity, an acceleration value of angular velocity, an angle, displacement information, stress, etc., of the attitude signal may also change. When the user gets up from a squatting state to a standing state, the amplitude information corresponding to the electromyographic signal and the angular velocity value, the direction of angular velocity, the acceleration value of angular velocity, the angle, the displacement information, and the stress corresponding to the attitude signal may change again. Based on this situation, the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> may segment, based on the feature information corresponding to the electromyographic signal or the feature information corresponding to the attitude signal, the movement signal. Detailed descriptions for segmenting the movement signal based on the feature information corresponding to the electromyographic signal or the feature information corresponding to the attitude signal may be found in <figref idrefs="DRAWINGS">FIG. <b>7</b> </figref> and <figref idrefs="DRAWINGS">FIG. <b>8</b> </figref> of the present disclosure and their related descriptions.</div>
    </li> <li> <para-num num="[0111]"> </para-num> <div id="p-0112" num="0111" class="description-line">In <figure-callout id="620" label="step" filenames="US20230210402A1-20230706-D00004.png" state="{{state}}">step</figure-callout> <b>620</b>, the movement of the user during motion may be monitored based on at least one segment of the movement signal.</div>
    </li> <li> <para-num num="[0112]"> </para-num> <div id="p-0113" num="0112" class="description-line">The step may be performed by <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> and/or <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b>. In some embodiments, monitoring of the movement of the user based on at least one segment of the movement signal may include matching the at least one segment of the movement signal with at least one segment of a preset movement signal to determine the movement type of the user. The at least one segment of the preset movement signal may be standard movement signals corresponding to different movements that are preset in a database. In some embodiments, a movement type of the user during motion may be determined by determining a matching degree of the at least one segment of the movement signal and the at least one segment of the preset movement signal. Further, the movement type of the user may be determined by determining whether the matching degree of the movement signal and the preset movement signal is within a first matching threshold range (e.g., greater than 80%). If so, the movement type of the user during motion may be determined based on the movement type corresponding to the preset movement signal. In some embodiments, monitoring the movement of the user during motion based on the at least one segment of the movement signal may further include determining the movement type of the user during motion by matching the feature information corresponding to the at least one segment of the electromyographic signal with feature information corresponding to an electromyographic signal of the at least one segment of the preset movement signal. For example, match degree(s) between one or more feature information (e.g., frequency information, amplitude information) of the segment of the electromyographic signal and one or more feature information of the segment of the preset movement signal may be determined respectively, and a determination may be made as to whether a weighted matching degree of the one or more feature information or an average matching degree of the one or more feature information is within a first matching threshold. If so, the movement type of the user during motion may be determined based on the movement type corresponding to the preset movement signal. In some embodiments, monitoring the movement of the user during motion based on the at least one segment of the movement signal may further include determining the movement type of the user during motion by matching the feature information corresponding to the at least one segment of the attitude signal with the feature information corresponding to the attitude signal of the at least one segment of the preset movement signal. For example, the matching degree of the one or more feature information (e.g., the angular velocity value, the angular velocity direction and the acceleration value of the angular velocity, the angle, the displacement information, the stress, etc.) of one segment of the attitude signal and the one or more feature information of one segment of the preset movement signal may be determined respectively to determine whether the weighted matching degree or the average matching degree of the one or more feature information is within the first matching threshold. If so, the movement type of the user may be determined according to a movement type corresponding to the preset movement signal. In some embodiments, monitoring the movement of the user during motion based on the at least one segment of the movement signal may further include determining the movement type of the user during motion by matching the feature information corresponding to the electromyographic signal and the feature information corresponding to the attitude signal of the at least one segment of the movement signal with the feature information corresponding to the electromyographic signal and the feature information corresponding to the attitude signal of the at least one segment of the preset movement signal.</div>
    </li> <li> <para-num num="[0113]"> </para-num> <div id="p-0114" num="0113" class="description-line">In some embodiments, monitoring the movement of the user during motion based on the at least one segment of the movement signal may include determining the movement quality of the user by matching the at least one segment of the movement signal with the at least one segment of the preset movement signal. Further, if a matching degree of the movement signal and the preset movement signal is within a second matching threshold range (e.g., greater than 90%), the movement quality of the user during motion may meet the standard. In some embodiments, determining the movement of the user during motion based on the movement signal of the at least one segment may include determining the movement quality of the user during motion by matching the one or more feature information of the movement signal of the at least one segment with the one or more feature information of the at least one segment of the preset movement signal. It should be noted that a segment of the movement signal may be a movement signal of a complete movement or a movement signal of a partial of a complete movement. In some embodiments, for a complex complete movement, there may be different ways of force generation at different stages of the complete movement, that is, there may be different movement signals at the different stages of the movement, and the user movement may be monitored in real time, and thus, the accuracy of the monitored movement signal at the different stages of the complete movement may be improved.</div>
    </li> <li> <para-num num="[0114]"> </para-num> <div id="p-0115" num="0114" class="description-line">It should be noted that the above description of the <figure-callout id="600" label="process" filenames="US20230210402A1-20230706-D00004.png" state="{{state}}">process</figure-callout> <b>600</b> is for example and illustration purposes only and does not limit the scope of application of the present disclosure. For those skilled in the art, various amendments and changes can be made to process <b>600</b> under the guidance of the present disclosure. However, these amendments and changes are still within the scope of the present disclosure. For example, in some embodiments, the user&#39;s movement may also be determined by a movement recognition model or a manually preset model.</div>
    </li> <li> <para-num num="[0115]"> </para-num> <div id="p-0116" num="0115" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>7</b> </figref> is a flowchart of an exemplary process for segmenting a movement signal according to some embodiments of the present disclosure. As shown in <figref idrefs="DRAWINGS">FIG. <b>7</b> </figref>, <figure-callout id="700" label="process" filenames="US20230210402A1-20230706-D00005.png" state="{{state}}">process</figure-callout> <b>700</b> may include the following steps.</div>
    </li> <li> <para-num num="[0116]"> </para-num> <div id="p-0117" num="0116" class="description-line">In <figure-callout id="710" label="step" filenames="US20230210402A1-20230706-D00005.png" state="{{state}}">step</figure-callout> <b>710</b>, at least one target feature point within the time domain window may be determined based on a time domain window of the electromyographic signal or the attitude signal and according to a preset condition.</div>
    </li> <li> <para-num num="[0117]"> </para-num> <div id="p-0118" num="0117" class="description-line">In some embodiments, the step may be performed by the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> and/or the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b>. The time domain window of the electromyographic signal may include an electromyographic signal over a range of time, and the time domain window of the attitude signal may include an attitude signal over a same range of time. A target feature point refers to a signal of the movement signal with a target feature, which may represent a stage of the user&#39;s movement. For example, when a user performs a seated chest press, at the beginning, the user&#39;s arms are extended outward horizontally, begin to rotate internally, come together, and finally return to the extended state again in the horizontal direction, this process is a complete seated chest press movement. When the user performs a seated chest press movement, the feature information corresponding to the electromyographic signal or the attitude signal may be different in each stage. By analyzing the feature information corresponding to the electromyographic signal (e.g., amplitude information, frequency information) or the feature information corresponding to the attitude signal (e.g., the angular velocity value, the direction of angular velocity, the acceleration value of angular velocity, the angle, the displacement information, the stress, etc.), the target feature point corresponding to a stage of the user&#39;s movement may be determined. In some embodiments, one or more target feature points may be determined from the time domain window based on the preset condition. In some embodiments, the preset condition may include one or more of a change in the direction of the angular velocity corresponding to the attitude signal, the angular velocity corresponding to the attitude signal being greater than or equal to an angular velocity threshold, the angle corresponding to the attitude signal reaching an angular threshold, the change of the angular velocity value corresponding to the attitude signal being the extreme value, and the amplitude information corresponding to the electromyographic signal being greater than or equal to an electromyographic threshold. In some embodiments, the target feature points at the different stages of a movement may correspond to different preset conditions. For example, in the seated chest press, a preset condition for a target feature point when the user&#39;s arms are horizontally extended outward and then start to internally rotate may be different from a preset condition for a target feature point when the arms are brought together. In some embodiments, the target feature points of different movements may correspond to different preset conditions. For example, the chest press movement and the bent-over movement may be different, and the preset conditions regarding the respective preset target feature points in these two movements may also be different. Exemplary descriptions of the preset condition may refer to the description of a movement start point, a movement middle point, and a movement end point in the present disclosure.</div>
    </li> <li> <para-num num="[0118]"> </para-num> <div id="p-0119" num="0118" class="description-line">In other embodiments, the at least one target feature point may be determined from the time domain windows based on both of the time domain windows of the electromyographic signal and the attitude signal, according to the preset condition. The time domain windows of the electromyographic signal and the attitude signal may include the electromyographic signal and the attitude signal over a range of time. The time of the electromyographic signal may correspond to the time of the attitude signal. For example, a time point of the electromyographic signal when the user starts to move may be the same as a time point of the attitude signal when the user starts to move. The target feature point here may be determined by combining the feature information corresponding to the electromyographic signal (e.g., the amplitude information) and the feature information corresponding to the attitude signal (e.g., the angular velocity value, the direction of angular velocity, the acceleration value of angular velocity, the angle, etc.).</div>
    </li> <li> <para-num num="[0119]"> </para-num> <div id="p-0120" num="0119" class="description-line">In <figure-callout id="720" label="step" filenames="US20230210402A1-20230706-D00005.png" state="{{state}}">step</figure-callout> <b>720</b>, the movement signal may be segmented based on the at least one target feature point.</div>
    </li> <li> <para-num num="[0120]"> </para-num> <div id="p-0121" num="0120" class="description-line">In some embodiments, the <figure-callout id="720" label="step" filenames="US20230210402A1-20230706-D00005.png" state="{{state}}">step</figure-callout> <b>720</b> may be performed by the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> and/or the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b>. In some embodiments, the target feature point in the electromyographic signal or the attitude signal may be one or more, and the movement signal may be divided into multiple segments by one or more target feature points. For example, when there is a target feature point in the electromyographic signal, the target feature point may divide the electromyographic signal into two segments, where the two segments may include the electromyographic signal before the target feature point and the electromyographic signal after the target feature point. Alternatively, the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> and/or the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b> may extract the electromyographic signal for a certain time range around the target feature point as a segment of the electromyographic signal. As another example, when the electromyographic signal has a plurality of target feature points (e.g., n-target feature points, and the first target feature point is not a beginning of the time domain window, the n<sup>th </sup>target feature point is not an end of the time domain window), the electromyographic signal may be divided into (n+1) segments based on the n target feature points. As another example, when the electromyographic signal has the plurality of target feature points (e.g., n-target feature points, the first target feature point is the beginning of the time domain window, the n<sup>th </sup>target feature point is not the end of the time domain window), the electromyographic signal may be divided into n segments based on the n target feature points. As a further example, when the electromyographic signal has the plurality of target feature points (e.g., n-target feature points, the first target feature point is the beginning of the time domain window, the n<sup>th </sup>target feature point is the end of the time domain window), the electromyographic signal may be divided into (n1) segments based on the n target feature points. It should be noted that the movement stage corresponding to the target feature point may include one or more types. When the movement stage corresponding to the target feature point are multiple types, the plurality of target feature points may be used as a benchmark for segmenting the movement signal. For example, the movement stage corresponding to the target feature point may include the movement start point and the movement end point, the movement start point may be before the movement end point, and in this situation, the movement signal between the movement start point and a next movement start point may be considered as a segment of the movement signal.</div>
    </li> <li> <para-num num="[0121]"> </para-num> <div id="p-0122" num="0121" class="description-line">In some embodiments, the target feature point may include one or more of the movement start point, the movement middle point, or the movement end point.</div>
    </li> <li> <para-num num="[0122]"> </para-num> <div id="p-0123" num="0122" class="description-line">To describe the segmentation of the movement signal, take the target feature point including all of the movement start point, the movement middle point and the movement end point as an exemplary illustration. The movement start point may be considered as a start point of a user movement cycle. In some embodiments, different movements may correspond to different preset conditions. For example, in the seated chest press, the preset condition may be that the direction of the angular velocity of the movement after the movement start point changes relative to the direction of the angular velocity of the movement before the movement start point, or that the value of the angular velocity at the movement start point is approximately 0 and the acceleration value of the angular velocity at the movement start point is greater than 0. In other words, when the user performs the seated chest press, the movement starting point may be set to the point when the arms are extended outward horizontally and start to internally rotate. As another example, in a bent-over movement, the preset condition may be that the angle of arm lift is greater than or equal to an angle threshold. Specifically, when the user performs a bent-over movement, the angle of arm lift when the user&#39;s arm is horizontal is 0, the angle of arm lift when the arm is down is negative, and the angle of arm lift when the arm is up is positive. When the user&#39;s arm is raised from the horizontal position, the arm is raised at an angle greater than 0. The point in time when the angle of the arm lift reaches the angle threshold may be considered as the movement start point. The angle threshold may be 70 to 20, or as a preference, the angle threshold may be 50 to 25. In some embodiments, to further ensure the accuracy of a selected movement start point, the preset condition may also include that the angular velocity of the arm within a specific range of time after the movement start point may be greater than or equal to an angular velocity threshold. The angular velocity threshold may range from 5/s50/s. According to preference of example, the angular velocity threshold may range from 10/s30/s. For example, when a user performs a bent-over movement, the angular velocity of the arm is continuously greater than the angular velocity threshold for a specific time range (e.g., 0.05 s, 0.1 s, 0.5 s) after an angular threshold is reached and the user&#39;s arm is continuously raised upward. In some embodiments, if the angular velocity of the selected movement start point according to the preset condition is less than the angular velocity threshold within a specific range of time, the preset condition continues until a movement start point is determined.</div>
    </li> <li> <para-num num="[0123]"> </para-num> <div id="p-0124" num="0123" class="description-line">In some embodiments, the movement middle point may be a point within one movement cycle from the start point. For example, when the user performs the seated chest press, a start point of the movement may be set to the time when the arms extend outward horizontally and begin to internally rotate, and the time when the arms come together may be determined as a movement middle point of the user. In some embodiments, the preset condition may be that a direction of the angular velocity at the point in time after the movement middle point changes relative to a direction of the angular velocity at the point in time before the movement middle point, and an angular velocity value at the movement middle point is approximately zero, wherein the direction of the angular velocity at the movement middle point is opposite to the direction of the angular velocity at the movement start point. In some embodiments, to improve the accuracy of the selection of the movement middle point, a change of the angular velocity (an acceleration of angular velocity) in a first specific time range after the movement middle point (e.g., 0.05 s, 0.1 s, 0.5 s) may be greater than an acceleration threshold of angular velocity (e.g., 0.05 rad/s). In some embodiments, the amplitude information in the electromyographic signal corresponding to the movement middle point may be greater than the electromyographic threshold while the movement middle point satisfies the preset condition described above. Since the different movements correspond to different electromyographic signals, the electromyographic threshold may be related to the user movement and the target electromyographic signal. In the seated chest press, the electromyographic signal at the pectoral muscle may be the target electromyographic signal. In some embodiments, the position corresponding to the movement middle point (also may be called as middle position) may be approximated as the maximum point of muscle force, where the electromyographic signal may have a relatively great value. It should be noted that the electromyographic signal at the part of the user&#39;s body when the user performs the movement during motion may be substantially higher than the electromyographic signal at the part of the user&#39;s body when the user does not perform the movement during motion (when the muscle in the particular part may be considered as a resting state). For example, an amplitude of the electromyographic signal at the part of the user&#39;s body when the user&#39;s movement reaches the middle position may be 10 times higher than that in the resting state. In addition, the relationship between the amplitude of the electromyographic signal at the part of the user when the movement position reaches the middle position (the movement middle point) and the amplitude of the electromyographic signal in the resting state may be different according to the different movement types performed by the user, and the relationship between the two may be adapted according to the actual movement. In some embodiments, to improve the accuracy of the selection of the movement middle point, the amplitude corresponding to a second specific time range after the movement middle point (e.g., 0.05 s, 0.1 s, 0.5 s) may be continuously greater than the electromyographic threshold. In some embodiments, in addition to the above preset condition (e.g., the angular velocity and an amplitude condition of the electromyographic signal), a Euler angle (also referred to as an angle) of the movement middle point and the start position may satisfy a certain condition preset to determine the movement middle point. For example, in the seated chest press, the Euler angle at the movement middle point relative to the movement start point may be greater than one or more Euler angle thresholds (also referred to as angle thresholds). For example, with a front-to-back direction of the human body as an X-axis, a left-right direction of the human body as a Y-axis, and a height direction of the human body as a Z-axis, a Euler angle changed in the X and Y directions may be less than 25, and the Euler angle changed in the Z direction may be greater than 40 (the movement of the seated chest press is mainly related to the rotation at the Z-axis direction, the above parameters are only reference examples). In some embodiments, the electromyographic thresholds and/or the Euler angle thresholds may be stored in advance in a storage device or a hard drive of the <figure-callout id="130" label="wearable device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">wearable device</figure-callout> <b>130</b>, or in the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b>, or may be determined based on an actual condition and adjusted in real time.</div>
    </li> <li> <para-num num="[0124]"> </para-num> <div id="p-0125" num="0124" class="description-line">In some embodiments, the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> may determine, based on the time domain window of the electromyographic signal or the attitude signal, the movement middle point from a time domain window at a time point after the movement start point according to a preset condition. In some embodiments, after the movement middle point is determined, whether there are other time points that meet the preset condition within the time range from the movement start point to the movement middle point may be re-verified, and if so, a movement start point closest to the movement middle point may be selected as the best movement start point. In some embodiments, if the difference between the time of the movement middle point and the time of the movement start point is greater than a specific time threshold (e.g.,  or  of a movement cycle), the movement middle point may be invalid, and the movement start point and movement middle point may be re-determined based on preset condition.</div>
    </li> <li> <para-num num="[0125]"> </para-num> <div id="p-0126" num="0125" class="description-line">In some embodiments, the movement end point may be a time point that is after the movement middle point, and within one movement cycle from the movement start point. For example, the movement end point may be set as a point that is one movement cycle from the movement start point, and the movement end point herein may be considered as an end of a movement cycle of the user. For example, when the user performs the seated chest press, the movement start point may be set as a time point when the arms extend horizontally to the left and right and start internal rotation, the time point when the arms close together may be the movement middle point of the user, and the time point when the arms return to the extended state again from the horizontal direction may correspond to the movement end point of the user. In some embodiments, the preset condition may be that a changed angular velocity value corresponding to the attitude signal is an extreme value. In some embodiments, to prevent jitter misjudgment, the change in Euler angle should exceed a certain Euler angle threshold, e.g., 20, in the time range from the movement middle point to the movement end point. In some embodiments, the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> may determine the movement end point from the time domain window after the movement middle point based on the time domain windows of the electromyographic signal and the attitude signal according to the preset condition. In some embodiments, if the difference between the time of the movement end point and the time of the movement middle point is greater than a specific time threshold (e.g.,  of a movement cycle), the movement start point and the movement middle point may be invalid, and the movement start point, the movement middle point, and the movement end point may be re-determined based on the preset condition.</div>
    </li> <li> <para-num num="[0126]"> </para-num> <div id="p-0127" num="0126" class="description-line">In some embodiments, at least one set of the movement start point, the movement middle point, and the movement end point in the movement signal may be repeatedly determined, and the movement signal may be segmented based on the at least one set of the movement start point, the movement middle point, and the movement end point as the target feature points. The step may be performed by the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> and/or the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b>. It should be noted that the segmentation of the movement signal is not limited to be based on the above movement start point, the movement middle point and the movement end point, but may also include other time points. For example, for the seated chest press, 5 time points may be selected according to the above steps, a first time point may be a movement start point, a second time point may be a moment of the maximum angular velocity of the internal rotation, a third time point may be the movement middle point, a fourth time point may be the moment of the maximum angular velocity of external rotation, a fifth time point may be the moment when the arms return to extend left and right, and the angular velocity is 0, that is, the movement end point. In this example, compared to the movement start point, the movement middle point and the movement end point in the above steps, the second time point is added as a  marker point of the movement cycle, the movement end point described in the above embodiments is used as the fourth time point for marking the  position of the movement cycle, and the fifth time point is added as an end point of the complete movement. For the seated chest press, more time points are used here, and a recognition of the movement quality may be done based on the signal of the first  of the movement cycle (i.e., the recognition of the movement quality for a single cycle does not depend on a complete analysis of the signal of a whole cycle), which may complete the monitoring and feedback of the user&#39;s movement without the end of a current cycle. At same time, all signals of the process of the whole movement may be completely recorded to be easily uploaded to the cloud or the mobile terminal device, thus more methods may be adopted to monitor the user&#39;s movement. For more complex movement, the cycle of the movement may be quite long, and each stage may have different force patterns. In some embodiments, the above method for determining each time point may be adopted to divide the movement into multiple stages, and the signal for each stage may be recognized and fed back separately to improve timeliness of feedback of the user&#39;s movement.</div>
    </li> <li> <para-num num="[0127]"> </para-num> <div id="p-0128" num="0127" class="description-line">It should be noted that the above segmentation and monitoring of the movement signal based on the movement start point, movement middle point and movement end point as a set of target feature points is only an exemplary illustration. In some embodiments, the user&#39;s movement signal may also be segmented and monitored based on any one or more of the movement start point, the movement middle point and the movement end point as the target feature points. For example, the movement signal may be segmented and monitored by using the movement start point as the target feature point. As another example, the movement start point and the movement end point may be used as a set of target feature points to segment and monitor the movement signal, and other time points or time ranges that can be used as the target feature points are within the scope of protection of the present disclosure.</div>
    </li> <li> <para-num num="[0128]"> </para-num> <div id="p-0129" num="0128" class="description-line">It should be noted that the above description of the <figure-callout id="700" label="process" filenames="US20230210402A1-20230706-D00005.png" state="{{state}}">process</figure-callout> <b>700</b> is for example and illustration purposes only and does not limit the scope of application of the present disclosure. For those skilled in the art, various amendments and changes can be made to the <figure-callout id="700" label="process" filenames="US20230210402A1-20230706-D00005.png" state="{{state}}">process</figure-callout> <b>700</b> under the guidance of the present disclosure. However, these amendments and changes are still within the scope of the present disclosure. For example, <figure-callout id="710" label="step" filenames="US20230210402A1-20230706-D00005.png" state="{{state}}">step</figure-callout> <b>710</b> and step <b>720</b> may be performed simultaneously by the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b>. As another example, <figure-callout id="710" label="step" filenames="US20230210402A1-20230706-D00005.png" state="{{state}}">step</figure-callout> <b>710</b> and step <b>720</b> may be performed simultaneously by the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> and the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b>, respectively.</div>
    </li> <li> <para-num num="[0129]"> </para-num> <div id="p-0130" num="0129" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>8</b> </figref> is a diagram illustrating exemplary movement signal segmentation according to some embodiments of the present disclosure. A horizontal coordinate in <figref idrefs="DRAWINGS">FIG. <b>8</b> </figref> may indicate a motion time of a user, and a vertical coordinate may indicate amplitude information of an electromyographic signal of a muscle part (e.g., pectoralis major) during seated chest press. <figref idrefs="DRAWINGS">FIG. <b>8</b> </figref> may also include an angular velocity curve and a Euler angle curve corresponding to an attitude signal of the wrist position of the user during motion. The angular velocity curve is configured to represent a velocity change of the user during motion and the Euler angle curve is configured to represent a position situation of a user&#39;s body part during motion. As shown in <figref idrefs="DRAWINGS">FIG. <b>8</b> </figref>, point A1 is determined as the movement start point according to the preset condition. Specifically, a direction of the angular velocity at a time point after the user&#39;s movement start point A1 changes relative to the direction of the angular velocity at a time point before the movement start point A1. Further, the angular velocity value at the movement start point A1 is approximately 0, and an acceleration value of the angular velocity at the movement start point A1 is greater than 0.</div>
    </li> <li> <para-num num="[0130]"> </para-num> <div id="p-0131" num="0130" class="description-line">Refer to <figref idrefs="DRAWINGS">FIG. <b>8</b> </figref>, point B1 is determined as the movement middle point according to the preset condition. Specifically, the direction of the angular velocity at the time point after the user&#39;s movement middle point B1 changes relative to the direction of the angular velocity at the time point before the movement <figure-callout id="1" label="middle point B" filenames="US20230210402A1-20230706-D00013.png,US20230210402A1-20230706-D00014.png" state="{{state}}">middle point B</figure-callout> <b>1</b>, and the angular velocity value at the movement middle point B1 is approximately 0. The direction of the angular velocity at the movement middle point B1 is opposite to the direction of the angular velocity at the movement start point A1. In addition, the amplitude of the electromyographic signal (shown as the electromyographic signal in <figref idrefs="DRAWINGS">FIG. <b>8</b> </figref>) corresponding to the movement middle point B1 is greater than the electromyographic threshold.</div>
    </li> <li> <para-num num="[0131]"> </para-num> <div id="p-0132" num="0131" class="description-line">Continue to refer to <figref idrefs="DRAWINGS">FIG. <b>8</b> </figref>, point Cl is determined as the movement end point according to the preset condition. Specifically, a changed angular velocity value at the movement end point Cl is the extreme value from the movement start point A1 to the movement end point Cl. In some embodiments, the <figure-callout id="700" label="process" filenames="US20230210402A1-20230706-D00005.png" state="{{state}}">process</figure-callout> <b>700</b> may complete the movement segmentation shown in <figref idrefs="DRAWINGS">FIG. <b>8</b> </figref>, such that the movement signal from the movement start point A1 to the movement end point Cl shown in <figref idrefs="DRAWINGS">FIG. <b>8</b> </figref> may be considered as a segment of the motion.</div>
    </li> <li> <para-num num="[0132]"> </para-num> <div id="p-0133" num="0132" class="description-line">It is noted that, in some embodiments, if a time interval between the movement middle point and the movement start point is greater than a specific time threshold (e.g.,  of a movement cycle), the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> may re-determine the movement start point to improve the accuracy of the movement segmentation. The specific time threshold here may be stored in a storage device or a hard drive of the <figure-callout id="130" label="wearable device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">wearable device</figure-callout> <b>130</b>, or in the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b>, or may be determined or adjusted based on the actual situation of the user during motion. For example, if the time interval between the movement start point A1 and the movement middle point B1 in <figref idrefs="DRAWINGS">FIG. <b>8</b> </figref> is greater than a specific time threshold, the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> may re-determine the movement start point, thereby improving the accuracy of the movement segmentation. In addition, the segmentation of the movement signal is not limited to be based on the above movement start point A1, the movement middle point B1 and the movement end point Cl, but may also include other time points, and the selection of the time points may be made according to the complexity of the movement.</div>
    </li> <li> <para-num num="[0133]"> </para-num> <div id="p-0134" num="0133" class="description-line">When obtaining the user&#39;s movement signal, other physiological parameter information of the user (e.g., a heart rate signal), an external condition such as a relative movement of the obtaining <figure-callout id="210" label="module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">module</figure-callout> <b>210</b> and the human body during motion or a compression of the obtaining <figure-callout id="210" label="module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">module</figure-callout> <b>210</b> may affect the quality of the movement signal, for example, resulting in an abrupt change in the electromyographic signal, thereby affecting the monitoring of the movement. For ease of description, an abrupt electromyographic signal may be described by using a singularity, and an exemplary singularity may include a burr signal, a discontinuous signal, etc. In some embodiments, monitoring the movement of the user during motion based at least on the feature information corresponding to the electromyographic signal or the feature information corresponding to the attitude signal may further include: pre-processing the electromyographic signal in a frequency domain or a time domain, obtaining, based on the preprocessed electromyographic signal, the feature information corresponding to the electromyographic signal, and monitoring, based on the feature information corresponding to the electromyographic signal or the feature information corresponding to the attitude signal, the movement of the user during motion. In some embodiments, pre-processing the electromyographic signal in the frequency domain or the time domain may include filtering the electromyographic signal in the frequency domain to select or retain components of the electromyographic signal in a particular frequency range in the frequency domain. In some embodiments, the obtaining <figure-callout id="210" label="module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">module</figure-callout> <b>210</b> may obtain an electromyographic signal in a frequency range of 1 Hz-1000 Hz, filter the electromyographic signal, and select an electromyographic signal in a specific frequency range (e.g., 30 Hz-150 Hz) for subsequent processing. In some embodiments, the specific frequency range may be 10 Hz-500 Hz. According to preference of example, the specific frequency range may be 15 Hz-300 Hz or 30 Hz-150 Hz. In some embodiments, a filtering process may include a low-pass filter processing. In some embodiments, the low-pass filter may include an LC passive filter, an RC passive filter, an RC active filter, a passive filter composed of special elements. In some embodiments, the passive filter composed of the special elements may include one or more of a piezoelectric ceramic filter, a crystal filter, an acoustic surface filter. It should be noted that the specific frequency range is not limited to the above range, but may also be other ranges, which may be selected according to the actual situation. More descriptions for monitoring, according to the feature information corresponding to the electromyographic signal or the feature information corresponding to the attitude signal, the movement of the user during motion may be found in <figref idrefs="DRAWINGS">FIG. <b>5</b> </figref>, <figref idrefs="DRAWINGS">FIG. <b>6</b> </figref> of the present disclosure and their relevant descriptions.</div>
    </li> <li> <para-num num="[0134]"> </para-num> <div id="p-0135" num="0134" class="description-line">In some embodiments, pre-processing the electromyographic signal in the frequency domain or the time domain may further include signal correction processing of the electromyographic signal in the time domain. The signal correction processing refers to a correction to the singularity (e.g., the burr signal, the discontinuous signal, etc.) in the electromyographic signal. In some embodiments, the signal correction processing of the electromyographic signal in the time domain may include determining the singularity in the electromyographic signal, i.e., determining the abrupt signal in the electromyographic signal. The singularity may be a sudden change in the amplitude of an electromyographic signal within a certain moment, causing a discontinuity in the signal. As another example, the electromyographic signal is morphologically smooth and there is no abrupt change in the amplitude of the electromyographic signal, but there is the abrupt change in the first-order differential of the electromyographic signal, and the first-order differential is discontinuous. In some embodiments, the method for determining the singularity in the electromyographic signal may include, but is not limited to, one or more of a Fourier transform, a wavelet transform, a fractal dimension, etc. In some embodiments, the signal correction processing of the electromyographic signal in the time domain may include removing the singularity in the electromyographic signal, for example, removing signals within a period of time at and near the singularity. Alternatively, the signal correction processing of the electromyographic signal in the time domain may include correcting the singularity of the electromyographic signal according to the feature information of the electromyographic signal in the specific time range, such as adjusting the amplitude of the singularity based on the signals around the singularity. In some embodiments, the feature information of the electromyographic signal may include the amplitude information, the statistic information of the amplitude information, etc. The statistic information of amplitude information (also referred to as an amplitude entropy) refers to a distribution of the amplitude information of the electromyographic signal in the time domain. In some embodiments, after a location (e.g., the time point) of the singularity in the electromyographic signal is determined by a signal processing algorithm (e.g., the Fourier transform, the wavelet transform, the fractal dimension), the singularity may be corrected based on the electromyographic signal in the specific time range before or after the location of the singularity. For example, when the singularity is an abrupt trough, the electromyographic signal at the abrupt trough may be supplemented based on the feature information (e.g., the amplitude information, the statistic information of the amplitude information) of the electromyographic signal in a specific time range (e.g., 5 ms-60 ms) before or after the abrupt trough.</div>
    </li> <li> <para-num num="[0135]"> </para-num> <div id="p-0136" num="0135" class="description-line">Exemplary illustration with the singularity as the burr signal, <figref idrefs="DRAWINGS">FIG. <b>9</b> </figref> is a flowchart of an exemplary process for pre-processing an electromyographic signal according to some embodiments of the present disclosure. As shown in <figref idrefs="DRAWINGS">FIG. <b>9</b> </figref>, the <figure-callout id="900" label="process" filenames="US20230210402A1-20230706-D00007.png" state="{{state}}">process</figure-callout> <b>900</b> may include following steps.</div>
    </li> <li> <para-num num="[0136]"> </para-num> <div id="p-0137" num="0136" class="description-line">In <figure-callout id="910" label="step" filenames="US20230210402A1-20230706-D00007.png" state="{{state}}">step</figure-callout> <b>910</b>, different time windows may be selected from the time domain window of the electromyographic signal based on the time domain window of the electromyographic signal, wherein the different time windows may cover different time ranges, respectively.</div>
    </li> <li> <para-num num="[0137]"> </para-num> <div id="p-0138" num="0137" class="description-line">In some embodiments, the step may be performed by the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> and/or the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b>. In some embodiments, the different windows may include at least one specific window. The specific window refers to a window with a specific time length selected from the time domain window. For example, when the time length of the time domain window of the electromyographic signal is 3 s, a time length of the specific window may be 100 ms. In some embodiments, the specific window may include a plurality of different time windows. Merely as way of exemplary illustration, the specific window may include a first time window and a second time window. The first time window may refer to a window corresponding to a partial time length of the specific window. For example, when the time length of the specific window is 100 ms, the time length of the first time window may be 80 ms. The second time window may be another window corresponding to the partial time length of the specific window. For example, when the specific window is 100 ms, the second time window may be 20 ms. In some embodiments, the first time window and the second time window may be consecutive time windows within a same specific window. In some embodiments, the first time window and the second time window may also be two discrete or overlapping time windows within the same specific window. For example, when the time length of the specific window is 100 ms, the time length of the first time window may be 80 ms and the time length of the second time window may be 25 ms. In this situation, the second time window may be overlapped with the first time window in 5 ms. In some embodiments, the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> may slide and update the specific window sequentially from an initially time point of the time domain window of the electromyographic signal according to the specific time length based on the time domain window of the electromyographic signal, and may continue to divide an updated specific window into the first time window and the second time window. The specific time length mentioned here may be less than 1 s, 2 s, 3 s, etc. For example, the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> may select a specific window of a specific time length of 100 ms and divide that specific window into a first time window of 80 ms and a second time window of 20 ms. Further, the specific window may be updated by sliding along the time direction. A sliding distance here may be a time length of the second time window (e.g., 20 ms) or other suitable time lengths, e.g., 30 ms, 40 ms, etc.</div>
    </li> <li> <para-num num="[0138]"> </para-num> <div id="p-0139" num="0138" class="description-line">In <figure-callout id="920" label="step" filenames="US20230210402A1-20230706-D00007.png" state="{{state}}">step</figure-callout> <b>920</b>, the burr signal may be determined based on the feature information corresponding to the electromyographic signal in the different time windows.</div>
    </li> <li> <para-num num="[0139]"> </para-num> <div id="p-0140" num="0139" class="description-line">In some embodiments, the step may be performed by the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> and/or the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b>. In some embodiments, the feature information corresponding to the electromyographic signal may include at least one of the amplitude information, the statistic information of the amplitude information. In some embodiments, the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> may obtain the amplitude information or the statistic information of the amplitude information corresponding to the electromyographic signal in different time windows (e.g., the first time window, the second time window) to determine the location of the burr signal. Detailed descriptions for determining, based on the feature information corresponding to the electromyographic signal in different time windows, the location of the burr signal may be found in <figref idrefs="DRAWINGS">FIG. <b>10</b> </figref> and its relevant descriptions.</div>
    </li> <li> <para-num num="[0140]"> </para-num> <div id="p-0141" num="0140" class="description-line">It should be noted that the above description of the <figure-callout id="900" label="process" filenames="US20230210402A1-20230706-D00007.png" state="{{state}}">process</figure-callout> <b>900</b> is for example and illustration purposes only and does not limit the scope of application of the present disclosure. For those skilled in the art, various amendments and changes can be made to process <b>900</b> under the guidance of the present disclosure. For example, the specific window is not limited to include the first time window and the second time window described above, but may also include other time windows, for example, a third time window, a fourth time window, etc. In addition, the specific range of moments before or after the position of the burr signal may be adapted according to the length of the burr signal, which may not be further limited herein. However, these amendments and changes are still within the scope of the present disclosure.</div>
    </li> <li> <para-num num="[0141]"> </para-num> <div id="p-0142" num="0141" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>10</b> </figref> is a flowchart illustrating an exemplary process for determining a burr signal according to some embodiments of the present disclosure. As shown in <figref idrefs="DRAWINGS">FIG. <b>10</b> </figref>, <figure-callout id="1000" label="process" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">process</figure-callout> <b>1000</b> may include the following steps.</div>
    </li> <li> <para-num num="[0142]"> </para-num> <div id="p-0143" num="0142" class="description-line">In <figure-callout id="1010" label="step" filenames="US20230210402A1-20230706-D00008.png" state="{{state}}">step</figure-callout> <b>1010</b>, first amplitude information corresponding to the electromyographic signal within the first time window and second amplitude information corresponding to the electromyographic signal within the second time window may be determined.</div>
    </li> <li> <para-num num="[0143]"> </para-num> <div id="p-0144" num="0143" class="description-line">In some embodiments, the step may be performed by the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> and/or the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b>. In some embodiments, the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> may select the time lengths of the first time window and the second time window, and extract the first amplitude information corresponding to the electromyographic signal during the time length of the first time window and the second amplitude information corresponding to the electromyographic signal during the time length of the second time window. In some embodiments, the first amplitude information may include an average amplitude of the electromyographic signal during the first time window, and the second amplitude information may include the average amplitude of the electromyographic signal during the second time window. For example, the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> may select a time length of a first time window as 80 ms, and extract the first amplitude information corresponding to the electromyographic signal within the first time window. The <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> may select a time length of a second time window as 20 ms, and extract the second amplitude information corresponding to the electromyographic signal within the second time window.</div>
    </li> <li> <para-num num="[0144]"> </para-num> <div id="p-0145" num="0144" class="description-line">In some embodiments, a selection of the time length of the first time window and the time length of the second time window may be related to the shortest burr signal length and amount of computation of the system. In some embodiments, the time length of the first time window and the time length of the second time window may be selected according to the feature of the burr signal. The time length of an electro-cardio burr signal is 40 ms-100 ms, the time interval between two burr signals in the electro-cardio signal may be about 1 s, a peak point of the burr signal is basically symmetrical on both sides, an amplitude distribution of the burr signal is relatively even on both sides, etc. In some embodiments, when the burr signal is the electro-cardio signal, a time length less than the length of the burr signal, e.g., a half of the length of the burr signal, may be selected as the time length of the second time window, and the time length of the first time window may be greater than (e.g., four times) the time length of the second time window. In some embodiments, the time length of the first time window may be within a range of an interval (about 1 s) between burr signals minus the time length of the second time window. It should also be noted that the above selected time length of the first time window and the time length of the second time window are not limited to the above description, as long as a sum of the time length of the second time window and the time length of the first time window is less than a time interval of adjacent two burr signals, or the time length of the second time window is less than a single burr signal length, or an amplitude of the electromyographic signal within the second time window and an amplitude of the electromyographic signal the first time window have a good discrimination.</div>
    </li> <li> <para-num num="[0145]"> </para-num> <div id="p-0146" num="0145" class="description-line">In <figure-callout id="1020" label="step" filenames="US20230210402A1-20230706-D00008.png" state="{{state}}">step</figure-callout> <b>1020</b>, a determination may be made as whether a ratio of the second amplitude information to the first amplitude information is greater than a threshold.</div>
    </li> <li> <para-num num="[0146]"> </para-num> <div id="p-0147" num="0146" class="description-line">In some embodiments, the step may be performed by the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> and/or the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b>. In some embodiments, the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> may determine whether the ratio of the second amplitude information corresponding to the electromyographic signal in the second time window to the first amplitude information corresponding to the electromyographic signal in the first time window is greater than the threshold. The threshold here may be stored in a storage device or a hard drive of the <figure-callout id="130" label="wearable device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">wearable device</figure-callout> <b>130</b>, or in the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b>, or may be adjusted according to an actual situation. In some embodiments, if the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> determines that the ratio of the second amplitude information to the first amplitude information is greater than the threshold, <figure-callout id="1020" label="step" filenames="US20230210402A1-20230706-D00008.png" state="{{state}}">step</figure-callout> <b>1020</b> may proceed to step <b>1030</b>. In other embodiments, if the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> determines that the ratio of the second amplitude information to the first amplitude information is not greater than the threshold, <figure-callout id="1020" label="step" filenames="US20230210402A1-20230706-D00008.png" state="{{state}}">step</figure-callout> <b>1020</b> may proceed to step <b>1040</b>.</div>
    </li> <li> <para-num num="[0147]"> </para-num> <div id="p-0148" num="0147" class="description-line">In <figure-callout id="1030" label="step" filenames="US20230210402A1-20230706-D00008.png" state="{{state}}">step</figure-callout> <b>1030</b>, a signal correction processing may be performed on the electromyographic signal within the second time window.</div>
    </li> <li> <para-num num="[0148]"> </para-num> <div id="p-0149" num="0148" class="description-line">In some embodiments, the step may be performed by the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> and/or the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b>. In some embodiments, the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> may perform the signal correction processing on the electromyographic signal within the second time window based on a comparison result of the ratio of the second amplitude information to the first amplitude information and the threshold in <figure-callout id="1020" label="step" filenames="US20230210402A1-20230706-D00008.png" state="{{state}}">step</figure-callout> <b>1020</b>. For example, in some embodiments, if the ratio of the second amplitude information to the first amplitude information is greater than the threshold, then the electromyographic signal in the second time window corresponding to the second amplitude information may be a burr signal. In some embodiments, processing the electromyographic signal within the second time window may include performing a signal correction processing on the electromyographic signal within the second time window based on the electromyographic signal within a specific time range before or after the second time window. In some embodiments, the signal correction processing of the electromyographic signal within the second time window may include, but is not limited to, a padding, an interpolation, etc. In some embodiments, the specific time range herein may be 5 ms-60 ms. According to preference of example, the specific time range may be 10 ms-50 ms or 20 ms-40 ms. It should be noted that the specific time range is not limited to the above range, for example, the specific time range may be greater than 60 ms, less than 5 ms, or other ranges. In practical application scenarios, the specific time range may be adapted based on the duration of the burr signal.</div>
    </li> <li> <para-num num="[0149]"> </para-num> <div id="p-0150" num="0149" class="description-line">In <figure-callout id="1040" label="step" filenames="US20230210402A1-20230706-D00008.png" state="{{state}}">step</figure-callout> <b>1040</b>, an electromyographic signal within the second time window may be retained.</div>
    </li> <li> <para-num num="[0150]"> </para-num> <div id="p-0151" num="0150" class="description-line">In some embodiments, the step may be performed by the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> and/or the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b>. In some embodiments, the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> may perform a retention on the electromyographic signal within the second time window according to the comparison result of the ratio of the second amplitude information to the first amplitude information and the threshold in <figure-callout id="1020" label="step" filenames="US20230210402A1-20230706-D00008.png" state="{{state}}">step</figure-callout> <b>1020</b>. For example, in some embodiments, when the ratio of the second amplitude information to the first amplitude information is not greater than the threshold, then the electromyographic signal within the second time window corresponding to the second amplitude information may be a normal electromyographic signal, and the normal electromyographic signal may be retained, i.e., the electromyographic signal within the second time window may be retained.</div>
    </li> <li> <para-num num="[0151]"> </para-num> <div id="p-0152" num="0151" class="description-line">It should be noted that the amplitude of the electromyographic signal is gradually increasing since electrical charges gradually accumulates during muscular exertion, so that the amplitude of the electromyographic signal within two adjacent time windows (e.g., the first time window and the second time window) does not change abruptly in the absence of a burr signal. In some embodiments, whether there is the burr signal in the electromyographic signal may be determined and the burr signal may be removed according to the <figure-callout id="1000" label="process" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">process</figure-callout> <b>1000</b>, to realize a real-time processing of the burr signal, thereby enabling the <figure-callout id="130" label="wearable device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">wearable device</figure-callout> <b>130</b> or the mobile <figure-callout id="140" label="terminal device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">terminal device</figure-callout> <b>140</b> to provide a real-time feedback of the motion state to the user, and helping the user to perform motion more scientifically.</div>
    </li> <li> <para-num num="[0152]"> </para-num> <div id="p-0153" num="0152" class="description-line">In some embodiments, the time length corresponding to the first time window may be greater than the time length corresponding to the second time window. In some embodiments, a specific time length corresponding to a specific window may be less than 1 s. In some embodiments, the ratio of the time length corresponding to the first time window to the time length corresponding to the second time window may be greater than 2. In some embodiments, the time length corresponding to the first time window, the time length corresponding to the second time window, and the specific time length corresponding to the specific window may be selected to ensure that the shortest burr signal (e.g., 40 ms) can be removed, and the system has a high signal-to-noise ratio, the calculation volume of the system may be decreased, repeated calculation of the system may be avoided, and the time complexity may be reduced, thereby improving the calculation efficiency and the calculation accuracy of the system.</div>
    </li> <li> <para-num num="[0153]"> </para-num> <div id="p-0154" num="0153" class="description-line">It should be noted that the above description of the <figure-callout id="1000" label="process" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">process</figure-callout> <b>1000</b> is for example and illustration purposes only, and does not limit the scope of application of the present disclosure. For those skilled in the art, various amendments and changes may be made to process <b>1000</b> under the guidance of the present disclosure. For example, the <figure-callout id="1000" label="above process" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">above process</figure-callout> <b>1000</b> is only an example where the singularity is the burr signal, and when the singularity is a trough signal, each of the above steps (e.g., <figure-callout id="1010" label="step" filenames="US20230210402A1-20230706-D00008.png" state="{{state}}">step</figure-callout> <b>1010</b>, <figure-callout id="1020" label="step" filenames="US20230210402A1-20230706-D00008.png" state="{{state}}">step</figure-callout> <b>1020</b>, <figure-callout id="1030" label="step" filenames="US20230210402A1-20230706-D00008.png" state="{{state}}">step</figure-callout> <b>1030</b>, etc.) and the technical schemes may be adjusted or other methods may be used to perform the signal correction processing. However, these amendments and changes are still within the scope of the present disclosure.</div>
    </li> <li> <para-num num="[0154]"> </para-num> <div id="p-0155" num="0154" class="description-line">In some embodiments, the signal correction processing may further be performed on the singularity of the electromyographic signal by the other methods, e.g., a high-pass method, a low-pass method, a band-pass method, a wavelet transform reconstruction method, etc. In some embodiments, for an application scenario where a low-frequency signal is not sensitive, a 100 Hz high-pass filter may be used for a removal of the burr signal. In some embodiments, in addition to the signal correction processing of the electromyographic signal, the other methods of the signal processing of the electromyographic signal, such as a filtering processing, a signal amplification, a phase adjustment, etc., may also be performed. In some embodiments, the electromyographic signal of the user collected by the electromyographic sensor may be converted into a digital electromyographic signal by an analog-to-digital converter (ADC), and the converted digital electromyographic signal may be subjected to a filtering process, which may filter out an industrial frequency signal and its harmonic signal, etc. In some embodiments, the processing of the electromyographic signal may further include removing motion artifacts of the user. The motion artifacts here refer to signal noises generated by a relative movement of the muscles at the position to be measured relative to the electromyographic module during an obtaining process of the electromyographic signal while the user in motion.</div>
    </li> <li> <para-num num="[0155]"> </para-num> <div id="p-0156" num="0155" class="description-line">In some embodiments, the attitude signal may be obtained by the attitude sensor on the <figure-callout id="130" label="wearable device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">wearable device</figure-callout> <b>130</b>. The attitude sensor on the <figure-callout id="130" label="wearable device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">wearable device</figure-callout> <b>130</b> may be distributed on the limb areas (e.g., the arms, the legs, etc.), the trunk areas (e.g., the chest, the abdomen, the back, the waist, etc.), and the head, etc. The attitude sensor may enable the collection of the attitude signal from other parts of the body such as the limb parts and the trunk parts. In some embodiments, the attitude sensor may be a sensor of an attitude and heading reference system (AHRS) with an attitude fusion algorithm. The attitude fusion algorithm may fuse data from a nine-axis inertial measurement unit (IMU) with a three-axis acceleration sensor, a three-axis angular velocity sensor, and a three-axis geomagnetic sensor into Euler angles or quaternions to obtain the attitude signal of the user&#39;s body part where the attitude sensor is located. In some embodiments, the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> and/or the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b> may determine the feature information corresponding to the attitude based on the attitude signal. In some embodiments, the feature information corresponding to the attitude signal may include, but is not limited to, the value of angular velocity, the direction of angular velocity, the acceleration value of angular velocity, etc. In some embodiments, the attitude sensor may be a strain sensor. The strain sensor may obtain a bending direction and a bending angle at the user&#39;s joints, thereby obtaining the attitude signal during the user&#39;s motion. For example, the strain sensor may be set at the knee joint of the user. When the user is in motion, the user&#39;s body part acts on the strain sensor, and the bending direction and the bending angle at the knee joint of the user may be determined based on the change in resistance or length of the strain sensor, thereby obtaining the attitude signal of the user&#39;s leg. In some embodiments, the attitude sensor may also include a fiber optic sensor, and the attitude signal may be represented by a change in direction after bending of a fiber from the fiber optic sensor. In some embodiments, the attitude sensor may also be a magnetic flux sensor, and the attitude signal may be represented by transformation of the magnetic flux. It should be noted that the type of attitude sensor is not limited to the above sensors, but can also be other sensors, the sensors that can obtain the user&#39;s attitude signal are within the scope of the attitude sensor of the present disclosure.</div>
    </li> <li> <para-num num="[0156]"> </para-num> <div id="p-0157" num="0156" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>11</b> </figref> is a flowchart of an exemplary process for determining feature information corresponding to an attitude signal according to some embodiments of the present disclosure. As shown in <figref idrefs="DRAWINGS">FIG. <b>11</b> </figref>, the <figure-callout id="1100" label="process" filenames="US20230210402A1-20230706-D00009.png" state="{{state}}">process</figure-callout> <b>1100</b> may include following steps.</div>
    </li> <li> <para-num num="[0157]"> </para-num> <div id="p-0158" num="0157" class="description-line">In <figure-callout id="1110" label="step" filenames="US20230210402A1-20230706-D00009.png" state="{{state}}">step</figure-callout> <b>1110</b>, a target coordinate system and a conversion relationship between the target coordinate system and at least one original coordinate system may be obtained.</div>
    </li> <li> <para-num num="[0158]"> </para-num> <div id="p-0159" num="0158" class="description-line">In some embodiments, the step may be performed by the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> and/or the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b>. In some embodiments, the original coordinate system may be a coordinate system corresponding to the attitude sensor set on the human body. When the user uses the <figure-callout id="130" label="wearable device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">wearable device</figure-callout> <b>130</b>, each attitude sensor on the <figure-callout id="130" label="wearable device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">wearable device</figure-callout> <b>130</b> is distributed on different parts of the human body, so that installation angles of the attitude sensors are different, and the attitude sensors in different parts use their own coordinate systems as the original coordinate systems, so the attitude sensors in different parts have different original coordinate systems. In some embodiments, an obtained attitude signal of the each attitude sensor may be represented in its corresponding original coordinate system. By transforming the attitude signal in different original coordinate systems into a same coordinate system (e.g., the target coordinate system), it is easy to determine a relative motion between different parts of the human body. In some embodiments, the target coordinate system refers to a human coordinate system established based on the human body. For example, a length direction of the human torso (i.e., a direction perpendicular to a transverse plane of the body) may be used as the Z-axis, an anterior-posterior direction of the human torso (i.e., a direction perpendicular to the coronal plane of the body) may be used as the X-axis, and a left-right direction of the human torso (i.e., a direction perpendicular to the sagittal plane of the body) may be used as the Y-axis in the target coordinate system. In some embodiments, there is a conversion relationship between the target coordinate system and the original coordinate system by which coordinate information in the original coordinate system may be converted to coordinate information in the target coordinate system. In some embodiments, the conversion relationship may be expressed as one or more rotation matrices. More descriptions for determining the conversion relationship between the target coordinate system and the original coordinate system may be found in <figref idrefs="DRAWINGS">FIG. <b>13</b> </figref> of the present disclosure and its relevant descriptions.</div>
    </li> <li> <para-num num="[0159]"> </para-num> <div id="p-0160" num="0159" class="description-line">In <figure-callout id="1120" label="step" filenames="US20230210402A1-20230706-D00009.png" state="{{state}}">step</figure-callout> <b>1120</b>, coordinate information in the at least one original coordinate system may be converted to coordinate information in the target coordinate system based on the conversion relationship.</div>
    </li> <li> <para-num num="[0160]"> </para-num> <div id="p-0161" num="0160" class="description-line">In some embodiments, the step may be performed by the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> and/or the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b>. The coordinate information in the original coordinate system may be three-dimensional coordinate information in the original coordinate system. The coordinate information in the target coordinate system may be the three-dimensional coordinate information in the target coordinate system. Merely as way of exemplary illustration, the coordinate information v<sub>1 </sub>in the original coordinate system may be converted to the coordinate information v<sub>2 </sub>in the target coordinate system according to the conversion relationship. Specifically, a conversion between the coordinate information v<sub>1 </sub>and the coordinate information v<sub>2 </sub>may be performed by using a rotation matrix. The rotation matrix here may be understood as the conversion relationship between the original coordinate system and the target coordinate system. Specifically, the coordinate information v<sub>1 </sub>in the original coordinate system may be converted to coordinate information v<sub>1</sub>1 using a first rotation matrix, the coordinate information v<sub>1</sub>1 may be converted to coordinate information v<sub>1</sub>2 using a second rotation matrix, and the coordinate information v<sub>1</sub>2 may be converted to coordinate information v<sub>1</sub>3 using a third rotation matrix. The coordinate information v<sub>1</sub>3 may be the coordinate information v<sub>2 </sub>in the target coordinate system. It should be noted that the rotation matrices are not limited to the above first rotation matrix, the second rotation matrix and the third rotation matrix, but may also include fewer or more rotation matrices. In some alternative embodiments, the rotation matrix may be a rotation matrix or a combination of a plurality of rotation matrices.</div>
    </li> <li> <para-num num="[0161]"> </para-num> <div id="p-0162" num="0161" class="description-line">In <figure-callout id="1130" label="step" filenames="US20230210402A1-20230706-D00009.png" state="{{state}}">step</figure-callout> <b>1130</b>, the feature information corresponding to the attitude signal may be determined based on the coordinate information in the target coordinate system.</div>
    </li> <li> <para-num num="[0162]"> </para-num> <div id="p-0163" num="0162" class="description-line">In some embodiments, the step may be performed by the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> and/or the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b>. In some embodiments, determining, based on the coordinate information in the target coordinate system, the feature information corresponding to the attitude signal may include determining, based on a plurality of coordinate information in the target coordinate system of the user during motion, the feature information corresponding to the attitude signal of the user. For example, when the user performs a seated chest press, the user&#39;s arm may correspond to the first coordinate information in the target coordinate system when the user&#39;s arm is held forward, and the user&#39;s arm may correspond to the second coordinate information in the target coordinate system when the user&#39;s arm is opened in a same plane as the torso. Based on the first coordinate information and the second coordinate information, the feature information, e.g., the angular velocity, the angular velocity direction, and the acceleration value of the angular velocity, corresponding to the attitude signal may be determined.</div>
    </li> <li> <para-num num="[0163]"> </para-num> <div id="p-0164" num="0163" class="description-line">It should be noted that the above description of the <figure-callout id="1100" label="process" filenames="US20230210402A1-20230706-D00009.png" state="{{state}}">process</figure-callout> <b>1100</b> is for example and illustration purposes only and does not limit the scope of application of the present disclosure. For those skilled in the art, various amendments and changes can be made to process <b>1100</b> under the guidance of the present disclosure. However, these amendments and changes are still within the scope of the present disclosure.</div>
    </li> <li> <para-num num="[0164]"> </para-num> <div id="p-0165" num="0164" class="description-line">In some embodiments, the relative motion between different motion parts of the user&#39;s body may be determined based on the feature information corresponding to the attitude sensors located at the different motion parts of the user&#39;s body. For example, by using the feature information corresponding to the attitude sensor at the user&#39;s arm and the feature information corresponding to the attitude sensor at the user&#39;s torso, the relative motion between the user&#39;s arm and torso during motion may be determined. <figref idrefs="DRAWINGS">FIG. <b>12</b> </figref> is a flowchart of an exemplary process for determining relative motion between different motion parts of a user according to some embodiments of the present disclosure. As shown in <figref idrefs="DRAWINGS">FIG. <b>12</b> </figref>, the <figure-callout id="1200" label="process" filenames="US20230210402A1-20230706-D00010.png" state="{{state}}">process</figure-callout> <b>1200</b> may include following steps.</div>
    </li> <li> <para-num num="[0165]"> </para-num> <div id="p-0166" num="0165" class="description-line">In <figure-callout id="1210" label="step" filenames="US20230210402A1-20230706-D00010.png" state="{{state}}">step</figure-callout> <b>1210</b>, feature information corresponding to at least two sensors respectively may be determined based on conversion relationships between different original coordinate systems and a target coordinate system.</div>
    </li> <li> <para-num num="[0166]"> </para-num> <div id="p-0167" num="0166" class="description-line">In some embodiments, the step may be performed by the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> and/or the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b>. In some embodiments, due to different installation positions of different sensors at the human body, there are different conversion relationships between the original coordinate systems corresponding to the sensors and the target coordinate system. In some embodiments, the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b> may convert the coordinate information in the original coordinate systems corresponding to the sensors at different parts of the user (e.g., small arm, large arm, torso, etc.) to the coordinate information in the target coordinate system, respectively, so that the feature information corresponding to at least two sensors may be determined respectively. More descriptions of the conversion of the coordinate information in the original coordinate system to coordinate information in the target coordinate system may be found elsewhere in the present disclosure, e.g., <figref idrefs="DRAWINGS">FIG. <b>11</b> </figref>, which may not be repeated herein.</div>
    </li> <li> <para-num num="[0167]"> </para-num> <div id="p-0168" num="0167" class="description-line">In <figure-callout id="1220" label="step" filenames="US20230210402A1-20230706-D00010.png" state="{{state}}">step</figure-callout> <b>1220</b>, a relative motion between different motion parts of a user may be determined based on the feature information corresponding to the at least two sensors respectively.</div>
    </li> <li> <para-num num="[0168]"> </para-num> <div id="p-0169" num="0168" class="description-line">In some embodiments, the step may be performed by the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> and/or the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b>. In some embodiments, a motion part may refer to a limb on the human body that can move independently, for example, a small arm, a large arm, a small leg, a thigh, etc. Merely as way of exemplary illustration, when the user performs an arm lifting dumbbell, the coordinate information in the target coordinate system corresponding to the sensor set at the small arm part and the coordinate information in the target coordinate system corresponding to the sensor set at the large arm part may be combined to determine the relative motion between the small arm and the large arm of the user, thereby determining the arm lifting dumbbell movement of the user.</div>
    </li> <li> <para-num num="[0169]"> </para-num> <div id="p-0170" num="0169" class="description-line">In some embodiments, a same motion part of the user may be arranged with a plurality of sensors of the same or different types, and the coordinate information in the original coordinate systems corresponding to a plurality of sensors of same or different types may be converted to the coordinate information in the target coordinate system, respectively. For example, a plurality of sensors of the same or different types may be arranged at different locations of the user&#39;s small arm part, and a plurality of coordinates in the target coordinate systems corresponding to a plurality of sensors of the same or different types may simultaneously represent the movement of the user&#39;s small arm part. For example, the coordinate information in the target coordinate systems corresponding to a plurality of sensors of the same type may be averaged, thereby improving the accuracy of the coordinate information of the motion parts during the user&#39;s motion. For example, the coordinate information in the target coordinate system may be obtained by performing a fusion algorithm (e.g., Kalman filtering, etc.) on the coordinate information in coordinate systems corresponding to a plurality sensors of different types.</div>
    </li> <li> <para-num num="[0170]"> </para-num> <div id="p-0171" num="0170" class="description-line">It should be noted that the above description of the <figure-callout id="1100" label="process" filenames="US20230210402A1-20230706-D00009.png" state="{{state}}">process</figure-callout> <b>1100</b> is for example and illustration purposes only and does not limit the scope of application of the present disclosure. For those skilled in the art, various amendments and changes can be made to process <b>1100</b> under the guidance of the present disclosure. However, these amendments and changes are still within the scope of the present disclosure.</div>
    </li> <li> <para-num num="[0171]"> </para-num> <div id="p-0172" num="0171" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>13</b> </figref> is a flowchart of an exemplary process for determining a conversion relationship between an original coordinate system and a specific coordinate system according to some embodiments of the present disclosure. In some embodiments, the process for determining the conversion relationship between the original coordinate system and the specific coordinate system may also be referred to as a calibration process. As shown in <figref idrefs="DRAWINGS">FIG. <b>13</b> </figref>, the <figure-callout id="1300" label="process" filenames="US20230210402A1-20230706-D00011.png" state="{{state}}">process</figure-callout> <b>1300</b> may include following steps.</div>
    </li> <li> <para-num num="[0172]"> </para-num> <div id="p-0173" num="0172" class="description-line">In <figure-callout id="1310" label="step" filenames="US20230210402A1-20230706-D00011.png" state="{{state}}">step</figure-callout> <b>1310</b>, a specific coordinate system may be constructed.</div>
    </li> <li> <para-num num="[0173]"> </para-num> <div id="p-0174" num="0173" class="description-line">In some embodiments, the step may be performed by the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> and/or the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b>. In some embodiments, the conversion relationship between at least one original coordinate system and the target coordinate system may be obtained by the calibration process. The specific coordinate system may refer to a reference coordinate system configured to determine the conversion relationship between the original coordinate system and the target coordinate system during the calibration process. In some embodiments, in a constructed specific coordinate system, a length direction of the torso when the human body is standing may be determined as the Z-axis, a front-to-back direction of the human body may be determined as the X-axis, and z left-to-right direction of the human torso may be determined as the Y-axis. In some embodiments, the specific coordinate system may be related to the orientation of the user during the calibration process. For example, if the user&#39;s body is facing a fixed direction (e.g., north) during the calibration process, the front (north) direction of the body may be the X-axis. In the calibration process, the X axis direction may be fixed.</div>
    </li> <li> <para-num num="[0174]"> </para-num> <div id="p-0175" num="0174" class="description-line">In <figure-callout id="1320" label="step" filenames="US20230210402A1-20230706-D00011.png" state="{{state}}">step</figure-callout> <b>1320</b>, first coordinate information in at least one original coordinate system when a user is in a first pose may be obtained.</div>
    </li> <li> <para-num num="[0175]"> </para-num> <div id="p-0176" num="0175" class="description-line">In some embodiments, the step may be performed by the obtaining <figure-callout id="210" label="module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">module</figure-callout> <b>210</b>. The first pose may be a pose that the user approximately remains standing. The obtaining module <b>210</b> (e.g., the sensor) may obtain the first coordinate information in the original coordinate system based on the user&#39;s first pose.</div>
    </li> <li> <para-num num="[0176]"> </para-num> <div id="p-0177" num="0176" class="description-line">In <figure-callout id="1330" label="step" filenames="US20230210402A1-20230706-D00011.png" state="{{state}}">step</figure-callout> <b>1330</b>, second coordinate information in the at least one original coordinate system when the user is in a second pose may be obtained.</div>
    </li> <li> <para-num num="[0177]"> </para-num> <div id="p-0178" num="0177" class="description-line">In some embodiments, the step may be performed by the obtaining <figure-callout id="210" label="module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">module</figure-callout> <b>210</b>. The second pose may be a pose that the user&#39;s body part (e.g., the arm) where the sensor is located is tilted forward. In some embodiments, the obtaining module <b>210</b> (e.g., the sensor) may obtain the second coordinate information in the original coordinate system based on the user&#39;s second pose (e.g., a forward tilting pose).</div>
    </li> <li> <para-num num="[0178]"> </para-num> <div id="p-0179" num="0178" class="description-line">In <figure-callout id="1340" label="step" filenames="US20230210402A1-20230706-D00011.png" state="{{state}}">step</figure-callout> <b>1340</b>, a relationship between the at least one original coordinate system and the specific coordinate system may be determined based on the first coordinate information, the second coordinate information, and the specific coordinate system.</div>
    </li> <li> <para-num num="[0179]"> </para-num> <div id="p-0180" num="0179" class="description-line">In some embodiments, the step may be performed by the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> and/or the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b>. In some embodiments, a first rotation matrix may be determined based on the first coordinate information corresponding to the first pose. In the first pose, since the Euler angles in the X direction and the Y direction of the specific coordinate system in a ZYX rotation order are 0, and the Euler angles in the X direction and the Y direction of the original coordinate system are not necessarily 0, then the first rotation matrix is the rotation matrix obtained by rotating the original coordinate system in the reverse direction around the X-axis and then around the Y-axis. In some embodiments, a second rotation matrix may be determined based on the second coordinate information of the second pose (e.g., the body part where the sensor is located is tilted forward). Specifically, in the second pose, it is known that the Euler angles of the specific coordinate system in the Y direction and a Z<sub>3 </sub>direction are 0 in the ZYZ rotation order, and the Euler angles of the original coordinate system in the Y direction and the Z<sub>3 </sub>direction are not necessarily 0, then the second rotation matrix is the rotation matrix obtained by rotating the original coordinate system in the reverse direction around the Y direction and then around the Z<sub>3 </sub>direction. The conversion relationship between the original coordinate system and the specific coordinate system may be determined based on the first rotation matrix and the second rotation matrix. In some embodiments, when there are a plurality of original coordinate systems (sensors), the conversion relationship between each original coordinate system and the specific coordinate system may be determined according to the above method.</div>
    </li> <li> <para-num num="[0180]"> </para-num> <div id="p-0181" num="0180" class="description-line">It should be noted that the first pose is not limited to an approximately standing pose, and the second pose is not limited to the pose that the user&#39;s body part (e.g., the arm) where the sensor is located is tilted forward. The first and second poses herein may be approximated as being stationary during the calibration process. In some embodiments, the first pose and/or the second pose may also be a dynamic pose during the calibration process. For example, the user&#39;s walking attitude may be a relatively fixed attitude, an angle and an angular velocity of the arms, the legs and the feet during walking may be extracted to recognize a movement, such as a forward stride, a forward arm swing, or the like. The user&#39;s forward walking attitude may be used as the second pose in the calibration process. In some embodiments, the second pose is not limited to one movement, and a plurality of movements may also be extracted as the second pose. For example, coordinate information of a plurality of movements may be fused to obtain a more accurate rotation matrix.</div>
    </li> <li> <para-num num="[0181]"> </para-num> <div id="p-0182" num="0181" class="description-line">In some embodiments, the rotation matrix may be dynamically corrected during the calibration process using one or more signal processing algorithms (e.g., using a Kalman filtering algorithm) to obtain a better transformation matrix in the whole calibration process.</div>
    </li> <li> <para-num num="[0182]"> </para-num> <div id="p-0183" num="0182" class="description-line">In some embodiments, a machine learning algorithm, or other algorithms may be used for automatic recognition of specific movements to update the rotation matrix in real time. For example, if the machine learning algorithm recognizes that a current user is walking, or standing, the calibration process may be automatically started. In this case, the wearable device no longer need an explicit calibration process, and the rotation matrix may be dynamically updated when the user uses the wearable device.</div>
    </li> <li> <para-num num="[0183]"> </para-num> <div id="p-0184" num="0183" class="description-line">In some embodiments, an installation position of the attitude sensor may be relatively fixed and a rotation matrix may be preset, which may make the recognition process of the specific movement more accurate. Further, the rotation matrix may continue to be corrected during the user&#39;s use of the wearable device to make the obtained rotation matrix closer to the real situation.</div>
    </li> <li> <para-num num="[0184]"> </para-num> <div id="p-0185" num="0184" class="description-line">It should be noted that the above description of the <figure-callout id="1300" label="process" filenames="US20230210402A1-20230706-D00011.png" state="{{state}}">process</figure-callout> <b>1300</b> is for example and illustration purposes only, and does not limit the scope of application of the present disclosure. For those skilled in the art, various amendments and changes can be made to process <b>1300</b> under the guidance of the present disclosure. However, these amendments and changes are still within the scope of the present disclosure.</div>
    </li> <li> <para-num num="[0185]"> </para-num> <div id="p-0186" num="0185" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>14</b> </figref> is a flowchart of an exemplary process for determining a conversion relationship between an original coordinate system and a target coordinate system according to some embodiments of the present disclosure. As shown in <figref idrefs="DRAWINGS">FIG. <b>14</b> </figref>, the <figure-callout id="1400" label="process" filenames="US20230210402A1-20230706-D00012.png" state="{{state}}">process</figure-callout> <b>1400</b> may include following steps.</div>
    </li> <li> <para-num num="[0186]"> </para-num> <div id="p-0187" num="0186" class="description-line">In <figure-callout id="1410" label="step" filenames="US20230210402A1-20230706-D00012.png" state="{{state}}">step</figure-callout> <b>1410</b>, a conversion relationship between a specific coordinate system and a target coordinate system may be obtained.</div>
    </li> <li> <para-num num="[0187]"> </para-num> <div id="p-0188" num="0187" class="description-line">In some embodiments, the step may be performed by the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> and/or the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b>. In both of the specific coordinate system and the target coordinate system, a length direction of the human torso may be determined as the Z-axis. Therefore, the conversion relationship between the specific coordinate relationship and the target coordinate system may be obtained based on a conversion relationship between the X-axis of the specific coordinate system and the X-axis of the target coordinate system and a conversion relationship between the Y-axis of the specific coordinate system and the Y-axis of the target coordinate system. The principle of obtaining the conversion relationship between the specific coordinate relationship and the target coordinate system may be found in <figref idrefs="DRAWINGS">FIG. <b>13</b> </figref> and its relevant descriptions.</div>
    </li> <li> <para-num num="[0188]"> </para-num> <div id="p-0189" num="0188" class="description-line">In some embodiments, in the specific coordinate system, the length direction of the human torso may be determined as the Z-axis and a front-to-back direction of the human body may be determined as a calibrated X-axis. Since the front-to-back direction of the user&#39;s body changes during motion (e.g., a turning motion) and cannot be fixed in the calibrated coordinate system, it is necessary to determine a coordinate system that can rotate with the body, i.e., the target coordinate system. In some embodiments, the target coordinate system may change with the user&#39;s orientation, and the X-axis of the target coordinate system is always in front of the human torso.</div>
    </li> <li> <para-num num="[0189]"> </para-num> <div id="p-0190" num="0189" class="description-line">In <figure-callout id="1420" label="step" filenames="US20230210402A1-20230706-D00012.png" state="{{state}}">step</figure-callout> <b>1420</b>, a conversion relationship between at least one original coordinate system and the target coordinate system may be determined according to a conversion relationship between the at least one original coordinate system and the specific coordinate system, and the conversion relationship between the specific coordinate system and the target coordinate system.</div>
    </li> <li> <para-num num="[0190]"> </para-num> <div id="p-0191" num="0190" class="description-line">In some embodiments, the step may be performed by the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> and/or the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b>. In some embodiments, the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b> may determine the conversion relationship between the at least one original coordinate system and the target coordinate system according to the conversion relationship between the at least one original coordinate system and the specific coordinate system determined in the <figure-callout id="1300" label="process" filenames="US20230210402A1-20230706-D00011.png" state="{{state}}">process</figure-callout> <b>1300</b> and the conversion relationship between the specific coordinate system and the target coordinate system determined in <figure-callout id="1410" label="step" filenames="US20230210402A1-20230706-D00012.png" state="{{state}}">step</figure-callout> <b>1410</b>, such that the coordinate information in the original coordinate system can be converted to the coordinate information in the target coordinate system.</div>
    </li> <li> <para-num num="[0191]"> </para-num> <div id="p-0192" num="0191" class="description-line">It should be noted that the above description of the <figure-callout id="1400" label="process" filenames="US20230210402A1-20230706-D00012.png" state="{{state}}">process</figure-callout> <b>1400</b> is for example and illustration purposes only and does not limit the scope of application of the present disclosure. For those skilled in the art, various amendments and changes can be made to the <figure-callout id="1400" label="process" filenames="US20230210402A1-20230706-D00012.png" state="{{state}}">process</figure-callout> <b>1400</b> under the guidance of the present disclosure. However, these amendments and changes are still within the scope of the present disclosure.</div>
    </li> <li> <para-num num="[0192]"> </para-num> <div id="p-0193" num="0192" class="description-line">In some embodiments, the position of the attitude sensor set on the <figure-callout id="130" label="wearable device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">wearable device</figure-callout> <b>130</b> may change and/or the installation angle of the attitude sensor on the human body may be different, then the user performs the same motion, and the attitude data returned by the attitude sensor may have great differences.</div>
    </li> <li> <para-num num="[0193]"> </para-num> <div id="p-0194" num="0193" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>15</b>A</figref> is an exemplary vector coordinate diagram illustrating Euler angle data in an original coordinate system at a position of a small arm of a human body according to some embodiments of the present disclosure. A boxed part may represent the Euler angle data (the coordinate information) in the original coordinate system corresponding to the position of the small arm when the user performs the same movement. As shown in <figref idrefs="DRAWINGS">FIG. <b>15</b>A</figref>, the result of the Euler angle vector in the Z-axis direction (shown as Z in <figref idrefs="DRAWINGS">FIG. <b>15</b>A</figref>) in the boxed part are approximately in a range of 180 to (80). The result of the Euler angle vector in the Y-axis direction (shown as Y in <figref idrefs="DRAWINGS">FIG. <b>15</b>A</figref>) fluctuate approximately around 0. The result of the Euler angle vector in the X-axis direction (shown as X in <figref idrefs="DRAWINGS">FIG. <b>15</b>A</figref>) fluctuate approximately around 80. A fluctuation range here may be 20.</div>
    </li> <li> <para-num num="[0194]"> </para-num> <div id="p-0195" num="0194" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>15</b>B</figref> is an exemplary vector coordinate diagram illustrating Euler angle data in another original coordinate system at a position of a small arm of a human body according to some embodiments of the present disclosure. The boxed part may represent the Euler angle data in the original coordinate system corresponding to the other position of the small arm when the user performs the same movement (the same movement as shown in <figref idrefs="DRAWINGS">FIG. <b>15</b>A</figref>). As shown in <figref idrefs="DRAWINGS">FIG. <b>15</b>B</figref>, the result of the Euler angle vector in the Z-axis direction (shown as Z in <figref idrefs="DRAWINGS">FIG. <b>15</b>B</figref>) in the boxed part is approximately in a range of 180 to 180. The result of the Euler angle vector in the Y-axis direction (shown as Y in <figref idrefs="DRAWINGS">FIG. <b>15</b>B</figref>) fluctuate approximately around 0. The result of the Euler angle vector in the X-axis direction (shown as X in <figref idrefs="DRAWINGS">FIG. <b>15</b>B</figref>) fluctuate approximately around 150. The fluctuation range here may be 20.</div>
    </li> <li> <para-num num="[0195]"> </para-num> <div id="p-0196" num="0195" class="description-line">The Euler angle data shown in <figref idrefs="DRAWINGS">FIG. <b>15</b>A</figref> and <figref idrefs="DRAWINGS">FIG. <b>15</b>B</figref> are the Euler angle data (the coordinate information) respectively obtained in the original coordinate system when the user performs the same movement at different positions of the human small arm (it can also be understood that the installation angle of the attitude sensor at the position of the human small arm is different). Compared with <figref idrefs="DRAWINGS">FIG. <b>15</b>A</figref> and <figref idrefs="DRAWINGS">FIG. <b>15</b>B</figref>, it can be seen that, the installation angle of the attitude sensor on the human body is different, when the user performs the same movement, the Euler angle data in the original coordinate system returned by the attitude sensor may vary greatly. For example, the result of the Euler angle vector in the Z-axis direction in <figref idrefs="DRAWINGS">FIG. <b>15</b>A</figref> is approximately in the range of 180-(80), and the result of the Euler angle vector in the Z-axis direction in <figref idrefs="DRAWINGS">FIG. <b>15</b>B</figref> is approximately in the range of 180-180, which are quite different from each other.</div>
    </li> <li> <para-num num="[0196]"> </para-num> <div id="p-0197" num="0196" class="description-line">In some embodiments, the Euler angle data in the original coordinate system corresponding to sensors with different installation angles may be converted to the Euler angle data in the target coordinate system, thereby facilitating the analysis of the attitude signal of the sensors at different positions. Merely as way of exemplary illustration, a line where the left arm is located may be abstracted as a unit vector pointing from the elbow to the wrist. T unit vector may be a coordinate value in the target coordinate system. In the target coordinate system, an axis pointing to the rear of the body may be determined as the X-axis, an axis pointing to the right side of the body may be determined as the Y-axis, and an axis pointing to the top of the body may be determined as the Z-axis, which conforms to the right-handed coordinate system. For example, a coordinate value [1, 0, 0] in the target coordinate system indicates that the arm is held forward flat. A coordinate value [0, 1, 0] in the target coordinate system indicates that the arm is held flat to the left. <figref idrefs="DRAWINGS">FIG. <b>16</b>A</figref> is an exemplary vector coordinate diagram of Euler angle data in a target coordinate system at a position of a small arm of a human body according to some embodiments of the present disclosure. <figref idrefs="DRAWINGS">FIG. <b>16</b>A</figref> is a curve obtained after the Euler angle data of the small arm in the original coordinate in <figref idrefs="DRAWINGS">FIG. <b>15</b>A</figref> is converted into vector coordinates in the target coordinate system. The boxed part may represent the Euler angle data in the target coordinate system at the position of the small arm when the user performs the same movement. As shown in <figref idrefs="DRAWINGS">FIG. <b>16</b>A</figref>, a small arm vector [x, y, z] in the boxed part moves reciprocally between a first position and a second position, wherein the first position is [0.2, 0.9, 0.38] and the second position is [0.1, 0.95, 0.3]. It should be noted that for each reciprocal movement of the small arm, there may be a small deviation between the first position and the second position.</div>
    </li> <li> <para-num num="[0197]"> </para-num> <div id="p-0198" num="0197" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>16</b>B</figref> is an exemplary vector coordinate diagram of Euler angle data in a target coordinate system at another location of a small arm of a human body according to some embodiments of the present disclosure. <figref idrefs="DRAWINGS">FIG. <b>16</b>B</figref> is a curve obtained after the Euler angle data of the small arm in the original coordinate in <figref idrefs="DRAWINGS">FIG. <b>15</b>B</figref> is converted into vector coordinates in the target coordinate system. The boxed part may represent the Euler angle data in the target coordinate system at another location of the small arm when the user performs the same movement (the same movement as the movement shown in <figref idrefs="DRAWINGS">FIG. <b>16</b>A</figref>). As shown in <figref idrefs="DRAWINGS">FIG. <b>16</b>B</figref>, a small arm vector [x, y, z] reciprocates between the first position and the second position similarly, wherein the first position is [<b>0</b>.<b>2</b>, 0.9, 0.38] and the second position is [0.1, 0.95, 0.3].</div>
    </li> <li> <para-num num="[0198]"> </para-num> <div id="p-0199" num="0198" class="description-line">Combining <figref idrefs="DRAWINGS">FIG. <b>15</b>A</figref> to <figref idrefs="DRAWINGS">FIG. <b>16</b>B</figref>, it can be seen from <figref idrefs="DRAWINGS">FIGS. <b>15</b>A and <b>15</b>B</figref> that the Euler angles in the original coordinate system have a great difference in the range of values and the fluctuation form due to the different installation positions of the two attitude sensors. After converting the coordinate information of the original coordinate system corresponding to the two attitude sensors to the vector coordinates corresponding to the target coordinate system (e.g., the vector coordinates in <figref idrefs="DRAWINGS">FIGS. <b>16</b>A and <b>16</b>B</figref>) respectively, two approximately same vector coordinates may be obtained. That is, the method can make the feature information corresponding to the attitude signal not affected by the sensor installation position. Specifically, in <figref idrefs="DRAWINGS">FIG. <b>16</b>A</figref> and <figref idrefs="DRAWINGS">FIG. <b>16</b>B</figref>, it can be seen that the two attitude sensors are installed at different positions on the small arm, and after the coordinate conversion, the same vector coordinates may be obtained, i.e., it can represent the process of the arm switching back and forth between two states of state <b>1</b> (arm held flat to the right) and state <b>2</b> (arm held flat to the front) during the process of the seated chest press.</div>
    </li> <li> <para-num num="[0199]"> </para-num> <div id="p-0200" num="0199" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>17</b> </figref> is an exemplary vector coordinate diagram of a limb vector in a target coordinate system according to some embodiments of the present disclosure. As shown in <figref idrefs="DRAWINGS">FIG. <b>17</b> </figref>, vector coordinates of attitude sensors in a target coordinate system at positions of the left small arm (<b>17</b>-<b>1</b>), the right small arm (<b>17</b>-<b>2</b>), the left large arm (<b>17</b>-<b>3</b>), the right large arm (<b>17</b>-<b>4</b>), and the torso (<b>17</b>-<b>5</b>) of the human body may be represented from top to bottom, respectively. The vector coordinates of each position (e.g., <b>17</b>-<b>1</b>, <b>17</b>-<b>2</b>, <b>17</b>-<b>3</b>, <b>17</b>-<b>4</b>, <b>17</b>-<b>5</b>) in the target coordinate system during motion of the human are illustrated in <figref idrefs="DRAWINGS">FIG. <b>17</b> </figref>. The first 4200 points in <figref idrefs="DRAWINGS">FIG. <b>17</b> </figref> may be calibration movements required for limb calibration, such as standing, torso forward, arm forward, arm side planks, etc. By using the calibration movements corresponding to the first 4200 points to calibrate, raw data collected by the attitude sensors may be converted to the Euler angles in the target coordinate system. To facilitate the analysis of the data, it may further be converted into the coordinate vector of the arm vector in the target coordinate system. In the target coordinate system, the X-axis may point to the front of the torso, the Y-axis may point to the left of the torso, and the Z-axis may point to the top of the torso. The reciprocal movements in <figref idrefs="DRAWINGS">FIG. <b>17</b> </figref> from left to right are <figure-callout id="1" label="movement" filenames="US20230210402A1-20230706-D00013.png,US20230210402A1-20230706-D00014.png" state="{{state}}">movement</figure-callout> <b>1</b>, <figure-callout id="2" label="movement" filenames="US20230210402A1-20230706-D00015.png,US20230210402A1-20230706-D00016.png" state="{{state}}">movement</figure-callout> <b>2</b>, <figure-callout id="3" label="movement" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">movement</figure-callout> <b>3</b>, <figure-callout id="4" label="movement" filenames="US20230210402A1-20230706-D00015.png,US20230210402A1-20230706-D00025.png" state="{{state}}">movement</figure-callout> <b>4</b>, <figure-callout id="5" label="movement" filenames="US20230210402A1-20230706-D00015.png,US20230210402A1-20230706-D00016.png" state="{{state}}">movement</figure-callout> <b>5</b>, and <figure-callout id="6" label="movement" filenames="US20230210402A1-20230706-D00015.png" state="{{state}}">movement</figure-callout> <b>6</b>, which are seated chest press, high pull-down, seated chest thrust, seated shoulder thrust, barbell dip head curl, and seated chest press, respectively. As shown in <figref idrefs="DRAWINGS">FIG. <b>17</b> </figref>, different movements have different movement patterns, which may be clearly recognized by using the limb vectors. At the same time, the same movement also has good repeatability. For example, the <figure-callout id="1" label="movement" filenames="US20230210402A1-20230706-D00013.png,US20230210402A1-20230706-D00014.png" state="{{state}}">movement</figure-callout> <b>1</b> and the <figure-callout id="6" label="movement" filenames="US20230210402A1-20230706-D00015.png" state="{{state}}">movement</figure-callout> <b>6</b> both represent the seated chest press, and the curves of these two movements have good repeatability.</div>
    </li> <li> <para-num num="[0200]"> </para-num> <div id="p-0201" num="0200" class="description-line">In some embodiments, the attitude data (e.g., the Euler angle, the angular velocity, etc.) directly output by a module of the original coordinate system may be converted to the attitude data in the target coordinate system according to <figure-callout id="1300" label="process" filenames="US20230210402A1-20230706-D00011.png" state="{{state}}">process</figure-callout> <b>1300</b> and <figure-callout id="1400" label="process" filenames="US20230210402A1-20230706-D00012.png" state="{{state}}">process</figure-callout> <b>1400</b>, so that highly consistent attitude data (e.g., the Euler angle, the angular velocity, the limb vector coordinate, etc.) may be obtained.</div>
    </li> <li> <para-num num="[0201]"> </para-num> <div id="p-0202" num="0201" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>18</b>A</figref> is a diagram illustrating an exemplary coordinate vector of an original angular velocity according to some embodiments of the present disclosure. The original angular velocity may be understood as the conversion of the Euler angle data in the original coordinate systems corresponding to the sensors with different installation angles to the Euler angle data in the target coordinate system. In some embodiments, factors such as jitter during the motion of the user may affect the result of the angular velocity in the attitude data. As shown in <figref idrefs="DRAWINGS">FIG. <b>18</b>A</figref>, the original angular velocity shows a more obvious unsmooth curve in its vector coordinate curve under an influence of jitter, etc. For example, a presence of an abrupt signal in the vector coordinate curve of the original angular velocity makes the vector coordinate curve of the original angular velocity unsmooth. In some embodiments, due to the impact of jitter, etc., on the angular velocity result, it is necessary to correct the jittered angular velocity to obtain a smooth vector coordinate curve. In some embodiments, the original angular velocity may be filtered using a 1 Hz-3 Hz low-pass filtering method. <figref idrefs="DRAWINGS">FIG. <b>18</b>B</figref> is a diagram illustrating exemplary results of an angular velocity after filtering processing according to some embodiments of the present disclosure. As shown in <figref idrefs="DRAWINGS">FIG. <b>18</b>B</figref>, after performing the 1 Hz-3 Hz low-pass filtering on the original angular velocity, the effect of jitter and other effects on the angular velocity (e.g., abrupt signals) may be eliminated, so that the vector coordinate curve corresponding to the angular velocity may be displayed smoother. In some embodiments, performing the low-pass filtering from 1 Hz to 3 Hz on the angular velocity may effectively prevent the effect of jitter, etc., on the attitude data (e.g., the Euler angle, the angular velocity, etc.), so as to facilitate the subsequent signal segmentation process. In some embodiments, the filtering process may also filter out an industrial frequency signal and its harmonic wave signal, burr signal, etc., from the movement signal. It should be noted that low-pass filtering at 1 Hz-3 Hz introduces time delay, which makes a movement point of the attitude signal and a movement point of a real electromyographic signal misaligned in time. Therefore, the time delay generated during the low-pass filtering process may be subtracted from the vector coordinate curve after the low-pass filtering processing, to ensure the synchronization of the attitude signal and the electromyographic signal in time. In some embodiments, the time delay may be associated with a center frequency of the filter. When the attitude signal and the electromyographic signal are processed with different filters, the time delay may be adjusted adaptively according to the center frequency of the filter. In some embodiments, since the angular range of the Euler angle is [480, +180], an obtained Euler angle may have a change of 180 to +180 or +180 to 180 when an actual Euler angle is not in this angular range. For example, when the angle is 181, the Euler angle changes to 179. In the practical application, the angle change may affect the determination of the angle difference, and it is necessary to correct the angle change first.</div>
    </li> <li> <para-num num="[0202]"> </para-num> <div id="p-0203" num="0202" class="description-line">In some embodiments, a movement recognition model may also be used to analyze the user&#39;s movement signal or the feature information corresponding to the movement signal, so as to recognize the user&#39;s movement. In some embodiments, the movement recognition model may include a trained machine learning model configured to recognize the user&#39;s movement. In some embodiments, the movement recognition model may include one or more machine learning models. In some embodiments, the movement recognition model may include, but is not limited to, one or more of a machine learning model that classifies the user&#39;s movement signal, a machine learning model that recognizes the movement quality of the user, a machine learning model that recognizes the number of movements of the user, and a machine learning model that recognizes a fatigue index of the user performing the movement. In some embodiments, the machine learning model may include one or more of a linear classification model (LR), a support vector machine model (SVM), a plain Bayesian model (NB), a K-nearest neighbor model (KNN), a decision tree model (DT), a random forest/a gradient boosting decision tree (RF/GDBT, etc.), etc. More descriptions regarding the movement recognition model may be found elsewhere in the present disclosure, such as <figref idrefs="DRAWINGS">FIG. <b>20</b> </figref> and its relevant descriptions.</div>
    </li> <li> <para-num num="[0203]"> </para-num> <div id="p-0204" num="0203" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>19</b> </figref> is a flowchart illustrating an exemplary motion monitoring and feedback method according to some embodiments of the present disclosure. As shown in <figref idrefs="DRAWINGS">FIG. <b>19</b> </figref>, the <figure-callout id="1900" label="process" filenames="US20230210402A1-20230706-D00017.png" state="{{state}}">process</figure-callout> <b>1900</b> may include the following steps.</div>
    </li> <li> <para-num num="[0204]"> </para-num> <div id="p-0205" num="0204" class="description-line">In <figure-callout id="1910" label="step" filenames="US20230210402A1-20230706-D00017.png" state="{{state}}">step</figure-callout> <b>1910</b>, a movement signal during a motion of a user may be obtained.</div>
    </li> <li> <para-num num="[0205]"> </para-num> <div id="p-0206" num="0205" class="description-line">In some embodiments, the step may be performed by the obtaining <figure-callout id="210" label="module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">module</figure-callout> <b>210</b>. In some embodiments, the movement signal may at least include feature information corresponding to an electromyographic signal and feature information corresponding to an attitude signal. The movement signal may refer to human body parameter information during the motion of the user. In some embodiments, the human body parameter information may include, but is not limited to, the electromyographic signal, the attitude signal, a heart rate signal, a temperature signal, a humidity signal, a blood oxygen concentration, or the like, or any combination thereof. In some embodiments, the movement signal may at least include the electromyographic signal and the attitude signal. In some embodiments, an electromyographic sensor in the obtaining <figure-callout id="210" label="module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">module</figure-callout> <b>210</b> may collect the electromyographic signal during the motion of the user, and an attitude sensor in the obtaining <figure-callout id="210" label="module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">module</figure-callout> <b>210</b> may collect the attitude signal during the motion of the user.</div>
    </li> <li> <para-num num="[0206]"> </para-num> <div id="p-0207" num="0206" class="description-line">In <figure-callout id="1920" label="step" filenames="US20230210402A1-20230706-D00017.png" state="{{state}}">step</figure-callout> <b>1920</b>, a movement of the motion of the user may be monitored based on the movement signal through a movement recognition model and a movement feedback may be performed based on an output result of the movement recognition model.</div>
    </li> <li> <para-num num="[0207]"> </para-num> <div id="p-0208" num="0207" class="description-line">In some embodiments, the step may be performed by the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> and/or the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b>. In some embodiments, the output result of the movement recognition model may include, but is not limited to, a movement type, a movement quality, a movement quantity, a fatigue index, or the like, or any combination thereof. For example, the movement recognition model may recognize the movement type of the user as the seated chest press based on the movement signal. As another example, one machine learning model of the movement recognition model may first recognize the movement type of the user as the seated chest press based on the movement signal, and another machine learning model of the movement recognition model may output the movement quality of the user as a standard movement or an incorrect movement according to the movement signal (e.g., amplitude information, the frequency information of the electromyographic signal, and/or an angular velocity, an angular velocity direction, and an acceleration value of angular velocity of the attitude signal). In some embodiments, the movement feedback may include sending prompt information. In some embodiments, the prompt information may include, but is not limited to, a voice prompt, a text prompt, an image prompt, a video prompt, etc. For example, if the output result of the movement recognition model is the incorrect movement, the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b> may control the <figure-callout id="130" label="wearable device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">wearable device</figure-callout> <b>130</b> or the mobile <figure-callout id="140" label="terminal device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">terminal device</figure-callout> <b>140</b> to send the voice prompt (e.g., information such as nonstandard movement) to the user to remind the user to adjust a fitness movement in time. As another example, if the output result of the movement recognition model is the standard movement, the <figure-callout id="130" label="wearable device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">wearable device</figure-callout> <b>130</b> or the mobile <figure-callout id="140" label="terminal device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">terminal device</figure-callout> <b>140</b> may not send the prompt information, or send prompt information such as standard movement. In some embodiments, the motion feedback may also include the <figure-callout id="130" label="wearable device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">wearable device</figure-callout> <b>130</b> stimulating a corresponding part of the motion of the user. For example, a component of the <figure-callout id="130" label="wearable device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">wearable device</figure-callout> <b>130</b> may stimulate the corresponding part of the motion of the user through a manner such as a vibration feedback, an electrical stimulation feedback, a pressure feedback, etc. For example, if the output result of the movement recognition model is the incorrect movement, the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b> may control the component of the <figure-callout id="130" label="wearable device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">wearable device</figure-callout> <b>130</b> to stimulate the corresponding part of the motion of the user. In some embodiments, the movement feedback may also include outputting a motion record during the motion of the user. The motion record here may refer to the movement type, a movement time, the movement quantity, the movement quality, the fatigue index, physiological parameter information during the motion of the user, or the like, or any combination thereof. Further description regarding the movement recognition model may be found elsewhere in the present disclosure and will not be repeated herein.</div>
    </li> <li> <para-num num="[0208]"> </para-num> <div id="p-0209" num="0208" class="description-line">It should be noted that the above description regarding the <figure-callout id="1900" label="process" filenames="US20230210402A1-20230706-D00017.png" state="{{state}}">process</figure-callout> <b>1900</b> is merely provided for the purpose of illustration, and not intended to limit the scope of the present disclosure. For those skilled in the art, various amendments and changes can be made to the <figure-callout id="1900" label="process" filenames="US20230210402A1-20230706-D00017.png" state="{{state}}">process</figure-callout> <b>1900</b> under the guidance of the present disclosure. However, these amendments and changes are still within the scope of the present disclosure.</div>
    </li> <li> <para-num num="[0209]"> </para-num> <div id="p-0210" num="0209" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>20</b> </figref> is a flowchart illustrating an exemplary process for model training according to some embodiments of the present disclosure.</div>
    </li> <li> <para-num num="[0210]"> </para-num> <div id="p-0211" num="0210" class="description-line">In <figure-callout id="2010" label="step" filenames="US20230210402A1-20230706-D00018.png" state="{{state}}">step</figure-callout> <b>2010</b>, sample information may be obtained.</div>
    </li> <li> <para-num num="[0211]"> </para-num> <div id="p-0212" num="0211" class="description-line">In some embodiments, the step may be performed by the obtaining <figure-callout id="210" label="module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">module</figure-callout> <b>210</b>. In some embodiments, the sample information may include a movement signal during a motion of a professional (e.g., a fitness instructor) and/or a non-professional. For example, the sample information may include an electromyographic signal and/or an attitude signal generated by the professional and/or the non-professional while performing a same type of movement (e.g., the seated chest press). In some embodiments, the electromyographic signal and/or the attitude signal in the sample information may be subjected to a segmentation processing of the <figure-callout id="700" label="process" filenames="US20230210402A1-20230706-D00005.png" state="{{state}}">process</figure-callout> <b>700</b>, a burr processing of the <figure-callout id="900" label="process" filenames="US20230210402A1-20230706-D00007.png" state="{{state}}">process</figure-callout> <b>900</b>, and a conversion processing of the <figure-callout id="1300" label="process" filenames="US20230210402A1-20230706-D00011.png" state="{{state}}">process</figure-callout> <b>1300</b>, etc., to form at least one segment of the electromyographic signal and/or the attitude signal. The at least one segment of the electromyographic signal and/or the attitude signal may be used as an input of a machine learning model to train the machine learning model. In some embodiments, feature information corresponding to the at least one segment of the electromyographic signal and/or feature information corresponding to the attitude signal may also be used as the input of the machine learning model to train the machine learning model. For example, frequency information and amplitude information of the electromyographic signal may be used as the input of the machine learning model. As another example, an angular velocity, an angular velocity direction, and an acceleration value of angular velocity of the attitude signal may be used as the input of the machine learning model. As another example, a movement start point, a movement middle point, and a movement end point of the movement signal may be used as the input of the machine learning model. In some embodiments, the sample information may be obtained from a storage device of the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b>. In some embodiments, the sample information may be obtained from the obtaining <figure-callout id="210" label="module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">module</figure-callout> <b>210</b>.</div>
    </li> <li> <para-num num="[0212]"> </para-num> <div id="p-0213" num="0212" class="description-line">In <figure-callout id="2020" label="step" filenames="US20230210402A1-20230706-D00018.png" state="{{state}}">step</figure-callout> <b>2020</b>, a movement recognition model may be trained.</div>
    </li> <li> <para-num num="[0213]"> </para-num> <div id="p-0214" num="0213" class="description-line">The step may be performed by the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b>. In some embodiments, the movement recognition model may include one or more machine learning models. For example, the movement recognition model may include, but is not limited to, a machine learning model that classifies the movement signal of the user, a machine learning model that recognizes a movement quality of the user, a machine learning model that recognizes a movement quantity of the user, a machine learning model that recognizes a fatigue degree of the user performing the movement, or any combination thereof. In some embodiments, the machine learning model may include a linear classification model (LR), a support vector machine model (SVM), a Naive Bayesian model (NB), a K-nearest neighbor model (KNN), a decision tree model (DT), a random forest/a gradient boosting decision tree (RF/GDBT, etc.), etc.</div>
    </li> <li> <para-num num="[0214]"> </para-num> <div id="p-0215" num="0214" class="description-line">In some embodiments, training of the machine learning model may include obtaining the sample information. In some embodiments, the sample information may include the movement signal during the motion of the professional (e.g., the fitness instructor) and/or the non-professional. For example, the sample information may include the electromyographic signal and/or the attitude signal generated by professional and/or the non-professional while performing the same type of movement (e.g., the seated chest press). In some embodiments, the electromyographic signal and/or the attitude signal in the sample information may be subjected to the segmentation processing of the <figure-callout id="700" label="process" filenames="US20230210402A1-20230706-D00005.png" state="{{state}}">process</figure-callout> <b>700</b>, the burr processing of the <figure-callout id="900" label="process" filenames="US20230210402A1-20230706-D00007.png" state="{{state}}">process</figure-callout> <b>900</b>, and the conversion processing of the <figure-callout id="1300" label="process" filenames="US20230210402A1-20230706-D00011.png" state="{{state}}">process</figure-callout> <b>1300</b>, etc., to form at least one segment of the electromyographic signal and/or the attitude signal. The at least one segment of the electromyographic signal and/or the attitude signal may be used as the input to the machine learning model to train the machine learning model. In some embodiments, the feature information corresponding to the at least one segment of the electromyographic signal and/or the feature information corresponding to the attitude signal may also be used as the input of the machine learning model to train the machine learning model. For example, the frequency information and the amplitude information of the electromyographic signal may be used as the input of the machine learning model. As another example, the angular velocity, the angular velocity direction, and the acceleration value of angular velocity of the attitude signal may be used as the input of the machine learning model. As another example, the movement start point, the movement middle point, and/or the movement end point signal (including the electromyographic signal and/or the attitude signal) corresponding to the signal may be used as the input of the machine learning model.</div>
    </li> <li> <para-num num="[0215]"> </para-num> <div id="p-0216" num="0215" class="description-line">In some embodiments, when a machine learning model that recognizes a movement type of the user is trained, the sample information from different movement types (each segment of the electromyographic signal or/and the attitude signal) may be labelled. For example, the sample information from the electromyographic signal and/or the attitude signal generated when the user performs the seated chest press may be labelled 1, where 1 is configured to represent the seated chest press. The sample information from the electromyographic signal and/or the attitude signal generated when the user performs a bicep curl may be marked as 2, where 2 is configured to represent the bicep curl. The feature information (e.g., the frequency information, the amplitude information) of the electromyographic signals and the feature information (e.g., the angular velocity, the angular velocity direction, the acceleration value of angular velocity) of the attitude signals corresponding to the different movement types may be different. The labelled sample information (e.g., the feature information corresponding to the electromyographic signal and/or the attitude signal in the sample information) may be used as the input of the machine learning model to train the machine learning model, so that the movement recognition model configured to recognize the movement type may be obtained, and by inputting the movement signal in the machine learning model, a movement type corresponding to the movement signal may be output.</div>
    </li> <li> <para-num num="[0216]"> </para-num> <div id="p-0217" num="0216" class="description-line">In some embodiments, the movement recognition model may further include the machine learning model for determining the movement quality of the user. The sample information here may include both a standard movement signal (also known as a positive sample) and a non-standard movement signal (also known as a negative sample). The standard movement signal may include a movement signal generated when the professional performs a standard movement. For example, a movement signal generated when the professional performs the seated chest press standardly may be the standard movement signal. The non-standard movement signal may include a movement signal generated when the user performs a non-standard movement (e.g., an incorrect movement). In some embodiments, the electromyographic signal and/or the attitude signal in the sample information may be subjected to the segmentation processing of the <figure-callout id="700" label="process" filenames="US20230210402A1-20230706-D00005.png" state="{{state}}">process</figure-callout> <b>700</b>, the burr processing of the <figure-callout id="900" label="process" filenames="US20230210402A1-20230706-D00007.png" state="{{state}}">process</figure-callout> <b>900</b>, and the conversion processing of the <figure-callout id="1300" label="process" filenames="US20230210402A1-20230706-D00011.png" state="{{state}}">process</figure-callout> <b>1300</b>, etc., to form at least one segment of the electromyographic signal and/or the attitude signal. The at least one segment of the electromyographic signal and/or the attitude signal may be used as the input of the machine learning model to train the machine learning model. In some embodiments, the positive sample and the negative sample of the sample information (each segment of the electromyographic signal or/the attitude signal) may be labelled. For example, the positive sample may be labelled 1 and the negative sample may be labelled 0. The 1 here may be configured to characterize a movement of the user as a standard movement, and the 0 here may be configured to characterize a movement of the user as an incorrect movement. A trained machine learning model may output different labels based on the input sample information (e.g., the positive sample, the negative sample). It should be noted that the movement recognition model may include one or more machine learning models for analyzing and recognizing the movement quality of the user. Different machine learning models may analyze and recognize the sample information from the different movement types, respectively.</div>
    </li> <li> <para-num num="[0217]"> </para-num> <div id="p-0218" num="0217" class="description-line">In some embodiments, the movement recognition model may also include a model that recognizes the movement quantity of fitness movements of the user. For example, at least one set of the movement start point, the movement middle point, and the movement end point may be obtained by performing segmentation processing of the <figure-callout id="700" label="process" filenames="US20230210402A1-20230706-D00005.png" state="{{state}}">process</figure-callout> <b>700</b> on the movement signal (e.g., the electromyographic signal and/or the attitude signal) in the sample information, each set of the movement start point, the movement middle point, and the movement end point may be labelled, respectively (e.g., the movement start point may be labeled <b>1</b>, the movement middle point may be labeled <b>2</b>, and the movement end point may be labeled <b>3</b>), and the labels may be used as the input of the machine learning model. For example, if a set of consecutive 1, 2, and 3 is input into the machine learning model, one movement may be output. For example, if three consecutive sets of 1, 2, and 3 are input into the machine learning model, three movements may be output.</div>
    </li> <li> <para-num num="[0218]"> </para-num> <div id="p-0219" num="0218" class="description-line">In some embodiments, the movement recognition model may also include the machine learning model for recognizing a fatigue index of the user. The sample information here may also include a physiological parameter signal such as an electro-cardio signal, a respiratory rate, a temperature signal, a humidity signal, etc. For example, different frequency ranges of the electro-cardio signal may be used as input data of the machine learning model. The frequency range of the electro-cardio signal from 60 beats/min to 100 beats/min may be labelled 1 (normal). The frequency range of the electro-cardio signal less than 60 beats/min or more than 100 beats/min may be labelled 2 (abnormal). In some embodiments, a further segmentation may be performed and different indices may be labeled as the input data based on the frequency of the electro-cardio signal of the user, and the trained machine learning model may output a corresponding fatigue index according to the frequency of the electro-cardio signal. In some embodiments, the machine learning model may also be trained in combination with the physiological parameter signal such as the respiratory rate, the temperature signal, etc. In some embodiments, the sample information may be obtained from the storage device of the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b>. In some embodiments, the sample information may be obtained from the obtaining <figure-callout id="210" label="module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">module</figure-callout> <b>210</b>. It should be noted that the movement recognition model may be any one of the machine learning models or a combination of the plurality of machine learning models, or include other machine learning models, which may be selected according to an actual situation. In addition, the input of the training of the machine learning model is not limited to one segment (one cycle) of the movement signal, but may also be part of a segment of the movement signal, or a plurality of segments of the movement signal, etc.</div>
    </li> <li> <para-num num="[0219]"> </para-num> <div id="p-0220" num="0219" class="description-line">In <figure-callout id="2030" label="step" filenames="US20230210402A1-20230706-D00018.png" state="{{state}}">step</figure-callout> <b>2030</b>, the movement recognition model may be extracted.</div>
    </li> <li> <para-num num="[0220]"> </para-num> <div id="p-0221" num="0220" class="description-line">In some embodiments, the step may be performed by the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b>. In some embodiments, the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b> and/or the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> may extract the movement recognition model. In some embodiments, the movement recognition model may be stored to the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b>, the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b>, or a mobile terminal.</div>
    </li> <li> <para-num num="[0221]"> </para-num> <div id="p-0222" num="0221" class="description-line">In <figure-callout id="2040" label="step" filenames="US20230210402A1-20230706-D00018.png" state="{{state}}">step</figure-callout> <b>2040</b>, the movement signal of the user may be obtained.</div>
    </li> <li> <para-num num="[0222]"> </para-num> <div id="p-0223" num="0222" class="description-line">In some embodiments, the step may be performed by the obtaining <figure-callout id="210" label="module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">module</figure-callout> <b>210</b>. For example, in some embodiments, an electromyographic sensor in the obtaining <figure-callout id="210" label="module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">module</figure-callout> <b>210</b> may obtain the electromyographic signal of the user, and an attitude sensor in the obtaining <figure-callout id="210" label="module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">module</figure-callout> <b>210</b> may obtain the attitude signal of the user. In some embodiments, the user movement signal may also include other physiological parameter signals such as the electro-cardio signal, the respiration signal, the temperature signal, the humidity signal, etc. during the motion of the user. In some embodiments, the obtained movement signal (e.g., the electromyographic signal and/or the attitude signal) may be subjected to the segmentation processing of the <figure-callout id="700" label="process" filenames="US20230210402A1-20230706-D00005.png" state="{{state}}">process</figure-callout> <b>700</b>, the burr processing of process the <b>900</b>, and the conversion processing of the <figure-callout id="1300" label="process" filenames="US20230210402A1-20230706-D00011.png" state="{{state}}">process</figure-callout> <b>1300</b>, etc., to form at least one segment of the electromyographic signal and/or the attitude signal.</div>
    </li> <li> <para-num num="[0223]"> </para-num> <div id="p-0224" num="0223" class="description-line">In <figure-callout id="2050" label="step" filenames="US20230210402A1-20230706-D00018.png" state="{{state}}">step</figure-callout> <b>2050</b>, the movement of the user may be determined based on the movement signal of the user through the movement recognition model.</div>
    </li> <li> <para-num num="[0224]"> </para-num> <div id="p-0225" num="0224" class="description-line">The step may be performed by the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b> and/or the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b>. In some embodiments, the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b> and/or the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> may determine the movement of the user based on the movement recognition model. In some embodiments, the trained movement recognition model may include one or more machine learning models. In some embodiments, the movement recognition model may include, but is not limited to, the machine learning model that classifies the movement signal of the user, the machine learning model that recognizes the movement quality of the user, the machine learning model that recognizes the movement quantity of user, the machine learning model that recognizes the fatigue index of the user performing the movement, or any combination thereof. The different machine learning models may have different recognition effects. For example, the machine learning model that classifies the movement signal may use the movement signal of the user as input data and output a corresponding movement type. As another example, the machine learning model that recognizes the movement quality of the user may use the movement signal of the user as input data and output the movement quality (e.g., a standard movement, an incorrect movement). As yet another example, the machine learning model that recognizes the fatigue index of the user performing the movement may use the movement signal (e.g., the frequency of the electro-cardio signal) of the user as input data and output the fatigue index of the user. In some embodiments, the movement signal of the user and the determination result (output) of the machine learning model may also be used as the sample information of training the movement recognition model, and the movement recognition model may be trained to optimize relevant parameters of the movement recognition model. It should be noted that the movement recognition model is not limited to the trained machine learning model described above, but can also be a preset model, for example, a manually preset conditional judgment algorithm or manually adding parameters (e.g., a confidence level) to the trained machine learning model, etc.</div>
    </li> <li> <para-num num="[0225]"> </para-num> <div id="p-0226" num="0225" class="description-line">In <figure-callout id="2060" label="step" filenames="US20230210402A1-20230706-D00018.png" state="{{state}}">step</figure-callout> <b>2060</b>, feedback may be performed on the movement of the user based on the determination result.</div>
    </li> <li> <para-num num="[0226]"> </para-num> <div id="p-0227" num="0226" class="description-line">In some embodiments, the step may be performed by the <figure-callout id="130" label="wearable device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">wearable device</figure-callout> <b>130</b> and/or the mobile <figure-callout id="140" label="terminal device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">terminal device</figure-callout> <b>140</b>. Further, the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b> and/or the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> may send a feedback instruction to the <figure-callout id="130" label="wearable device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">wearable device</figure-callout> <b>130</b> and/or the mobile <figure-callout id="140" label="terminal device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">terminal device</figure-callout> <b>140</b> based on the determination result of the movement of the user. The <figure-callout id="130" label="wearable device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">wearable device</figure-callout> <b>130</b> and/or the mobile <figure-callout id="140" label="terminal device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">terminal device</figure-callout> <b>140</b> may perform feedback to the user based on the feedback instruction. In some embodiments, the feedback may include sending prompt information (e.g., text information, image information, video information, voice information, indicator information, etc.) and/or stimulating the body of the user by performing a corresponding movement (a manner such as a current stimulation, a vibration, a pressure change, a heat change, etc.). For example, when a user performs a sit-up movement, it may be determined that the user is exerting too much force on a trapezius muscle during the motion (i.e., head and neck movements of the user are not standard) by monitoring the movement signal of the user. In this case, the input/output module <b>260</b> (e.g., a vibration prompter) in the <figure-callout id="130" label="wearable device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">wearable device</figure-callout> <b>130</b> and the mobile terminal device <b>140</b> (e.g., a smartwatch, a smartphone etc.) may perform a corresponding feedback movement (e.g., applying the vibration to the user&#39;s body part, sending the voice prompt, etc.) to prompt the user to adjust an exertion part in time. In some embodiments, during the motion of the user, the movement type, the movement quality, and the movement quantity during the motion of the user may be determined by monitoring the movement signal during the motion of the user, and the mobile <figure-callout id="140" label="terminal device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">terminal device</figure-callout> <b>140</b> may output corresponding movement records, so that the user can understand his/her motion situation during the motion.</div>
    </li> <li> <para-num num="[0227]"> </para-num> <div id="p-0228" num="0227" class="description-line">In some embodiments, when the feedback is performed to the user, the feedback may be matched to perception of the user. For example, when the movement of the user is not standard, the vibration stimulation may be performed on an area corresponding to the movement of the user, and the user may know that the movement is not standard based on the vibration stimulation. The vibration stimulation is within an acceptable range of the user. Further, a matching model may be constructed based on the movement signal of the user and the perception of the user to find a best balance between the user perception and a real feedback.</div>
    </li> <li> <para-num num="[0228]"> </para-num> <div id="p-0229" num="0228" class="description-line">In some embodiments, the movement recognition model may further be trained based on the movement signal of the user. In some embodiments, training the movement recognition model according to the movement signal of the user may include determining a confidence level of the movement signal of the user by evaluating the movement signal of the user. The confidence level may indicate a quality of the movement signal of the user. For example, the higher the confidence level, the better the quality of the movement signal of the user. In some embodiments, evaluating the movement signal of the user may be performed at a stage such as movement signal obtaining, pre-processing, segmentation, and/or recognition.</div>
    </li> <li> <para-num num="[0229]"> </para-num> <div id="p-0230" num="0229" class="description-line">In some embodiments, training the movement recognition model according to the movement signal of the user may further include determining whether the confidence level is greater than a confidence level threshold (e.g., <b>80</b>). If the confidence level is greater than or equal to the confidence level threshold, the movement recognition model may be trained by using the movement signal of the user corresponding to the confidence level as sample data. If the confidence level is smaller than the confidence level threshold, the movement signal of the user corresponding to the confidence level may not be used as sample data to train the movement recognition model. In some embodiments, the confidence level may include, but is not limited to, a confidence level of any stage of the movement signal obtaining, the movement signal pre-processing, the movement signal segmentation, or the movement signal recognition. For example, the confidence level of the movement signal collected by the obtaining <figure-callout id="210" label="module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">module</figure-callout> <b>210</b> may be used as a determination criterion. In some embodiments, the confidence level may further include a joint confidence level of several stages such as the movement signal obtaining, the movement signal pre-processing, the movement signal segmentation, or the movement signal recognition. The joint confidence level may be obtained by averaging or weighting the confidence level of each stage, etc. In some embodiments, the movement recognition model may be trained in real time, periodically (e.g., a day, a week, a month, etc.), or when a certain data volume is met according to the movement signal of the user.</div>
    </li> <li> <para-num num="[0230]"> </para-num> <div id="p-0231" num="0230" class="description-line">It should be noted that the above description regarding the <figure-callout id="2000" label="process" filenames="US20230210402A1-20230706-D00018.png" state="{{state}}">process</figure-callout> <b>2000</b> is merely provided for the purpose of illustration, and not intended to limit the scope of the present disclosure. For those skilled in the art, various amendments and changes can be made to the <figure-callout id="2000" label="process" filenames="US20230210402A1-20230706-D00018.png" state="{{state}}">process</figure-callout> <b>2000</b> under the guidance of the present disclosure. However, these amendments and changes are still within the scope of the present disclosure.</div>
    </li> <li> <para-num num="[0231]"> </para-num> <div id="p-0232" num="0231" class="description-line">In some embodiments, when the movement of the user is not standard, the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b> and/or the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> may send the feedback instruction to the <figure-callout id="130" label="wearable device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">wearable device</figure-callout> <b>130</b> and/or the <figure-callout id="140" label="mobile terminal" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">mobile terminal</figure-callout> <b>140</b> based on the determination result of the movement of the user. The <figure-callout id="130" label="wearable device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">wearable device</figure-callout> <b>130</b> and/or the <figure-callout id="140" label="mobile terminal" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">mobile terminal</figure-callout> <b>140</b> may perform feedback to the user based on the feedback instruction. For example, the input/output module <b>260</b> (e.g., a vibration prompter) in the <figure-callout id="130" label="wearable device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">wearable device</figure-callout> <b>130</b> and the mobile terminal device <b>140</b> (e.g., a smartwatch, a smart phone, etc.) may perform the corresponding feedback movement (e.g., applying the vibration to the user&#39;s body part, sending the voice prompt, etc.) to prompt the user that the movement is non-standard or incorrect. In this case, although the user receives the information prompt that there is a non-standard movement during the motion, the user may be unable to identify a reason for the non-standard movement according to the feedback movement, such as a non-standard posture, an incorrect exertion position of a muscle, an incorrect exertion strength of a muscle, etc. On the other hand, if the user feels good about himself/herself after receiving the feedback movement that the motion movement is not standard from the <figure-callout id="100" label="motion monitoring system" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">motion monitoring system</figure-callout> <b>100</b>, the user&#39;s credibility of the <figure-callout id="100" label="motion monitoring system" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">motion monitoring system</figure-callout> <b>100</b> may also decrease. For example, when a user performs the bicep curl, a standard posture of the movement may be that shoulders needs to be relaxed. The user may subjectively believe that he has relaxed, but in fact, the shoulders may exert force involuntarily, resulting in excessive force on the trapezius muscle. At this time, the user&#39;s subjective perception may be inconsistent with an analysis result of the <figure-callout id="130" label="wearable device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">wearable device</figure-callout> <b>130</b> and/or the mobile <figure-callout id="140" label="terminal device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">terminal device</figure-callout> <b>140</b>, and the user may think that the feedback result of the <figure-callout id="130" label="wearable device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">wearable device</figure-callout> <b>130</b> and/or the mobile <figure-callout id="140" label="terminal device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">terminal device</figure-callout> <b>140</b> is inaccurate. Therefore, the embodiments of the present disclosure may also provide a method for displaying a motion monitoring interface. The method may display information related to the motion of the user (e.g., the exertion position of the muscle, the exertion strength of the muscle, and the user&#39;s movement model) by using a display device. The user can intuitively observe a problem in the motion according to display content, and timely adjust the movement for a scientific motion.</div>
    </li> <li> <para-num num="[0232]"> </para-num> <div id="p-0233" num="0232" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>21</b>A</figref> is a flowchart illustrating an exemplary process of a method for displaying a motion monitoring interface according to some embodiments of the present disclosure. As shown in <figref idrefs="DRAWINGS">FIG. <b>21</b>A</figref>, the <figure-callout id="2100" label="process" filenames="US20230210402A1-20230706-D00019.png" state="{{state}}">process</figure-callout> <b>2100</b> may include the following steps.</div>
    </li> <li> <para-num num="[0233]"> </para-num> <div id="p-0234" num="0233" class="description-line">In <figure-callout id="2110" label="step" filenames="US20230210402A1-20230706-D00019.png" state="{{state}}">step</figure-callout> <b>2110</b>, a movement signal during a motion of a user may be obtained from at least one sensor.</div>
    </li> <li> <para-num num="[0234]"> </para-num> <div id="p-0235" num="0234" class="description-line">In some embodiments, the <figure-callout id="2110" label="step" filenames="US20230210402A1-20230706-D00019.png" state="{{state}}">step</figure-callout> <b>2110</b> may be performed by the obtaining <figure-callout id="210" label="module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">module</figure-callout> <b>210</b>. In some embodiments, the movement signal during the motion of the user may refer to human body parameter information during the motion of the user. In some embodiments, the human body parameter information may include, but is not limited to, an electromyographic signal, an attitude signal, an electro-cardio signal, a temperature signal, a humidity signal, a blood oxygen concentration, a respiratory rate, or the like, or any combination thereof. In some embodiments, a sensor in the obtaining <figure-callout id="210" label="module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">module</figure-callout> <b>210</b> may obtain the movement signal during the motion of the user. In some embodiments, an electromyography sensor in the obtaining <figure-callout id="210" label="module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">module</figure-callout> <b>210</b> may collect the electromyographic signal during the motion of the user. For example, when the user performs the seated chest press, the electromyography sensor in the wearable device corresponding to a position of a human pectoral muscle, a latissimus dorsi, etc. may collect the electromyographic signal corresponding to the muscle position of the user. In some embodiments, an attitude sensor in the obtaining <figure-callout id="210" label="module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">module</figure-callout> <b>210</b> may collect the attitude signal during the motion of the user. For example, when the user performs a barbell press motion, the attitude sensor in the wearable device corresponding to a position of a human triceps brachii muscle may collect the attitude signal of the position of the user&#39;s triceps brachii muscle. In some embodiments, the at least one sensor may include, but is not limited to, an attitude sensor, an electro-cardio sensor, an electromyography sensor, a temperature sensor, a humidity sensor, an inertial sensor, an acid-base sensor, an acoustic transducer, or the like, or any combination thereof. Different types of sensors may be placed at different positions of the user&#39;s body according to different signals to be measured, so that different types of sensors and/or sensors at different positions can collect different movement signals.</div>
    </li> <li> <para-num num="[0235]"> </para-num> <div id="p-0236" num="0235" class="description-line">In some embodiments, the movement signal may be a movement signal formed after the movement signal collected by a plurality of sensors in the obtaining <figure-callout id="210" label="module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">module</figure-callout> <b>210</b> during the motion of the user is subject to a signal processing process such as filtering, rectification, and/or wavelet transform, a segmentation processing of the <figure-callout id="700" label="process" filenames="US20230210402A1-20230706-D00005.png" state="{{state}}">process</figure-callout> <b>700</b>, a burr processing of the <figure-callout id="900" label="process" filenames="US20230210402A1-20230706-D00007.png" state="{{state}}">process</figure-callout> <b>900</b>, or permutation and combination of any one or more of the above processing processes. As described above, the signal processing process such as filtering, rectification, and/or wavelet transform, the segmentation processing of <figure-callout id="700" label="process" filenames="US20230210402A1-20230706-D00005.png" state="{{state}}">process</figure-callout> <b>700</b>, and the burr processing of <figure-callout id="900" label="process" filenames="US20230210402A1-20230706-D00007.png" state="{{state}}">process</figure-callout> <b>900</b> may be performed by the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> and/or the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b>. The obtaining <figure-callout id="210" label="module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">module</figure-callout> <b>210</b> may obtain the processed movement signal from the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> and/or the <figure-callout id="110" label="processing device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">processing device</figure-callout> <b>110</b>.</div>
    </li> <li> <para-num num="[0236]"> </para-num> <div id="p-0237" num="0236" class="description-line">In <figure-callout id="2120" label="step" filenames="US20230210402A1-20230706-D00019.png" state="{{state}}">step</figure-callout> <b>2120</b>, information related to the motion of the user may be determined by processing the movement signal.</div>
    </li> <li> <para-num num="[0237]"> </para-num> <div id="p-0238" num="0237" class="description-line">In some embodiments, the <figure-callout id="2120" label="step" filenames="US20230210402A1-20230706-D00019.png" state="{{state}}">step</figure-callout> <b>2120</b> may be performed by the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b>. In some embodiments, the information related to the motion of the user may include a movement type, a movement frequency, a movement intensity, a movement model of the user, or the like, or any combination thereof. In some embodiments, the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> may determine feature information of the movement signal (e.g., amplitude information, frequency information of the electromyographic signal, and/or an angular velocity, an angular velocity direction, and an acceleration value of angular velocity of the attitude signal) by analyzing and processing the movement signal of the user, and determine the information related to the motion of the user according to the feature information of the movement signal.</div>
    </li> <li> <para-num num="[0238]"> </para-num> <div id="p-0239" num="0238" class="description-line">In some embodiments, the information related to the motion of the user may include an exertion strength of at least one muscle during the motion of the user. In some embodiments, the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> may determine the exertion strength of the at least one muscle of the user according to the electromyographic signal collected by the electromyography sensor. For example, when a user performs a deep squat movement, the electromyography sensor set at a position of a human gluteus maximus, a quadriceps femoris muscle, etc. may collect the electromyographic signal corresponding to the muscle position of the user, and the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> may determine the exertion strength of the gluteus maximus and quadriceps femoris muscle of the user based on a signal strength of the obtained electromyographic signal.</div>
    </li> <li> <para-num num="[0239]"> </para-num> <div id="p-0240" num="0239" class="description-line">In some embodiments, the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> may determine the movement type of the user based on the movement signal. For example, the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> may determine the movement type based on the movement signal and a movement recognition model (e. g., the movement recognition model described in <figref idrefs="DRAWINGS">FIG. <b>20</b> </figref>) of the user. For example, the movement type may be manually input. Further, the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> may determine a muscle located at an exercise position (also called a muscle of the exercise position) of the user and a muscle located at a non-exercise position (also called a muscle of the non-exercise position) of the user according to the movement type of the user. The muscle of the non-exercise position may be a muscle of a position where an incorrect exertion easily occurs or a muscle at a part that is easy to be injured when the user perform a certain movement. Different movement types may correspond to different muscles of exercise positions and different muscles of non-exercise positions. In some embodiments, the user may preset the muscle of the exercise position and the muscle of the non-exercise position corresponding to each movement type. In some embodiments, the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> may determine whether an exertion part of the user is correct and whether the movement posture is standard when a corresponding movement is performed according to the exertion strengths of the muscle of the exercise position and/or the muscle of the non-exercise position of the user. For example, if the exertion strength of the muscle of the exercise position is too small (e g, smaller than a certain threshold) and/or the exertion strength of the muscle of the non-exercise position is too large (e.g., greater than a certain threshold), it may be considered that the exertion part during the motion of the user is incorrect. In this case, the input/<figure-callout id="260" label="output module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">output module</figure-callout> <b>260</b> may send a feedback signal to the user to prompt the user to adjust the movement in time.</div>
    </li> <li> <para-num num="[0240]"> </para-num> <div id="p-0241" num="0240" class="description-line">In some embodiments, the information related to the motion of the user may include a user movement model representing a movement of the motion of the user. For example, when the user performs a dumbbell flying bird movement, the attitude sensor set at a position such as a human deltoid muscle, an upper limb joint (e.g., an arm elbow joint), etc. may collect the attitude signal of the deltoid muscle and the upper limb joint of the user. The <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> may process each attitude signal to obtain the feature information corresponding to each attitude signal (e.g., angular velocity information, acceleration information, stress information, displacement information), and the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> may generate the movement model of the dumbbell flying bird movement according to the feature information. Further description regarding generating the user movement model during the motion of the user based on the attitude signal may be found in <figref idrefs="DRAWINGS">FIG. <b>22</b> </figref> and related description thereof.</div>
    </li> <li> <para-num num="[0241]"> </para-num> <div id="p-0242" num="0241" class="description-line">In <figure-callout id="2130" label="step" filenames="US20230210402A1-20230706-D00019.png" state="{{state}}">step</figure-callout> <b>2130</b>, the information related to the motion of the user may be displayed.</div>
    </li> <li> <para-num num="[0242]"> </para-num> <div id="p-0243" num="0242" class="description-line">In some embodiments, the <figure-callout id="2130" label="step" filenames="US20230210402A1-20230706-D00019.png" state="{{state}}">step</figure-callout> <b>2130</b> may be performed by the input/<figure-callout id="260" label="output module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">output module</figure-callout> <b>260</b>. In some embodiments, the information related to the motion of the user may be displayed on a display device (e.g., a display screen) of the <figure-callout id="130" label="wearable device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">wearable device</figure-callout> <b>130</b> or the mobile <figure-callout id="140" label="terminal device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">terminal device</figure-callout> <b>140</b>, so that the user can intuitively observe a motion situation during the motion.</div>
    </li> <li> <para-num num="[0243]"> </para-num> <div id="p-0244" num="0243" class="description-line">In some embodiments, as shown in <figref idrefs="DRAWINGS">FIG. <b>21</b>B</figref>, an interface of the display device may display a front <figure-callout id="2101" label="muscle distribution map" filenames="US20230210402A1-20230706-D00020.png" state="{{state}}">muscle distribution map</figure-callout> <b>2101</b> and a back muscle distribution diagram <b>2102</b> of a human body. When the user starts to exert force, a color of a muscle corresponding to an exertion part of the user in the human muscle distribution map (e.g., the front <figure-callout id="2101" label="muscle distribution map" filenames="US20230210402A1-20230706-D00020.png" state="{{state}}">muscle distribution map</figure-callout> <b>2101</b> and the back muscle distribution map <b>2102</b>) may change, so that the user can intuitively feel the exertion strength of the muscle according to the color change corresponding to the muscle in the human muscle distribution map. For example, when a user performs a sit-up movement, an exertion strength of a muscle such as a rectus abdominis muscle, an external oblique muscle, an internal oblique muscle, and a transverse muscle of abdomen of the user&#39;s abdomen, and a trapezius muscle of the user&#39;s shoulder may be displayed in the human muscle distribution map. In some embodiments, the greater the exertion strength of a certain muscle of the user, the darker the color corresponding to the muscle in the human muscle distribution map (e.g., the closer to red).</div>
    </li> <li> <para-num num="[0244]"> </para-num> <div id="p-0245" num="0244" class="description-line">In some embodiments, the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> and/or the user may determine whether the sit-up movement is standard or not according to the exertion strength of muscles of different positions. For example, if the exertion strength of the rectus abdominis muscle, the external oblique muscle, the internal oblique muscle, and the transverse muscle of the user&#39;s abdomen is greater than a first strength threshold (the first strength threshold may be set according to the exertion strength of the corresponding muscle when a professional performs a standard sit-up movement), and when the exertion strength of the trapezius muscle of the user&#39;s shoulder is smaller than a second strength threshold (the second strength threshold may be set according to the exertion strength of the corresponding muscle when the professional performs the standard sit-up movement), the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> may determine that the sit-up movement of the user is standard. Otherwise, the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> may determine that the sit-up movement of the user is non-standard.</div>
    </li> <li> <para-num num="[0245]"> </para-num> <div id="p-0246" num="0245" class="description-line">It should be noted that the front <figure-callout id="2101" label="muscle distribution map" filenames="US20230210402A1-20230706-D00020.png" state="{{state}}">muscle distribution map</figure-callout> <b>2101</b> and the back <figure-callout id="2102" label="muscle distribution map" filenames="US20230210402A1-20230706-D00020.png" state="{{state}}">muscle distribution map</figure-callout> <b>2102</b> of the human body shown in <figref idrefs="DRAWINGS">FIG. <b>21</b>B</figref> are only examples. The front <figure-callout id="2101" label="muscle distribution map" filenames="US20230210402A1-20230706-D00020.png" state="{{state}}">muscle distribution map</figure-callout> <b>2101</b> and the back <figure-callout id="2102" label="muscle distribution map" filenames="US20230210402A1-20230706-D00020.png" state="{{state}}">muscle distribution map</figure-callout> <b>2102</b> of the human body may be arranged up and down, left and right, or in other arrangement modes easy to observe in the interface.</div>
    </li> <li> <para-num num="[0246]"> </para-num> <div id="p-0247" num="0246" class="description-line">In some embodiments, the input/<figure-callout id="260" label="output module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">output module</figure-callout> <b>260</b> may obtain a user input regarding a target muscle. The target muscle may refer to a muscle that the user pays more attention to during the motion. For example, the target muscle may be a muscle that the user focuses on during an exercise. In some embodiments, a position of the target muscle and/or a count of target muscles may be related to the movement type of the user. For example, when the user performs the deep squat movement, the target muscle may include the gluteus maximus, the quadriceps femoris muscle, a tibialis anterior muscle, or the like, or any combination thereof. As another example, when the user performs the sit-up movement, the target muscle may include the rectus abdominis muscle, the external oblique muscle, the internal oblique muscle, the transverse muscle of abdomen, the trapezius muscle, or the like, or any combination thereof. In some embodiments, the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> may determine the movement type of the user based on the movement signal, and determine the target muscle according to the movement type of the user automatically. In some embodiments, the user may determine the movement type manually, and the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> may determine the target muscle according to the movement type input by the user based on a corresponding relationship between the movement type and the target muscle. In some embodiments, the user may determine the target muscle manually. For example, the user may set a specific muscle as the target muscle by clicking the specific muscle in the human muscle distribution map. As another example, the user may set a specific muscle as the target muscle by inputting a name of the specific muscle in the interface of the display device.</div>
    </li> <li> <para-num num="[0247]"> </para-num> <div id="p-0248" num="0247" class="description-line">In some embodiments, the interface of the display device may include a status bar (e.g., a <figure-callout id="2103" label="status bar" filenames="US20230210402A1-20230706-D00020.png" state="{{state}}">status bar</figure-callout> <b>2103</b> and a <figure-callout id="2104" label="status bar" filenames="US20230210402A1-20230706-D00020.png" state="{{state}}">status bar</figure-callout> <b>2104</b> shown in <figref idrefs="DRAWINGS">FIG. <b>21</b>B</figref>). The status bar may be configured to display information of the target muscle (e.g., an exertion strength of the target muscle). For example, when the target muscle input by the user is a pectoralis major muscle, the exertion strength of the pectoralis major muscle may be displayed through the status bar. In some embodiments, a color of the status bar may be related to the exertion strength of the target muscle. For example, the darker the color of the status bar, the greater the exertion strength of the target muscle. By displaying the status bar in the interface, the user may feel the exertion strength of the target muscle more intuitively, and the exertion strength of the muscle may be characterized more quantitatively. In some embodiments, the status bar may display a proportional relationship between the exertion strength of the target muscle and a standard exertion strength (or the maximum exertion strength). The standard exertion strength may be set according to an exertion strength corresponding to a muscle when the professional performs a standard movement. The maximum exertion strength may be set according to an exertion strength limit of a human muscle. For example, if the status bar is full, it may indicate that the exertion strength of the target muscle of the user is consistent with the standard exertion strength. The user may more intuitively feel a difference between his/her exertion strength of muscle and the standard exertion strength of muscle through the status bar displayed in the interface, so that the user can timely adjust his/her exertion strength of muscle.</div>
    </li> <li> <para-num num="[0248]"> </para-num> <div id="p-0249" num="0248" class="description-line">In some embodiments, a count of status bars may be related to a count of target muscles. For example, when the user sets a triceps brachii muscle as the target muscle, two status bars may be displayed on left and right sides of the interface, respectively. The left status bar (e.g., the <figure-callout id="2103" label="status bar" filenames="US20230210402A1-20230706-D00020.png" state="{{state}}">status bar</figure-callout> <b>2103</b> shown in <figref idrefs="DRAWINGS">FIG. <b>21</b>B</figref>) may be configured to display an exertion strength of a triceps brachii muscle on the left arm of the user. The right status bar (e.g., the <figure-callout id="2104" label="status bar" filenames="US20230210402A1-20230706-D00020.png" state="{{state}}">status bar</figure-callout> <b>2104</b> shown in <figref idrefs="DRAWINGS">FIG. <b>21</b>B</figref>) may be configured to display an exertion strength of a triceps brachii muscle on the right arm of the user. The exertion strengths of the target muscles on the left and right sides of the user may be displayed through two status bars, which may help the user determine whether the exertion strengths of the muscles on the left and right sides of the body are balanced during the motion, so as to avoid physical damage caused by uneven force on the left and right sides of the body. It should be noted that the status bars shown in <figref idrefs="DRAWINGS">FIG. <b>21</b>B</figref> are only examples. The count of the status bars may be any numeric value. The status bar may be set at any position of the interface.</div>
    </li> <li> <para-num num="[0249]"> </para-num> <div id="p-0250" num="0249" class="description-line">In some embodiments, the input/<figure-callout id="260" label="output module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">output module</figure-callout> <b>260</b> may include a sound output device (e. g., a speaker). The sound output device may make a sound (e.g., a sound of flame burning, bells, water flow), and a volume of the sound may be related to the exertion strength of the target muscle. For example, the volume of the sound may be positively related to the exertion strength of the target muscle, that is, the greater the exertion strength of the target muscle, the greater the volume of the sound; and the weaker the exertion strength of the target muscle, the smaller the volume of the sound. In some embodiments, the sound output device may include a left channel and a right channel, and different channels may correspond to the exertion strengths of different target muscles. For example, the sound from the left channel may correspond to the exertion strength of the target muscle on the left side of the user&#39;s body (e.g., the triceps brachii muscle on the left arm), and the sound from the right channel may correspond to the exertion strength of the target muscle on the right side of the user&#39;s body (e.g., the triceps brachii muscle on the right arm). By using the multi-channel voice mode of the sound output device, the user may feel the exertion strengths of the muscles in different parts of the body. The user may determine whether the exertion strengths of the muscles on the left and right sides of the body are balanced during the motion only by hearing, which can further improve the user&#39;s sense of experience.</div>
    </li> <li> <para-num num="[0250]"> </para-num> <div id="p-0251" num="0250" class="description-line">It should be noted that the above description regarding the <figure-callout id="2100" label="process" filenames="US20230210402A1-20230706-D00019.png" state="{{state}}">process</figure-callout> <b>2100</b> is merely provided for the purpose of illustration, and not intended to limit the scope of the present disclosure. For those skilled in the art, various amendments and changes can be made to the <figure-callout id="2100" label="process" filenames="US20230210402A1-20230706-D00019.png" state="{{state}}">process</figure-callout> <b>2100</b> under the guidance of the present disclosure. For example, the <figure-callout id="2120" label="step" filenames="US20230210402A1-20230706-D00019.png" state="{{state}}">step</figure-callout> <b>2120</b> may be divided into a plurality of steps to perform processing and determination of the movement signal, respectively. However, these amendments and changes are still within the scope of the present disclosure.</div>
    </li> <li> <para-num num="[0251]"> </para-num> <div id="p-0252" num="0251" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>22</b> </figref> is a flowchart illustrating an exemplary process for displaying a motion monitoring interface according to some embodiments of the present disclosure. As shown in <figref idrefs="DRAWINGS">FIG. <b>22</b> </figref>, the <figure-callout id="2200" label="process" filenames="US20230210402A1-20230706-D00021.png" state="{{state}}">process</figure-callout> <b>2200</b> may include the following steps.</div>
    </li> <li> <para-num num="[0252]"> </para-num> <div id="p-0253" num="0252" class="description-line">In <figure-callout id="2210" label="step" filenames="US20230210402A1-20230706-D00021.png" state="{{state}}">step</figure-callout> <b>2210</b>, a user movement model representing a movement of the motion of the user may be generated based on an attitude signal.</div>
    </li> <li> <para-num num="[0253]"> </para-num> <div id="p-0254" num="0253" class="description-line">In some embodiments, the <figure-callout id="2210" label="step" filenames="US20230210402A1-20230706-D00021.png" state="{{state}}">step</figure-callout> <b>2210</b> may be performed by the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b>. In some embodiments, the user movement model may include a user three-dimensional (3D) movement model, a user three-dimensional (2D) movement model, etc. The user 3D movement model and/or the user 2D movement model may reproduce the movement of the motion of the user. It may be understood that the movement reproduction of the motion of the user may reflect a posture of the motion of the user to a certain extent, without requiring the reproduced movement to be completely consistent with the real movement of the user.</div>
    </li> <li> <para-num num="[0254]"> </para-num> <div id="p-0255" num="0254" class="description-line">In some embodiments, the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> may generate the user movement model representing the movement of the motion of the user based on the attitude signal collected by an attitude sensor. In some embodiments, a plurality of attitude sensors may be placed at different positions of the wearable device <b>130</b> (e.g., positions of the <figure-callout id="130" label="wearable device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">wearable device</figure-callout> <b>130</b> corresponding to a trunk, limbs and joints) according to an attitude signal required to be obtained to measure the attitude signals corresponding to different parts of a human body. The attitude signals corresponding to the different parts may reflect a relative motion situation between different parts of the human body. In some embodiments, the attitude signal may be associated with a type of attitude sensor. For example, when the attitude sensor is an angular velocity triaxial sensor, the obtained attitude signal may be angular velocity information. As another example, when the attitude sensor is an angular velocity triaxial sensor and an acceleration triaxial sensor, the obtained attitude signal may be the angular velocity information and acceleration information. As yet another example, when the attitude sensor is a strain gauge sensor, the strain gauge sensor may be set at a joint position of the user. By measuring a magnitude of a resistance in the strain gauge sensor that changes with a tensile length, the obtained attitude signals may include displacement information, stress, etc. The attitude signals may characterize a bending angle and a bending direction at the joint of the user. As yet another example, the attitude sensor may be an ultrasonic sensor that is set at a fixed position of the joint or the limb of the user. A position of the sensor may be determined by measuring the time of flight (TOF) of an acoustic wave, so as to determine an attitude of the user. The attitude signal obtained by the attitude sensor and feature information corresponding to the attitude sensor (e.g., an angular velocity direction, an angular velocity value, an acceleration value of angular velocity, angle, displacement information, stress, etc.) may reflect a posture of the motion of the user. The <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> may generate the user movement model representing the movement of the motion of the user based on the posture of the motion of the user. For example, the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> may generate a virtual character (e. g., a 3D or 2D animation model) to display the posture of the motion of the user.</div>
    </li> <li> <para-num num="[0255]"> </para-num> <div id="p-0256" num="0255" class="description-line">In some embodiments, the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> may determine other types of information related to the motion of the user (e.g., muscle information) based on other types of movement signals (e.g., an electromyographic signal), and display the other types of information related to the motion of the user on the user movement model. In some embodiments, the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> may determine an exertion strength of at least one muscle of the user based on the electromyographic signal, and the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> may display the exertion strength of the at least one muscle of the user on a corresponding position of the user movement model. For example, when the user performs a deep squat movement, the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> may obtain the electromyographic signal from an electromyography sensor set at a position such as a gluteus maximus, a quadriceps femoris muscle, a tibialis anterior muscle, etc. The <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> may determine the exertion strength of the muscle such as the gluteus maximus, the quadriceps femoris muscle, and the tibialis anterior muscle, respectively, according to the electromyographic signal, and display the exertion strength of the muscle of the gluteus maximus, the quadriceps femoris muscle, and the tibialis anterior muscle at the position corresponding to the gluteus maximus, the quadriceps femoris muscle, and the tibialis anterior muscle in the user movement model. In some embodiments, different muscle strengths may correspond to different display colors. By displaying the other types of information related to the motion of the user in the user movement model at the same time, the user can understand the motion state more intuitively and comprehensively.</div>
    </li> <li> <para-num num="[0256]"> </para-num> <div id="p-0257" num="0256" class="description-line">In <figure-callout id="2220" label="step" filenames="US20230210402A1-20230706-D00021.png" state="{{state}}">step</figure-callout> <b>2220</b>, a standard movement model may be obtained.</div>
    </li> <li> <para-num num="[0257]"> </para-num> <div id="p-0258" num="0257" class="description-line">In some embodiments, the <figure-callout id="2220" label="step" filenames="US20230210402A1-20230706-D00021.png" state="{{state}}">step</figure-callout> <b>2220</b> may be performed by the obtaining <figure-callout id="210" label="module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">module</figure-callout> <b>210</b>. In some embodiments, the standard movement model may be a movement model generated based on standard movement information (e.g., standard attitude information, standard electromyography information) during a motion of a professional (e.g., a fitness instructor). In some embodiments, the standard movement model may include a standard 3D movement model, a standard 2D movement model, etc. The standard 3D movement model and/or the standard 2D movement model may reproduce the movement of the professional. It may be understood that the movement reproduction of the standard movement may reflect a posture of the motion of the professional to a certain extent, without requiring the reproduced movement to be completely consistent with the real movement of the professional. In some embodiments, the standard movement model may display a plurality of types of information related to the motion (e.g., muscle information) during the motion of the professional.</div>
    </li> <li> <para-num num="[0258]"> </para-num> <div id="p-0259" num="0258" class="description-line">In some embodiments, different types of movements may correspond to different standard movement models. For example, a sit-up movement may correspond to a sit-up standard movement model, and a dumbbell flying bird movement may correspond to a dumbbell flying bird standard movement model. In some embodiments, a plurality of standard movement models corresponding to a plurality of motion types may be stored in a storage device of the <figure-callout id="100" label="motion monitoring system" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">motion monitoring system</figure-callout> <b>100</b> in advance. The obtaining <figure-callout id="210" label="module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">module</figure-callout> <b>210</b> may obtain, according to the movement type of the user, the standard movement model corresponding to the movement type of the user from the storage device.</div>
    </li> <li> <para-num num="[0259]"> </para-num> <div id="p-0260" num="0259" class="description-line">In <figure-callout id="2230" label="step" filenames="US20230210402A1-20230706-D00021.png" state="{{state}}">step</figure-callout> <b>2230</b>, the user movement model and the standard movement model may be displayed.</div>
    </li> <li> <para-num num="[0260]"> </para-num> <div id="p-0261" num="0260" class="description-line">In some embodiments, the <figure-callout id="2230" label="step" filenames="US20230210402A1-20230706-D00021.png" state="{{state}}">step</figure-callout> <b>2230</b> may be performed by the input/<figure-callout id="260" label="output module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">output module</figure-callout> <b>260</b>. In some embodiments, the display device may display the user movement model and the standard movement model simultaneously. For example, the user movement model and the standard movement model may be displayed on top of each other or side by side. By observing and comparing the user movement model and the standard movement model, the user may determine whether the movement of the motion is standard more intuitively and quickly, so as to adjust the movement of the motion in time.</div>
    </li> <li> <para-num num="[0261]"> </para-num> <div id="p-0262" num="0261" class="description-line">In some embodiments, a determination may be made as whether the movement of the user needs to be adjusted by comparing a degree of coincidence between a contour of the user movement model and a contour of the standard movement model. For example, if the degree of coincidence between the contour of the user movement model and the contour of the standard movement model is greater than a threshold (e.g., 90%, 95%, 98%), it may be determined that the movement of the user is standard and does not need to be adjusted. If the degree of coincidence between the contour of the user movement model and the contour of the standard movement model is smaller than a threshold (e.g., 90%, 95%, 98%), it may be determined that the movement of the user is non-standard. The input/<figure-callout id="260" label="output module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">output module</figure-callout> <b>260</b> may prompt the user to adjust the movement of the motion.</div>
    </li> <li> <para-num num="[0262]"> </para-num> <div id="p-0263" num="0262" class="description-line">In some embodiments, a determination may be made as whether the movement of the user needs to be adjusted by comparing the muscle information displayed on the user movement model with the muscle information displayed on the standard movement model. For the convenience of illustration, a bicep curl movement of a left arm may be taken as an example. In the bicep curl movement, muscles mainly involved in the movement may include a biceps brachii muscle, a deltoid muscle, a trapezius muscle, and a pectoral muscle. <figref idrefs="DRAWINGS">FIGS. <b>23</b>A to <b>23</b>C</figref> are schematic diagrams illustrating motion monitoring interfaces according to some embodiments of the present disclosure. <figref idrefs="DRAWINGS">FIGS. <b>23</b>A to <b>23</b>C</figref> are a user movement model <b>010</b> (also referred to as an <figure-callout id="010" label="electromyography animation" filenames="US20230210402A1-20230706-D00022.png,US20230210402A1-20230706-D00023.png" state="{{state}}">electromyography animation</figure-callout> <b>010</b> of a virtual user character) and a standard movement model <b>020</b> (also referred to as a <figure-callout id="020" label="reference electromyography animation" filenames="US20230210402A1-20230706-D00022.png,US20230210402A1-20230706-D00023.png" state="{{state}}">reference electromyography animation</figure-callout> <b>020</b> of a virtual reference character) displayed on the display device, respectively. In <figref idrefs="DRAWINGS">FIGS. <b>23</b>A to <b>23</b>C</figref>, the <figure-callout id="010" label="electromyography animation" filenames="US20230210402A1-20230706-D00022.png,US20230210402A1-20230706-D00023.png" state="{{state}}">electromyography animation</figure-callout> <b>010</b> of the virtual user character may be displayed in a left half of the motion monitoring interface, and the <figure-callout id="020" label="reference electromyography animation" filenames="US20230210402A1-20230706-D00022.png,US20230210402A1-20230706-D00023.png" state="{{state}}">reference electromyography animation</figure-callout> <b>020</b> of the virtual reference character may be displayed in a right half of the motion monitoring interface. The motion monitoring interface shown in <figref idrefs="DRAWINGS">FIG. <b>23</b>A</figref> may correspond to the electromyography animation at a moment before the movement starts. As shown in <figref idrefs="DRAWINGS">FIG. <b>23</b>A</figref>, the user and the professional may be in a relaxed state before the movement starts, so all muscles may not exert force. At this time, a <figure-callout id="011" label="user display area" filenames="US20230210402A1-20230706-D00022.png,US20230210402A1-20230706-D00023.png" state="{{state}}">user display area</figure-callout> <b>011</b> corresponding to the biceps brachii muscle, a <figure-callout id="012" label="user display area" filenames="US20230210402A1-20230706-D00022.png,US20230210402A1-20230706-D00023.png" state="{{state}}">user display area</figure-callout> <b>012</b> corresponding to the deltoid muscle, a <figure-callout id="013" label="user display area" filenames="US20230210402A1-20230706-D00022.png,US20230210402A1-20230706-D00023.png" state="{{state}}">user display area</figure-callout> <b>013</b> corresponding to the trapezius muscle, and a <figure-callout id="014" label="user display area" filenames="US20230210402A1-20230706-D00022.png,US20230210402A1-20230706-D00023.png" state="{{state}}">user display area</figure-callout> <b>014</b> corresponding to the pectoral muscle in the <figure-callout id="010" label="electromyography animation" filenames="US20230210402A1-20230706-D00022.png,US20230210402A1-20230706-D00023.png" state="{{state}}">electromyography animation</figure-callout> <b>010</b> of the virtual user character may have no color display. A <figure-callout id="021" label="user display area" filenames="US20230210402A1-20230706-D00022.png,US20230210402A1-20230706-D00023.png" state="{{state}}">user display area</figure-callout> <b>021</b> corresponding to the biceps brachii muscle, a <figure-callout id="022" label="user display area" filenames="US20230210402A1-20230706-D00022.png,US20230210402A1-20230706-D00023.png" state="{{state}}">user display area</figure-callout> <b>022</b> corresponding to the deltoid muscle, a <figure-callout id="023" label="user display area" filenames="US20230210402A1-20230706-D00022.png,US20230210402A1-20230706-D00023.png" state="{{state}}">user display area</figure-callout> <b>023</b> corresponding to the trapezius, and a <figure-callout id="024" label="user display area" filenames="US20230210402A1-20230706-D00022.png,US20230210402A1-20230706-D00023.png" state="{{state}}">user display area</figure-callout> <b>024</b> corresponding to the pectoral muscle in the <figure-callout id="020" label="reference electromyography animation" filenames="US20230210402A1-20230706-D00022.png,US20230210402A1-20230706-D00023.png" state="{{state}}">reference electromyography animation</figure-callout> <b>020</b> of the virtual reference character may also have no color display.</div>
    </li> <li> <para-num num="[0263]"> </para-num> <div id="p-0264" num="0263" class="description-line">The motion monitoring interface shown in <figref idrefs="DRAWINGS">FIG. <b>23</b>B</figref> may correspond to an electromyography animation at a certain moment in a process of the bicep curl movement. In the process of the bicep curl movement, theoretically, a main exertion point may be the biceps brachii muscle. In some cases, the pectoral muscle may also exert slightly, for example, when the user does not chin up and chest out. In a standard bicep curl movement, the trapezius muscle may not need to be involved in exertion or may exert slightly. As shown in <figref idrefs="DRAWINGS">FIG. <b>23</b>B</figref>, a color displayed in the <figure-callout id="013" label="user display area" filenames="US20230210402A1-20230706-D00022.png,US20230210402A1-20230706-D00023.png" state="{{state}}">user display area</figure-callout> <b>013</b> corresponding to the trapezius muscle in the <figure-callout id="010" label="electromyography animation" filenames="US20230210402A1-20230706-D00022.png,US20230210402A1-20230706-D00023.png" state="{{state}}">electromyography animation</figure-callout> <b>010</b> of the virtual user character is darker than a color displayed in the <figure-callout id="023" label="reference display area" filenames="US20230210402A1-20230706-D00022.png,US20230210402A1-20230706-D00023.png" state="{{state}}">reference display area</figure-callout> <b>023</b> corresponding to the trapezius muscle in the <figure-callout id="020" label="electromyography animation" filenames="US20230210402A1-20230706-D00022.png,US20230210402A1-20230706-D00023.png" state="{{state}}">electromyography animation</figure-callout> <b>020</b> of the virtual reference character, which may indicate that the trapezius muscle exerts a relatively large force when the user performs the bicep curl movement, and the exertion strength exceeds an exertion strength of the trapezius muscle in the standard bicep curl movement.</div>
    </li> <li> <para-num num="[0264]"> </para-num> <div id="p-0265" num="0264" class="description-line">The motion monitoring interface shown in <figref idrefs="DRAWINGS">FIG. <b>23</b>C</figref> may correspond to an electromyographic animation at a certain moment from an end of the bicep curl movement to a beginning of a next movement cycle. In a set of continuous bicep curl movements, the user may not be in a completely relaxed state from the end of a complete movement cycle to the beginning of a next complete movement cycle. That is, when a barbell reaches the bottom, the biceps muscle cannot be completely relaxed, but may need to maintain a certain amount of exertion strength, so as to achieve the best exercise effect. As shown in <figref idrefs="DRAWINGS">FIG. <b>23</b>C</figref>, in the <figure-callout id="010" label="electromyography animation" filenames="US20230210402A1-20230706-D00022.png,US20230210402A1-20230706-D00023.png" state="{{state}}">electromyography animation</figure-callout> <b>010</b> of the virtual user character, the <figure-callout id="011" label="user display area" filenames="US20230210402A1-20230706-D00022.png,US20230210402A1-20230706-D00023.png" state="{{state}}">user display area</figure-callout> <b>011</b> corresponding to the biceps brachii muscle has no color display, which may indicate that the user is in a completely relaxed state. In the <figure-callout id="020" label="reference electromyography animation" filenames="US20230210402A1-20230706-D00022.png,US20230210402A1-20230706-D00023.png" state="{{state}}">reference electromyography animation</figure-callout> <b>020</b> of the virtual reference character, the color of the <figure-callout id="021" label="reference display area" filenames="US20230210402A1-20230706-D00022.png,US20230210402A1-20230706-D00023.png" state="{{state}}">reference display area</figure-callout> <b>021</b> corresponding to the biceps brachii muscle is darker.</div>
    </li> <li> <para-num num="[0265]"> </para-num> <div id="p-0266" num="0265" class="description-line">To sum up, by observing the <figure-callout id="010" label="electromyography animation" filenames="US20230210402A1-20230706-D00022.png,US20230210402A1-20230706-D00023.png" state="{{state}}">electromyography animation</figure-callout> <b>010</b> of the virtual user character and the <figure-callout id="020" label="reference electromyography animation" filenames="US20230210402A1-20230706-D00022.png,US20230210402A1-20230706-D00023.png" state="{{state}}">reference electromyography animation</figure-callout> <b>020</b> of the virtual reference character, the user may clearly and intuitively view a difference between the exertion strength of the muscle of the user in the <figure-callout id="010" label="electromyography animation" filenames="US20230210402A1-20230706-D00022.png,US20230210402A1-20230706-D00023.png" state="{{state}}">electromyography animation</figure-callout> <b>010</b> of the virtual user character and the exertion strength of the standard muscle in the <figure-callout id="020" label="reference electromyography animation" filenames="US20230210402A1-20230706-D00022.png,US20230210402A1-20230706-D00023.png" state="{{state}}">reference electromyography animation</figure-callout> <b>020</b> of the virtual reference character, find problems in the current movement, and adjust the movement in time. Further description regarding displaying the user movement model and the standard movement model may be found in the priority of International Application No. PCT/CN2021/093302, filed on May 12, 2021, the entire contents of which are hereby incorporated by reference.</div>
    </li> <li> <para-num num="[0266]"> </para-num> <div id="p-0267" num="0266" class="description-line">It should be noted that the above description regarding the <figure-callout id="2200" label="process" filenames="US20230210402A1-20230706-D00021.png" state="{{state}}">process</figure-callout> <b>2200</b> is merely provided the purpose of illustration, and not intended to limit the scope of the present disclosure. For those skilled in the art, various amendments and changes can be made to the <figure-callout id="2200" label="process" filenames="US20230210402A1-20230706-D00021.png" state="{{state}}">process</figure-callout> <b>2200</b> under the guidance of the present disclosure. However, these amendments and changes are still within the scope of the present disclosure.</div>
    </li> <li> <para-num num="[0267]"> </para-num> <div id="p-0268" num="0267" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>24</b> </figref> is a flowchart illustrating an exemplary process for displaying a motion monitoring interface according to some embodiments of the present disclosure. As shown in <figref idrefs="DRAWINGS">FIG. <b>24</b> </figref>, the <figure-callout id="2400" label="process" filenames="US20230210402A1-20230706-D00024.png" state="{{state}}">process</figure-callout> <b>2400</b> may include the following steps.</div>
    </li> <li> <para-num num="[0268]"> </para-num> <div id="p-0269" num="0268" class="description-line">In <figure-callout id="2410" label="step" filenames="US20230210402A1-20230706-D00024.png" state="{{state}}">step</figure-callout> <b>2410</b>, a movement signal may be segmented based on an electromyographic signal or an attitude signal.</div>
    </li> <li> <para-num num="[0269]"> </para-num> <div id="p-0270" num="0269" class="description-line">In some embodiments, the <figure-callout id="2410" label="step" filenames="US20230210402A1-20230706-D00024.png" state="{{state}}">step</figure-callout> <b>2410</b> may be performed by the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b>. In some embodiments, an obtaining process of the movement signal (e.g., the electromyographic signal, the attitude signal) during a motion of a user may be continuous, and a movement during the motion of the user may be a combination of a plurality of sets of movements or a combination of movements of different movement types. In order to analyze each movement during the motion of the user, the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> may segment the movement signal of the user based on the electromyographic signal or the attitude signal during the motion of the user. In some embodiments, segmenting the movement signal may refer to dividing the movement signal into signal segments with a same time duration or different time durations, or extracting one or more signal segments with a specific time duration from the movement signal. In some embodiments, each segment of the movement signal may correspond to one or more complete movements of the user. For example, when the user performs a deep squat movement, the user goes from a standing posture to a squatting posture, gets up, and returns to the standing posture, which may be regarded as completing the deep squat movement. The movement signal collected by the obtaining <figure-callout id="210" label="module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">module</figure-callout> <b>210</b> in the process may be regarded as a segment (or a cycle) of movement signal. After that, the movement signal collected by the obtaining <figure-callout id="210" label="module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">module</figure-callout> <b>210</b> that the user completes a next squat movement may be regarded as another segment of movement signal. A change of each movement step during the motion of the user may cause the electromyographic signal and the attitude signal of a corresponding part to change. Based on the situation, the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> may segment the movement signal of the user based on the electromyographic signal or the attitude signal. For example, the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> may segment the movement signal of the user based on feature information corresponding to the electromyographic signal or feature information corresponding to the attitude signal. Detailed description regarding the segmenting the movement signal based on the electromyographic signal or the attitude signal may be found in <figref idrefs="DRAWINGS">FIGS. <b>6</b> to <b>8</b> </figref> of the present disclosure and related description thereof.</div>
    </li> <li> <para-num num="[0270]"> </para-num> <div id="p-0271" num="0270" class="description-line">In <figure-callout id="2420" label="step" filenames="US20230210402A1-20230706-D00024.png" state="{{state}}">step</figure-callout> <b>2420</b>, a monitoring result may be determined by monitoring a movement of the motion of the user based on at least one segment of the movement signal.</div>
    </li> <li> <para-num num="[0271]"> </para-num> <div id="p-0272" num="0271" class="description-line">In some embodiments, the <figure-callout id="2420" label="step" filenames="US20230210402A1-20230706-D00024.png" state="{{state}}">step</figure-callout> <b>2420</b> may be performed by the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b>. In some embodiments, the at least one segment of the movement signal may be a movement signal of the user in at least one training process. In some embodiments, the training process may refer to a process in which a user completes a training movement. For example, the user completing a deep squat movement may be the training process. In some embodiments, the training process may also refer to a process in which the user completes a plurality of same or different training movements. For example, the user completing a plurality of deep squat movements successively may be a training process. As another example, the user completing the deep squat movement and a jumping movement in situ successively may be a training process. In some embodiments, the training process may refer to a process in which the user completes training movements within a certain period of time. For example, the training process may be a process of training movements completed within a day, a week, a month, or a year.</div>
    </li> <li> <para-num num="[0272]"> </para-num> <div id="p-0273" num="0272" class="description-line">It should be noted that a segment of movement signal may be a movement signal of a complete training process or a movement signal of a part of the training process in a complete training process. In some embodiments, for a complex complete training process, there may be different exertion modes and different exertion strengths of muscles at different stages of the complete training process, that is, there may be different movement signals at different stages of the training process. The real-time performance of monitoring of the movement of the user may be improved by monitoring the movement signals at the different stages of the complete training process.</div>
    </li> <li> <para-num num="[0273]"> </para-num> <div id="p-0274" num="0273" class="description-line">In some embodiments, the monitoring result may include a movement type, a movement quantity, a movement quality, a movement time, physiological parameter information, a core stability, an interval time, an expected recovery time of the user, or the like, or any combination thereof, during the at least one training process. The physiological parameter information of the user may include, but is not limited to, a heart rate (e.g., an average heart rate, the maximum heart rate), a blood pressure, a body temperature, an energy consumption during the motion, or the like, or any combination thereof. In most training, muscles of the abdomen and the waist may need to be kept in a state of tension to maintain stability of the trunk, improve training efficiency and reduce a risk of injury. An ability of the muscles of the waist and the abdomen to maintain exertion may be called the core stability. The interval time may refer to a time interval between two consecutive movements. For example, when a user performs a deep squat movement, the interval time may refer to the time interval between a first deep squat movement and a second deep squat movement. The expected recovery time may refer to a time it takes for each part of the body (e.g., muscle) to recover from a motion state to a normal state after the user completes the motion. For example, the expected recovery time may be the time it takes for the muscle of the user to recover from a fatigue state to a relaxed state after the user completes the motion.</div>
    </li> <li> <para-num num="[0274]"> </para-num> <div id="p-0275" num="0274" class="description-line">In some embodiments, the monitoring result may be determined by monitoring the motion of the user based on the at least one segment of movement signal. In some embodiments, the monitoring result (e.g., the movement type, the movement quality) may be determined based on the at least one segment of movement signal (e.g., the electromyographic signal, the attitude signal) and at least one segment of preset movement signal (e.g., a preset electromyographic signal, a preset attitude signal). The at least one preset movement signal may be a standard movement signal collected by a sensor when a professional performs a standard movement. The preset movement signal may be stored in a database in advance. In some embodiments, the movement type or the movement quality during the motion of the user may be determined by determining a matching degree between feature information corresponding to the at least one segment of movement signal and feature information corresponding to the at least one segment of preset movement signal. For example, if it is determined that the matching degree between the feature information corresponding to a segment of movement signal of the user and the feature information corresponding to a segment of the preset movement signal is higher than a certain threshold (e.g., 95%), it may be determined that the movement type during the motion of the user is consistent with the movement type of the preset movement signal. As another example, if it is determined that the matching degree between a segment of movement signal of the user and a segment of preset movement signal of a same type is higher than a certain threshold (e.g., 95%), it may be determined that the movement quality of the user during the motion meets a requirement and does not need to be adjusted. In some embodiments, the monitoring result (e.g., the heart rate and the energy consumption) of the motion of the user may be determined based on the feature information corresponding to physiological signals of the user (e.g., electro-cardio signals and respiratory signals) collected by different types of sensors. Further description regarding determining the motion type, the movement type, the movement quantity, the movement quality, the movement time, the physiological parameter information, etc. of the user may be found in <figref idrefs="DRAWINGS">FIGS. <b>19</b>-<b>20</b> </figref> of the present disclosure and related descriptions thereof.</div>
    </li> <li> <para-num num="[0275]"> </para-num> <div id="p-0276" num="0275" class="description-line">In some embodiments, the method for determining the monitoring result by monitoring the user based on the at least one segment of movement signal may be an algorithm not based on another segment of movement signal. In some embodiments, the algorithm may be based on a machine learning model. The movement signal may be input into the machine learning model, and the movement type, the movement quantity, the movement quality, or an error point of the movement may be given through a neural network model or a traditional machine learning model. In some embodiments, the algorithm may be based on an algorithm based on state machine transition. When the movement experiences a series of states, the movement type, movement quantity, the movement quality, or the error point of the movement may be output. In some embodiments, the algorithm may be a combination of threshold judgments. The movement type, the movement quantity, the movement quality, or the error point of the movement may be given by judging whether the movement signal meets a series of conditions.</div>
    </li> <li> <para-num num="[0276]"> </para-num> <div id="p-0277" num="0276" class="description-line">In some embodiments, the core stability of the user may be determined based on the electromyographic signal obtained by an electromyography sensor. For example, the core stability of the user may be determined based on a proportion of an exertion time of an abdominal muscle of the use during a training process. In the training process, the greater the proportion of the exertion time of the abdominal muscle of the user, the better the core stability of the user. In some embodiments, the core stability of the user may be determined based on the attitude signal obtained by an attitude sensor. For example, the core stability of the user may be determined based on a motion amplitude of the trunk of the user during a training process. In some embodiments, the core stability of the user may be determined based on the electromyographic signal and the attitude signal. For example, the core stability of the user may be determined based on the proportion of the exertion time of the abdominal muscle of the user and the motion amplitude of the trunk of the user in the training process.</div>
    </li> <li> <para-num num="[0277]"> </para-num> <div id="p-0278" num="0277" class="description-line">In some embodiments, the monitoring result may include muscle information of the user. In some embodiments, the muscle information of the user may include, but is not limited to, a participation degree of at least one muscle, an energy consumption of the at least one muscle, a fatigue degree of the at least one muscle, a balance of at least two muscles, an ability of the at least one muscle, or the like, or any combination thereof.</div>
    </li> <li> <para-num num="[0278]"> </para-num> <div id="p-0279" num="0278" class="description-line">The participation degree (also referred to as a contribution degree) and the fatigue degree of muscle may indicate whether a target training muscle (e.g., a key training muscle) has been effectively exercised during the motion, and whether other non-target training muscles have exertion compensation, so that the movement quality of the user may be evaluated. In some embodiments, the energy consumption of muscle may be determined based on the electromyographic signal of the muscle of the user and a training time. In some embodiments, the participation degree of each muscle may be determined based on a proportion of an energy consumption of each muscle to an energy consumption of all muscles during the motion of the user. For example, if the energy consumption of all muscles in a certain training is 500 kcal and the energy consumption of pectoral muscles is 250 kcal, the participation degree (the contribution degree) of the pectoral muscles may be determined as 50%. In some embodiments, the participation degree of muscle may be determined based on the feature information of the electromyographic signal. The feature information of the electromyographic signal may include amplitude information (e.g., a mean square amplitude, an integrated electromyogram, an amplitude envelope) and/or frequency information (e.g., an average power frequency, a median frequency, a short-term zero crossing rate) of the electromyographic signal. For example, the participation degree of muscle may be determined based on a percentage of integrated electromyogram of the muscle during a training process (or during a movement).</div>
    </li> <li> <para-num num="[0279]"> </para-num> <div id="p-0280" num="0279" class="description-line">In some embodiments, the electromyographic signal may be preprocessed, and the participation degree of muscle may be determined based on the amplitude information and/or the frequency information of the preprocessed electromyographic signal. In some embodiments, since different muscles have different types of muscle fibers and different counts of muscles, magnitudes of electromyographic signals that the different muscles can emit may be also different. For example, under a same degree of subjective effort, a muscle group such as the biceps brachii muscle, etc. may be more likely to emit a relatively large electromyographic signal, while a muscle group such as the pectoral muscle, etc. may emit a relatively small electromyographic signal. Therefore, the electromyographic signal may be normalized to eliminate or weaken a difference in the magnitude of the electromyographic signal emitted from the different muscle groups. In some embodiments, there may be a nonlinear relationship between the electromyographic signal and an exertion strength of the user. For example, when the exertion strength of the user is relatively large, the amplitude of the electromyographic signal may increase slowly. Therefore, the amplitude of electromyographic signal may be nonlinearized, and the processed electromyographic signal may be used to determine the participation degree of muscle.</div>
    </li> <li> <para-num num="[0280]"> </para-num> <div id="p-0281" num="0280" class="description-line">The fatigue degree of muscle may be configured to evaluate the maximum capacity and a growth capacity of the muscle of the user, which may reflect whether the muscle of the user has been adequately exercised. When the user performs the motion (especially a strength training), the motion may make the muscle enter a fatigue state, and an excessive recovery may be formed using natural repair of a body, resulting in an increase in strength, volume, endurance and explosive power of the muscle. Therefore, it is necessary to evaluate the fatigue degree of the muscle of the user after the motion. In some embodiments, the fatigue degree of muscle may be determined based on the feature information of the electromyographic signal. For example, the fatigue degree of muscle may be determined based on a degree of change (e.g., a degree of decline) of a feature value (e.g., an average power frequency, a median frequency, a short-term zero crossing rate) of the electromyographic signal during at least one training process (e.g., between a plurality of movements). As another example, if it is detected that the amplitude of the electromyographic signal shows a decline trend during a process of a user performing the plurality of movements, it may indicate that the muscle has gradually entered the fatigue state. The faster the amplitude of the electromyographic signal declines (that is, the higher the slope of the amplitude), the higher the fatigue degree of muscle. As another example, if the amplitude of the electromyographic signal is detected to have a high degree of jitter, it may indicate that the muscle has gradually entered the fatigue state. As another example, the fatigue degree of muscle may be determined based on a degree of stability of the electromyography amplitude envelope. The lower the degree of stability of the electromyography amplitude envelope, the higher the fatigue degree of muscle. In some embodiments, the fatigue degree of muscle may be determined based on the feature information of the attitude signal (e.g., an angular velocity, an angular velocity direction, an acceleration of angular velocity, an angle, displacement information, and stress). For example, if it is detected that the attitude signal has a high degree of jitter, and the movement of the user is jittered or severely deformed, it may indicate that the muscle is in the fatigue state.</div>
    </li> <li> <para-num num="[0281]"> </para-num> <div id="p-0282" num="0281" class="description-line">In some embodiments, the fatigue degree of muscle may be determined using a trained machine learning model. For example, the trained machine learning model may be generated by training an initial model based on sample information. In some embodiments, the sample information may include sample movement signals and sample fatigue degrees of muscles of a plurality of users. The sample fatigue degree may be determined based on the sample movement signal. In some embodiments, the initial model may be trained based on the sample information using a training algorithm to generate the trained machine learning model. Exemplary training algorithms may include a gradient descent algorithm, a Newton algorithm, a quasi-Newton algorithm, a conjugate gradient algorithm, a generation adversarial learning algorithm, etc. The trained machine learning model may be used to determine the fatigue degree of the muscle of the user based on the movement signal of the user. For example, the movement signal of the user may be input into the trained machine learning model, and the trained machine learning model may output the fatigue degree of the muscle of the user.</div>
    </li> <li> <para-num num="[0282]"> </para-num> <div id="p-0283" num="0282" class="description-line">In some embodiments, a determination may be made as whether a current motion exceeds a load of the user according to the fatigue degree of the muscle of the user. For example, when it is determined that the fatigue degree of a certain muscle of the user exceeds a first fatigue threshold, it may be determined that the current amount of motion has exceeded the load of the user. At this time, a prompt may be sent to the user to remind the user to reduce the amount of motion or stop the motion to prevent injury. As another example, when it is determined that the fatigue degree of a certain muscle of the user is lower than a second fatigue threshold, it may be determined that the current amount of motion of the user is insufficient to achieve an expected training effect, or it may indicate that the user still has more spare energy. At this time, a prompt may be sent to the user to remind the user to increase the amount of motion to ensure the training effect. In some embodiments, the recovery time may be estimated according to the fatigue degree of the user and fed back to the user to help the user plan a next motion in advance.</div>
    </li> <li> <para-num num="[0283]"> </para-num> <div id="p-0284" num="0283" class="description-line">In some embodiments, the balance of at least two muscles may be a motion balance of left and right muscles in a same muscle group of the user&#39;s body. For example, the balance of at least two muscles may refer to a balance of the left pectoralis major muscle and the right pectoralis major muscle of the user. When the muscles on the left and right sides of the body are unbalanced during the motion of the user, it may not only affect the beauty of the movement, but also affect a standard degree of the movement. When the muscles on the left and right sides of the body are unbalanced, the user may face a risk of injury. Therefore, it is necessary to monitor the balance of the left and right muscles of the user&#39;s body. In some embodiments, the balance of muscles may include a balance of exertion strengths of muscles, a balance of fatigue degrees of muscles, a balance of energy consumptions of muscles, etc.</div>
    </li> <li> <para-num num="[0284]"> </para-num> <div id="p-0285" num="0284" class="description-line">In some embodiments, the balance of at least two muscles may be determined based on the feature information of the movement signal (e.g., the electromyographic signal, the attitude signal). In some embodiments, a determination may be made as whether the exertion strengths of the two muscles is balanced by comparing the amplitude information of the electromyographic signals of the two muscles (e.g., the root mean square amplitude, the integral electromyogram, the amplitude envelope). For example, if a difference between the amplitude information of the electromyographic signals of the two muscles is within a threshold range, it may be considered that the exertion strengths of the two muscles are substantially the same. In some embodiments, a determination may be made as whether the fatigue degrees of the two muscles are the same by comparing the frequency information of the electromyographic signals of two muscles (e.g., the average power frequency, the median frequency, the short-term zero crossing rate). For example, if a difference between the frequency information of the electromyographic signals of the two muscles is within a threshold range, it may be considered that the fatigue degrees of the two muscles are substantially the same. In some embodiments, a determination may be made as whether motion speeds and motion angles of left and right limbs of the user&#39;s body are consistent by comparing the feature information of the attitude signals of the two muscles (e.g., the acceleration and the angular velocity), so as to determine the balance of the posture of the movement of the user. In some embodiments, the balance degree of left and right muscles of the user&#39;s body may be comprehensively determined based on the balance of the exertion strengths of the at least two muscles, the balance of the fatigue degrees of the at least two muscles, and the balance of the movement posture of the motion of the user. In some embodiments, when it is determined that the balance degree of the left and right muscles of the user is relatively low, a prompt may be sent to the user to remind the user to strengthen exercise of some muscle groups or improve the posture of the current exercise to ensure the effect of the motion.</div>
    </li> <li> <para-num num="[0285]"> </para-num> <div id="p-0286" num="0285" class="description-line">The ability of muscle may be a training amount when the user reaches exhaustion during training. In some embodiments, the ability of muscle may be represented by a characteristic amount determined by one or more of characteristics such as an energy consumption, a count of groups of motion, a count of motion times, a weight, a time, etc. For example, the ability of muscle may be expressed by a total work obtained by multiplying a total count of times of motion by a total weight, or expressed by a power obtained by multiplying the total count of times of motion by the total weight and dividing by the time. In some embodiments, the fatigue degree of muscle of the user may be determined based on the electromyographic signal and/or the attitude signal, the training amount (e.g., an energy consumption amount) of the user when the fatigue degree of muscle of the user is relatively high (e.g., higher than a fatigue threshold) may be determined, and the training amount (e.g., the energy consumption amount) of the user at this time may be used as the ability of muscle of the user.</div>
    </li> <li> <para-num num="[0286]"> </para-num> <div id="p-0287" num="0286" class="description-line">In <figure-callout id="2430" label="step" filenames="US20230210402A1-20230706-D00024.png" state="{{state}}">step</figure-callout> <b>2430</b>, a movement feedback mode may be determined based on the monitoring result.</div>
    </li> <li> <para-num num="[0287]"> </para-num> <div id="p-0288" num="0287" class="description-line">In some embodiments, the <figure-callout id="2430" label="step" filenames="US20230210402A1-20230706-D00024.png" state="{{state}}">step</figure-callout> <b>2430</b> may be performed by the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b>.</div>
    </li> <li> <para-num num="[0288]"> </para-num> <div id="p-0289" num="0288" class="description-line">In some embodiments, the movement feedback mode may include a feedback manner, a feedback priority, a feedback content, or the like, or any combination thereof. In some embodiments, the feedback mode may include, but is not limited to, a text prompt, a voice prompt, an image prompt, a video prompt, a vibration prompt, a pressure prompt, or the like, or any combination thereof. For example, the text prompt may be displayed through a display of the input/<figure-callout id="260" label="output module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">output module</figure-callout> <b>260</b>. The voice prompt may be realized by playing sound through a speaker in the input/<figure-callout id="260" label="output module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">output module</figure-callout> <b>260</b> and/or the <figure-callout id="130" label="wearable device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">wearable device</figure-callout> <b>130</b>. The image prompt and the video prompt may be realized by the display of the input/<figure-callout id="260" label="output module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">output module</figure-callout> <b>260</b> and/or the <figure-callout id="130" label="wearable device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">wearable device</figure-callout> <b>130</b>. The vibration prompt may be realized by a vibration of a vibration module in the input/<figure-callout id="260" label="output module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">output module</figure-callout> <b>260</b> and/or the <figure-callout id="130" label="wearable device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">wearable device</figure-callout> <b>130</b>. The pressure prompt may be realized through electrodes in the <figure-callout id="130" label="wearable device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">wearable device</figure-callout> <b>130</b>. In some embodiments, the movement feedback mode may be determined according to the movement type of the motion of the user. For example, when the user is running, since the text prompt is not easy to be received by the user, the voice prompt, the vibration prompt, or the pressure prompt may be selected to feedback the monitoring result to the user.</div>
    </li> <li> <para-num num="[0289]"> </para-num> <div id="p-0290" num="0289" class="description-line">In some embodiments, the feedback priority may include immediate feedback, feedback after a movement is completed, feedback after a training is completed, etc. The immediate feedback may refer to that the input/<figure-callout id="260" label="output module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">output module</figure-callout> <b>260</b> immediately performs feedback to the user according to the corresponding feedback mode when the user has a problem (e.g., an exertion strength of the muscle is relatively high) during the motion. The feedback after a movement/training is completed may refer to that the input/<figure-callout id="260" label="output module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">output module</figure-callout> <b>260</b> performs feedback to the user in a form of a training suggestion after the user completes a movement/training. In some embodiments, the feedback priority of the movement may be determined based on the movement type of the user. For example, when the movement type of the motion of the user is a movement that is easy to cause injury to the user, for example, a deep squat movement is easy to cause knee buckle, resulting damage to the user&#39;s knee, at this time, the priority of the movement feedback mode may be relatively high, and a more eye-catching feedback mode (e.g., a text prompt with signs) may be used to perform feedback, so that the user may receive the feedback and adjust the movement posture in time. As another example, if the movement type of the motion of the user is a bicep curl movement, the user&#39;s arm is likely to be in a relaxed state without continuous exertion at the lowest point, resulting in low training efficiency, but may not cause harm to the user&#39;s body. At this time, the priority of the movement feedback mode may be relatively low, for example, the feedback may be performed through the text prompt after the user completes the training.</div>
    </li> <li> <para-num num="[0290]"> </para-num> <div id="p-0291" num="0290" class="description-line">In some embodiments, a determination may be made as whether an error occurs in the movement of the motion of the user based on the monitoring result, and the feedback priority of the movement may be determined according to a type of movement error of the motion of the user. The type of movement error may reflect a degree of damage to the user&#39;s body when the user makes the movement error. In some embodiments, the type of movement error may be divided into a type of primary movement error, a type of secondary movement error, and a type of tertiary movement error. The type of primary movement error may be a type of movement error that is easy to cause injury (e.g., knee buckle during the deep squat movement) to the user. The type of secondary movement error may be a type of movement error in which a target training muscle has not been effectively exercised (e.g., arms are bent to exert when the user performs the seated chest press, so that the biceps brachii muscle is exercised but the pectoral muscles are not exercised). The type of tertiary movement error may be a type of movement error that leads to a relatively low training efficiency (e.g., running too slow). In some embodiments, when the type of movement error is the type of primary movement error, the feedback priority may be the immediate feedback. When the type of movement error is the type of secondary movement error, the feedback priority may be the feedback after a movement is completed. When the type of movement error is the tertiary movement error, the feedback priority may be the feedback after a training is completed.</div>
    </li> <li> <para-num num="[0291]"> </para-num> <div id="p-0292" num="0291" class="description-line">In some embodiments, the feedback content may include the monitoring result (e.g., the movement type, the movement quantity, the movement quality, the movement time), the type of movement error, a degree of movement completion, the training suggestion, or the like, or any combination thereof. In some embodiments, the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> may determine the feedback content according to the motion monitoring result such as the movement type and the type of movement error of the motion of the user. For example, after the user completes a training, the input/<figure-callout id="260" label="output module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">output module</figure-callout> <b>260</b> may feedback training information (e.g., the movement type, the movement quantity, the movement quality, the movement time) during the training process to the user, so as to help the user fully understand the training process. As another example, when the user makes a movement error during the motion (e.g., knee buckle during the deep squat movement), the input/<figure-callout id="260" label="output module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">output module</figure-callout> <b>260</b> may prompt the user of the current movement error to help the user adjust the movement in time. In some embodiments, when the user makes a movement error (e.g., an exertion of a certain muscle is wrong) during the motion, the error of the user may be displayed at a position corresponding to the certain muscle in the user movement model. For example, a manner such as an edge flicker, a sign, a word, a symbol (e.g., an exclamation mark), etc. may be used at the position corresponding to the certain muscle in the user movement model to prompt the user that the exertion of the certain muscle at the position is wrong.</div>
    </li> <li> <para-num num="[0292]"> </para-num> <div id="p-0293" num="0292" class="description-line">In <figure-callout id="2440" label="step" filenames="US20230210402A1-20230706-D00024.png" state="{{state}}">step</figure-callout> <b>2440</b>, a movement feedback may be performed to the user according to the movement feedback mode.</div>
    </li> <li> <para-num num="[0293]"> </para-num> <div id="p-0294" num="0293" class="description-line">In some embodiments, the <figure-callout id="2440" label="step" filenames="US20230210402A1-20230706-D00024.png" state="{{state}}">step</figure-callout> <b>2440</b> may be performed by the input/<figure-callout id="260" label="output module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">output module</figure-callout> <b>260</b>.</div>
    </li> <li> <para-num num="[0294]"> </para-num> <div id="p-0295" num="0294" class="description-line">In some embodiments, the input/<figure-callout id="260" label="output module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">output module</figure-callout> <b>260</b> may display the monitoring result to the user in a form of a text, a chart (e.g., a line chart, a bar chart, a pie chart, a histogram), a sound, an image, a video, or the like, or any combination thereof.</div>
    </li> <li> <para-num num="[0295]"> </para-num> <div id="p-0296" num="0295" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>25</b> </figref> is a schematic diagram illustrating a motion monitoring interface according to some embodiments of the present disclosure. As shown in <figref idrefs="DRAWINGS">FIG. <b>25</b> </figref>, basic training information and exercise counts after a user completes a training is displayed in the form of a text in an <figure-callout id="2500" label="interface" filenames="US20230210402A1-20230706-D00025.png" state="{{state}}">interface</figure-callout> <b>2500</b>. In some embodiments, the user may formulate a training plan in advance before the training starts. After the training, the user may compare the basic training information after the training with the training plan to help the user determine a degree of completion of the training plan.</div>
    </li> <li> <para-num num="[0296]"> </para-num> <div id="p-0297" num="0296" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>26</b> </figref> is a schematic diagram illustrating a motion monitoring interface according to some embodiments of the present disclosure. As shown in <figref idrefs="DRAWINGS">FIG. <b>26</b> </figref>, an energy consumption of each muscle after a user completes a training is displayed in the form of a pie chart and a text in an <figure-callout id="2600" label="interface" filenames="US20230210402A1-20230706-D00026.png" state="{{state}}">interface</figure-callout> <b>2600</b>. It may be seen from <figref idrefs="DRAWINGS">FIG. <b>26</b> </figref> that, in the training, the energy consumption of each muscle of the user is arranged in descending order of a pectoral muscle, a biceps brachii muscle, a latissimus dorsi muscle and other muscles. The user may intuitively observe a proportion of energy consumption of each muscle through the pie chart.</div>
    </li> <li> <para-num num="[0297]"> </para-num> <div id="p-0298" num="0297" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>27</b> </figref> is a schematic diagram illustrating a motion monitoring interface according to some embodiments of the present disclosure. As shown in <figref idrefs="DRAWINGS">FIG. <b>27</b> </figref>, a fatigue degree of muscle, an evaluation of the fatigue degree, and an evaluation of the maximum ability of muscle after a user completes a training is displayed in the form of a pattern and a text in an <figure-callout id="2700" label="interface" filenames="US20230210402A1-20230706-D00026.png" state="{{state}}">interface</figure-callout> <b>2700</b>. As shown in <figref idrefs="DRAWINGS">FIG. <b>27</b> </figref>, different fatigue degrees of muscle may be represented by circular patterns of different colors, and the fatigue degree of each muscle may be evaluated according to the degree fatigue of muscle and the maximum ability of muscle (e.g., exhausted, with remaining strength, relaxed).</div>
    </li> <li> <para-num num="[0298]"> </para-num> <div id="p-0299" num="0298" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>28</b> </figref> is a schematic diagram illustrating a motion monitoring interface according to some embodiments of the present disclosure. As shown in <figref idrefs="DRAWINGS">FIG. <b>28</b> </figref>, a balance of left and right muscles of a body after a user completes a training is displayed in the form of a histogram in an <figure-callout id="2800" label="interface" filenames="US20230210402A1-20230706-D00027.png" state="{{state}}">interface</figure-callout> <b>2800</b>. Each kind of muscle may correspond to a columnar strip. A position, a length, and/or a color of the columnar strip may indicate the balance of the kind of muscle corresponding to the columnar strip. For example, the longer the length and/or the darker the color of the columnar strip corresponding to the muscle, the poorer the balance of the muscle. As shown in <figref idrefs="DRAWINGS">FIG. <b>28</b> </figref>, the columnar strips corresponding to a pectoral muscle and a biceps brachii muscle are located on the right, which may indicate that the right pectoral muscle and the right biceps brachii muscle have a relatively high energy. The columnar strip corresponding a latissimus dorsi muscle is on the left, which may indicate that the left latissimus dorsi has a relatively high energy. In addition, a length of the columnar strip corresponding to the pectoral muscle is longer (or darker) than a length of the columnar strip corresponding to the biceps brachii muscle, which may indicate that the balance of the pectoral muscle is lower than the balance of the latissimus dorsi muscle.</div>
    </li> <li> <para-num num="[0299]"> </para-num> <div id="p-0300" num="0299" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>29</b> </figref> is a schematic diagram illustrating a motion monitoring interface according to some embodiments of the present disclosure. As shown in <figref idrefs="DRAWINGS">FIG. <b>29</b> </figref>, a proportion of an exertion time of an abdominal muscle during a training process of a user is displayed in the form of a status bar in an <figure-callout id="2900" label="interface" filenames="US20230210402A1-20230706-D00027.png" state="{{state}}">interface</figure-callout> <b>2900</b>, which may reflect a core stability of the user. For example, it can be seen from <figref idrefs="DRAWINGS">FIG. <b>29</b> </figref> that the proportion of the exertion time of the abdominal muscle during the training process (e.g., sit-ups) of the user is 70%, which may reflect that the core stability of the user is good.</div>
    </li> <li> <para-num num="[0300]"> </para-num> <div id="p-0301" num="0300" class="description-line">In some embodiments, the monitoring result may be displayed in a user model (e.g., the front <figure-callout id="2101" label="muscle distribution map" filenames="US20230210402A1-20230706-D00020.png" state="{{state}}">muscle distribution map</figure-callout> <b>2101</b> shown in <figref idrefs="DRAWINGS">FIG. <b>21</b>B</figref>, the back <figure-callout id="2102" label="muscle distribution model" filenames="US20230210402A1-20230706-D00020.png" state="{{state}}">muscle distribution model</figure-callout> <b>2102</b>, and the <figure-callout id="010" label="user movement model" filenames="US20230210402A1-20230706-D00022.png,US20230210402A1-20230706-D00023.png" state="{{state}}">user movement model</figure-callout> <b>010</b> shown in <figref idrefs="DRAWINGS">FIGS. <b>23</b>A to <b>23</b>C</figref>). For example, an energy consumption of at least one muscle, a fatigue degree of the at least one muscle, a training balance of at least two muscles, an ability of the at least one muscle of the user, or the like, or any combination thereof, may be displayed at least one specific location in the user model. The at least one specific location in the user model may correspond to a location of at least one muscle in the user. In some embodiments, energy consumptions of different muscles, fatigue degrees of different muscles, training balances of different muscles, and/or abilities of different muscles may correspond to different display colors, so that the user may feel the training result more intuitively. In some embodiments, the input/<figure-callout id="260" label="output module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">output module</figure-callout> <b>260</b> may obtain a user input regarding a target muscle and display information of the target muscle in the display interface.</div>
    </li> <li> <para-num num="[0301]"> </para-num> <div id="p-0302" num="0301" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>30</b> </figref> is a schematic diagram illustrating a motion monitoring interface according to some embodiments of the present disclosure. As shown in <figref idrefs="DRAWINGS">FIG. <b>30</b> </figref>, contribution degrees of muscles (e.g., percentages of energy consumptions of muscles) during a training process of a user is displayed in the form of human muscle distribution map in an <figure-callout id="3000" label="interface" filenames="US20230210402A1-20230706-D00028.png" state="{{state}}">interface</figure-callout> <b>3000</b>. It can be seen from <figref idrefs="DRAWINGS">FIG. <b>30</b> </figref> that the contribution degree of a left pectoralis major muscle of the user is 20%, the contribution degree of a right pectoralis major muscle is 30%, and the contribution degrees of a left biceps brachii muscle and a right biceps muscle brachii muscle are both 20%. In some embodiments, the higher the contribution degree of the muscle, the darker the color of the muscle at a corresponding position in the muscle distribution map.</div>
    </li> <li> <para-num num="[0302]"> </para-num> <div id="p-0303" num="0302" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>31</b> </figref> is a schematic diagram illustrating a motion monitoring interface according to some embodiments of the present disclosure. As shown in <figref idrefs="DRAWINGS">FIG. <b>31</b> </figref>, a fatigue degree of muscle during a training process of the user is displayed in the form of human muscle distribution map in an <figure-callout id="3100" label="interface" filenames="US20230210402A1-20230706-D00029.png" state="{{state}}">interface</figure-callout> <b>3100</b>. For example, the higher the fatigue degree of the muscle, the darker the color of the muscle at a corresponding position in the muscle distribution map.</div>
    </li> <li> <para-num num="[0303]"> </para-num> <div id="p-0304" num="0303" class="description-line">It should be noted that the interface display modes shown in <figref idrefs="DRAWINGS">FIGS. <b>25</b>-<b>31</b> </figref> are only examples. In some embodiments, the balance of at least two muscles and/or the ability of muscle may be displayed in the interface in the form of human muscle distribution map. In some embodiments, a plurality of monitoring results may be displayed in a plurality of ways in one interface. For example, the contribution degree of muscle and the fatigue degree of muscle of the user during a training process may be displayed simultaneously in the human muscle distribution map. As another example, the energy consumption of each muscle after the user completes the training may be displayed in the form of the pie chart in the interface, and the energy consumption of each muscle during the training process of the user may be displayed in the human muscle distribution map at the same time.</div>
    </li> <li> <para-num num="[0304]"> </para-num> <div id="p-0305" num="0304" class="description-line">In some embodiments, the <figure-callout id="100" label="motion monitoring system" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">motion monitoring system</figure-callout> <b>100</b> may count motion data during a plurality of training processes of the user and generate a motion record, thereby helping the user understand changes in physical performance and physical quality during long-term exercise and helping the user maintain good exercise habits.</div>
    </li> <li> <para-num num="[0305]"> </para-num> <div id="p-0306" num="0305" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>32</b> </figref> is a schematic diagram illustrating a motion monitoring interface according to some embodiments of the present disclosure. As shown in <figref idrefs="DRAWINGS">FIG. <b>32</b> </figref>, a contribution degree (or an energy consumption) of each muscle of a user in different training cycles (e.g., training cycles in a unit of day, week, month, and year) is displayed through a <figure-callout id="3210" label="histogram" filenames="US20230210402A1-20230706-D00030.png" state="{{state}}">histogram</figure-callout> <b>3210</b> in an <figure-callout id="3200" label="interface" filenames="US20230210402A1-20230706-D00030.png" state="{{state}}">interface</figure-callout> <b>3200</b>. For example, contribution degrees of different muscles may be displayed in different colors in columnar bars. In some embodiments, the user may select a target muscle in a <figure-callout id="3220" label="muscle distribution map" filenames="US20230210402A1-20230706-D00030.png" state="{{state}}">muscle distribution map</figure-callout> <b>3220</b> in the <figure-callout id="3200" label="interface" filenames="US20230210402A1-20230706-D00030.png" state="{{state}}">interface</figure-callout> <b>3200</b>. For example, the user may click a muscle in the <figure-callout id="3220" label="muscle distribution map" filenames="US20230210402A1-20230706-D00030.png" state="{{state}}">muscle distribution map</figure-callout> <b>3220</b> as the target muscle. As shown in <figref idrefs="DRAWINGS">FIG. <b>33</b> </figref>, when the user selects a <figure-callout id="3330" label="pectoral muscle" filenames="US20230210402A1-20230706-D00030.png" state="{{state}}">pectoral muscle</figure-callout> <b>3330</b> in a <figure-callout id="3320" label="muscle distribution map" filenames="US20230210402A1-20230706-D00030.png" state="{{state}}">muscle distribution map</figure-callout> <b>3320</b> as the target muscle, the contribution degree of the pectoral muscle in the different training cycles is displayed through a <figure-callout id="3310" label="histogram" filenames="US20230210402A1-20230706-D00030.png" state="{{state}}">histogram</figure-callout> <b>3310</b> in an <figure-callout id="3300" label="interface" filenames="US20230210402A1-20230706-D00030.png" state="{{state}}">interface</figure-callout> <b>3300</b>. Through long term statistics on the contribution degree of each muscle group, the user can understand his/her training preferences and training history, for example, which muscles are often exercised and which muscles have not been exercised for a long time, so as to help the user better develop a training plan.</div>
    </li> <li> <para-num num="[0306]"> </para-num> <div id="p-0307" num="0306" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>34</b> </figref> is a schematic diagram illustrating a motion monitoring interface according to some embodiments of the present disclosure. As shown in <figref idrefs="DRAWINGS">FIG. <b>34</b> </figref>, the maximum energy consumption of each muscle during a training process of a user is displayed through a <figure-callout id="3410" label="histogram" filenames="US20230210402A1-20230706-D00031.png" state="{{state}}">histogram</figure-callout> <b>3410</b> in an <figure-callout id="3400" label="interface" filenames="US20230210402A1-20230706-D00031.png" state="{{state}}">interface</figure-callout> <b>3400</b>, thereby reflecting an ability of each muscle. In some embodiments, the user may select a target muscle in a <figure-callout id="3420" label="muscle distribution map" filenames="US20230210402A1-20230706-D00031.png" state="{{state}}">muscle distribution map</figure-callout> <b>3420</b> in the <figure-callout id="3400" label="interface" filenames="US20230210402A1-20230706-D00031.png" state="{{state}}">interface</figure-callout> <b>3400</b>. For example, the user may click a muscle in the <figure-callout id="3420" label="muscle distribution map" filenames="US20230210402A1-20230706-D00031.png" state="{{state}}">muscle distribution map</figure-callout> <b>3420</b> as the target muscle. As shown in <figref idrefs="DRAWINGS">FIG. <b>35</b> </figref>, when the user selects a <figure-callout id="3530" label="pectoral muscle" filenames="US20230210402A1-20230706-D00031.png" state="{{state}}">pectoral muscle</figure-callout> <b>3530</b> in a <figure-callout id="3520" label="muscle distribution map" filenames="US20230210402A1-20230706-D00031.png" state="{{state}}">muscle distribution map</figure-callout> <b>3520</b> as the target muscle, the maximum energy consumption of the pectoral muscle in different training cycles is displayed through a <figure-callout id="3510" label="line chart" filenames="US20230210402A1-20230706-D00031.png" state="{{state}}">line chart</figure-callout> <b>3510</b> in an <figure-callout id="3500" label="interface" filenames="US20230210402A1-20230706-D00031.png" state="{{state}}">interface</figure-callout> <b>3500</b>. Through long-term statistics on the ability of each muscle group, the user can understand the growth of his/her ability, so as to help the user better develop a training plan.</div>
    </li> <li> <para-num num="[0307]"> </para-num> <div id="p-0308" num="0307" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>36</b> </figref> is a schematic diagram illustrating a motion monitoring interface according to some embodiments of the present disclosure. As shown in <figref idrefs="DRAWINGS">FIG. <b>36</b> </figref>, a balance of muscle of the user is displayed through a <figure-callout id="3610" label="histogram" filenames="US20230210402A1-20230706-D00032.png" state="{{state}}">histogram</figure-callout> <b>3610</b> in an <figure-callout id="3600" label="interface" filenames="US20230210402A1-20230706-D00032.png" state="{{state}}">interface</figure-callout> <b>3600</b>. In some embodiments, the user may select a target muscle in a <figure-callout id="3620" label="muscle distribution map" filenames="US20230210402A1-20230706-D00032.png" state="{{state}}">muscle distribution map</figure-callout> <b>3620</b> in the <figure-callout id="3600" label="interface" filenames="US20230210402A1-20230706-D00032.png" state="{{state}}">interface</figure-callout> <b>3600</b>. For example, the user may click a muscle in the <figure-callout id="3620" label="muscle distribution map" filenames="US20230210402A1-20230706-D00032.png" state="{{state}}">muscle distribution map</figure-callout> <b>3620</b> as the target muscle. At this time, the interface may show the balance of the target muscle in different training cycles. By keeping a long-term record of the balance (or the core stability) of muscle, the user can understand his/her shortcomings and adjust the training plan in time.</div>
    </li> <li> <para-num num="[0308]"> </para-num> <div id="p-0309" num="0308" class="description-line">It should be noted that the above description regarding the <figure-callout id="2400" label="process" filenames="US20230210402A1-20230706-D00024.png" state="{{state}}">process</figure-callout> <b>2400</b> is merely provided for the purpose of illustration, and not intended to limit the scope of the present disclosure. For those skilled in the art, various modifications and changes can be made to process <b>2400</b> under the guidance of the present disclosure. However, these amendments and changes are still within the scope of the present disclosure.</div>
    </li> <li> <para-num num="[0309]"> </para-num> <div id="p-0310" num="0309" class="description-line">In some embodiments, the <figure-callout id="100" label="motion monitoring system" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">motion monitoring system</figure-callout> <b>100</b> may calibrate the movement signal of the user obtained by the sensor. In some embodiments, the electromyographic signal collected by the electromyography sensor may be vulnerable to a plurality of factors (e.g., an individual user difference, a user skin status, an installation position of the electromyography sensor, an exertion strength of muscle, a fatigue degree of muscle). The factor such as the individual user difference, the user skin status, the installation position of the electromyography sensor, etc. may make it impossible to directly compare the obtained electromyographic signals for different users. Therefore, it is necessary to calibrate the electromyographic signal, so as to eliminate or weaken the influence of the factor such as the individual user difference, the user skin status, the installation position of the electromyography sensor, etc. on the electromyographic signal. In some embodiments, the <figure-callout id="100" label="motion monitoring system" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">motion monitoring system</figure-callout> <b>100</b> may guide the user to perform a series of calibration movements (e.g., movements such as push-ups, etc. that can mobilize a large number of muscle groups to exert) to activate most of the muscle groups to be detected before the motion starts (e.g., a warm-up phase). For example, a display device (e. g., a screen) of the <figure-callout id="130" label="wearable device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">wearable device</figure-callout> <b>130</b> or the mobile <figure-callout id="140" label="terminal device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">terminal device</figure-callout> <b>140</b> may display the calibration movement, and the user may follow instructions to perform a corresponding calibration movement. The <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> may determine an electromyographic signal collected by the electromyography sensor when the user performs the calibration movement as a reference value, and calibrate all the electromyographic signals collected by the user in the movement. For example, taking the push-up movement as the calibration movement as an example, before starting the motion, the <figure-callout id="100" label="motion monitoring system" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">motion monitoring system</figure-callout> <b>100</b> may guide the user to perform a plurality of sets of push-ups (e.g., <b>3</b>-<b>5</b> push-ups), and collect electromyographic signals of activated muscles such as the pectoral muscle, the biceps brachii muscle, the triceps brachii muscle, the rectus abdominis muscle of the user, etc. through the electromyography sensor, and determine a specific multiple of the electromyography amplitude of the muscle activated by the push up movement as the reference value. In some embodiments, a range of the multiple may be between 1.2-5 times. For example, the multiple may be between 1.2-3 times. In some embodiments, each muscle may correspond to different multiples. The multiple may be a value preset by the user or the <figure-callout id="100" label="motion monitoring system" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">motion monitoring system</figure-callout> <b>100</b>, or a value determined by analyzing a feature of the electromyographic signal. In some embodiments, the reference value of the electromyographic signal of a target user in the motion may be determined based on a plurality of historical electromyographic signals collected when the target user performs a calibration movement during a plurality of historical motions. In some embodiments, the reference value of the electromyographic signal of the target user in the motion may be determined based on a plurality of electromyographic signals collected when a plurality of users perform a calibration movement. By using the plurality of historical electromyographic signals collected when the target user performs the calibration movement and/or the electromyographic signals collected when other users perform the calibration movement to adjust the electromyographic signals collected when the target user performs the current calibration movement, the accuracy and rationality of the reference value of the electromyographic signal in the movement may be improved.</div>
    </li> <li> <para-num num="[0310]"> </para-num> <div id="p-0311" num="0310" class="description-line">In some embodiments, the <figure-callout id="100" label="motion monitoring system" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">motion monitoring system</figure-callout> <b>100</b> may guide the user to warm up and display a warm-up result of the user. The warm-up exercise before the motion can improve the motion performance of the user, prevent the user from muscle twitching during the motion, and reduce the risk of injury. In some embodiments, the display device (e.g., the screen) of the <figure-callout id="130" label="wearable device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">wearable device</figure-callout> <b>130</b> or the mobile <figure-callout id="140" label="terminal device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">terminal device</figure-callout> <b>140</b> may display a series of warm-up movements to guide the user to warm up. In some embodiments, the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> may determine the warm-up result of the user based on physiological information of the user. For example, since the warm-up exercise will cause the heart rate of the user to increase, the body temperature of the user to rise, and a volume of perspiration of the user to increase, the sensor (e.g., an electrode) or other hardware devices disposed on the <figure-callout id="130" label="wearable device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">wearable device</figure-callout> <b>130</b> may detect a contact impedance generated by the contact between the electrode and the human body, thus determining a sweating state of the human body, and determining whether the warm-up exercise of the user is sufficient according to the sweating state of the human body. As another example, a determination may be made as whether the warm-up exercise of the user is sufficient based on the fatigue degree of muscle of the user. As another example, a determination may be made as whether the warm-up exercise of the user is sufficient based on information such as an exercise volume, the heart rate, the body temperature, etc. of the user. In some embodiments, a warm-up suggestion may be provided to the user according to the warm-up result, for example, to prompt the user that the warm-up exercise is sufficient to start a formal exercise, or prompt the user to continue the warm-up exercise.</div>
    </li> <li> <para-num num="[0311]"> </para-num> <div id="p-0312" num="0311" class="description-line">In some embodiments, the <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> may determine whether a working state of the sensor is normal based on the movement signal collected by the sensor. The working state of the sensor may include a contact state between the and the skin. The contact state between the sensor and the skin may include a degree of fit between the sensor and the skin, the contact impedance between the sensor and the skin, etc. The quality of the movement signal collected by the sensor set on the user&#39;s skin may be related to the contact state between the sensor and the skin. For example, when the degree of fit between the sensor and the skin is poor, there may be more noise in the movement signal collected by the sensor, resulting in that the movement signal cannot reflect a real motion state of the user. In some embodiments, the degree of fit between the sensor and the skin may be determined according to the quality of the movement signal (e.g., an amount of noise in the movement signal) and/or the contact impedance between the sensor and the skin. If the degree of fit between the sensor and the skin is lower than a certain threshold, it may be determined that the working state of the sensor is abnormal. At this time, prompt information may be sent to the user to remind the user to check the state of the sensor. <figref idrefs="DRAWINGS">FIG. <b>37</b> </figref> is a schematic diagram illustrating a motion monitoring interface according to some embodiments of the present disclosure. As shown in <figref idrefs="DRAWINGS">FIG. <b>37</b> </figref>, an <figure-callout id="3700" label="interface" filenames="US20230210402A1-20230706-D00033.png" state="{{state}}">interface</figure-callout> <b>3700</b> displays a human <figure-callout id="3710" label="muscle distribution map" filenames="US20230210402A1-20230706-D00033.png" state="{{state}}">muscle distribution map</figure-callout> <b>3710</b>, and a dotted <figure-callout id="3720" label="line" filenames="US20230210402A1-20230706-D00033.png" state="{{state}}">line</figure-callout> <b>3720</b> indicates that the degree of fit between the sensor at a position of the right pectoral muscle and the user&#39;s skin is relatively low. In some embodiments, the position with low degree of fit between the sensor and the user&#39;s skin may be marked by other ways (e.g., mark using different colors).</div>
    </li> <li> <para-num num="[0312]"> </para-num> <div id="p-0313" num="0312" class="description-line">In some embodiments, the movement signal of the user may include a signal related to a feature of the user. The <figure-callout id="220" label="processing module" filenames="US20230210402A1-20230706-D00002.png" state="{{state}}">processing module</figure-callout> <b>220</b> may determine feature information of the user based on the signal related to the feature of the user. The feature information of the user may include body shape information, body composition information, etc. The body shape information may include a waist circumference, a chest circumference, a hip circumference, an arm length, a leg length, a shoulder width, etc. The body composition information may include a body weight, a body fat percentage, a fat distribution, a fat thickness, a muscle distribution, a bone density, etc. For example, a plurality of strain gauge sensors may be set at a plurality of parts of the user&#39;s body. By measuring a magnitude of a resistance of the strain gauge sensor that changes with a tensile length, the movement signals obtained may include displacement information, stress, etc. The movement signals may indicate the body shape information of the user. As another example, electrical signals may be applied to electrodes set at a plurality of parts of the user&#39;s body, and information of the conductivity characteristics inside the human body may be extracted by measuring a body surface potential, so as to perform a positioning measurement on the body composition of the user.</div>
    </li> <li> <para-num num="[0313]"> </para-num> <div id="p-0314" num="0313" class="description-line">In some embodiments, the <figure-callout id="100" label="motion monitoring system" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">motion monitoring system</figure-callout> <b>100</b> may monitor the feature information of the user for a long time, and display a statistical analysis result to the user to help the user better understand a physical condition and develop a more reasonable exercise plan. For example, the <figure-callout id="100" label="motion monitoring system" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">motion monitoring system</figure-callout> <b>100</b> may recommend an appropriate exercise to the user, such as a muscle building exercise, a fat loss exercise, a stretching sport, etc., according to a change (e.g., a fat distribution of each part of the user, a muscle distribution of each part of the user) of the feature information of the user over a period of time.</div>
    </li> <li> <para-num num="[0314]"> </para-num> <div id="p-0315" num="0314" class="description-line">In some embodiments, the wearable device of appropriate size may be recommended to the user according to the body shape information. For example, if the user becomes thinner after a long period of exercise, a prompt may be sent to the user to remind the user to replace with a new wearable device. As another example, when the user select other types of wearable devices, appropriate sizes may be recommended to the user according to the body shape information.</div>
    </li> <li> <para-num num="[0315]"> </para-num> <div id="p-0316" num="0315" class="description-line">In some embodiments, when the user wears the <figure-callout id="130" label="wearable device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">wearable device</figure-callout> <b>130</b> to exercise, the user may select a perceptual training mode. In the perceptual training mode, when the user&#39;s muscle (e.g., the target muscle) exerts, the display device (e.g., the screen) of the <figure-callout id="130" label="wearable device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">wearable device</figure-callout> <b>130</b> or the mobile <figure-callout id="140" label="terminal device" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">terminal device</figure-callout> <b>140</b> may display the exertion strength of the muscle. For example, the exertion strength of the target muscle may be displayed through a status bar (e.g., the <figure-callout id="2103" label="status bars" filenames="US20230210402A1-20230706-D00020.png" state="{{state}}"> <figure-callout id="2104" label="status bars" filenames="US20230210402A1-20230706-D00020.png" state="{{state}}">status bars</figure-callout> </figure-callout> <b>2103</b> and <b>2104</b> shown in <figref idrefs="DRAWINGS">FIG. <b>21</b>B</figref>). As another example, the exertion strength of the target muscle may be displayed by the amount of the sound emitted by a sound output device (e.g., a speaker). As yet another example, a brightness and a color of a corresponding muscle position may be changed in a user model to show a change of the exertion strength of the target muscle. In some embodiments, if the exertion strength of the target muscle of the user is consistent with a standard exertion strength, the user may be prompted (e.g., by the voice prompt, the text prompt, etc.) to help the user strengthen the feeling of controlling muscles. Through the perceptual training mode, it can help the user learn to control limbs and muscles, increase an ability of the brain and the nervous system to control muscles, effectively improve a motion performance, improve a movement pattern, and even correct a posture.</div>
    </li> <li> <para-num num="[0316]"> </para-num> <div id="p-0317" num="0316" class="description-line">In some embodiments, the <figure-callout id="100" label="motion monitoring system" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">motion monitoring system</figure-callout> <b>100</b> may formulate a motion plan of the user based on information related to the user. The information related to the user may include feature information (e.g., the gender, the body shape information, the body composition information), an exercise history, an injury history, a health status, an expected training objective (e.g., a muscle building training, a fat loss training, a cardio pulmonary enhancement training, a posture correction training), an expected training intensity (e.g., a high-intensity training, a medium intensity training, a low-intensity training), a training type preference (e.g., an equipment training, a body weight training, an anaerobic training, an aerobic training), etc. of the user. In some embodiments, a professional (e.g., a fitness instructor) may formulate a motion plan according to the information related to the user, and upload the motion plan to the <figure-callout id="100" label="motion monitoring system" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">motion monitoring system</figure-callout> <b>100</b>. The user may modify and adjust the motion plan according to an actual situation. <figref idrefs="DRAWINGS">FIG. <b>38</b> </figref> is a schematic diagram illustrating a motion monitoring interface according to some embodiments of the present disclosure. As shown in <figref idrefs="DRAWINGS">FIG. <b>38</b> </figref>, a user may enter or select a training objective (e.g., a muscle to be strengthened, an enhancement objective), a training intensity (e.g., the high-intensity training, the medium intensity training, the low-intensity training), a training type preference (e.g., the equipment training, the body weight training, the anaerobic training, the aerobic training), a training time, a planning cycle, etc. in an <figure-callout id="3800" label="interface" filenames="US20230210402A1-20230706-D00034.png" state="{{state}}">interface</figure-callout> <b>3800</b>. The <figure-callout id="100" label="motion monitoring system" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">motion monitoring system</figure-callout> <b>100</b> may specify an appropriate motion plan for the user according to the input and the selection of the user.</div>
    </li> <li> <para-num num="[0317]"> </para-num> <div id="p-0318" num="0317" class="description-line">In some embodiments, the <figure-callout id="100" label="motion monitoring system" filenames="US20230210402A1-20230706-D00000.png,US20230210402A1-20230706-D00001.png" state="{{state}}">motion monitoring system</figure-callout> <b>100</b> may estimate a service life of the wearable device (e.g., a remaining usable time, a remaining count of cleanable times, a remaining count of usable times). For example, the wearable device may include a clothing life analysis module. The clothing life analysis module may determine a wear degree of the wearable device according to the contact impedance between the and the user, the quality of the movement signal (e.g., an electromyography sensor signal, an inertial sensor signal, a stress sensor signal) collected by the sensor, and the status of the wearable device (e.g., a count of times cleaned, a used time, a count of times used), and estimate the service life according to the wear degree of the wearable device. In some embodiments, when the service life of the wearable device is less than a certain usable time (e.g., one week) or less than a certain count of usable times (e.g., five times), a prompt may be sent to the user to remind the user to replace with a new wearable device in time.</div>
    </li> <li> <para-num num="[0318]"> </para-num> <div id="p-0319" num="0318" class="description-line">Having thus described the basic concepts, it may be rather apparent to those skilled in the art after reading this detailed disclosure that the foregoing detailed disclosure is intended to be presented by way of example only and is not limiting. Various alterations, improvements, and modifications may occur and are intended to those skilled in the art, though not expressly stated herein. These alterations, improvements, and modifications are intended to be suggested by this disclosure and are within the spirit and scope of the exemplary embodiments of this disclosure.</div>
    </li> <li> <para-num num="[0319]"> </para-num> <div id="p-0320" num="0319" class="description-line">Moreover, certain terminology has been used to describe embodiments of the present disclosure. For example, the terms one embodiment, an embodiment, and/or some embodiments mean that a particular feature, structure or characteristic described in connection with the embodiment is included in at least one embodiment of the present disclosure. Therefore, it is emphasized and should be appreciated that two or more references to an embodiment or one embodiment or an alternative embodiment in various portions of this specification are not necessarily all referring to the same embodiment. Furthermore, the particular features, structures or characteristics may be combined as suitable in one or more embodiments of the present disclosure.</div>
    </li> <li> <para-num num="[0320]"> </para-num> <div id="p-0321" num="0320" class="description-line">Further, it will be appreciated by one skilled in the art, aspects of the present disclosure may be illustrated and described herein in any of a number of patentable classes or context including any new and useful process, machine, manufacture, or composition of matter, or any new and useful improvement thereof. Accordingly, aspects of the present disclosure may be implemented entirely hardware, entirely software (including firmware, resident software, micro-code, etc.) or combining software and hardware implementation that may all generally be referred to herein as a data block, module, engine, unit, component, or system. Furthermore, aspects of the present disclosure may take the form of a computer program product embodied in one or more computer-readable media having computer-readable program code embodied thereon.</div>
    </li> <li> <para-num num="[0321]"> </para-num> <div id="p-0322" num="0321" class="description-line">A computer storage medium may include a propagated data signal with computer readable program code embodied therein, for example, in baseband or as part of a carrier wave. Such a propagated signal may take any of a variety of forms, including electro-magnetic, optical, or the like, or any suitable combination thereof. A computer storage medium may be any computer-readable medium that is not a computer-readable storage medium and that may communicate, propagate, or transport a program for use by or in connection with an instruction execution system, apparatus, or device. Program code embodied on a computer-readable signal medium may be transmitted using any appropriate medium, including wireless, wireline, optical fiber cable, RF, or the like, or any suitable combination of the foregoing.</div>
    </li> <li> <para-num num="[0322]"> </para-num> <div id="p-0323" num="0322" class="description-line">Computer program code for carrying out operations for aspects of the present disclosure may be written in any combination of one or more programming languages, including an object-oriented programming language such as Java, Scala, Smalltalk, Eiffel, JADE, Emerald, C++, C #, VB. NET, Python or the like, conventional procedural programming languages, such as the C programming language, Visual Basic, Fortran 2003, Perl, COBOL 2002, PHP, ABAP, dynamic programming languages such as Python, Ruby, and Groovy, or other programming languages. The program code may execute entirely on the user&#39;s computer, partly on the user&#39;s computer, as a stand-alone software package, partly on the user&#39;s computer and partly on a remote computer or entirely on the remote computer or server. In the latter scenario, the remote computer may be connected to the user&#39;s computer through any type of network, including a local area network (LAN) or a wide area network (WAN), or the connection may be made to an external computer (for example, through the Internet) or in a cloud computing environment or offered as a service such as a Software as a Service (SaaS).</div>
    </li> <li> <para-num num="[0323]"> </para-num> <div id="p-0324" num="0323" class="description-line">Furthermore, the recited order of processing elements or sequences, or the use of numbers, letters, or other designations therefore, is not intended to limit the claimed processes and methods to any order except as may be specified in the claims. Although the above disclosure discusses through various examples what is currently considered to be a variety of useful embodiments of the disclosure, it is to be understood that such detail is solely for that purpose and that the appended claims are not limited to the disclosed embodiments, but, on the contrary, are intended to cover modifications and equivalent arrangements that are within the spirit and scope of the disclosed embodiments. For example, although the implementation of various components described above may be embodied in a hardware device, it may also be implemented as a software-only solution, e.g., an installation on an existing server or mobile device.</div>
    </li> <li> <para-num num="[0324]"> </para-num> <div id="p-0325" num="0324" class="description-line">Similarly, it should be appreciated that in the foregoing description of embodiments of the present disclosure, various features are sometimes grouped together in a single embodiment, figure, or description thereof for the purpose of streamlining the disclosure aiding in the understanding of one or more of the various inventive embodiments. This method of disclosure, however, is not to be interpreted as reflecting an intention that the claimed subject matter requires more features than are expressly recited in each claim. Rather, inventive embodiments lie in less than all features of a single foregoing disclosed embodiment.</div>
    </li> <li> <para-num num="[0325]"> </para-num> <div id="p-0326" num="0325" class="description-line">In some embodiments, the numbers expressing quantities, properties, and so forth, used to describe and claim certain embodiments of the application are to be understood as being modified in some instances by the term about, approximate, or substantially. For example, about, approximate, or substantially may indicate 20% variation of the value it describes, unless otherwise stated. Accordingly, in some embodiments, the numerical parameters set forth in the written description and attached claims are approximations that may vary depending upon the desired properties sought to be obtained by a particular embodiment. In some embodiments, the numerical parameters should be construed in light of the number of reported significant digits and by applying ordinary rounding techniques. Notwithstanding that the numerical ranges and parameters setting forth the broad scope of some embodiments of the application are approximations, the numerical values set forth in the specific examples are reported as precisely as practicable.</div>
    </li> <li> <para-num num="[0326]"> </para-num> <div id="p-0327" num="0326" class="description-line">Each of the patents, patent applications, publications of patent applications, and other material, such as articles, books, specifications, publications, documents, things, and/or the like, referenced herein is hereby incorporated herein by this reference in its entirety for all purposes, excepting any prosecution file history associated with same, any of same that is inconsistent with or in conflict with the present document, or any of same that may have a limiting effect as to the broadest scope of the claims now or later associated with the present document. By way of example, should there be any inconsistency or conflict between the description, definition, and/or the use of a term associated with any of the incorporated material and that associated with the present document, the description, definition, and/or the use of the term in the present document shall prevail.</div>
    </li> <li> <para-num num="[0327]"> </para-num> <div id="p-0328" num="0327" class="description-line">In closing, it is to be understood that the embodiments of the application disclosed herein are illustrative of the principles of the embodiments of the application. Other modifications that may be employed may be within the scope of the application. Thus, by way of example, but not of limitation, alternative configurations of the embodiments of the application may be utilized in accordance with the teachings herein. Accordingly, embodiments of the present application are not limited to that precisely as shown and described.</div>
    
  </li> </ul>
  </div>
  </section>

  <section itemprop="claims" itemscope>
    <h2>Claims (<span itemprop="count">20</span>)</h2>
    
    <div itemprop="content" html><div mxw-id="PCLM417696059" lang="EN" load-source="patent-office" class="claims">
    <div class="claim"> <div id="CLM-00001" num="00001" class="claim">
      <div class="claim-text"> <b>1</b>. A method for displaying a motion monitoring interface, comprising:
<div class="claim-text">obtaining a movement signal during a motion of a user from at least one sensor, wherein the movement signal at least includes an electromyographic signal or an attitude signal;</div> <div class="claim-text">determining information related to the motion of the user by processing the movement signal;</div> <div class="claim-text">displaying the information related to the motion of the user;</div> <div class="claim-text">determining a movement feedback mode based on the information related to the motion of the user; and</div> <div class="claim-text">performing a movement feedback to the user according to the movement feedback mode.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00002" num="00002" class="claim">
      <div class="claim-text"> <b>2</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the determining information related to the motion of the user by processing the movement signal comprises:
<div class="claim-text">determining an exertion strength of at least one muscle of the user based on the electromyographic signal.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00003" num="00003" class="claim">
      <div class="claim-text"> <b>3</b>. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the displaying the information related to the motion of the user comprises:
<div class="claim-text">obtaining a user input regarding a target muscle; and</div> <div class="claim-text">displaying a status bar, wherein a color of the status bar is related to an exertion strength of the target muscle, or</div> <div class="claim-text">making a sound, wherein a volume of the sound is related to the exertion strength of the target muscle.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00004" num="00004" class="claim">
      <div class="claim-text"> <b>4</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the determining information related to the motion of the user by processing the movement signal comprises:
<div class="claim-text">generating a user movement model representing a movement of the motion of the user based on the attitude signal.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00005" num="00005" class="claim">
      <div class="claim-text"> <b>5</b>. The method of <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the displaying the information related to the motion of the user comprises:
<div class="claim-text">obtaining a standard movement model; and</div> <div class="claim-text">displaying the user movement model and the standard movement model.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00006" num="00006" class="claim">
      <div class="claim-text"> <b>6</b>. The method of <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the displaying the information related to the motion of the user comprises:
<div class="claim-text">determining an exertion strength of at least one muscle of the user based on the electromyographic signal; and</div> <div class="claim-text">displaying the exertion strength of the at least one muscle on the user movement model.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00007" num="00007" class="claim">
      <div class="claim-text"> <b>7</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the determining information related to the motion of the user by processing the movement signal comprises:
<div class="claim-text">segmenting the movement signal based on the electromyographic signal or the attitude signal; and</div> <div class="claim-text">determining a monitoring result by monitoring a movement of the motion of the user based on at least one segment of the movement signal.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00008" num="00008" class="claim">
      <div class="claim-text"> <b>8</b>. The method of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein the determining a movement feedback mode based on the information related to the motion of the user comprises:
<div class="claim-text">determining the movement feedback mode based on the monitoring result.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00009" num="00009" class="claim">
      <div class="claim-text"> <b>9</b>. The method of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein
<div class="claim-text">the at least one segment of the movement signal is a movement signal of the user in at least one training process, and</div> <div class="claim-text">the monitoring result includes at least one of a movement type, a movement quantity, a movement quality, a movement time, physiological parameter information of the user, or a core stability of the user during the at least one training process.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00010" num="00010" class="claim">
      <div class="claim-text"> <b>10</b>. The method of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein the monitoring result includes muscle information of the user corresponding to at least one time point, the muscle information of the user includes at least one of an energy consumption of at least one muscle, a fatigue degree of the at least one muscle, a balance of at least two muscles, or an ability of the at least one muscle, and the displaying the information related to the motion of the user comprises:
<div class="claim-text">displaying at least one of the energy consumption of the at least one muscle, the fatigue degree of the at least one muscle, the balance of the at least two muscles, or the ability of the at least one muscle on at least one location in a user model, wherein the at least one location in the user model corresponds to a location of the at least one muscle in the user.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00011" num="00011" class="claim">
      <div class="claim-text"> <b>11</b>. The method of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein energy consumptions of different muscles, fatigue degrees of different muscles, training balances of different muscles, and/or abilities of different muscles correspond to different display colors.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00012" num="00012" class="claim">
      <div class="claim-text"> <b>12</b>. The method of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the displaying the information related to the motion of the user comprises:
<div class="claim-text">obtaining a user input regarding a target muscle; and</div> <div class="claim-text">displaying information of the target muscle.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00013" num="00013" class="claim">
      <div class="claim-text"> <b>13</b>. The method of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein the displaying the information related to the motion of the user comprises:
<div class="claim-text">displaying the monitoring result in at least one form of a text, a chart, a sound, an image, or a video.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00014" num="00014" class="claim">
      <div class="claim-text"> <b>14</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:
<div class="claim-text">calibrating the movement signal.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00015" num="00015" class="claim">
      <div class="claim-text"> <b>15</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:
<div class="claim-text">determining whether a working state of the at least one sensor is normal based on the movement signal; and</div> <div class="claim-text">in response to determining that the working state of the at least one sensor is abnormal, displaying prompt information.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00016" num="00016" class="claim">
      <div class="claim-text"> <b>16</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the movement signal includes a signal related to a feature of the user, and the method further comprises:
<div class="claim-text">determining body shape information and/or body composition information of the user based on the signal related to the feature of the user; and</div> <div class="claim-text">displaying the body shape information and/or the body composition information of the user.</div> </div>
    </div>
    </div> <div class="claim"> <div id="CLM-00017" num="00017" class="claim">
      <div class="claim-text"> <b>17</b>. An electronic device, wherein the electronic device comprises:
<div class="claim-text">a display device, configured to display content;</div> <div class="claim-text">an input device, configured to receive a user input;</div> <div class="claim-text">at least one sensor, configured to detect a movement signal during a motion of a user, wherein the movement signal at least includes an electromyographic signal or an attitude signal; and</div> <div class="claim-text">a processor, connected to the display device, the input device, and the at least one sensor, wherein the processor is configured to:</div> <div class="claim-text">obtain the movement signal during the motion of the user from the at least one sensor;</div> <div class="claim-text">determine information related to the motion of the user by processing the movement signal;</div> <div class="claim-text">control the display device to display the information related to the motion of the user;</div> <div class="claim-text">determine a movement feedback mode based on the information related to the motion of the user; and</div> <div class="claim-text">perform a movement feedback to the user according to the movement feedback mode.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00018" num="00018" class="claim">
      <div class="claim-text"> <b>18</b>. The electronic device of <claim-ref idref="CLM-00017">claim 17</claim-ref>, wherein the processor is configured to:
<div class="claim-text">determine whether a working state of the at least one sensor is normal based on the movement signal; and</div> <div class="claim-text">in response to determining that the working state of the at least one sensor is abnormal, display prompt information.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00019" num="00019" class="claim">
      <div class="claim-text"> <b>19</b>. The electronic device of <claim-ref idref="CLM-00017">claim 17</claim-ref>, wherein the movement signal includes a signal related to a feature of the user, and the processor is configured to:
<div class="claim-text">determine body shape information and/or body composition information of the user based on the signal related to the feature of the user; and</div> <div class="claim-text">display the body shape information and/or the body composition information of the user.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00020" num="00020" class="claim">
      <div class="claim-text"> <b>20</b>. The electronic device of <claim-ref idref="CLM-00017">claim 17</claim-ref>, wherein to control the display device to display the information related to the motion of the user, the processor is configured to:
<div class="claim-text">obtain, form the input device, a user input regarding a target muscle; and</div> <div class="claim-text">control the display device to display the information related to information of the target muscle.</div> </div>
    </div>
  </div> </div>
  </div>
  </section>

  <section itemprop="application" itemscope>

    <section itemprop="metadata" itemscope>
      <span itemprop="applicationNumber">US18/182,373</span>
      <span itemprop="priorityDate">2021-03-19</span>
      <span itemprop="filingDate">2023-03-13</span>
      <span itemprop="title">Methods and devices for motion monitoring 
     </span>
      <span itemprop="ifiStatus">Pending</span>
      
      <a href="/patent/US20230210402A1/en">
        <span itemprop="representativePublication">US20230210402A1</span>
        (<span itemprop="primaryLanguage">en</span>)
      </a>
    </section>

    

    <h2>Applications Claiming Priority (5)</h2>
    <table>
      <thead>
        <tr>
          <th>Application Number</th>
          <th>Priority Date</th>
          <th>Filing Date</th>
          <th>Title</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="appsClaimingPriority" itemscope repeat>
          <td>
            <span itemprop="applicationNumber">PCT/CN2021/081931</span>
            <a href="/patent/WO2022193330A1/en">
              <span itemprop="representativePublication">WO2022193330A1</span>
                (<span itemprop="primaryLanguage">en</span>)
            </a>
          </td>
          <td itemprop="priorityDate">2021-03-19</td>
          <td itemprop="filingDate">2021-03-19</td>
          <td itemprop="title">Exercise monitoring method and system 
       </td>
        </tr>
        <tr itemprop="appsClaimingPriority" itemscope repeat>
          <td>
            <span itemprop="applicationNumber">WOPCT/CN2021/081931</span>
            
          </td>
          <td itemprop="priorityDate"></td>
          <td itemprop="filingDate">2021-03-19</td>
          <td itemprop="title"></td>
        </tr>
        <tr itemprop="appsClaimingPriority" itemscope repeat>
          <td>
            <span itemprop="applicationNumber">WOPCT/CN2021/093302</span>
            
          </td>
          <td itemprop="priorityDate"></td>
          <td itemprop="filingDate">2021-05-12</td>
          <td itemprop="title"></td>
        </tr>
        <tr itemprop="appsClaimingPriority" itemscope repeat>
          <td>
            <span itemprop="applicationNumber">PCT/CN2021/093302</span>
            <a href="/patent/WO2022193425A1/en">
              <span itemprop="representativePublication">WO2022193425A1</span>
                (<span itemprop="primaryLanguage">en</span>)
            </a>
          </td>
          <td itemprop="priorityDate">2021-03-19</td>
          <td itemprop="filingDate">2021-05-12</td>
          <td itemprop="title">Exercise data display method and system 
       </td>
        </tr>
        <tr itemprop="appsClaimingPriority" itemscope repeat>
          <td>
            <span itemprop="applicationNumber">PCT/CN2022/081718</span>
            <a href="/patent/WO2022194281A1/en">
              <span itemprop="representativePublication">WO2022194281A1</span>
                (<span itemprop="primaryLanguage">en</span>)
            </a>
          </td>
          <td itemprop="priorityDate">2021-03-19</td>
          <td itemprop="filingDate">2022-03-18</td>
          <td itemprop="title">Motion monitoring method and device 
       </td>
        </tr>
      </tbody>
    </table>

    <h2>Related Parent Applications (1)</h2>
    <table>
      <thead>
        <tr>
          <th>Application Number</th>
          <th>Title</th>
          <th>Priority Date</th>
          <th>Filing Date</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="parentApps" itemscope repeat>
          <td>
            <span itemprop="applicationNumber">PCT/CN2022/081718</span>
            <span itemprop="relationType">Continuation</span>
            <a href="/patent/WO2022194281A1/en">
              <span itemprop="representativePublication">WO2022194281A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
          </td>
          <td itemprop="priorityDate">2021-03-19</td>
          <td itemprop="filingDate">2022-03-18</td>
          <td itemprop="title">Motion monitoring method and device 
       </td>
        </tr>
      </tbody>
    </table>

    

    <h2>Publications (1)</h2>
    <table>
      <thead>
        <tr>
          <th>Publication Number</th>
          <th>Publication Date</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="pubs" itemscope repeat>
          <td>
            <span itemprop="publicationNumber">US20230210402A1</span>
            
            <span itemprop="thisPatent">true</span>
            <a href="/patent/US20230210402A1/en">
              US20230210402A1
              (<span itemprop="primaryLanguage">en</span>)
            </a>
          </td>
          <td itemprop="publicationDate">2023-07-06</td>
        </tr>
      </tbody>
    </table>

  </section>

  <section itemprop="family" itemscope>
    <h1>Family</h1>
    <h2>ID=83322076</h2>

    <h2>Family Applications (1)</h2>
    <table>
      <thead>
        <tr>
          <th>Application Number</th>
          <th>Title</th>
          <th>Priority Date</th>
          <th>Filing Date</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="applications" itemscope repeat>
          <td>
            <span itemprop="applicationNumber">US18/182,373</span>
            <span itemprop="ifiStatus">Pending</span>
            
            <a href="/patent/US20230210402A1/en">
              <span itemprop="representativePublication">US20230210402A1</span>
                (<span itemprop="primaryLanguage">en</span>)
            </a>
          </td>
          <td itemprop="priorityDate">2021-03-19</td>
          <td itemprop="filingDate">2023-03-13</td>
          <td itemprop="title">Methods and devices for motion monitoring 
     </td>
        </tr>
      </tbody>
    </table>

    

    

    <h2>Country Status (6)</h2>
    <table>
      <thead>
        <tr>
          <th>Country</th>
          <th>Link</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="countryStatus" itemscope repeat>
          <td>
            <span itemprop="countryCode">US</span>
            (<span itemprop="num">1</span>)
            <meta itemprop="thisCountry" content="true">
          </td>
          <td>
            <a href="/patent/US20230210402A1/en">
              <span itemprop="representativePublication">US20230210402A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
          </td>
        </tr>
        <tr itemprop="countryStatus" itemscope repeat>
          <td>
            <span itemprop="countryCode">EP</span>
            (<span itemprop="num">1</span>)
            
          </td>
          <td>
            <a href="/patent/EP4202667A1/en">
              <span itemprop="representativePublication">EP4202667A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
          </td>
        </tr>
        <tr itemprop="countryStatus" itemscope repeat>
          <td>
            <span itemprop="countryCode">JP</span>
            (<span itemprop="num">1</span>)
            
          </td>
          <td>
            <a href="/patent/JP2023553625A/en">
              <span itemprop="representativePublication">JP2023553625A</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
          </td>
        </tr>
        <tr itemprop="countryStatus" itemscope repeat>
          <td>
            <span itemprop="countryCode">KR</span>
            (<span itemprop="num">1</span>)
            
          </td>
          <td>
            <a href="/patent/KR20230091961A/en">
              <span itemprop="representativePublication">KR20230091961A</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
          </td>
        </tr>
        <tr itemprop="countryStatus" itemscope repeat>
          <td>
            <span itemprop="countryCode">CN</span>
            (<span itemprop="num">2</span>)
            
          </td>
          <td>
            <a href="/patent/CN116963807A/en">
              <span itemprop="representativePublication">CN116963807A</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
          </td>
        </tr>
        <tr itemprop="countryStatus" itemscope repeat>
          <td>
            <span itemprop="countryCode">WO</span>
            (<span itemprop="num">1</span>)
            
          </td>
          <td>
            <a href="/patent/WO2022194281A1/en">
              <span itemprop="representativePublication">WO2022194281A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
          </td>
        </tr>
      </tbody>
    </table>

    <h2>Cited By (1)</h2>
    <table>
      <caption>* Cited by examiner,  Cited by third party</caption>
      <thead>
        <tr>
          <th>Publication number</th>
          <th>Priority date</th>
          <th>Publication date</th>
          <th>Assignee</th>
          <th>Title</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="forwardReferencesOrig" itemscope repeat>
          <td>
            <a href="/patent/CN117110952A/en">
              <span itemprop="publicationNumber">CN117110952A</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2023-08-18</td>
          <td itemprop="publicationDate">2023-11-24</td>
          <td><span itemprop="assigneeOriginal"></span></td>
          <td itemprop="title">Signal processing method and signal processing device for Hall sensor 
       </td>
        </tr>
      </tbody>
    </table>

    

    

    <h2>Family Cites Families (8)</h2>
    <table>
      <caption>* Cited by examiner,  Cited by third party</caption>
      <thead>
        <tr>
          <th>Publication number</th>
          <th>Priority date</th>
          <th>Publication date</th>
          <th>Assignee</th>
          <th>Title</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="backwardReferencesFamily" itemscope repeat>
          <td>
            <a href="/patent/US20090319459A1/en">
              <span itemprop="publicationNumber">US20090319459A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2008-02-20</td>
          <td itemprop="publicationDate">2009-12-24</td>
          <td><span itemprop="assigneeOriginal">Massachusetts Institute Of Technology</span></td>
          <td itemprop="title">Physically-animated Visual Display 
       </td>
        </tr>
        <tr itemprop="backwardReferencesFamily" itemscope repeat>
          <td>
            <a href="/patent/CN105797350A/en">
              <span itemprop="publicationNumber">CN105797350A</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2016-03-18</td>
          <td itemprop="publicationDate">2016-07-27</td>
          <td><span itemprop="assigneeOriginal"></span></td>
          <td itemprop="title">Intelligent method and system for body building posture recognition, evaluation, early-warning and intensity estimation 
       </td>
        </tr>
        <tr itemprop="backwardReferencesFamily" itemscope repeat>
          <td>
            <a href="/patent/CN108211309A/en">
              <span itemprop="publicationNumber">CN108211309A</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2017-05-25</td>
          <td itemprop="publicationDate">2018-06-29</td>
          <td><span itemprop="assigneeOriginal"></span></td>
          <td itemprop="title">The guidance method and device of body building 
       </td>
        </tr>
        <tr itemprop="backwardReferencesFamily" itemscope repeat>
          <td>
            <a href="/patent/CN108211308B/en">
              <span itemprop="publicationNumber">CN108211308B</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2017-05-25</td>
          <td itemprop="publicationDate">2019-08-16</td>
          <td><span itemprop="assigneeOriginal"></span></td>
          <td itemprop="title">A kind of movement effects methods of exhibiting and device 
       </td>
        </tr>
        <tr itemprop="backwardReferencesFamily" itemscope repeat>
          <td>
            <a href="/patent/CN110109532A/en">
              <span itemprop="publicationNumber">CN110109532A</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2018-06-11</td>
          <td itemprop="publicationDate">2019-08-09</td>
          <td><span itemprop="assigneeOriginal"></span></td>
          <td itemprop="title">A kind of human action Compare System obtaining system based on human body attitude 
       </td>
        </tr>
        <tr itemprop="backwardReferencesFamily" itemscope repeat>
          <td>
            <a href="/patent/CN113230640A/en">
              <span itemprop="publicationNumber">CN113230640A</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2021-06-17</td>
          <td itemprop="publicationDate">2021-08-10</td>
          <td><span itemprop="assigneeOriginal"></span></td>
          <td itemprop="title">System and method for analyzing movement of bicyclist 
       </td>
        </tr>
        <tr itemprop="backwardReferencesFamily" itemscope repeat>
          <td>
            <a href="/patent/CN114081479A/en">
              <span itemprop="publicationNumber">CN114081479A</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2021-12-08</td>
          <td itemprop="publicationDate">2022-02-25</td>
          <td><span itemprop="assigneeOriginal"></span></td>
          <td itemprop="title">Body state detection method and device, electronic equipment and intelligent garment 
       </td>
        </tr>
        <tr itemprop="backwardReferencesFamily" itemscope repeat>
          <td>
            <a href="/patent/CN114298089A/en">
              <span itemprop="publicationNumber">CN114298089A</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2021-12-10</td>
          <td itemprop="publicationDate">2022-04-08</td>
          <td><span itemprop="assigneeOriginal"></span></td>
          <td itemprop="title">Multi-mode strength training assisting method and system 
       </td>
        </tr>
      </tbody>
    </table>

    <ul>
      <li itemprop="applicationsByYear" itemscope repeat>
        <span itemprop="year">2021</span>
        <ul>
          <li itemprop="application" itemscope repeat>
            <span itemprop="filingDate">2021-05-12</span>
            <span itemprop="countryCode">CN</span>
            <span itemprop="applicationNumber">CN202180064627.1A</span>
            <a href="/patent/CN116963807A/en"><span itemprop="documentId">patent/CN116963807A/en</span></a>
            <span itemprop="legalStatusCat">active</span>
            <span itemprop="legalStatus">Pending</span>
            
          </li>
        </ul>
      </li>
      <li itemprop="applicationsByYear" itemscope repeat>
        <span itemprop="year">2022</span>
        <ul>
          <li itemprop="application" itemscope repeat>
            <span itemprop="filingDate">2022-03-18</span>
            <span itemprop="countryCode">JP</span>
            <span itemprop="applicationNumber">JP2023535549A</span>
            <a href="/patent/JP2023553625A/en"><span itemprop="documentId">patent/JP2023553625A/en</span></a>
            <span itemprop="legalStatusCat">active</span>
            <span itemprop="legalStatus">Pending</span>
            
          </li>
          <li itemprop="application" itemscope repeat>
            <span itemprop="filingDate">2022-03-18</span>
            <span itemprop="countryCode">KR</span>
            <span itemprop="applicationNumber">KR1020237016947A</span>
            <a href="/patent/KR20230091961A/en"><span itemprop="documentId">patent/KR20230091961A/en</span></a>
            <span itemprop="legalStatusCat">active</span>
            <span itemprop="legalStatus">Search and Examination</span>
            
          </li>
          <li itemprop="application" itemscope repeat>
            <span itemprop="filingDate">2022-03-18</span>
            <span itemprop="countryCode">CN</span>
            <span itemprop="applicationNumber">CN202280006986.6A</span>
            <a href="/patent/CN117157622A/en"><span itemprop="documentId">patent/CN117157622A/en</span></a>
            <span itemprop="legalStatusCat">active</span>
            <span itemprop="legalStatus">Pending</span>
            
          </li>
          <li itemprop="application" itemscope repeat>
            <span itemprop="filingDate">2022-03-18</span>
            <span itemprop="countryCode">WO</span>
            <span itemprop="applicationNumber">PCT/CN2022/081718</span>
            <a href="/patent/WO2022194281A1/en"><span itemprop="documentId">patent/WO2022194281A1/en</span></a>
            <span itemprop="legalStatusCat">active</span>
            <span itemprop="legalStatus">Application Filing</span>
            
          </li>
          <li itemprop="application" itemscope repeat>
            <span itemprop="filingDate">2022-03-18</span>
            <span itemprop="countryCode">EP</span>
            <span itemprop="applicationNumber">EP22770633.0A</span>
            <a href="/patent/EP4202667A1/en"><span itemprop="documentId">patent/EP4202667A1/en</span></a>
            <span itemprop="legalStatusCat">active</span>
            <span itemprop="legalStatus">Pending</span>
            
          </li>
        </ul>
      </li>
      <li itemprop="applicationsByYear" itemscope repeat>
        <span itemprop="year">2023</span>
        <ul>
          <li itemprop="application" itemscope repeat>
            <span itemprop="filingDate">2023-03-13</span>
            <span itemprop="countryCode">US</span>
            <span itemprop="applicationNumber">US18/182,373</span>
            <a href="/patent/US20230210402A1/en"><span itemprop="documentId">patent/US20230210402A1/en</span></a>
            <span itemprop="legalStatusCat">active</span>
            <span itemprop="legalStatus">Pending</span>
            <span itemprop="thisApp" content="true" bool></span>
          </li>
        </ul>
      </li>
    </ul>

    </section>

  

  

  <h2>Cited By (1)</h2>
  <table>
    <caption>* Cited by examiner,  Cited by third party</caption>
    <thead>
      <tr>
        <th>Publication number</th>
        <th>Priority date</th>
        <th>Publication date</th>
        <th>Assignee</th>
        <th>Title</th>
      </tr>
    </thead>
    <tbody>
      <tr itemprop="forwardReferences" itemscope repeat>
        <td>
          <a href="/patent/CN117110952A/en">
            <span itemprop="publicationNumber">CN117110952A</span>
            (<span itemprop="primaryLanguage">en</span>)
          </a>
          <span itemprop="examinerCited">*</span>
          
        </td>
        <td itemprop="priorityDate">2023-08-18</td>
        <td itemprop="publicationDate">2023-11-24</td>
        <td><span itemprop="assigneeOriginal"></span></td>
        <td itemprop="title">Signal processing method and signal processing device for Hall sensor 
       </td>
      </tr>
    </tbody>
  </table>

  <section>
    <h2>Also Published As</h2>
    <table>
      <thead>
        <tr>
          <th>Publication number</th>
          <th>Publication date</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="docdbFamily" itemscope repeat>
          <td>
            <a href="/patent/CN116963807A/en">
              <span itemprop="publicationNumber">CN116963807A</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
          </td>
          <td itemprop="publicationDate">2023-10-27</td>
        </tr>
        <tr itemprop="docdbFamily" itemscope repeat>
          <td>
            <a href="/patent/WO2022194281A1/en">
              <span itemprop="publicationNumber">WO2022194281A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
          </td>
          <td itemprop="publicationDate">2022-09-22</td>
        </tr>
        <tr itemprop="docdbFamily" itemscope repeat>
          <td>
            <a href="/patent/EP4202667A1/en">
              <span itemprop="publicationNumber">EP4202667A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
          </td>
          <td itemprop="publicationDate">2023-06-28</td>
        </tr>
        <tr itemprop="docdbFamily" itemscope repeat>
          <td>
            <a href="/patent/JP2023553625A/en">
              <span itemprop="publicationNumber">JP2023553625A</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
          </td>
          <td itemprop="publicationDate">2023-12-25</td>
        </tr>
        <tr itemprop="docdbFamily" itemscope repeat>
          <td>
            <a href="/patent/KR20230091961A/en">
              <span itemprop="publicationNumber">KR20230091961A</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
          </td>
          <td itemprop="publicationDate">2023-06-23</td>
        </tr>
        <tr itemprop="docdbFamily" itemscope repeat>
          <td>
            <a href="/patent/CN117157622A/en">
              <span itemprop="publicationNumber">CN117157622A</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
          </td>
          <td itemprop="publicationDate">2023-12-01</td>
        </tr>
      </tbody>
    </table>
  </section>

  <section>
    <h2>Similar Documents</h2>
    <table>
      <thead>
        <tr>
          <th>Publication</th>
          <th>Publication Date</th>
          <th>Title</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/US9795337B2/en">
                <span itemprop="publicationNumber">US9795337B2</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2017-10-24">2017-10-24</time>
            
            
          </td>
          <td itemprop="title">System, apparatus, and method for promoting usage of core muscles and other applications 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/US20180055375A1/en">
                <span itemprop="publicationNumber">US20180055375A1</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2018-03-01">2018-03-01</time>
            
            
          </td>
          <td itemprop="title">Systems and methods for determining an intensity level of an exercise using photoplethysmogram (ppg) 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/US11246531B2/en">
                <span itemprop="publicationNumber">US11246531B2</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2022-02-15">2022-02-15</time>
            
            
          </td>
          <td itemprop="title">Fatigue measurement in a sensor equipped garment 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/US20230233103A1/en">
                <span itemprop="publicationNumber">US20230233103A1</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2023-07-27">2023-07-27</time>
            
            
          </td>
          <td itemprop="title">Motion monitoring methods and systems 
     </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/US9731184B2/en">
                <span itemprop="publicationNumber">US9731184B2</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2017-08-15">2017-08-15</time>
            
            
          </td>
          <td itemprop="title">Exercise assistive device 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/US20190046839A1/en">
                <span itemprop="publicationNumber">US20190046839A1</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2019-02-14">2019-02-14</time>
            
            
          </td>
          <td itemprop="title">Muscle stress measurement in a sensor equipped garment 
     </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/US20190046107A1/en">
                <span itemprop="publicationNumber">US20190046107A1</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2019-02-14">2019-02-14</time>
            
            
          </td>
          <td itemprop="title">Exercise application based on muscle stress measurement 
     </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/KR101999748B1/en">
                <span itemprop="publicationNumber">KR101999748B1</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2019-07-12">2019-07-12</time>
            
            
          </td>
          <td itemprop="title">IoT FITNESS EQUIPMENT, EXERCISE INSTRUCTION SYSTEM, AND EXERCISE INSTRUCTION METHOD USING THEREOF 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/CN107961523A/en">
                <span itemprop="publicationNumber">CN107961523A</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2018-04-27">2018-04-27</time>
            
            
          </td>
          <td itemprop="title">Human body training system and intelligent body-building system based on heart rate detection 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/US20230210402A1/en">
                <span itemprop="publicationNumber">US20230210402A1</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2023-07-06">2023-07-06</time>
            
            
          </td>
          <td itemprop="title">Methods and devices for motion monitoring 
     </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/CN106178466A/en">
                <span itemprop="publicationNumber">CN106178466A</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2016-12-07">2016-12-07</time>
            
            
          </td>
          <td itemprop="title">A kind of body-building expenditure analysis method and system 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/CN210575125U/en">
                <span itemprop="publicationNumber">CN210575125U</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2020-05-19">2020-05-19</time>
            
            
          </td>
          <td itemprop="title">Intelligent sports equipment 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/CN116785659A/en">
                <span itemprop="publicationNumber">CN116785659A</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2023-09-22">2023-09-22</time>
            
            
          </td>
          <td itemprop="title">Motion monitoring method and device 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/US10779748B2/en">
                <span itemprop="publicationNumber">US10779748B2</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2020-09-22">2020-09-22</time>
            
            
          </td>
          <td itemprop="title">Biometric electromyography sensor device for fatigue monitoring and injury prevention and methods for using same 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/TW202239378A/en">
                <span itemprop="publicationNumber">TW202239378A</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2022-10-16">2022-10-16</time>
            
            
          </td>
          <td itemprop="title">Method and system for motion monitoring 
     </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/US20210252339A1/en">
                <span itemprop="publicationNumber">US20210252339A1</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2021-08-19">2021-08-19</time>
            
            
          </td>
          <td itemprop="title">Augmented reality for detecting athletic fatigue 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/TW201701223A/en">
                <span itemprop="publicationNumber">TW201701223A</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2017-01-01">2017-01-01</time>
            
            
          </td>
          <td itemprop="title">System and method for sharing bodybuilding recording 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/US20230337989A1/en">
                <span itemprop="publicationNumber">US20230337989A1</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2023-10-26">2023-10-26</time>
            
            
          </td>
          <td itemprop="title">Motion data display method and system 
     </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/RU2813471C1/en">
                <span itemprop="publicationNumber">RU2813471C1</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2024-02-12">2024-02-12</time>
            
            
          </td>
          <td itemprop="title">Methods and systems for identifying user action 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            
            <meta itemprop="isScholar" content="true">
              <meta itemprop="scholarID" content="11343431270777568982">
              <a href="/scholar/11343431270777568982"><span itemprop="scholarAuthors">Ivanov et al.</span></a>
            
          </td>
          <td>
            
            <time itemprop="publicationDate" datetime="2020">2020</time>
            
          </td>
          <td itemprop="title">Recognition and Control of the Athlete&#39;s Movements Using a Wearable Electronics System</td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/CN115105819A/en">
                <span itemprop="publicationNumber">CN115105819A</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2022-09-27">2022-09-27</time>
            
            
          </td>
          <td itemprop="title">Motion monitoring method and system 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/US20230039042A1/en">
                <span itemprop="publicationNumber">US20230039042A1</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2023-02-09">2023-02-09</time>
            
            
          </td>
          <td itemprop="title">Muscle activation, and associated algorithms, systems and methods 
     </td>
        </tr>
      </tbody>
    </table>
  </section>

  <section>
    <h2>Legal Events</h2>
    <table>
      <thead>
        <tr>
          <th>Date</th>
          <th>Code</th>
          <th>Title</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="legalEvents" itemscope repeat>
          <td><time itemprop="date" datetime="2023-09-01">2023-09-01</time></td>
          <td itemprop="code">AS</td>
          <td itemprop="title">Assignment</td>
          <td>
            <p itemprop="attributes" itemscope repeat>
              <strong itemprop="label">Owner name</strong>:
              <span itemprop="value">SHENZHEN SHOKZ CO., LTD., CHINA</span>
            </p>
            <p itemprop="attributes" itemscope repeat>
              <strong itemprop="label">Free format text</strong>:
              <span itemprop="value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:SU, LEI;LI, MEIQI;ZHOU, XIN;AND OTHERS;REEL/FRAME:064771/0371</span>
            </p>
            <p itemprop="attributes" itemscope repeat>
              <strong itemprop="label">Effective date</strong>:
              <span itemprop="value">20220331</span>
            </p>
          </td>
        </tr>
      </tbody>
    </table>
  </section>

</article>

    </search-app>
    <script type="text/javascript" src="//www.gstatic.com/feedback/api.js"></script>
    <script type="text/javascript" src="//www.gstatic.com/feedback/js/help/prod/service/lazy.min.js"></script>
    <script type="text/javascript">
      if (window.help && window.help.service) {
        helpApi = window.help.service.Lazy.create(0, {apiKey: 'AIzaSyDTEI_0tLX4varJ7bwK8aT-eOI5qr3BmyI', locale: 'en-US'});
        window.requestedSurveys = new Set();
        window.requestSurvey = function(triggerId) {
          if (window.requestedSurveys.has(triggerId)) {
            return;
          }
          window.requestedSurveys.add(triggerId);
          helpApi.requestSurvey({
            triggerId: triggerId,
            enableTestingMode: false,
            callback: (requestSurveyCallbackParam) => {
              if (!requestSurveyCallbackParam.surveyData) {
                return;
              }
              helpApi.presentSurvey({
                productData: {
                  productVersion: window.version,
                  customData: {
                    "experiments": "72459301,72474719",
                  },
                },
                surveyData: requestSurveyCallbackParam.surveyData,
                colorScheme: 1,
                customZIndex: 10000,
              });
            }
          });
        };

        window.requestSurvey('YXTwAsvoW0kedxbuTdH0RArc9VhT');
      }
    </script>
    <script src="/sw/null_loader.js"></script>
  </body>
</html>
