<!DOCTYPE html>
<html lang="en">
  <head>
    <title>US20210287438A1 - Localization method and apparatus of displaying virtual object in augmented reality 
        - Google Patents</title>

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta charset="UTF-8">
    <meta name="referrer" content="origin-when-crossorigin">
    <link rel="canonical" href="https://patents.google.com/patent/US20210287438A1/en">
    <meta name="description" content="
     Disclosed is a localization method and apparatus that may acquire localization information of a device, generate a first image that includes a directional characteristic corresponding to an object included in an input image, generate a second image in which the object is projected based on the localization information, to map data corresponding to a location of the object, and adjust the localization information based on visual alignment between the first image and the second image. 
   
   ">
    <meta name="DC.type" content="patent">
    <meta name="DC.title" content="Localization method and apparatus of displaying virtual object in augmented reality 
       ">
    <meta name="DC.date" content="2021-06-01" scheme="dateSubmitted">
    <meta name="DC.description" content="
     Disclosed is a localization method and apparatus that may acquire localization information of a device, generate a first image that includes a directional characteristic corresponding to an object included in an input image, generate a second image in which the object is projected based on the localization information, to map data corresponding to a location of the object, and adjust the localization information based on visual alignment between the first image and the second image. 
   
   ">
    <meta name="citation_patent_application_number" content="US:17/335,199">
    <meta name="citation_pdf_url" content="https://patentimages.storage.googleapis.com/64/b2/b2/03d81bf3340195/US20210287438A1.pdf">
    <meta name="citation_patent_publication_number" content="US:20210287438:A1">
    <meta name="DC.date" content="2021-09-16">
    <meta name="DC.contributor" content="Minjung SON" scheme="inventor">
    <meta name="DC.contributor" content="Hyun Sung Chang" scheme="inventor">
    <meta name="DC.contributor" content="Samsung Electronics Co Ltd" scheme="assignee">
    <meta name="DC.relation" content="US:20050180602:A1" scheme="references">
    <meta name="DC.relation" content="US:20130294642:A1" scheme="references">
    <meta name="DC.relation" content="US:20150356741:A1" scheme="references">
    <meta name="DC.relation" content="US:20190122115:A1" scheme="references">
    <meta name="DC.relation" content="US:20200119830:A1" scheme="references">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:400,400italic,500,500italic,700">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Product+Sans">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Google+Sans:wght@400;500;700">

    <style>
      body { transition: none; }
    </style>

    <script>
      window.version = 'patent-search.search_20240108_RC01';

      function sendFeedback() {
        userfeedback.api.startFeedback({
          'productId': '713680',
          'bucket': 'patent-search-web',
          'productVersion': window.version,
        });
      }

      window.experiments = {};
      window.experiments.patentCountries = "ae,ag,al,am,ao,ap,ar,at,au,aw,az,ba,bb,bd,be,bf,bg,bh,bj,bn,bo,br,bw,bx,by,bz,ca,cf,cg,ch,ci,cl,cm,cn,co,cr,cs,cu,cy,cz,dd,de,dj,dk,dm,do,dz,ea,ec,ee,eg,em,ep,es,fi,fr,ga,gb,gc,gd,ge,gh,gm,gn,gq,gr,gt,gw,hk,hn,hr,hu,ib,id,ie,il,in,ir,is,it,jo,jp,ke,kg,kh,km,kn,kp,kr,kw,kz,la,lc,li,lk,lr,ls,lt,lu,lv,ly,ma,mc,md,me,mg,mk,ml,mn,mo,mr,mt,mw,mx,my,mz,na,ne,ng,ni,nl,no,nz,oa,om,pa,pe,pg,ph,pl,pt,py,qa,ro,rs,ru,rw,sa,sc,sd,se,sg,si,sk,sl,sm,sn,st,su,sv,sy,sz,td,tg,th,tj,tm,tn,tr,tt,tw,tz,ua,ug,us,uy,uz,vc,ve,vn,wo,yu,za,zm,zw";
      
      
      window.experiments.keywordWizard = true;
      
      
      
      window.experiments.definitions = true;

      window.Polymer = {
        dom: 'shady',
        lazyRegister: true,
      };
    </script>

    <script src="//www.gstatic.com/patent-search/frontend/patent-search.search_20240108_RC01/scs/compiled_dir/webcomponentsjs/webcomponents-lite.min.js"></script>
    <link rel="import" href="//www.gstatic.com/patent-search/frontend/patent-search.search_20240108_RC01/scs/compiled_dir/search-app-vulcanized.html">
  </head>
  <body unresolved>
    <script src="//www.gstatic.com/patent-search/frontend/patent-search.search_20240108_RC01/scs/compiled_dir/search-app-vulcanized.js"></script>
    <search-app>
      
      

      <article class="result" itemscope itemtype="http://schema.org/ScholarlyArticle">
  <h1 itemprop="pageTitle">US20210287438A1 - Localization method and apparatus of displaying virtual object in augmented reality 
        - Google Patents</h1>
  <span itemprop="title">Localization method and apparatus of displaying virtual object in augmented reality 
       </span>

  <meta itemprop="type" content="patent">
  <a href="https://patentimages.storage.googleapis.com/64/b2/b2/03d81bf3340195/US20210287438A1.pdf" itemprop="pdfLink">Download PDF</a>
  <h2>Info</h2>

  <dl>
    <dt>Publication number</dt>
    <dd itemprop="publicationNumber">US20210287438A1</dd>
    <meta itemprop="numberWithoutCodes" content="20210287438">
    <meta itemprop="kindCode" content="A1">
    <meta itemprop="publicationDescription" content="Patent application publication">
    <span>US20210287438A1</span>
    <span>US17/335,199</span>
    <span>US202117335199A</span>
    <span>US2021287438A1</span>
    <span>US 20210287438 A1</span>
    <span>US20210287438 A1</span>
    <span>US 20210287438A1</span>
    <span>  </span>
    <span> </span>
    <span> </span>
    <span>US 202117335199 A</span>
    <span>US202117335199 A</span>
    <span>US 202117335199A</span>
    <span>US 2021287438 A1</span>
    <span>US2021287438 A1</span>
    <span>US 2021287438A1</span>

    <dt>Authority</dt>
    <dd itemprop="countryCode">US</dd>
    <dd itemprop="countryName">United States</dd>

    <dt>Prior art keywords</dt>
    <dd itemprop="priorArtKeywords" repeat>image</dd>
    <dd itemprop="priorArtKeywords" repeat>localization</dd>
    <dd itemprop="priorArtKeywords" repeat>information</dd>
    <dd itemprop="priorArtKeywords" repeat>pixels</dd>
    <dd itemprop="priorArtKeywords" repeat>localization information</dd>

    <dt>Prior art date</dt>
    <dd><time itemprop="priorArtDate" datetime="2018-09-11">2018-09-11</time></dd>

    <dt>Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)</dt>
    <dd itemprop="legalStatusIfi" itemscope>
      <span itemprop="status">Granted</span>
    </dd>
  </dl>

  <dt>Application number</dt>
  <dd itemprop="applicationNumber">US17/335,199</dd>

  

  <dt>Other versions</dt>
  <dd itemprop="directAssociations" itemscope repeat>
    <a href="/patent/US11842447B2/en">
      <span itemprop="publicationNumber">US11842447B2</span>
      (<span itemprop="primaryLanguage">en</span>
    </a>
  </dd>

  <dt>Inventor</dt>
  <dd itemprop="inventor" repeat>Minjung SON</dd>
  <dd itemprop="inventor" repeat>Hyun Sung Chang</dd>

  <dt>Current Assignee (The listed assignees may be inaccurate. Google has not performed a legal analysis and makes no representation or warranty as to the accuracy of the list.)</dt>
  <dd itemprop="assigneeCurrent" repeat>
    Samsung Electronics Co Ltd
  </dd>

  <dt>Original Assignee</dt>
  <dd itemprop="assigneeOriginal" repeat>Samsung Electronics Co Ltd</dd>

  <dt>Priority date (The priority date is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the date listed.)</dt>
  <dd><time itemprop="priorityDate" datetime="2018-09-11">2018-09-11</time></dd>

  <dt>Filing date</dt>
  <dd><time itemprop="filingDate" datetime="2021-06-01">2021-06-01</time></dd>

  <dt>Publication date</dt>
  <dd><time itemprop="publicationDate" datetime="2021-09-16">2021-09-16</time></dd>

  
  <dd itemprop="events" itemscope repeat>
    <time itemprop="date" datetime="2021-06-01">2021-06-01</time>
    <span itemprop="title">Application filed by Samsung Electronics Co Ltd</span>
    <span itemprop="type">filed</span>
    <span itemprop="critical" content="true" bool>Critical</span>
    
    
    
    <span itemprop="assigneeSearch">Samsung Electronics Co Ltd</span>
  </dd>
  <dd itemprop="events" itemscope repeat>
    <time itemprop="date" datetime="2021-06-01">2021-06-01</time>
    <span itemprop="title">Priority to US17/335,199</span>
    <span itemprop="type">priority</span>
    <span itemprop="critical" content="true" bool>Critical</span>
    
    
    <span itemprop="documentId">patent/US11842447B2/en</span>
    
  </dd>
  <dd itemprop="events" itemscope repeat>
    <time itemprop="date" datetime="2021-09-16">2021-09-16</time>
    <span itemprop="title">Publication of US20210287438A1</span>
    <span itemprop="type">publication</span>
    <span itemprop="critical" content="true" bool>Critical</span>
    
    
    <span itemprop="documentId">patent/US20210287438A1/en</span>
    
  </dd>
  <dd itemprop="events" itemscope repeat>
    <time itemprop="date" datetime="2023-12-12">2023-12-12</time>
    <span itemprop="title">Application granted</span>
    <span itemprop="type">granted</span>
    <span itemprop="critical" content="true" bool>Critical</span>
    
    
    
    
  </dd>
  <dd itemprop="events" itemscope repeat>
    <time itemprop="date" datetime="2023-12-12">2023-12-12</time>
    <span itemprop="title">Publication of US11842447B2</span>
    <span itemprop="type">publication</span>
    <span itemprop="critical" content="true" bool>Critical</span>
    
    
    <span itemprop="documentId">patent/US11842447B2/en</span>
    
  </dd>
  <dd itemprop="events" itemscope repeat>
    <time itemprop="date">Status</time>
    <span itemprop="title">Active</span>
    <span itemprop="type">legal-status</span>
    <span itemprop="critical" content="true" bool>Critical</span>
    <span itemprop="current" content="true" bool>Current</span>
    
    
    
  </dd>
  <dd itemprop="events" itemscope repeat>
    <time itemprop="date" datetime="2039-01-28">2039-01-28</time>
    <span itemprop="title">Anticipated expiration</span>
    <span itemprop="type">legal-status</span>
    <span itemprop="critical" content="true" bool>Critical</span>
    
    
    
    
  </dd>

  <h2>Links</h2>
  <ul>
    <li itemprop="links" itemscope repeat>
          <meta itemprop="id" content="usptoLink">
          <a href="https://appft.uspto.gov/netacgi/nph-Parser?Sect1=PTO1&Sect2=HITOFF&p=1&u=/netahtml/PTO/srchnum.html&r=1&f=G&l=50&d=PG01&s1=20210287438.PGNR." itemprop="url" target="_blank"><span itemprop="text">USPTO</span></a>
        </li>
        
        <li itemprop="links" itemscope repeat>
          <meta itemprop="id" content="usptoPatentCenterLink">
          <a href="https://patentcenter.uspto.gov/applications/17335199" itemprop="url" target="_blank"><span itemprop="text">USPTO PatentCenter</span></a>
        </li>
        <li itemprop="links" itemscope repeat>
          <meta itemprop="id" content="usptoAssignmentLink">
          <a href="https://assignment.uspto.gov/patent/index.html#/patent/search/resultFilter?searchInput=20210287438" itemprop="url" target="_blank"><span itemprop="text">USPTO Assignment</span></a>
        </li>

    <li itemprop="links" itemscope repeat>
        <meta itemprop="id" content="espacenetLink">
        <a href="https://worldwide.espacenet.com/publicationDetails/biblio?CC=US&amp;NR=2021287438A1&amp;KC=A1&amp;FT=D" itemprop="url" target="_blank"><span itemprop="text">Espacenet</span></a>
      </li>
      

    

    
      <li itemprop="links" itemscope repeat>
        <meta itemprop="id" content="globalDossierLink">
        <a href="https://globaldossier.uspto.gov/#/result/publication/US/20210287438/1" itemprop="url" target="_blank"><span itemprop="text">Global Dossier</span></a>
      </li>

      

      

      

      <li itemprop="links" itemscope repeat>
        <meta itemprop="id" content="stackexchangeLink">
        <a href="https://patents.stackexchange.com/questions/tagged/US20210287438" itemprop="url"><span itemprop="text">Discuss</span></a>
      </li>
      
  </ul>

  <ul itemprop="concept" itemscope>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000004807</span>
      <span itemprop="name">localization</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>title</span>
      <span itemprop="sections" repeat>claims</span>
      <span itemprop="sections" repeat>abstract</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">251</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000000034</span>
      <span itemprop="name">method</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>title</span>
      <span itemprop="sections" repeat>claims</span>
      <span itemprop="sections" repeat>abstract</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">69</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000003190</span>
      <span itemprop="name">augmentative effect</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>title</span>
      <span itemprop="sections" repeat>claims</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">13</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000000007</span>
      <span itemprop="name">visual effect</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>claims</span>
      <span itemprop="sections" repeat>abstract</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">53</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000013528</span>
      <span itemprop="name">artificial neural network</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>claims</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">43</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">239000011521</span>
      <span itemprop="name">glass</span>
      <span itemprop="domain">Substances</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>claims</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">7</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000005259</span>
      <span itemprop="name">measurement</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>claims</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">4</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000011176</span>
      <span itemprop="name">pooling</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>claims</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">4</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000001419</span>
      <span itemprop="name">dependent effect</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>claims</span>
      <span itemprop="count">10</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000002194</span>
      <span itemprop="name">synthesizing effect</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>claims</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000015654</span>
      <span itemprop="name">memory</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">16</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000008569</span>
      <span itemprop="name">process</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">12</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000010586</span>
      <span itemprop="name">diagram</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">9</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000006870</span>
      <span itemprop="name">function</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">8</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000012545</span>
      <span itemprop="name">processing</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">8</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000004891</span>
      <span itemprop="name">communication</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">7</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000012986</span>
      <span itemprop="name">modification</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">7</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000004048</span>
      <span itemprop="name">modification</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">7</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000012549</span>
      <span itemprop="name">training</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">7</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">239000004575</span>
      <span itemprop="name">stone</span>
      <span itemprop="domain">Substances</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">4</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000013527</span>
      <span itemprop="name">convolutional neural network</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">3</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000013500</span>
      <span itemprop="name">data storage</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">2</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">239000000284</span>
      <span itemprop="name">extract</span>
      <span itemprop="domain">Substances</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">2</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000005457</span>
      <span itemprop="name">optimization</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">2</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000000306</span>
      <span itemprop="name">recurrent effect</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">2</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000009466</span>
      <span itemprop="name">transformation</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">2</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000001133</span>
      <span itemprop="name">acceleration</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000003213</span>
      <span itemprop="name">activating effect</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000008901</span>
      <span itemprop="name">benefit</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000002457</span>
      <span itemprop="name">bidirectional effect</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">239000003086</span>
      <span itemprop="name">colorant</span>
      <span itemprop="domain">Substances</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000004590</span>
      <span itemprop="name">computer program</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000007423</span>
      <span itemprop="name">decrease</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000014509</span>
      <span itemprop="name">gene expression</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000007654</span>
      <span itemprop="name">immersion</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000003993</span>
      <span itemprop="name">interaction</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000011835</span>
      <span itemprop="name">investigation</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000033001</span>
      <span itemprop="name">locomotion</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000007726</span>
      <span itemprop="name">management method</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000013507</span>
      <span itemprop="name">mapping</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000003287</span>
      <span itemprop="name">optical effect</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000001902</span>
      <span itemprop="name">propagating effect</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000004044</span>
      <span itemprop="name">response</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000006403</span>
      <span itemprop="name">short-term memory</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
  </ul>

  <section>
    <h2>Images</h2>
    <ul>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/f1/0d/51/422e8586be6378/US20210287438A1-20210916-D00000.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/c4/f3/4b/1816000c71c852/US20210287438A1-20210916-D00000.png">
        <ul>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/19/f3/86/3250bff87f26c0/US20210287438A1-20210916-D00001.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/e6/cf/05/303c410679c0a4/US20210287438A1-20210916-D00001.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="1">
            <meta itemprop="id" content="110">
            <meta itemprop="label" content="object">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="531">
              <meta itemprop="top" content="651">
              <meta itemprop="right" content="610">
              <meta itemprop="bottom" content="688">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="1">
            <meta itemprop="id" content="115">
            <meta itemprop="label" content="guide lane">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1005">
              <meta itemprop="top" content="666">
              <meta itemprop="right" content="1084">
              <meta itemprop="bottom" content="703">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="1">
            <meta itemprop="id" content="120">
            <meta itemprop="label" content="AR image">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1503">
              <meta itemprop="top" content="398">
              <meta itemprop="right" content="1579">
              <meta itemprop="bottom" content="434">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="1">
            <meta itemprop="id" content="130">
            <meta itemprop="label" content="object">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="532">
              <meta itemprop="top" content="1425">
              <meta itemprop="right" content="613">
              <meta itemprop="bottom" content="1465">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="1">
            <meta itemprop="id" content="135">
            <meta itemprop="label" content="guide lane">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1000">
              <meta itemprop="top" content="1445">
              <meta itemprop="right" content="1077">
              <meta itemprop="bottom" content="1482">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="1">
            <meta itemprop="id" content="140">
            <meta itemprop="label" content="AR image">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1499">
              <meta itemprop="top" content="1174">
              <meta itemprop="right" content="1577">
              <meta itemprop="bottom" content="1211">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/8f/e0/43/464c4646339610/US20210287438A1-20210916-D00002.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/0c/f1/75/8d6a80a853ae53/US20210287438A1-20210916-D00002.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="2">
            <meta itemprop="id" content="210">
            <meta itemprop="label" content="operation">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1564">
              <meta itemprop="top" content="365">
              <meta itemprop="right" content="1650">
              <meta itemprop="bottom" content="403">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="2">
            <meta itemprop="id" content="220">
            <meta itemprop="label" content="operation">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1564">
              <meta itemprop="top" content="592">
              <meta itemprop="right" content="1647">
              <meta itemprop="bottom" content="631">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="2">
            <meta itemprop="id" content="230">
            <meta itemprop="label" content="operation">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1563">
              <meta itemprop="top" content="875">
              <meta itemprop="right" content="1648">
              <meta itemprop="bottom" content="913">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="2">
            <meta itemprop="id" content="240">
            <meta itemprop="label" content="operation">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1564">
              <meta itemprop="top" content="1157">
              <meta itemprop="right" content="1647">
              <meta itemprop="bottom" content="1195">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/9c/0a/39/0536d98690f386/US20210287438A1-20210916-D00003.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/84/3e/53/4d4a7a6d7c39d6/US20210287438A1-20210916-D00003.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="3">
            <meta itemprop="id" content="310">
            <meta itemprop="label" content="operation">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="336">
              <meta itemprop="top" content="1197">
              <meta itemprop="right" content="373">
              <meta itemprop="bottom" content="1280">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="3">
            <meta itemprop="id" content="320">
            <meta itemprop="label" content="operation">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="338">
              <meta itemprop="top" content="606">
              <meta itemprop="right" content="372">
              <meta itemprop="bottom" content="686">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="3">
            <meta itemprop="id" content="330">
            <meta itemprop="label" content="operation">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="529">
              <meta itemprop="top" content="1198">
              <meta itemprop="right" content="563">
              <meta itemprop="bottom" content="1279">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="3">
            <meta itemprop="id" content="340">
            <meta itemprop="label" content="operation">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="529">
              <meta itemprop="top" content="20">
              <meta itemprop="right" content="564">
              <meta itemprop="bottom" content="100">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="3">
            <meta itemprop="id" content="350">
            <meta itemprop="label" content="operation">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="529">
              <meta itemprop="top" content="605">
              <meta itemprop="right" content="563">
              <meta itemprop="bottom" content="686">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="3">
            <meta itemprop="id" content="360">
            <meta itemprop="label" content="operation">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="722">
              <meta itemprop="top" content="1200">
              <meta itemprop="right" content="759">
              <meta itemprop="bottom" content="1280">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="3">
            <meta itemprop="id" content="370">
            <meta itemprop="label" content="operation">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="968">
              <meta itemprop="top" content="1199">
              <meta itemprop="right" content="1003">
              <meta itemprop="bottom" content="1280">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/0e/ff/21/2dc035e4710d37/US20210287438A1-20210916-D00004.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/b6/0f/82/b25fb86a37dc26/US20210287438A1-20210916-D00004.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="4">
            <meta itemprop="id" content="410">
            <meta itemprop="label" content="input image">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="671">
              <meta itemprop="top" content="136">
              <meta itemprop="right" content="751">
              <meta itemprop="bottom" content="174">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="4">
            <meta itemprop="id" content="420">
            <meta itemprop="label" content="first image">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="671">
              <meta itemprop="top" content="746">
              <meta itemprop="right" content="751">
              <meta itemprop="bottom" content="781">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="4">
            <meta itemprop="id" content="430">
            <meta itemprop="label" content="second image">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1589">
              <meta itemprop="top" content="1367">
              <meta itemprop="right" content="1667">
              <meta itemprop="bottom" content="1402">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="4">
            <meta itemprop="id" content="440">
            <meta itemprop="label" content="image">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="672">
              <meta itemprop="top" content="1357">
              <meta itemprop="right" content="748">
              <meta itemprop="bottom" content="1395">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="4">
            <meta itemprop="id" content="450">
            <meta itemprop="label" content="image">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="672">
              <meta itemprop="top" content="1972">
              <meta itemprop="right" content="751">
              <meta itemprop="bottom" content="2008">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/9f/de/67/5870a6722e4b4c/US20210287438A1-20210916-D00005.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/de/69/00/9593e972bf5273/US20210287438A1-20210916-D00005.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="5">
            <meta itemprop="id" content="510">
            <meta itemprop="label" content="input image">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="728">
              <meta itemprop="top" content="146">
              <meta itemprop="right" content="812">
              <meta itemprop="bottom" content="184">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="5">
            <meta itemprop="id" content="530">
            <meta itemprop="label" content="neural network">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="702">
              <meta itemprop="top" content="841">
              <meta itemprop="right" content="788">
              <meta itemprop="bottom" content="881">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="5">
            <meta itemprop="id" content="550">
            <meta itemprop="label" content="distance field map">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="727">
              <meta itemprop="top" content="1348">
              <meta itemprop="right" content="811">
              <meta itemprop="bottom" content="1387">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/df/c3/13/a62c125e3f90e2/US20210287438A1-20210916-D00006.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/da/87/b3/318ae5c0d614b5/US20210287438A1-20210916-D00006.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="6">
            <meta itemprop="id" content="605">
            <meta itemprop="label" content="input image">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="41">
              <meta itemprop="top" content="349">
              <meta itemprop="right" content="111">
              <meta itemprop="bottom" content="384">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="6">
            <meta itemprop="id" content="610">
            <meta itemprop="label" content="first image">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="674">
              <meta itemprop="top" content="115">
              <meta itemprop="right" content="747">
              <meta itemprop="bottom" content="147">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="6">
            <meta itemprop="id" content="620">
            <meta itemprop="label" content="second image">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1263">
              <meta itemprop="top" content="114">
              <meta itemprop="right" content="1334">
              <meta itemprop="bottom" content="149">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="6">
            <meta itemprop="id" content="630">
            <meta itemprop="label" content="image">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1263">
              <meta itemprop="top" content="460">
              <meta itemprop="right" content="1335">
              <meta itemprop="bottom" content="495">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="6">
            <meta itemprop="id" content="650">
            <meta itemprop="label" content="second image">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1263">
              <meta itemprop="top" content="986">
              <meta itemprop="right" content="1334">
              <meta itemprop="bottom" content="1018">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/3e/c6/6f/f657d62e9729e4/US20210287438A1-20210916-D00007.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/ed/77/d6/27dca54c3ed959/US20210287438A1-20210916-D00007.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="7">
            <meta itemprop="id" content="1">
            <meta itemprop="label" content="BACKGROUND">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="437">
              <meta itemprop="top" content="1143">
              <meta itemprop="right" content="460">
              <meta itemprop="bottom" content="1195">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="7">
            <meta itemprop="id" content="1">
            <meta itemprop="label" content="BACKGROUND">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1119">
              <meta itemprop="top" content="1382">
              <meta itemprop="right" content="1142">
              <meta itemprop="bottom" content="1434">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="7">
            <meta itemprop="id" content="710">
            <meta itemprop="label" content="line">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="483">
              <meta itemprop="top" content="132">
              <meta itemprop="right" content="566">
              <meta itemprop="bottom" content="169">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="7">
            <meta itemprop="id" content="720">
            <meta itemprop="label" content="line">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1077">
              <meta itemprop="top" content="372">
              <meta itemprop="right" content="1160">
              <meta itemprop="bottom" content="410">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="7">
            <meta itemprop="id" content="730">
            <meta itemprop="label" content="line">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1078">
              <meta itemprop="top" content="586">
              <meta itemprop="right" content="1161">
              <meta itemprop="bottom" content="624">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="7">
            <meta itemprop="id" content="740">
            <meta itemprop="label" content="lines">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="473">
              <meta itemprop="top" content="1140">
              <meta itemprop="right" content="559">
              <meta itemprop="bottom" content="1194">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="7">
            <meta itemprop="id" content="750">
            <meta itemprop="label" content="lines">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1156">
              <meta itemprop="top" content="1378">
              <meta itemprop="right" content="1241">
              <meta itemprop="bottom" content="1432">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="7">
            <meta itemprop="id" content="760">
            <meta itemprop="label" content="line">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1164">
              <meta itemprop="top" content="1590">
              <meta itemprop="right" content="1248">
              <meta itemprop="bottom" content="1645">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/44/54/b2/9268017b0514a1/US20210287438A1-20210916-D00008.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/31/6f/08/4c47b5a064d0d2/US20210287438A1-20210916-D00008.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="8">
            <meta itemprop="id" content="810">
            <meta itemprop="label" content="operation">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1545">
              <meta itemprop="top" content="374">
              <meta itemprop="right" content="1627">
              <meta itemprop="bottom" content="412">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="8">
            <meta itemprop="id" content="820">
            <meta itemprop="label" content="operation">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1544">
              <meta itemprop="top" content="630">
              <meta itemprop="right" content="1626">
              <meta itemprop="bottom" content="667">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="8">
            <meta itemprop="id" content="830">
            <meta itemprop="label" content="operation">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1545">
              <meta itemprop="top" content="940">
              <meta itemprop="right" content="1628">
              <meta itemprop="bottom" content="981">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="8">
            <meta itemprop="id" content="840">
            <meta itemprop="label" content="operation">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1545">
              <meta itemprop="top" content="1223">
              <meta itemprop="right" content="1625">
              <meta itemprop="bottom" content="1262">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/c0/35/56/0b50991452cdce/US20210287438A1-20210916-D00009.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/a7/3e/c2/8855f46c3b93a0/US20210287438A1-20210916-D00009.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="9">
            <meta itemprop="id" content="910">
            <meta itemprop="label" content="learning image">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="132">
              <meta itemprop="top" content="942">
              <meta itemprop="right" content="170">
              <meta itemprop="bottom" content="1027">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="9">
            <meta itemprop="id" content="930">
            <meta itemprop="label" content="inference image">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="132">
              <meta itemprop="top" content="17">
              <meta itemprop="right" content="170">
              <meta itemprop="bottom" content="101">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="9">
            <meta itemprop="id" content="940">
            <meta itemprop="label" content="map data">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="807">
              <meta itemprop="top" content="945">
              <meta itemprop="right" content="845">
              <meta itemprop="bottom" content="1027">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="9">
            <meta itemprop="id" content="950">
            <meta itemprop="label" content="reference image">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="807">
              <meta itemprop="top" content="19">
              <meta itemprop="right" content="845">
              <meta itemprop="bottom" content="102">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="9">
            <meta itemprop="id" content="960">
            <meta itemprop="label" content="loss">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="467">
              <meta itemprop="top" content="17">
              <meta itemprop="right" content="510">
              <meta itemprop="bottom" content="102">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/c4/96/a8/57070c64b13213/US20210287438A1-20210916-D00010.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/10/0c/0a/919f18d88f3156/US20210287438A1-20210916-D00010.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="10">
            <meta itemprop="id" content="1010">
            <meta itemprop="label" content="learning image">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="715">
              <meta itemprop="top" content="118">
              <meta itemprop="right" content="814">
              <meta itemprop="bottom" content="152">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="10">
            <meta itemprop="id" content="1020">
            <meta itemprop="label" content="map data image">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="715">
              <meta itemprop="top" content="708">
              <meta itemprop="right" content="814">
              <meta itemprop="bottom" content="742">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="10">
            <meta itemprop="id" content="1030">
            <meta itemprop="label" content="reference images">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="714">
              <meta itemprop="top" content="1301">
              <meta itemprop="right" content="815">
              <meta itemprop="bottom" content="1336">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="10">
            <meta itemprop="id" content="1040">
            <meta itemprop="label" content="reference images">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="716">
              <meta itemprop="top" content="1893">
              <meta itemprop="right" content="815">
              <meta itemprop="bottom" content="1928">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/75/94/ca/844d56b3612f43/US20210287438A1-20210916-D00011.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/72/01/b0/37f500d71f10f9/US20210287438A1-20210916-D00011.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="11">
            <meta itemprop="id" content="1110">
            <meta itemprop="label" content="operation">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="333">
              <meta itemprop="top" content="1200">
              <meta itemprop="right" content="367">
              <meta itemprop="bottom" content="1299">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="11">
            <meta itemprop="id" content="1120">
            <meta itemprop="label" content="operation">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="336">
              <meta itemprop="top" content="585">
              <meta itemprop="right" content="368">
              <meta itemprop="bottom" content="686">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="11">
            <meta itemprop="id" content="1130">
            <meta itemprop="label" content="operation">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="519">
              <meta itemprop="top" content="1198">
              <meta itemprop="right" content="555">
              <meta itemprop="bottom" content="1300">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="11">
            <meta itemprop="id" content="1140">
            <meta itemprop="label" content="operation">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="545">
              <meta itemprop="top" content="18">
              <meta itemprop="right" content="581">
              <meta itemprop="bottom" content="118">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="11">
            <meta itemprop="id" content="1150">
            <meta itemprop="label" content="operation">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="545">
              <meta itemprop="top" content="586">
              <meta itemprop="right" content="581">
              <meta itemprop="bottom" content="684">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="11">
            <meta itemprop="id" content="1160">
            <meta itemprop="label" content="operation">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="756">
              <meta itemprop="top" content="1199">
              <meta itemprop="right" content="791">
              <meta itemprop="bottom" content="1300">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="11">
            <meta itemprop="id" content="1170">
            <meta itemprop="label" content="operation">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="943">
              <meta itemprop="top" content="1201">
              <meta itemprop="right" content="976">
              <meta itemprop="bottom" content="1300">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/36/fc/b8/ca2a178d52ba58/US20210287438A1-20210916-D00012.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/0c/51/b2/c873b52adafcaa/US20210287438A1-20210916-D00012.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="12">
            <meta itemprop="id" content="1210">
            <meta itemprop="label" content="first candidate image">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="520">
              <meta itemprop="top" content="150">
              <meta itemprop="right" content="628">
              <meta itemprop="bottom" content="185">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="12">
            <meta itemprop="id" content="1220">
            <meta itemprop="label" content="second candidate image">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="520">
              <meta itemprop="top" content="823">
              <meta itemprop="right" content="626">
              <meta itemprop="bottom" content="860">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/3c/28/dc/36c0131bc6d239/US20210287438A1-20210916-D00013.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/4e/92/b5/7ae8dfa2bd46db/US20210287438A1-20210916-D00013.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="13">
            <meta itemprop="id" content="1330">
            <meta itemprop="label" content="operation">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="522">
              <meta itemprop="top" content="1192">
              <meta itemprop="right" content="561">
              <meta itemprop="bottom" content="1295">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="13">
            <meta itemprop="id" content="1360">
            <meta itemprop="label" content="operation">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="716">
              <meta itemprop="top" content="1192">
              <meta itemprop="right" content="753">
              <meta itemprop="bottom" content="1294">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/7e/73/90/44d23c48ad3f6c/US20210287438A1-20210916-D00014.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/5a/e6/2f/872dbfdf5d33a6/US20210287438A1-20210916-D00014.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="14">
            <meta itemprop="id" content="1400">
            <meta itemprop="label" content="localization apparatus">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="573">
              <meta itemprop="top" content="136">
              <meta itemprop="right" content="680">
              <meta itemprop="bottom" content="174">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="14">
            <meta itemprop="id" content="1405">
            <meta itemprop="label" content="communication bus">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="636">
              <meta itemprop="top" content="259">
              <meta itemprop="right" content="740">
              <meta itemprop="bottom" content="297">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="14">
            <meta itemprop="id" content="1410">
            <meta itemprop="label" content="sensors">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="319">
              <meta itemprop="top" content="381">
              <meta itemprop="right" content="426">
              <meta itemprop="bottom" content="420">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="14">
            <meta itemprop="id" content="1430">
            <meta itemprop="label" content="processor">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1079">
              <meta itemprop="top" content="585">
              <meta itemprop="right" content="1187">
              <meta itemprop="bottom" content="627">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="14">
            <meta itemprop="id" content="1450">
            <meta itemprop="label" content="memory">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="319">
              <meta itemprop="top" content="796">
              <meta itemprop="right" content="423">
              <meta itemprop="bottom" content="837">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="14">
            <meta itemprop="id" content="1470">
            <meta itemprop="label" content="communication interface">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1081">
              <meta itemprop="top" content="1005">
              <meta itemprop="right" content="1188">
              <meta itemprop="bottom" content="1044">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="14">
            <meta itemprop="id" content="1490">
            <meta itemprop="label" content="display device">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="318">
              <meta itemprop="top" content="1212">
              <meta itemprop="right" content="423">
              <meta itemprop="bottom" content="1249">
            </span>
          </li>
        </ul>
      </li>
    </ul>
  </section>

  <section>
    <h2>Classifications</h2>
    <ul>
      <li>
        <ul itemprop="classifications" itemscope repeat>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G</span>&mdash;<span itemprop="Description">PHYSICS</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G01</span>&mdash;<span itemprop="Description">MEASURING; TESTING</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G01C</span>&mdash;<span itemprop="Description">MEASURING DISTANCES, LEVELS OR BEARINGS; SURVEYING; NAVIGATION; GYROSCOPIC INSTRUMENTS; PHOTOGRAMMETRY OR VIDEOGRAMMETRY</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G01C21/00</span>&mdash;<span itemprop="Description">Navigation; Navigational instruments not provided for in groups G01C1/00 - G01C19/00</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G01C21/26</span>&mdash;<span itemprop="Description">Navigation; Navigational instruments not provided for in groups G01C1/00 - G01C19/00 specially adapted for navigation in a road network</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G01C21/28</span>&mdash;<span itemprop="Description">Navigation; Navigational instruments not provided for in groups G01C1/00 - G01C19/00 specially adapted for navigation in a road network with correlation of data from several navigational instruments</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G01C21/30</span>&mdash;<span itemprop="Description">Map- or contour-matching</span>
            <meta itemprop="Leaf" content="true"><meta itemprop="FirstCode" content="true"><meta itemprop="IsCPC" content="true">
          </li>
        </ul>
      </li>
      <li>
        <ul itemprop="classifications" itemscope repeat>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G</span>&mdash;<span itemprop="Description">PHYSICS</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06</span>&mdash;<span itemprop="Description">COMPUTING; CALCULATING OR COUNTING</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06T</span>&mdash;<span itemprop="Description">IMAGE DATA PROCESSING OR GENERATION, IN GENERAL</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06T19/00</span>&mdash;<span itemprop="Description">Manipulating 3D models or images for computer graphics</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06T19/003</span>&mdash;<span itemprop="Description">Navigation within 3D models or images</span>
            <meta itemprop="Leaf" content="true"><meta itemprop="FirstCode" content="true"><meta itemprop="IsCPC" content="true">
          </li>
        </ul>
      </li>
      <li>
        <ul itemprop="classifications" itemscope repeat>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G</span>&mdash;<span itemprop="Description">PHYSICS</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06</span>&mdash;<span itemprop="Description">COMPUTING; CALCULATING OR COUNTING</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06T</span>&mdash;<span itemprop="Description">IMAGE DATA PROCESSING OR GENERATION, IN GENERAL</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06T7/00</span>&mdash;<span itemprop="Description">Image analysis</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06T7/70</span>&mdash;<span itemprop="Description">Determining position or orientation of objects or cameras</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06T7/73</span>&mdash;<span itemprop="Description">Determining position or orientation of objects or cameras using feature-based methods</span>
            <meta itemprop="Leaf" content="true"><meta itemprop="FirstCode" content="true"><meta itemprop="IsCPC" content="true">
          </li>
        </ul>
      </li>
      <li>
        <ul itemprop="classifications" itemscope repeat>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G</span>&mdash;<span itemprop="Description">PHYSICS</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G02</span>&mdash;<span itemprop="Description">OPTICS</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G02B</span>&mdash;<span itemprop="Description">OPTICAL ELEMENTS, SYSTEMS OR APPARATUS</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G02B27/00</span>&mdash;<span itemprop="Description">Optical systems or apparatus not provided for by any of the groups G02B1/00 - G02B26/00, G02B30/00</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G02B27/01</span>&mdash;<span itemprop="Description">Head-up displays</span>
            <meta itemprop="Leaf" content="true"><meta itemprop="IsCPC" content="true">
          </li>
        </ul>
      </li>
      <li>
        <ul itemprop="classifications" itemscope repeat>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G</span>&mdash;<span itemprop="Description">PHYSICS</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06</span>&mdash;<span itemprop="Description">COMPUTING; CALCULATING OR COUNTING</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06F</span>&mdash;<span itemprop="Description">ELECTRIC DIGITAL DATA PROCESSING</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06F3/00</span>&mdash;<span itemprop="Description">Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06F3/01</span>&mdash;<span itemprop="Description">Input arrangements or combined input and output arrangements for interaction between user and computer</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06F3/011</span>&mdash;<span itemprop="Description">Arrangements for interaction with the human body, e.g. for user immersion in virtual reality</span>
            <meta itemprop="Leaf" content="true"><meta itemprop="IsCPC" content="true">
          </li>
        </ul>
      </li>
      <li>
        <ul itemprop="classifications" itemscope repeat>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G</span>&mdash;<span itemprop="Description">PHYSICS</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06</span>&mdash;<span itemprop="Description">COMPUTING; CALCULATING OR COUNTING</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06T</span>&mdash;<span itemprop="Description">IMAGE DATA PROCESSING OR GENERATION, IN GENERAL</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06T19/00</span>&mdash;<span itemprop="Description">Manipulating 3D models or images for computer graphics</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06T19/006</span>&mdash;<span itemprop="Description">Mixed reality</span>
            <meta itemprop="Leaf" content="true"><meta itemprop="IsCPC" content="true">
          </li>
        </ul>
      </li>
      <li>
        <ul itemprop="classifications" itemscope repeat>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G</span>&mdash;<span itemprop="Description">PHYSICS</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06</span>&mdash;<span itemprop="Description">COMPUTING; CALCULATING OR COUNTING</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06T</span>&mdash;<span itemprop="Description">IMAGE DATA PROCESSING OR GENERATION, IN GENERAL</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06T7/00</span>&mdash;<span itemprop="Description">Image analysis</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06T7/30</span>&mdash;<span itemprop="Description">Determination of transform parameters for the alignment of images, i.e. image registration</span>
            <meta itemprop="Leaf" content="true"><meta itemprop="IsCPC" content="true">
          </li>
        </ul>
      </li>
      <li>
        <ul itemprop="classifications" itemscope repeat>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G</span>&mdash;<span itemprop="Description">PHYSICS</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06</span>&mdash;<span itemprop="Description">COMPUTING; CALCULATING OR COUNTING</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06V</span>&mdash;<span itemprop="Description">IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06V10/00</span>&mdash;<span itemprop="Description">Arrangements for image or video recognition or understanding</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06V10/70</span>&mdash;<span itemprop="Description">Arrangements for image or video recognition or understanding using pattern recognition or machine learning</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06V10/82</span>&mdash;<span itemprop="Description">Arrangements for image or video recognition or understanding using pattern recognition or machine learning using neural networks</span>
            <meta itemprop="Leaf" content="true"><meta itemprop="IsCPC" content="true">
          </li>
        </ul>
      </li>
      <li>
        <ul itemprop="classifications" itemscope repeat>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G</span>&mdash;<span itemprop="Description">PHYSICS</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06</span>&mdash;<span itemprop="Description">COMPUTING; CALCULATING OR COUNTING</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06V</span>&mdash;<span itemprop="Description">IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06V20/00</span>&mdash;<span itemprop="Description">Scenes; Scene-specific elements</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06V20/50</span>&mdash;<span itemprop="Description">Context or environment of the image</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06V20/56</span>&mdash;<span itemprop="Description">Context or environment of the image exterior to a vehicle by using sensors mounted on the vehicle</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06V20/588</span>&mdash;<span itemprop="Description">Recognition of the road, e.g. of lane markings; Recognition of the vehicle driving pattern in relation to the road</span>
            <meta itemprop="Leaf" content="true"><meta itemprop="IsCPC" content="true">
          </li>
        </ul>
      </li>
      <li>
        <ul itemprop="classifications" itemscope repeat>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G</span>&mdash;<span itemprop="Description">PHYSICS</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G01</span>&mdash;<span itemprop="Description">MEASURING; TESTING</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G01C</span>&mdash;<span itemprop="Description">MEASURING DISTANCES, LEVELS OR BEARINGS; SURVEYING; NAVIGATION; GYROSCOPIC INSTRUMENTS; PHOTOGRAMMETRY OR VIDEOGRAMMETRY</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G01C25/00</span>&mdash;<span itemprop="Description">Manufacturing, calibrating, cleaning, or repairing instruments or devices referred to in the other groups of this subclass</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G01C25/005</span>&mdash;<span itemprop="Description">Manufacturing, calibrating, cleaning, or repairing instruments or devices referred to in the other groups of this subclass initial alignment, calibration or starting-up of inertial devices</span>
            <meta itemprop="Leaf" content="true"><meta itemprop="Additional" content="true"><meta itemprop="IsCPC" content="true">
          </li>
        </ul>
      </li>
      <li>
        <ul itemprop="classifications" itemscope repeat>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G</span>&mdash;<span itemprop="Description">PHYSICS</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06</span>&mdash;<span itemprop="Description">COMPUTING; CALCULATING OR COUNTING</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06T</span>&mdash;<span itemprop="Description">IMAGE DATA PROCESSING OR GENERATION, IN GENERAL</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06T2207/00</span>&mdash;<span itemprop="Description">Indexing scheme for image analysis or image enhancement</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06T2207/20</span>&mdash;<span itemprop="Description">Special algorithmic details</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06T2207/20081</span>&mdash;<span itemprop="Description">Training; Learning</span>
            <meta itemprop="Leaf" content="true"><meta itemprop="Additional" content="true"><meta itemprop="IsCPC" content="true">
          </li>
        </ul>
      </li>
      <li>
        <ul itemprop="classifications" itemscope repeat>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G</span>&mdash;<span itemprop="Description">PHYSICS</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06</span>&mdash;<span itemprop="Description">COMPUTING; CALCULATING OR COUNTING</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06T</span>&mdash;<span itemprop="Description">IMAGE DATA PROCESSING OR GENERATION, IN GENERAL</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06T2207/00</span>&mdash;<span itemprop="Description">Indexing scheme for image analysis or image enhancement</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06T2207/20</span>&mdash;<span itemprop="Description">Special algorithmic details</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06T2207/20084</span>&mdash;<span itemprop="Description">Artificial neural networks [ANN]</span>
            <meta itemprop="Leaf" content="true"><meta itemprop="Additional" content="true"><meta itemprop="IsCPC" content="true">
          </li>
        </ul>
      </li>
    </ul>
  </section>

  

  

  <section>
    <h2>Definitions</h2>
    <ul>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the following description</span>
        <span itemprop="definition">relates to a localization method and apparatus for displaying a virtual object in augmented reality (AR).</span>
        <meta itemprop="num_attr" content="0002">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">AR</span>
        <span itemprop="definition">augmented reality</span>
        <meta itemprop="num_attr" content="0002">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">augmented reality (AR) services</span>
        <span itemprop="definition">are provided in various fields, such as, for example, driving assistance for vehicles and other transportation devices, games, and amusements.</span>
        <meta itemprop="num_attr" content="0003">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Various localization methods</span>
        <span itemprop="definition">may be used to provide realistically AR.</span>
        <meta itemprop="num_attr" content="0003">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a sensor-based localization method</span>
        <span itemprop="definition">may use various sensors, for example, a global positioning system (GPS) sensor and an inertial measurement unit (IMU) sensor, to verify a location and a direction of an object.</span>
        <meta itemprop="num_attr" content="0003">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">GPS</span>
        <span itemprop="definition">global positioning system</span>
        <meta itemprop="num_attr" content="0003">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">IMU</span>
        <span itemprop="definition">inertial measurement unit</span>
        <meta itemprop="num_attr" content="0003">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a sensor-based localization method</span>
        <span itemprop="definition">requires a very price sensor with high accuracy, and thus, commercialization and miniaturization is difficult.</span>
        <meta itemprop="num_attr" content="0003">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a vision-based localization method using camera information to acquire highly precise coordinate information</span>
        <span itemprop="definition">may be difficult to use in an environment with many dynamic objects having continuous motions.</span>
        <meta itemprop="num_attr" content="0003">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a localization method</span>
        <span itemprop="definition">including acquiring localization information of a device, generating a first image including a directional characteristic corresponding to an object included in an input image, generating a second image in which the object is projected, based on the localization information, on to map data corresponding to a location of the object, and updating the localization information based on visual alignment between the first image and the second image.</span>
        <meta itemprop="num_attr" content="0005">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the localization information</span>
        <span itemprop="definition">may include a location of the apparatus and a pose of the apparatus.</span>
        <meta itemprop="num_attr" content="0006">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the generating of the second image</span>
        <span itemprop="definition">may include placing a virtual camera at the location on the map data, and adjusting a pose of the virtual camera based on the pose of the apparatus, and generating an image of a viewpoint at which the object is viewed from the virtual camera.</span>
        <meta itemprop="num_attr" content="0007">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the directional characteristic</span>
        <span itemprop="definition">may correspond to a probability distribution indicating a degree of closeness to the object.</span>
        <meta itemprop="num_attr" content="0008">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the input image</span>
        <span itemprop="definition">may be based on an output of a first sensor, and the localization information may be based on an output of a second sensor.</span>
        <meta itemprop="num_attr" content="0009">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the localization method</span>
        <span itemprop="definition">may include determining a virtual object on the map data for an augmented reality (AR) service, and displaying the virtual object and the input image may be based on the adjusted localization information.</span>
        <meta itemprop="num_attr" content="0010">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">AR</span>
        <span itemprop="definition">augmented reality</span>
        <meta itemprop="num_attr" content="0010">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the virtual object</span>
        <span itemprop="definition">may represent driving route information.</span>
        <meta itemprop="num_attr" content="0011">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the generating of the first image</span>
        <span itemprop="definition">may include generating a probability map that represents the directional characteristic using a trained neural network.</span>
        <meta itemprop="num_attr" content="0012">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Each pixel in the probability map</span>
        <span itemprop="definition">may be configured to store a distance from the each pixel to a closest seed pixel.</span>
        <meta itemprop="num_attr" content="0013">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the seed pixel</span>
        <span itemprop="definition">may include a pixel corresponding to the object among pixels included in the input image.</span>
        <meta itemprop="num_attr" content="0014">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the generating of the second image</span>
        <span itemprop="definition">may include generating the second image using a transformer configured to transform a coordinate system of the map data to a coordinate system of the second image.</span>
        <meta itemprop="num_attr" content="0015">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the localization information</span>
        <span itemprop="definition">may include 6 degrees of freedom (6DoF).</span>
        <meta itemprop="num_attr" content="0016">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the updating of the localization information</span>
        <span itemprop="definition">may include calculating a degree of the visual alignment by matching the first image and the second image, and modifying the localization information to increase the degree of the virtual alignment based on the directional characteristic.</span>
        <meta itemprop="num_attr" content="0017">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the calculating</span>
        <span itemprop="definition">may include adding up values of pixels corresponding to the object in the second image from among pixels in the first image.</span>
        <meta itemprop="num_attr" content="0018">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the modifying of the localization information based on the directional characteristic</span>
        <span itemprop="definition">may include modifying the localization information to transform the object in the second image based on the directional characteristic.</span>
        <meta itemprop="num_attr" content="0019">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the modifying of the localization information based on the directional characteristic</span>
        <span itemprop="definition">may include moving or rotating the object in the second image based on the directional characteristic.</span>
        <meta itemprop="num_attr" content="0020">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the first image</span>
        <span itemprop="definition">may be configured to classify the object based on an object type and to store a directional characteristic for each object type</span>
        <meta itemprop="num_attr" content="0021">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the second image</span>
        <span itemprop="definition">may be configured to classify the object based on the object type and to store the projected object for the each object type.</span>
        <meta itemprop="num_attr" content="0021">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the modifying</span>
        <span itemprop="definition">may include calculating a degree of visual alignment for each object type by matching the first image and the second image, and modifying the localization information to increase the degree of visual alignment based on the directional characteristic.</span>
        <meta itemprop="num_attr" content="0022">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the input image</span>
        <span itemprop="definition">may include a driving image of a vehicle.</span>
        <meta itemprop="num_attr" content="0023">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the object</span>
        <span itemprop="definition">may include any one or any combination of a line, a road surface marking, a traffic light, a sign, a curb stone, and a structure.</span>
        <meta itemprop="num_attr" content="0024">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a learning method</span>
        <span itemprop="definition">including receiving a learning image, generating a reference image including a directional characteristic corresponding to an object in the learning image, based on map data for the learning image, generating an inference image that infers the directional characteristic corresponding to the object in the learning image, using a neural network, and training the neural network based on a difference between the reference image and the inference image.</span>
        <meta itemprop="num_attr" content="0025">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the training</span>
        <span itemprop="definition">may include training the neural network to minimize the difference between the reference image and the inference image.</span>
        <meta itemprop="num_attr" content="0026">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the directional characteristic</span>
        <span itemprop="definition">may correspond to a probability distribution indicating a degree of closeness to the object.</span>
        <meta itemprop="num_attr" content="0027">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Each pixel in the reference image and the inference image</span>
        <span itemprop="definition">may be configured to store a distance from the each pixel to closest a seed pixel.</span>
        <meta itemprop="num_attr" content="0028">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Each of the reference image and the inference image</span>
        <span itemprop="definition">may be configured to classify the object based on a type of the object and to store the directional characteristic for each object type.</span>
        <meta itemprop="num_attr" content="0029">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the training</span>
        <span itemprop="definition">may include training the neural network based on a type difference between the reference image and the inference image.</span>
        <meta itemprop="num_attr" content="0030">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the learning image</span>
        <span itemprop="definition">may include a driving image of a vehicle.</span>
        <meta itemprop="num_attr" content="0031">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the object</span>
        <span itemprop="definition">may include any one or any combination of a line, a road surface marking, a traffic light, a sign, a curb stone, and a structure.</span>
        <meta itemprop="num_attr" content="0032">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a localization apparatus</span>
        <span itemprop="definition">including sensors configured to acquire localization information of a device and an input image, and a processor configured to generate a first image including a directional characteristic corresponding to an object included in the input image, to generate a second image in which the object is projected, based on the localization information, on to map data corresponding to a location of the object, and to adjust the localization information based on visual alignment between the first image and the second image.</span>
        <meta itemprop="num_attr" content="0033">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a localization method</span>
        <span itemprop="definition">including acquiring an input image corresponding to a location of a device, receiving map data corresponding to a location of an object, generating second images in which the object is projected, based on plurality of respective candidate localization information, on to the map data, calculating a degree of visual alignment for each of the second images by matching the input image and the each of the second images, selecting a second image having the greatest degree of visual alignment from the second images, and updating localization information based on a candidate localization information corresponding to the selected second image.</span>
        <meta itemprop="num_attr" content="0034">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the localization method</span>
        <span itemprop="definition">may include generating a first image comprising a probability map indicating a directional characteristic corresponding to the object, and wherein the calculating of the degree of visual alignment may include matching the first image and the each of the second images.</span>
        <meta itemprop="num_attr" content="0035">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a localization apparatus</span>
        <span itemprop="definition">including a first sensor configured to capture an image, a second sensor configured to acquire localization information of a device a head-up display (HUD), a processor configured to generate a first image including a directional characteristic corresponding to an object included in the image, generate a second image in which the object is projected, based on the localization information, on to map data corresponding to a location of the object, update the localization information based on visual alignment between the first image and the second image, and display the object and the input image on to the map data based on the adjusted localization information in the HUD for an augmented reality (AR) service.</span>
        <meta itemprop="num_attr" content="0036">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">HUD</span>
        <span itemprop="definition">head-up display</span>
        <meta itemprop="num_attr" content="0036">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIGS. 1A, 1B, and 1C</span>
        <span itemprop="definition">illustrate examples of a visual alignment result corresponding to a localization error.</span>
        <meta itemprop="num_attr" content="0038">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 2</span>
        <span itemprop="definition">is a diagram illustrating an example of a localization method.</span>
        <meta itemprop="num_attr" content="0039">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 3</span>
        <span itemprop="definition">illustrates an example of a localization method.</span>
        <meta itemprop="num_attr" content="0040">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 4</span>
        <span itemprop="definition">illustrates an example of a localization process.</span>
        <meta itemprop="num_attr" content="0041">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 5</span>
        <span itemprop="definition">illustrates an example of a process of generating a first image.</span>
        <meta itemprop="num_attr" content="0042">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 6</span>
        <span itemprop="definition">illustrates an example of a method of modifying localization information.</span>
        <meta itemprop="num_attr" content="0043">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIGS. 7A and 7B</span>
        <span itemprop="definition">illustrate examples of a method of modifying localization information.</span>
        <meta itemprop="num_attr" content="0044">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 8</span>
        <span itemprop="definition">is a diagram illustrating an example of a learning method.</span>
        <meta itemprop="num_attr" content="0045">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 9</span>
        <span itemprop="definition">illustrates an example of a learning process.</span>
        <meta itemprop="num_attr" content="0046">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 10</span>
        <span itemprop="definition">illustrates an example of images for learning.</span>
        <meta itemprop="num_attr" content="0047">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 11</span>
        <span itemprop="definition">illustrates an example of a learning method.</span>
        <meta itemprop="num_attr" content="0048">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 12</span>
        <span itemprop="definition">illustrates an example of a localization updating process of FIG. 11 .</span>
        <meta itemprop="num_attr" content="0049">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 13</span>
        <span itemprop="definition">is a diagram illustrating an example of a localization method.</span>
        <meta itemprop="num_attr" content="0050">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 14</span>
        <span itemprop="definition">is a diagram illustrating an example of a localization apparatus.</span>
        <meta itemprop="num_attr" content="0051">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">first, second, third A, B, (a), and (b)</span>
        <span itemprop="definition">may be used herein to describe various members, components, regions, layers, or sections, these members, components, regions, layers, or sections are not to be limited by these terms. Rather, these terms are only used to distinguish one member, component, region, layer, or section from another member, component, region, layer, or section. Thus, a first member, component, region, layer, or section referred to in examples described herein may also be referred to as a second member, component, region, layer, or section without departing from the teachings of the examples.</span>
        <meta itemprop="num_attr" content="0055">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the first component</span>
        <span itemprop="definition">may be directly connected, coupled, or joined to the second component, or a third component may be connected, coupled, or joined between the first component and the second component.</span>
        <meta itemprop="num_attr" content="0056">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a third component</span>
        <span itemprop="definition">may not be connected or joined between the first component and the second component. Similar expressions, for example, between and immediately between and adjacent to and immediately adjacent to, are also to be construed in this manner.</span>
        <meta itemprop="num_attr" content="0056">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIGS. 1A, 1B, and 10</span>
        <span itemprop="definition">illustrate examples of a visual alignment result corresponding to a localization error.</span>
        <meta itemprop="num_attr" content="0060">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Augmented reality</span>
        <span itemprop="definition">refers to adding or augmenting information based on reality to images and providing the added or augmented information.</span>
        <meta itemprop="num_attr" content="0061">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the AR</span>
        <span itemprop="definition">may provide an image in which a virtual object corresponding to a virtual image is added to an image or a background image of a real world. Since the real world and the virtual world are harmonized in the AR, a user may experience sense of immersion that enables real-time interaction between the user and the virtual world, without recognizing that a virtual environment is distinct from a real environment.</span>
        <meta itemprop="num_attr" content="0061">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a location and a pose</span>
        <span itemprop="definition">i.e., localization information of a user device or the user to which the AR is to be provided should be verified.</span>
        <meta itemprop="num_attr" content="0061">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the localization information</span>
        <span itemprop="definition">is used to locate a virtual object at a desired location in an image.</span>
        <meta itemprop="num_attr" content="0062">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a degree of visual alignment when projecting the virtual object onto a two-dimensional (2D) image</span>
        <span itemprop="definition">is more important than an error occurring on an actual three-dimensional (3D) space or an error occurring in feature matching.</span>
        <meta itemprop="num_attr" content="0062">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the degree of visual alignment</span>
        <span itemprop="definition">corresponds to, for example, an overlapping ratio or a matching ratio between the virtual object and the real image.</span>
        <meta itemprop="num_attr" content="0062">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the degree of visual alignment</span>
        <span itemprop="definition">varies based on a localization error as shown in FIGS. 1A and 1B .</span>
        <meta itemprop="num_attr" content="0062">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIGS. 1A and 1B</span>
        <span itemprop="definition">an example of displaying a driving guide lane corresponding to a virtual object on a road surface is described as an example.</span>
        <meta itemprop="num_attr" content="0062">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the examples described herein</span>
        <span itemprop="definition">may be used to generate information to support a driver or to control an autonomous vehicle.</span>
        <meta itemprop="num_attr" content="0063">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the examples described herein</span>
        <span itemprop="definition">may also be used to interpret visual information in a device, such as, for example, an intelligent system installed for fully autonomous driving or driving assistance in a vehicle, and used to assist safe and comfortable driving.</span>
        <meta itemprop="num_attr" content="0063">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the examples described herein</span>
        <span itemprop="definition">may be applicable to vehicles and vehicle management systems such as, for example, an autonomous vehicle, an automatic or autonomous driving system, an intelligent vehicle, an advanced driver assistance system (ADAS), a navigation system to assist a vehicle with safely maintaining a lane on which the vehicle is travelling, a smartphone, or a mobile device.</span>
        <meta itemprop="num_attr" content="0063">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">ADAS</span>
        <span itemprop="definition">advanced driver assistance system</span>
        <meta itemprop="num_attr" content="0063">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the examples related to displaying a driving guide lane corresponding to a virtual object</span>
        <span itemprop="definition">is provided as an example only, and other examples such as, for example, training, gaming, applications in healthcare, public safety, tourism, and marketing are considered to be well within the scope of the present disclosure.</span>
        <meta itemprop="num_attr" content="0063">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">an AR image 120</span>
        <span itemprop="definition">is based on a visual alignment result when a localization error is small.</span>
        <meta itemprop="num_attr" content="0064">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">an AR image 140</span>
        <span itemprop="definition">is based on a visual alignment result when the localization error is large.</span>
        <meta itemprop="num_attr" content="0064">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a reference path of a vehicle</span>
        <span itemprop="definition">is displayed on a road image based on localization information of an object 110 .</span>
        <meta itemprop="num_attr" content="0065">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the object 110</span>
        <span itemprop="definition">corresponds to a user terminal and/or the vehicle that performs localization.</span>
        <meta itemprop="num_attr" content="0065">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a driving guide lane 115</span>
        <span itemprop="definition">i. e., a virtual object to be displayed, may be visually well aligned with an actual road image as shown in the AR image 120 .</span>
        <meta itemprop="num_attr" content="0065">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a driving guide lane 135</span>
        <span itemprop="definition">that is a virtual object to be displayed may not be visually aligned with an actual road image as shown in the AR image 140 .</span>
        <meta itemprop="num_attr" content="0065">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">an accurate AR service</span>
        <span itemprop="definition">may be provided by optimizing localization information to increase a degree of visual alignment when projecting a virtual object onto a two-dimensional (2D) image.</span>
        <meta itemprop="num_attr" content="0066">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">localization information</span>
        <span itemprop="definition">includes a location and a pose of an apparatus.</span>
        <meta itemprop="num_attr" content="0067">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the location</span>
        <span itemprop="definition">corresponds to 3D coordinates (x, y, z).</span>
        <meta itemprop="num_attr" content="0067">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">x coordinate</span>
        <span itemprop="definition">denotes a lateral location t x</span>
        <meta itemprop="num_attr" content="0067">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">y coordinate</span>
        <span itemprop="definition">denotes a vertical location t y</span>
        <meta itemprop="num_attr" content="0067">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">z coordinate</span>
        <span itemprop="definition">denotes a longitudinal location t z .</span>
        <meta itemprop="num_attr" content="0067">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the pose</span>
        <span itemprop="definition">corresponds to pitch r x , yaw r y , and roll r z .</span>
        <meta itemprop="num_attr" content="0067">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the location</span>
        <span itemprop="definition">is acquired using, for example, a geographical positioning system (GPS) sensor and a lidar</span>
        <meta itemprop="num_attr" content="0067">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the pose</span>
        <span itemprop="definition">is acquired using, for example, an inertial measurement unit (IMU) sensor and a gyro sensor.</span>
        <meta itemprop="num_attr" content="0067">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the localization information</span>
        <span itemprop="definition">may be understood to include 6 degrees of freedom (6DoF) that includes the location and the pose.</span>
        <meta itemprop="num_attr" content="0067">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">6DoF</span>
        <span itemprop="definition">6 degrees of freedom</span>
        <meta itemprop="num_attr" content="0067">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the vehicle described herein</span>
        <span itemprop="definition">refers to any mode of transportation, delivery, or communication such as, for example, an automobile, a truck, a tractor, a scooter, a motorcycle, a cycle, an amphibious vehicle, a snowmobile, a boat, a public transit vehicle, a bus, a monorail, a train, a tram, an autonomous or automated driving vehicle, an intelligent vehicle, a self-driving vehicle, an unmanned aerial vehicle, an electric vehicle (EV), a hybrid vehicle, a smart mobility device, a ADAS, or a drone.</span>
        <meta itemprop="num_attr" content="0068">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the smart mobility device</span>
        <span itemprop="definition">includes mobility devices such as, for example, electric wheels, an electric kickboard, and an electric bike.</span>
        <meta itemprop="num_attr" content="0068">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">vehicles</span>
        <span itemprop="definition">include motorized and non-motorized vehicles, for example, a vehicle with a power engine (for example, a cultivator or a motorcycle), a bicycle or a handcart.</span>
        <meta itemprop="num_attr" content="0068">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a road</span>
        <span itemprop="definition">is a thoroughfare, route, or connection, between two places that has been improved to allow travel by foot or some form of conveyance, such as a vehicle.</span>
        <meta itemprop="num_attr" content="0069">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a road</span>
        <span itemprop="definition">can include various types of roads such as, for example, highways, national roads, farm roads, local roads, or high-speed national roads.</span>
        <meta itemprop="num_attr" content="0069">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a road</span>
        <span itemprop="definition">may include a single lane or a plurality of lanes. Lanes correspond to road spaces that are distinguished from each other by road lines marked on a surface of a road.</span>
        <meta itemprop="num_attr" content="0069">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a lane</span>
        <span itemprop="definition">is a space of a plane on which a vehicle is traveling among a plurality of lanes, i.e., as a space occupied and used by the vehicle. One lane is distinguished from the other lanes by right and left markings of the lane.</span>
        <meta itemprop="num_attr" content="0069">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the term line</span>
        <span itemprop="definition">may be understood as various types of lines, for example, a solid line, a dotted line, a curved line, and a zigzagged line, which are marked in colors such as, white, blue, or yellow on the road surface.</span>
        <meta itemprop="num_attr" content="0070">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the line</span>
        <span itemprop="definition">may correspond to a line on one side that distinguishes a single lane and may also be a pair of lines, that is, a left lane and a right lane corresponding to a lane boundary line that distinguishes a single lane a center line of road, and a stop line.</span>
        <meta itemprop="num_attr" content="0070">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a line</span>
        <span itemprop="definition">may indicate an area prohibited for parking and stopping, a crosswalk, a towaway zone, and indication of speed limit.</span>
        <meta itemprop="num_attr" content="0070">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the AR navigation device</span>
        <span itemprop="definition">is used to mark a line, to generate visual information to help steering of an autonomous driving vehicle, or to provide a variety of control information for driving of a vehicle.</span>
        <meta itemprop="num_attr" content="0071">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the AR navigation device</span>
        <span itemprop="definition">may provide visual information to a display.</span>
        <meta itemprop="num_attr" content="0071">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the display</span>
        <span itemprop="definition">is a head-up display (HUD), a vehicular infotainment system, a dashboard in a vehicle, or a screen in the vehicle that used augmented reality.</span>
        <meta itemprop="num_attr" content="0071">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the display</span>
        <span itemprop="definition">is installed for driving assistance or complete autonomous driving of a vehicle and to assist safe and pleasant driving.</span>
        <meta itemprop="num_attr" content="0071">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the display</span>
        <span itemprop="definition">may also be implemented as an eye glass display (EGD), which includes one-eyed glass or two-eyed glasses.</span>
        <meta itemprop="num_attr" content="0071">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">EGD</span>
        <span itemprop="definition">eye glass display</span>
        <meta itemprop="num_attr" content="0071">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 2</span>
        <span itemprop="definition">is a diagram illustrating an example of a localization method.</span>
        <meta itemprop="num_attr" content="0072">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the operations in FIG. 2</span>
        <span itemprop="definition">may be performed in the sequence and manner as shown, although the order of some operations may be changed or some of the operations omitted without departing from the spirit and scope of the illustrative examples described. Many of the operations shown in FIG. 2 may be performed in parallel or concurrently.</span>
        <meta itemprop="num_attr" content="0072">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">One or more blocks of FIG. 2 , and combinations of the blocks,</span>
        <span itemprop="definition">can be implemented by special purpose hardware-based computer that perform the specified functions, or combinations of special purpose hardware and computer instructions.</span>
        <meta itemprop="num_attr" content="0072">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 1</span>
        <span itemprop="definition">are also applicable to FIG. 2 , and are incorporated herein by reference. Thus, the above description may not be repeated here.</span>
        <meta itemprop="num_attr" content="0072">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a localization apparatus</span>
        <span itemprop="definition">acquires localization information of a corresponding apparatus.</span>
        <meta itemprop="num_attr" content="0073">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the apparatus</span>
        <span itemprop="definition">refers to an apparatus that performs the localization method, such as, for example, a vehicle, a navigation device, and a user device such as a smartphone.</span>
        <meta itemprop="num_attr" content="0073">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the localization information</span>
        <span itemprop="definition">may have 6DoF that includes a location and a pose of the apparatus.</span>
        <meta itemprop="num_attr" content="0073">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the localization information</span>
        <span itemprop="definition">is acquired based on output of a sensor, such as, for example, an IMU sensor, a GPS sensor, a lidar sensor, and a radar.</span>
        <meta itemprop="num_attr" content="0073">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the localization information</span>
        <span itemprop="definition">may be, for example, initial localization information of the localization apparatus.</span>
        <meta itemprop="num_attr" content="0073">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the localization apparatus</span>
        <span itemprop="definition">generates a first image that includes a directional characteristic corresponding to an object included in an input image.</span>
        <meta itemprop="num_attr" content="0074">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the input image</span>
        <span itemprop="definition">may correspond to a background image or another image that is displayed with a virtual object for an AR service.</span>
        <meta itemprop="num_attr" content="0074">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the input image</span>
        <span itemprop="definition">includes a driving image of the vehicle.</span>
        <meta itemprop="num_attr" content="0074">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the driving image</span>
        <span itemprop="definition">may be captured from, for example, a photographing device mounted to the vehicle.</span>
        <meta itemprop="num_attr" content="0074">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the driving image</span>
        <span itemprop="definition">includes a plurality of frames.</span>
        <meta itemprop="num_attr" content="0074">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the localization apparatus</span>
        <span itemprop="definition">acquires the input image based on output of the photographing device.</span>
        <meta itemprop="num_attr" content="0074">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the photographing device</span>
        <span itemprop="definition">is fastened at a location, such as, a for example, a windshield, a dashboard, a front fender, and a rear-view mirror, to capture an image ahead of the vehicle.</span>
        <meta itemprop="num_attr" content="0074">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the photographing device</span>
        <span itemprop="definition">may include, for example, a vision sensor, an image sensor, or a device that performs a similar function.</span>
        <meta itemprop="num_attr" content="0074">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the photographing device</span>
        <span itemprop="definition">may capture a single image or may capture an image per frame if needed.</span>
        <meta itemprop="num_attr" content="0074">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the driving image</span>
        <span itemprop="definition">may be captured from another apparatus, aside from the localization apparatus.</span>
        <meta itemprop="num_attr" content="0074">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the driving image</span>
        <span itemprop="definition">may be an input image 410 of FIG. 4 .</span>
        <meta itemprop="num_attr" content="0074">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">objects</span>
        <span itemprop="definition">include a line, a road surface marking, a traffic light, a sign, a curb stone, a pedestrian, other vehicles, and a structure.</span>
        <meta itemprop="num_attr" content="0074">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the localization apparatus</span>
        <span itemprop="definition">In operation 220 , the localization apparatus generates a probability map, for example, a distance field map, indicating directional characteristic using a pretrained neural network.</span>
        <meta itemprop="num_attr" content="0075">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a probability map</span>
        <span itemprop="definition">for example, a distance field map, indicating directional characteristic using a pretrained neural network.</span>
        <meta itemprop="num_attr" content="0075">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">directional characteristic corresponding to an object</span>
        <span itemprop="definition">may correspond to a probability distribution indicating a degree of closeness to the object.</span>
        <meta itemprop="num_attr" content="0075">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">each of pixels included in the probability map</span>
        <span itemprop="definition">stores a distance from the corresponding pixel to a seed pixel closest.</span>
        <meta itemprop="num_attr" content="0075">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the seed pixel</span>
        <span itemprop="definition">may be a pixel corresponding to the object among pixels included in an image.</span>
        <meta itemprop="num_attr" content="0075">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the first image</span>
        <span itemprop="definition">may be, for example, a distance field map 550 of FIG. 5 .</span>
        <meta itemprop="num_attr" content="0075">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a method of generating the probability map using the localization apparatus</span>
        <span itemprop="definition">will be further described with reference to FIG. 5 .</span>
        <meta itemprop="num_attr" content="0075">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the localization apparatus</span>
        <span itemprop="definition">generates a second image in which the object is projected according to the localization information based on map data including a location of the object.</span>
        <meta itemprop="num_attr" content="0076">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the map data</span>
        <span itemprop="definition">is high-density (HD) map data.</span>
        <meta itemprop="num_attr" content="0076">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">An HD map</span>
        <span itemprop="definition">refers to a three-dimensional (3D) map having high density, for example, centimeter-based density, for autonomous driving.</span>
        <meta itemprop="num_attr" content="0076">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Line-based information</span>
        <span itemprop="definition">for example, a center line of road and a boundary line, and information, for example, a traffic light, a sign, a curb stone, a road surface marking, and various structures, may be included in the HD map in a 3D digital format.</span>
        <meta itemprop="num_attr" content="0076">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the HD map</span>
        <span itemprop="definition">may be built using, for example, a mobile mapping system (MMS).</span>
        <meta itemprop="num_attr" content="0076">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">MMS</span>
        <span itemprop="definition">mobile mapping system</span>
        <meta itemprop="num_attr" content="0076">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the MMS</span>
        <span itemprop="definition">refers to a 3D spatial information investigation system including various sensors, and may include a moving object with a sensor, such as, for example, a camera, a lidar, and a GPS for measurement of a location and geographical features. Sensors of the MMS interact with each other flexibly and acquire various and precise location information.</span>
        <meta itemprop="num_attr" content="0076">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a sensor</span>
        <span itemprop="definition">such as, for example, a camera, a lidar, and a GPS for measurement of a location and geographical features.</span>
        <meta itemprop="num_attr" content="0076">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Sensors of the MMS</span>
        <span itemprop="definition">interact with each other flexibly and acquire various and precise location information.</span>
        <meta itemprop="num_attr" content="0076">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">generating the second image in which the object is projected according to the localization information based on the map data</span>
        <span itemprop="definition">means, for example, that the localization apparatus places a virtual camera at a location included in the localization information, on the map data, adjusts a pose of the virtual camera based on a pose included in the localization information, and generates an image of a viewpoint at which the object is viewed from the virtual camera.</span>
        <meta itemprop="num_attr" content="0077">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the localization information</span>
        <span itemprop="definition">generates the second image using, for example, a transformer that transforms a coordinate system of map data to a coordinate system of the second image.</span>
        <meta itemprop="num_attr" content="0078">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the transformer</span>
        <span itemprop="definition">may be, for example, a homographic function representing a transformation relationship between corresponding points when projecting one plane onto another plane or an artificial neural network that performs the transformation.</span>
        <meta itemprop="num_attr" content="0078">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the localization apparatus</span>
        <span itemprop="definition">extracts partial data from the map data based on the localization information and generates the second image from the extracted partial data using the transformer.</span>
        <meta itemprop="num_attr" content="0078">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the second image</span>
        <span itemprop="definition">may be, for example, a second image 430 of FIG. 4 .</span>
        <meta itemprop="num_attr" content="0078">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the localization apparatus</span>
        <span itemprop="definition">modifies or adjusts the localization information based on visual alignment between the first image and the second image.</span>
        <meta itemprop="num_attr" content="0079">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the localization apparatus</span>
        <span itemprop="definition">calculates a degree of the visual alignment by matching the first image and the second image. For example, the localization apparatus adds up values of pixels corresponding to an object included in the second image among a plurality of pixels included in the first image and determines a result of the addition as the degree of visual alignment.</span>
        <meta itemprop="num_attr" content="0079">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the degree of visual alignment</span>
        <span itemprop="definition">may be represented in, for example, a gradient descent form.</span>
        <meta itemprop="num_attr" content="0079">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the localization apparatus</span>
        <span itemprop="definition">modifies the localization information to increase the degree of visual alignment based on the directional characteristic corresponding to the object.</span>
        <meta itemprop="num_attr" content="0079">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the localization apparatus</span>
        <span itemprop="definition">modifies the localization information to transform, for example, move or rotate, the object included in the second image based on the directional characteristic. A method of modifying, by the localization apparatus, the localization information will be further described with reference to FIG. 6 .</span>
        <meta itemprop="num_attr" content="0079">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the localization apparatus</span>
        <span itemprop="definition">determines the virtual object on the map data for the AR service.</span>
        <meta itemprop="num_attr" content="0080">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the virtual object</span>
        <span itemprop="definition">may represent driving route information using an arrow indicator or a road marking indicating a direction of progress.</span>
        <meta itemprop="num_attr" content="0080">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the localization apparatus</span>
        <span itemprop="definition">may display the virtual object and the input image on, for example, a head-up display (HUD), a navigation system, or a display of a user device based on the localization information modified in operation 240 .</span>
        <meta itemprop="num_attr" content="0080">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">HUD</span>
        <span itemprop="definition">head-up display</span>
        <meta itemprop="num_attr" content="0080">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a navigation system</span>
        <span itemprop="definition">or a display of a user device based on the localization information modified in operation 240 .</span>
        <meta itemprop="num_attr" content="0080">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 3</span>
        <span itemprop="definition">illustrates an example of a localization method</span>
        <meta itemprop="num_attr" content="0081">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 4</span>
        <span itemprop="definition">illustrates an example of describing a localization process.</span>
        <meta itemprop="num_attr" content="0081">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the operations in FIGS. 3-4</span>
        <span itemprop="definition">may be performed in the sequence and manner as shown, although the order of some operations may be changed or some of the operations omitted without departing from the spirit and scope of the illustrative examples described. Many of the operations shown in FIGS. 3-4 may be performed in parallel or concurrently.</span>
        <meta itemprop="num_attr" content="0081">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">One or more blocks of FIGS. 3-4 , and combinations of the blocks,</span>
        <span itemprop="definition">can be implemented by special purpose hardware-based computer that perform the specified functions, or combinations of special purpose hardware and computer instructions.</span>
        <meta itemprop="num_attr" content="0081">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIGS. 1-2</span>
        <span itemprop="definition">are also applicable to FIGS. 3-4 , and are incorporated herein by reference. Thus, the above description may not be repeated here.</span>
        <meta itemprop="num_attr" content="0081">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the localization apparatus</span>
        <span itemprop="definition">acquires the input image 410 .</span>
        <meta itemprop="num_attr" content="0082">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the localization apparatus</span>
        <span itemprop="definition">receives the input image 410 generated by capturing an object using an image sensor.</span>
        <meta itemprop="num_attr" content="0082">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the input image 410</span>
        <span itemprop="definition">may be an image corresponding to a current location of an apparatus.</span>
        <meta itemprop="num_attr" content="0082">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the localization apparatus</span>
        <span itemprop="definition">receives or acquires map data that includes a location of the object.</span>
        <meta itemprop="num_attr" content="0083">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the localization apparatus</span>
        <span itemprop="definition">estimates the object from the input image 410 acquired in operation 310 .</span>
        <meta itemprop="num_attr" content="0084">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the localization apparatus</span>
        <span itemprop="definition">may generate a first image 420 that includes a directional characteristic corresponding to the object based on the input image 410 .</span>
        <meta itemprop="num_attr" content="0084">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the localization apparatus</span>
        <span itemprop="definition">generates the first image 420 using a pretrained neural network.</span>
        <meta itemprop="num_attr" content="0084">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the localization apparatus</span>
        <span itemprop="definition">may use the pretrained neural network to stably estimate the object regardless of various obstacles, such as, for example, a vehicle, a pedestrian, and a street tree, in the input image 410 .</span>
        <meta itemprop="num_attr" content="0084">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the pretrained neural network</span>
        <span itemprop="definition">when the input image 410 is applied, the pretrained neural network generates the first image 420 by activating a portion corresponding to a line in the applied input image 410 .</span>
        <meta itemprop="num_attr" content="0084">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the first image 420</span>
        <span itemprop="definition">may include, for example, a 2D distance field map.</span>
        <meta itemprop="num_attr" content="0084">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the localization apparatus</span>
        <span itemprop="definition">performs initial localization.</span>
        <meta itemprop="num_attr" content="0085">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the localization apparatus</span>
        <span itemprop="definition">generates the second image 430 in which the object is projected based on the initial localization by applying localization information corresponding to the initial localization on the map data that is acquired in operation 320 .</span>
        <meta itemprop="num_attr" content="0085">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the localization apparatus</span>
        <span itemprop="definition">performs visual alignment on the first image 420 and the second image 430 .</span>
        <meta itemprop="num_attr" content="0086">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the localization apparatus</span>
        <span itemprop="definition">visually aligns the first image 420 and the second image 430 , as shown in an image 440 .</span>
        <meta itemprop="num_attr" content="0086">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the localization apparatus</span>
        <span itemprop="definition">optimizes the visual alignment.</span>
        <meta itemprop="num_attr" content="0087">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the localization apparatus</span>
        <span itemprop="definition">calculates a localization modification value so that the first image 420 and the second image 430 may maximally overlap through the visual alignment.</span>
        <meta itemprop="num_attr" content="0087">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the localization apparatus</span>
        <span itemprop="definition">may optimize the visual alignment by changing the localization information to maximize overlapping between the first image 420 and the second image 430 based on the initial localization performed in operation 340 .</span>
        <meta itemprop="num_attr" content="0087">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">gradient-based optimization</span>
        <span itemprop="definition">may be readily performed using the first image 420 in which information is spread over the entire image, i.e., the distance field map.</span>
        <meta itemprop="num_attr" content="0087">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the localization apparatus</span>
        <span itemprop="definition">applies the localization modification value to the localization information and updates the localization information to optimize the visual alignment between the first image 420 and the second image 430 , as shown in an image 450 .</span>
        <meta itemprop="num_attr" content="0088">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 5</span>
        <span itemprop="definition">illustrates an example of describing a process of generating a first image.</span>
        <meta itemprop="num_attr" content="0089">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a process of applying an input image 510 to a neural network 530 and generating a distance field map 550 corresponding to a first image</span>
        <span itemprop="definition">will be described with reference to FIG. 5 .</span>
        <meta itemprop="num_attr" content="0089">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the neural network 530</span>
        <span itemprop="definition">refers to a neural network that is pretrained to generate a first image including a directional characteristic corresponding to an object included in the input image 510 , based on the input image 510 .</span>
        <meta itemprop="num_attr" content="0090">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the neural network 530</span>
        <span itemprop="definition">may be a deep neural network (DNN) or an n-layer neural network.</span>
        <meta itemprop="num_attr" content="0090">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the DNN or n-layer neural network</span>
        <span itemprop="definition">may correspond to a convolutional neural network (CNN), a recurrent neural network (RNN), a deep belief network, a fully connected network, a bi-directional neural network, a restricted Boltzman machine, and a bidirectional long short term memory (BLSTM), or may include different or overlapping neural network portions respectively with full, convolutional, recurrent, and/or bi-directional connections.</span>
        <meta itemprop="num_attr" content="0090">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the neural network 53</span>
        <span itemprop="definition">may be embodied as a CNN, but is not limited thereto.</span>
        <meta itemprop="num_attr" content="0090">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the neural network 530</span>
        <span itemprop="definition">may be embodied as an architecture having a plurality of layers including an input image, feature maps, and an output.</span>
        <meta itemprop="num_attr" content="0091">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a convolution operation</span>
        <span itemprop="definition">is performed on the input image with a filter referred to as a kernel, and as a result, the feature maps are output.</span>
        <meta itemprop="num_attr" content="0091">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the convolution operation</span>
        <span itemprop="definition">is performed again on the output feature maps as input feature maps, with a kernel, and new feature maps are output.</span>
        <meta itemprop="num_attr" content="0091">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the neural network 530</span>
        <span itemprop="definition">may include a pooling layer or a fully connected layer.</span>
        <meta itemprop="num_attr" content="0091">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the neural network 530</span>
        <span itemprop="definition">estimates the object included in the input image 510 based on a form of the distance field map 550 . For example, when the first image includes directional characteristic information associated with a close object as in the distance field map 550 , a directional characteristic of optimization may be readily determined using a gradient descent scheme. When the probability distribution indicating a degree of closeness to the object is distributed over the overall image as in the distance field map 550 , an amount of data for learning may be increased. Performance of the neural network 530 may be enhanced compared to learning by sparse data.</span>
        <meta itemprop="num_attr" content="0092">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 6</span>
        <span itemprop="definition">illustrates an example of describing a method of modifying localization information.</span>
        <meta itemprop="num_attr" content="0093">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 6</span>
        <span itemprop="definition">illustrates an input image 605 , a first image 610 , and a second image 620 .</span>
        <meta itemprop="num_attr" content="0093">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the first image 610</span>
        <span itemprop="definition">is generated based on the input image 605 .</span>
        <meta itemprop="num_attr" content="0093">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the second image 620</span>
        <span itemprop="definition">is generated by projecting an object based on localization information (x, y, z, r x , r y , r z ) corresponding to an initial localization, based on map data.</span>
        <meta itemprop="num_attr" content="0093">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the localization apparatus</span>
        <span itemprop="definition">matches the first image 610 and the second image 620 to be an image 630 and calculates a degree of visual alignment therebetween in a form of, for example, score .</span>
        <meta itemprop="num_attr" content="0094">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the localization apparatus</span>
        <span itemprop="definition">adds up values of pixels corresponding to an object included in the second image 620 from among a plurality of pixels included in the first image 610 and calculates an addition result in the form of a score.</span>
        <meta itemprop="num_attr" content="0094">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">each of the plurality of pixels included in the first image 610</span>
        <span itemprop="definition">may have a value between 0 and 1 based on a distance from an object adjacent to the respective pixel.</span>
        <meta itemprop="num_attr" content="0095">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Each pixel</span>
        <span itemprop="definition">may have a value close to 1 as the distance from the adjacent object decreases and may have a value close to 0 as the distance from the adjacent object increases.</span>
        <meta itemprop="num_attr" content="0095">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the localization apparatus</span>
        <span itemprop="definition">extracts pixels that match the second image 620 from among the plurality of pixels included in the first image 610 , adds up values of the extracted pixels, and calculates a score.</span>
        <meta itemprop="num_attr" content="0095">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the localization apparatus</span>
        <span itemprop="definition">modifies localization information to increase the degree of visual alignment, i.e., the score based on the directional characteristic of the first image 610 .</span>
        <meta itemprop="num_attr" content="0096">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the localization apparatus</span>
        <span itemprop="definition">calculates a localization modification value so that the localization of the object included in the second image 620 fits the directional characteristic of the first image 610 .</span>
        <meta itemprop="num_attr" content="0096">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the localization apparatus</span>
        <span itemprop="definition">updates the localization information to be     640 by applying the localization modification value to the localization information corresponding to the initial localization. For example, the localization apparatus determines a direction in which the object of the second image 620 is to be moved to increase the score, based on the directional characteristic included in the first image 610 . Once the localization information is updated, the object of the second image 620 is moved. Thus, the localization apparatus updates the localization information based on the directional characteristic included in the first image 610 .</span>
        <meta itemprop="num_attr" content="0096">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the localization apparatus</span>
        <span itemprop="definition">generates an updated second image 650 based on the updated localization information .</span>
        <meta itemprop="num_attr" content="0097">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the localization apparatus</span>
        <span itemprop="definition">calculates a score  by matching the updated second image 650 and the first image 610 .</span>
        <meta itemprop="num_attr" content="0097">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the localization apparatus</span>
        <span itemprop="definition">calculates a localization modification value to maximize the score through the aforementioned process and outputs optimized localization information *.</span>
        <meta itemprop="num_attr" content="0098">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIGS. 7A and 7B</span>
        <span itemprop="definition">illustrate examples of describing a method of modifying localization information.</span>
        <meta itemprop="num_attr" content="0099">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 7A</span>
        <span itemprop="definition">illustrates an example in which objects included in an input image is not classified for each type.</span>
        <meta itemprop="num_attr" content="0100">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the localization apparatus</span>
        <span itemprop="definition">modifies localization information to increase a degree of visual alignment between the first image and the second image calculated by matching the first image and the second image.</span>
        <meta itemprop="num_attr" content="0100">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the localization apparatus</span>
        <span itemprop="definition">may not accurately verify whether to match the line 720 and the line 710 or whether to match the line 720 and the line 730 , which may make it difficult to accurately modify the localization information.</span>
        <meta itemprop="num_attr" content="0100">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 7B</span>
        <span itemprop="definition">illustrates an example in which objects in an input image are classified according to a type of the object.</span>
        <meta itemprop="num_attr" content="0101">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the first image</span>
        <span itemprop="definition">may classify the object based on a type of the object and may store a directional characteristic for each type of object.</span>
        <meta itemprop="num_attr" content="0101">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the second image</span>
        <span itemprop="definition">may classify the object based on a type of the object and may store a projected object for each object type.</span>
        <meta itemprop="num_attr" content="0101">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a line 740 and a line 760</span>
        <span itemprop="definition">may correspond to objects included in the first image.</span>
        <meta itemprop="num_attr" content="0101">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the line 740</span>
        <span itemprop="definition">may correspond to a first type (Type 1 ) and the line 760 may correspond to a second type (Type 2 ).</span>
        <meta itemprop="num_attr" content="0101">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a line 750</span>
        <span itemprop="definition">may be included in the second image and correspond to the first type (Type 1 ).</span>
        <meta itemprop="num_attr" content="0101">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the localization apparatus</span>
        <span itemprop="definition">matches the first image and the second image and calculates a degree of visual alignment for each object type.</span>
        <meta itemprop="num_attr" content="0102">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the localization apparatus</span>
        <span itemprop="definition">modifies the localization information to increase the degree of visual alignment for each type based on the directional characteristic.</span>
        <meta itemprop="num_attr" content="0102">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the localization apparatus</span>
        <span itemprop="definition">may calculate a degree of visual alignments for objects, the lines 740 and 750 , corresponding to the first type (Type 1 ) and may modify localization information to increase the degree of visual alignment corresponding to the first type based on the directional characteristic.</span>
        <meta itemprop="num_attr" content="0103">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the localization apparatus</span>
        <span itemprop="definition">may modify the localization information to match the objects that are the lines 740 and 750 .</span>
        <meta itemprop="num_attr" content="0103">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 8</span>
        <span itemprop="definition">is a diagram illustrating an example of a learning method</span>
        <meta itemprop="num_attr" content="0104">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 9</span>
        <span itemprop="definition">illustrates an example of a learning process.</span>
        <meta itemprop="num_attr" content="0104">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the operations in FIG. 8</span>
        <span itemprop="definition">may be performed in the sequence and manner as shown, although the order of some operations may be changed or some of the operations omitted without departing from the spirit and scope of the illustrative examples described. Many of the operations shown in FIG. 8 may be performed in parallel or concurrently.</span>
        <meta itemprop="num_attr" content="0104">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">One or more blocks of FIG. 8 , and combinations of the blocks,</span>
        <span itemprop="definition">can be implemented by special purpose hardware-based computer that perform the specified functions, or combinations of special purpose hardware and computer instructions.</span>
        <meta itemprop="num_attr" content="0104">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a training of a neural network, by a learning apparatus, to generate a first image from an input image to optimize localization information for AR</span>
        <span itemprop="definition">will be described with reference to FIGS. 8, 9 and 10 .</span>
        <meta itemprop="num_attr" content="0104">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIGS. 1-7B</span>
        <span itemprop="definition">are also applicable to FIG. 8 , and are incorporated herein by reference. Thus, the above description may not be repeated here.</span>
        <meta itemprop="num_attr" content="0104">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the learning apparatus</span>
        <span itemprop="definition">receives a learning image 910 .</span>
        <meta itemprop="num_attr" content="0105">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the learning image 910</span>
        <span itemprop="definition">may include, for example, a driving image of a vehicle.</span>
        <meta itemprop="num_attr" content="0105">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the learning image 910</span>
        <span itemprop="definition">may be, for example, a learning image 1010 of FIG. 10 .</span>
        <meta itemprop="num_attr" content="0105">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the learning apparatus</span>
        <span itemprop="definition">In operation 820 , the learning apparatus generates a reference image 950 that includes a directional characteristic corresponding to an object included in the learning image 910 , based on map data 940 for the learning image 910 .</span>
        <meta itemprop="num_attr" content="0106">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the directional characteristic</span>
        <span itemprop="definition">corresponds to a probability distribution indicating a degree of closeness to an object.</span>
        <meta itemprop="num_attr" content="0106">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the reference image 950</span>
        <span itemprop="definition">may correspond to a ground truth (GT) image.</span>
        <meta itemprop="num_attr" content="0106">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the reference image 950</span>
        <span itemprop="definition">may be, for example, a reference image 1030 or a reference image 1040 of FIG. 10 .</span>
        <meta itemprop="num_attr" content="0106">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the learning apparatus</span>
        <span itemprop="definition">In operation 830 , the learning apparatus generates an inference image 930 that infers the directional characteristic corresponding to the object included in the learning image 910 , using a neural network 920 .</span>
        <meta itemprop="num_attr" content="0107">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the neural network 920</span>
        <span itemprop="definition">may be, for example, the neural network 530 of FIG. 5 .</span>
        <meta itemprop="num_attr" content="0107">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a method of generating, by the learning apparatus, the inference image 930</span>
        <span itemprop="definition">will be further described with reference to FIG. 10 .</span>
        <meta itemprop="num_attr" content="0107">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the learning apparatus</span>
        <span itemprop="definition">trains the neural network 920 based on a difference, for example, a loss 960 between the reference image 950 and the inference image 930 .</span>
        <meta itemprop="num_attr" content="0108">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the learning apparatus</span>
        <span itemprop="definition">may train the neural network 920 to minimize the difference between the reference image 950 and the inference image 930 .</span>
        <meta itemprop="num_attr" content="0108">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the learning apparatus</span>
        <span itemprop="definition">may train the neural network 920 through, for example, supervised learning.</span>
        <meta itemprop="num_attr" content="0108">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the learning apparatus</span>
        <span itemprop="definition">may update the neural network 920 through a gradient descent scheme based on the loss 930 that is back-propagated to the neural network 920 through back-propagation learning and output values of nodes included in the neural network 920 .</span>
        <meta itemprop="num_attr" content="0108">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the back-propagation learning</span>
        <span itemprop="definition">refers to a method of estimating the loss 960 by performing forward computation on the reference image 950 and updating the neural network 920 to reduce the loss 960 while propagating the estimated loss 960 starting from an output layer of the neural network 920 toward a hidden layer and an input layer.</span>
        <meta itemprop="num_attr" content="0108">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 10</span>
        <span itemprop="definition">illustrates an example of images for learning.</span>
        <meta itemprop="num_attr" content="0109">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 10</span>
        <span itemprop="definition">illustrates the learning image 1010 , a map data image 1020 , and the reference images 1030 and 1040 .</span>
        <meta itemprop="num_attr" content="0109">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the learning apparatus</span>
        <span itemprop="definition">trains a neural network to estimate the reference images 1030 and 1040 from the learning image 1010 .</span>
        <meta itemprop="num_attr" content="0110">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the map data image 1020</span>
        <span itemprop="definition">represents objects in the learning image 1010 using a discrete binary value.</span>
        <meta itemprop="num_attr" content="0110">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">learning information</span>
        <span itemprop="definition">may be too sparse to smoothly perform learning.</span>
        <meta itemprop="num_attr" content="0110">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">learning</span>
        <span itemprop="definition">may be performed using a distance field map, such as the reference images 1030 and 1040 . Sparse learning information may be spread across the overall image through the distance field map. When learning information is present over the entire target image as in the distance field map, it is possible to train the neural network based on sufficient learning information.</span>
        <meta itemprop="num_attr" content="0110">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the learning apparatus</span>
        <span itemprop="definition">generates the reference image 1030 or the reference image 1040 from the map data image 1020 by adjusting an importance of spread information in a distance field.</span>
        <meta itemprop="num_attr" content="0111">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the learning apparatus</span>
        <span itemprop="definition">may adjust an importance of spread information in the distance field, such as e   0.02d .</span>
        <meta itemprop="num_attr" content="0111">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">d</span>
        <span itemprop="definition">denotes a distance between a seed pixel corresponding to an object and a corresponding pixel.</span>
        <meta itemprop="num_attr" content="0111">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 11</span>
        <span itemprop="definition">illustrates an example of a learning method</span>
        <meta itemprop="num_attr" content="0112">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 12</span>
        <span itemprop="definition">illustrates an example of a localization updating process of FIG. 11</span>
        <meta itemprop="num_attr" content="0112">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the operations in FIG. 11</span>
        <span itemprop="definition">may be performed in the sequence and manner as shown, although the order of some operations may be changed or some of the operations omitted without departing from the spirit and scope of the illustrative examples described. Many of the operations shown in FIG. 11 may be performed in parallel or concurrently.</span>
        <meta itemprop="num_attr" content="0112">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">One or more blocks of FIG. 11 , and combinations of the blocks</span>
        <span itemprop="definition">can be implemented by special purpose hardware-based computer that perform the specified functions, or combinations of special purpose hardware and computer instructions.</span>
        <meta itemprop="num_attr" content="0112">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIGS. 1-10</span>
        <span itemprop="definition">are also applicable to FIG. 11 , and are incorporated herein by reference. Thus, the above description may not be repeated here.</span>
        <meta itemprop="num_attr" content="0112">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the localization apparatus</span>
        <span itemprop="definition">acquires an input image.</span>
        <meta itemprop="num_attr" content="0113">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the input image</span>
        <span itemprop="definition">refers to an image corresponding to a current location of a corresponding apparatus.</span>
        <meta itemprop="num_attr" content="0113">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the localization apparatus</span>
        <span itemprop="definition">receives or acquires map data that includes a location of an object.</span>
        <meta itemprop="num_attr" content="0114">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the localization apparatus</span>
        <span itemprop="definition">applies a plurality of pieces of candidate localization information to the map data acquired in operation 1120 .</span>
        <meta itemprop="num_attr" content="0114">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the localization apparatus</span>
        <span itemprop="definition">generates second candidate images each in which an object is projected based on the candidate localization information.</span>
        <meta itemprop="num_attr" content="0114">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the localization apparatus</span>
        <span itemprop="definition">may generate second candidate images, for example, a first candidate image (candidate 1 ) 1210 and a second candidate image (candidate 2 ) 1220 of FIG. 12 , each to which the candidate localization information is applied.</span>
        <meta itemprop="num_attr" content="0114">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the localization apparatus</span>
        <span itemprop="definition">scores visual alignment between the input image and each of the second candidate images. For example, a degree of visual alignment between the input image and the first candidate image 1210 is scored as 0.43 and a degree of visual alignment between the input image and the second candidate image 1220 is scored as 0.98.</span>
        <meta itemprop="num_attr" content="0115">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the localization apparatus</span>
        <span itemprop="definition">searches for a best score having a highest value from among the scores output in operation 1130 . Referring to FIG. 12 , the localization apparatus retrieves 0.98 as the best score from among the scores 0.43 and 0.98. In operation 1170 , the localization apparatus updates the localization information by selecting a candidate localization corresponding to the best score retrieved in operation 1160 .</span>
        <meta itemprop="num_attr" content="0116">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 13</span>
        <span itemprop="definition">is a diagram illustrating an example of a localization method.</span>
        <meta itemprop="num_attr" content="0117">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the operations in FIG. 13</span>
        <span itemprop="definition">may be performed in the sequence and manner as shown, although the order of some operations may be changed or some of the operations omitted without departing from the spirit and scope of the illustrative examples described. Many of the operations shown in FIG. 13 may be performed in parallel or concurrently.</span>
        <meta itemprop="num_attr" content="0117">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">One or more blocks of FIG. 13 , and combinations of the blocks,</span>
        <span itemprop="definition">can be implemented by special purpose hardware-based computer that perform the specified functions, or combinations of special purpose hardware and computer instructions.</span>
        <meta itemprop="num_attr" content="0117">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIGS. 1-12</span>
        <span itemprop="definition">are also applicable to FIG. 13 , and are incorporated herein by reference. Thus, the above description may not be repeated here.</span>
        <meta itemprop="num_attr" content="0117">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the localization apparatus</span>
        <span itemprop="definition">generates a first image, for example, a distance field map, from an input image by estimating an object in operation 1330 prior to scoring a degree of visual alignment in operation 1360 .</span>
        <meta itemprop="num_attr" content="0118">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the localization apparatus</span>
        <span itemprop="definition">calculates scores between the first image and second candidate images.</span>
        <meta itemprop="num_attr" content="0118">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 14</span>
        <span itemprop="definition">is a diagram illustrating an example of a localization apparatus.</span>
        <meta itemprop="num_attr" content="0119">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a localization apparatus 1400</span>
        <span itemprop="definition">includes sensors 1410 and a processor 1430 .</span>
        <meta itemprop="num_attr" content="0119">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the localization apparatus 1400</span>
        <span itemprop="definition">further includes a memory 1450 , a communication interface 1470 , and a display device 1490 .</span>
        <meta itemprop="num_attr" content="0119">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the sensors 1410 , the processor 1430 , the memory 1450 , the communication interface 1470 , and the display device 1490</span>
        <span itemprop="definition">are connected to each other through a communication bus 1405 .</span>
        <meta itemprop="num_attr" content="0119">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the sensors 1410</span>
        <span itemprop="definition">may include, for example, an image sensor, a vision sensor, an accelerometer sensor, a gyro sensor, a GPS sensor, an IMU sensor, a radar, and a lidar.</span>
        <meta itemprop="num_attr" content="0120">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the sensor(s) 1410</span>
        <span itemprop="definition">may acquire an input image that includes a driving image of a vehicle.</span>
        <meta itemprop="num_attr" content="0120">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the sensor(s) 1410</span>
        <span itemprop="definition">may sense sensing information, for example, speed, acceleration, driving direction, handle steering angle of the vehicle, and a speed of the vehicle, in addition to localization information, for example, GPS coordinates, a location, and a pose of the vehicle.</span>
        <meta itemprop="num_attr" content="0120">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processor 1430</span>
        <span itemprop="definition">generates a first image that includes a directional characteristic corresponding to an object included in the input image. In an example, the processor 1430 generates a second image in which the object is projected based on localization information, based on map data that includes the location of the object. In an example, the processor 1430 modifies the localization information based on visual alignment between the first image and the second image.</span>
        <meta itemprop="num_attr" content="0121">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the localization apparatus 1400</span>
        <span itemprop="definition">acquires a variety of sensing information including the input image from various sensors through the communication interface 1470 .</span>
        <meta itemprop="num_attr" content="0122">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the communication interface 1470</span>
        <span itemprop="definition">receives sensing information including a driving image from other sensors outside the localization apparatus 1400 .</span>
        <meta itemprop="num_attr" content="0122">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processor 1430</span>
        <span itemprop="definition">provides an AR service by outputting the modified localization information through the communication interface 1470 and/or the display device 1490 or by displaying a virtual object and the input image on map data based on the modified localization information. Also, the processor 1430 may perform the one or more methods described with reference to FIGS. 1 to 13 or an algorithm corresponding thereto.</span>
        <meta itemprop="num_attr" content="0123">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processor 1430</span>
        <span itemprop="definition">refers to a data processing device configured as hardware with a circuitry in a physical structure to execute desired operations.</span>
        <meta itemprop="num_attr" content="0124">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the desired operations</span>
        <span itemprop="definition">may include codes or instructions included in a program.</span>
        <meta itemprop="num_attr" content="0124">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the data processing device configured as hardware</span>
        <span itemprop="definition">may include a microprocessor, a central processing unit (CPU), a processor core, a multicore processor, a multiprocessor, an application-specific integrated circuit (ASIC), and a field programmable gate array (FPGA). Further details on the processor 1430 are provided below.</span>
        <meta itemprop="num_attr" content="0124">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processor 1430</span>
        <span itemprop="definition">executes the program and controls the localization apparatus 1400 .</span>
        <meta itemprop="num_attr" content="0125">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the program code executed by the processor 1430</span>
        <span itemprop="definition">may be stored in the memory 1450 .</span>
        <meta itemprop="num_attr" content="0125">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the memory 1450</span>
        <span itemprop="definition">stores the localization information of the localization apparatus 1400 , the first image, the second image, and/or the modified localization information.</span>
        <meta itemprop="num_attr" content="0126">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the memory 1450</span>
        <span itemprop="definition">stores a variety of information that is generated during a processing process of the processor 1430 .</span>
        <meta itemprop="num_attr" content="0126">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the memory 14450</span>
        <span itemprop="definition">stores the map data.</span>
        <meta itemprop="num_attr" content="0126">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the memory 1450</span>
        <span itemprop="definition">stores a variety of data and programs.</span>
        <meta itemprop="num_attr" content="0126">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the memory 1450</span>
        <span itemprop="definition">may include, for example, a volatile memory or a non-volatile memory.</span>
        <meta itemprop="num_attr" content="0126">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the memory 1450</span>
        <span itemprop="definition">may include a mass storage medium, such as a hard disk, to store a variety of data. Further details on the memory 1450 are provided below.</span>
        <meta itemprop="num_attr" content="0126">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the display device 1490</span>
        <span itemprop="definition">outputs the localization information modified by the processor 1430 , or displays a virtual object with the input image on map data based on the modified localization information.</span>
        <meta itemprop="num_attr" content="0127">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the display device 1490</span>
        <span itemprop="definition">is a physical structure that includes one or more hardware components that provide the ability to render a user interface and/or receive user input.</span>
        <meta itemprop="num_attr" content="0127">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the localization information or the virtual object with the input image on map data based on the modified localization information</span>
        <span itemprop="definition">is displayed on a wind shield glass or a separate screen of the vehicle using a head-up display (HUD) or is displayed on an augmented reality head-up display (AR HUD).</span>
        <meta itemprop="num_attr" content="0127">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the localization apparatus 1400</span>
        <span itemprop="definition">transmits the localization information to an electronic control unit (ECU) or a vehicle control unit (VCU) of a vehicle. The ECU or the VCU displays the localization information on display device 1490 of the vehicle.</span>
        <meta itemprop="num_attr" content="0127">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the displaying of the object</span>
        <span itemprop="definition">is not limited to the example described above, and any other instrument cluster, vehicular infotainment system, screen in the vehicle, or display panel in the vehicle may perform the display function.</span>
        <meta itemprop="num_attr" content="0128">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Other displays</span>
        <span itemprop="definition">such as, for example, smart phone and eye glass display (EGD) that are operatively connected to the localization apparatus 1400 may be used without departing from the spirit and scope of the illustrative examples described.</span>
        <meta itemprop="num_attr" content="0128">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">EGD</span>
        <span itemprop="definition">eye glass display</span>
        <meta itemprop="num_attr" content="0128">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the localization apparatus</span>
        <span itemprop="definition">may perform the localization method independent of a viewpoint by updating 3D localization information of the localization apparatus using a result of performing the localization method based on a photographing apparatus, although a viewpoint between the photographing device and the localization apparatus does not match, such as, for example, an HUD and AR glasses. Also, when the viewpoint between the photographing device and the localization information matches, such as, for example, a mobile terminal and a smartphone, the localization apparatus may update 3D localization information and, additionally, may directly use a 2D location in an image for modification.</span>
        <meta itemprop="num_attr" content="0129">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the localization apparatus, processor 1430 and other apparatuses, units, modules, devices, and other components described herein</span>
        <span itemprop="definition">are implemented by hardware components.</span>
        <meta itemprop="num_attr" content="0130">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">hardware components</span>
        <span itemprop="definition">that may be used to perform the operations described in this application where appropriate include controllers, sensors, generators, drivers, memories, comparators, arithmetic logic units, adders, subtractors, multipliers, dividers, integrators, and any other electronic components configured to perform the operations described in this application.</span>
        <meta itemprop="num_attr" content="0130">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">one or more of the hardware components that perform the operations described in this application</span>
        <span itemprop="definition">are implemented by computing hardware, for example, by one or more processors or computers.</span>
        <meta itemprop="num_attr" content="0130">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a processor or computer</span>
        <span itemprop="definition">may be implemented by one or more processing elements, such as an array of logic gates, a controller and an arithmetic logic unit, a digital signal processor, a microcomputer, a programmable logic controller, a field-programmable gate array, a programmable logic array, a microprocessor, or any other device or combination of devices that is configured to respond to and execute instructions in a defined manner to achieve a desired result.</span>
        <meta itemprop="num_attr" content="0130">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a processor or computer</span>
        <span itemprop="definition">includes, or is connected to, one or more memories storing instructions or software that are executed by the processor or computer.</span>
        <meta itemprop="num_attr" content="0130">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Hardware components implemented by a processor or computer</span>
        <span itemprop="definition">may execute instructions or software, such as an operating system (OS) and one or more software applications that run on the OS, to perform the operations described in this application.</span>
        <meta itemprop="num_attr" content="0130">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">OS</span>
        <span itemprop="definition">operating system</span>
        <meta itemprop="num_attr" content="0130">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the hardware components</span>
        <span itemprop="definition">may also access, manipulate, process, create, and store data in response to execution of the instructions or software.</span>
        <meta itemprop="num_attr" content="0130">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">processor</span>
        <span itemprop="definition">or computer may be used in the description of the examples described in this application, but in other examples multiple processors or computers may be used, or a processor or computer may include multiple processing elements, or multiple types of processing elements, or both.</span>
        <meta itemprop="num_attr" content="0130">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a single hardware component or two or more hardware components</span>
        <span itemprop="definition">may be implemented by a single processor, or two or more processors, or a processor and a controller.</span>
        <meta itemprop="num_attr" content="0130">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">One or more hardware components</span>
        <span itemprop="definition">may be implemented by one or more processors, or a processor and a controller, and one or more other hardware components may be implemented by one or more other processors, or another processor and another controller.</span>
        <meta itemprop="num_attr" content="0130">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">One or more processors</span>
        <span itemprop="definition">may implement a single hardware component, or two or more hardware components.</span>
        <meta itemprop="num_attr" content="0130">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a hardware component</span>
        <span itemprop="definition">may have any one or more of different processing configurations, examples of which include a single processor, independent processors, parallel processors, single-instruction single-data (SISD) multiprocessing, single-instruction multiple-data (SIMD) multiprocessing, multiple-instruction single-data (MISD) multiprocessing, and multiple-instruction multiple-data (MIMD) multiprocessing.</span>
        <meta itemprop="num_attr" content="0130">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">SISD</span>
        <span itemprop="definition">single-instruction single-data</span>
        <meta itemprop="num_attr" content="0130">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">SIMD</span>
        <span itemprop="definition">single-instruction multiple-data</span>
        <meta itemprop="num_attr" content="0130">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">MIMD</span>
        <span itemprop="definition">multiple-instruction multiple-data</span>
        <meta itemprop="num_attr" content="0130">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the methods that perform the operations described in this application</span>
        <span itemprop="definition">are performed by computing hardware, for example, by one or more processors or computers, implemented as described above executing instructions or software to perform the operations described in this application that are performed by the methods.</span>
        <meta itemprop="num_attr" content="0131">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a single operation or two or more operations</span>
        <span itemprop="definition">may be performed by a single processor, or two or more processors, or a processor and a controller.</span>
        <meta itemprop="num_attr" content="0131">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">One or more operations</span>
        <span itemprop="definition">may be performed by one or more processors, or a processor and a controller, and one or more other operations may be performed by one or more other processors, or another processor and another controller.</span>
        <meta itemprop="num_attr" content="0131">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">One or more processors, or a processor and a controller</span>
        <span itemprop="definition">may perform a single operation, or two or more operations.</span>
        <meta itemprop="num_attr" content="0131">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Instructions or software to control a processor or computer to implement the hardware components and perform the methods as described above</span>
        <span itemprop="definition">are written as computer programs, code segments, instructions or any combination thereof, for individually or collectively instructing or configuring the processor or computer to operate as a machine or special-purpose computer to perform the operations performed by the hardware components and the methods as described above.</span>
        <meta itemprop="num_attr" content="0132">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the instructions or software</span>
        <span itemprop="definition">includes at least one of an applet, a dynamic link library (DLL), middleware, firmware, a device driver, an application program storing the method of preventing the collision.</span>
        <meta itemprop="num_attr" content="0132">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the instructions or software</span>
        <span itemprop="definition">include machine code that is directly executed by the processor or computer, such as machine code produced by a compiler.</span>
        <meta itemprop="num_attr" content="0132">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the instructions or software</span>
        <span itemprop="definition">include higher-level code that is executed by the processor or computer using an interpreter. Programmers of ordinary skill in the art can readily write the instructions or software based on the block diagrams and the flow charts illustrated in the drawings and the corresponding descriptions in the specification, which disclose algorithms for performing the operations performed by the hardware components and the methods as described above.</span>
        <meta itemprop="num_attr" content="0132">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the instructions or software to control computing hardware</span>
        <span itemprop="definition">for example, one or more processors or computers, to implement the hardware components and perform the methods as described above, and any associated data, data files, and data structures, may be recorded, stored, or fixed in or on one or more non-transitory computer-readable storage media.</span>
        <meta itemprop="num_attr" content="0133">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Examples of a non-transitory computer-readable storage medium</span>
        <span itemprop="definition">include read-only memory (ROM), random-access memory (RAM), CD-ROMs, CD-Rs, CD&#43;Rs, CD-RWs, CD&#43;RWs, DVD-ROMs, DVD-Rs, DVD&#43;Rs, DVD-RWs, DVD&#43;RWs, DVD-RAMs, BD-ROMs, BD-Rs, BD-R LTHs, BD-REs, magnetic tapes, floppy disks, magneto-optical data storage devices, optical data storage devices, hard disks, solid-state disks, and any other device that is configured to store the instructions or software and any associated data, data files, and data structures in a non-transitory manner and provide the instructions or software and any associated data, data files, and data structures to one or more processors or computers so that the one or more processors or computers can execute the instructions.</span>
        <meta itemprop="num_attr" content="0133">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">ROM</span>
        <span itemprop="definition">read-only memory</span>
        <meta itemprop="num_attr" content="0133">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">RAM</span>
        <span itemprop="definition">random-access memory</span>
        <meta itemprop="num_attr" content="0133">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">CD-ROMs</span>
        <span itemprop="definition">CD-Rs, CD&#43;Rs, CD-</span>
        <meta itemprop="num_attr" content="0133">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the instructions or software and any associated data, data files, and data structures</span>
        <span itemprop="definition">are distributed over network-coupled computer systems so that the instructions and software and any associated data, data files, and data structures are stored, accessed, and executed in a distributed fashion by the one or more processors or computers.</span>
        <meta itemprop="num_attr" content="0133">
      </li>
    </ul>
  </section>

  


  <section itemprop="abstract" itemscope>
    <h2>Abstract</h2>
    
    <div itemprop="content" html><abstract mxw-id="PA464401457" lang="EN" source="national office" load-source="docdb">
    <div class="abstract">Disclosed is a localization method and apparatus that may acquire localization information of a device, generate a first image that includes a directional characteristic corresponding to an object included in an input image, generate a second image in which the object is projected based on the localization information, to map data corresponding to a location of the object, and adjust the localization information based on visual alignment between the first image and the second image.</div>
  </abstract>
  </div>
  </section>

  <section itemprop="description" itemscope>
    <h2>Description</h2>
    
    <div itemprop="content" html><ul mxw-id="PDES302332091" lang="EN" load-source="patent-office" class="description">
    
    <heading id="h-0001">CROSS-REFERENCE TO RELATED APPLICATIONS</heading>
    <li> <para-num num="[0001]"> </para-num> <div id="p-0002" num="0001" class="description-line">This application is a continuation of U.S. application Ser. No. 16/259,420, filed on Jan. 28, 2019, and claims the benefit under 35 USC  119(a) of Korean Patent Application No. 10-2018-0108252 filed on Sep. 11, 2018 in the Korean Intellectual Property Office, the entire disclosures of which are all incorporated herein by reference for all purposes.</div>
    
    
    </li> <heading id="h-0002"> <figure-callout id="1" label="BACKGROUND" filenames="US20210287438A1-20210916-D00007.png" state="{{state}}">BACKGROUND</figure-callout> </heading>
    <heading id="h-0003">1. Field</heading>
    <li> <para-num num="[0002]"> </para-num> <div id="p-0003" num="0002" class="description-line">The following description relates to a localization method and apparatus for displaying a virtual object in augmented reality (AR).</div>
    </li> <heading id="h-0004">2. Description of Related Art</heading>
    <li> <para-num num="[0003]"> </para-num> <div id="p-0004" num="0003" class="description-line">Various types of augmented reality (AR) services are provided in various fields, such as, for example, driving assistance for vehicles and other transportation devices, games, and amusements. Various localization methods may be used to provide realistically AR. For example, a sensor-based localization method may use various sensors, for example, a global positioning system (GPS) sensor and an inertial measurement unit (IMU) sensor, to verify a location and a direction of an object. When high accuracy is required, a sensor-based localization method requires a very price sensor with high accuracy, and thus, commercialization and miniaturization is difficult. Also, a vision-based localization method using camera information to acquire highly precise coordinate information may be difficult to use in an environment with many dynamic objects having continuous motions.</div>
    </li> <heading id="h-0005">SUMMARY</heading>
    <li> <para-num num="[0004]"> </para-num> <div id="p-0005" num="0004" class="description-line">This Summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description. This Summary is not intended to identify key features or essential features of the claimed subject matter, nor is it intended to be used as an aid in determining the scope of the claimed subject matter.</div>
    </li> <li> <para-num num="[0005]"> </para-num> <div id="p-0006" num="0005" class="description-line">In one general aspect, there is provided a localization method including acquiring localization information of a device, generating a first image including a directional characteristic corresponding to an object included in an input image, generating a second image in which the object is projected, based on the localization information, on to map data corresponding to a location of the object, and updating the localization information based on visual alignment between the first image and the second image.</div>
    </li> <li> <para-num num="[0006]"> </para-num> <div id="p-0007" num="0006" class="description-line">The localization information may include a location of the apparatus and a pose of the apparatus.</div>
    </li> <li> <para-num num="[0007]"> </para-num> <div id="p-0008" num="0007" class="description-line">The generating of the second image may include placing a virtual camera at the location on the map data, and adjusting a pose of the virtual camera based on the pose of the apparatus, and generating an image of a viewpoint at which the object is viewed from the virtual camera.</div>
    </li> <li> <para-num num="[0008]"> </para-num> <div id="p-0009" num="0008" class="description-line">The directional characteristic may correspond to a probability distribution indicating a degree of closeness to the object.</div>
    </li> <li> <para-num num="[0009]"> </para-num> <div id="p-0010" num="0009" class="description-line">The input image may be based on an output of a first sensor, and the localization information may be based on an output of a second sensor.</div>
    </li> <li> <para-num num="[0010]"> </para-num> <div id="p-0011" num="0010" class="description-line">The localization method may include determining a virtual object on the map data for an augmented reality (AR) service, and displaying the virtual object and the input image may be based on the adjusted localization information.</div>
    </li> <li> <para-num num="[0011]"> </para-num> <div id="p-0012" num="0011" class="description-line">The virtual object may represent driving route information.</div>
    </li> <li> <para-num num="[0012]"> </para-num> <div id="p-0013" num="0012" class="description-line">The generating of the first image may include generating a probability map that represents the directional characteristic using a trained neural network.</div>
    </li> <li> <para-num num="[0013]"> </para-num> <div id="p-0014" num="0013" class="description-line">Each pixel in the probability map may be configured to store a distance from the each pixel to a closest seed pixel.</div>
    </li> <li> <para-num num="[0014]"> </para-num> <div id="p-0015" num="0014" class="description-line">The seed pixel may include a pixel corresponding to the object among pixels included in the input image.</div>
    </li> <li> <para-num num="[0015]"> </para-num> <div id="p-0016" num="0015" class="description-line">The generating of the second image may include generating the second image using a transformer configured to transform a coordinate system of the map data to a coordinate system of the second image.</div>
    </li> <li> <para-num num="[0016]"> </para-num> <div id="p-0017" num="0016" class="description-line">The localization information may include 6 degrees of freedom (6DoF).</div>
    </li> <li> <para-num num="[0017]"> </para-num> <div id="p-0018" num="0017" class="description-line">The updating of the localization information may include calculating a degree of the visual alignment by matching the first image and the second image, and modifying the localization information to increase the degree of the virtual alignment based on the directional characteristic.</div>
    </li> <li> <para-num num="[0018]"> </para-num> <div id="p-0019" num="0018" class="description-line">The calculating may include adding up values of pixels corresponding to the object in the second image from among pixels in the first image.</div>
    </li> <li> <para-num num="[0019]"> </para-num> <div id="p-0020" num="0019" class="description-line">The modifying of the localization information based on the directional characteristic may include modifying the localization information to transform the object in the second image based on the directional characteristic.</div>
    </li> <li> <para-num num="[0020]"> </para-num> <div id="p-0021" num="0020" class="description-line">The modifying of the localization information based on the directional characteristic may include moving or rotating the object in the second image based on the directional characteristic.</div>
    </li> <li> <para-num num="[0021]"> </para-num> <div id="p-0022" num="0021" class="description-line">The first image may be configured to classify the object based on an object type and to store a directional characteristic for each object type, and the second image may be configured to classify the object based on the object type and to store the projected object for the each object type.</div>
    </li> <li> <para-num num="[0022]"> </para-num> <div id="p-0023" num="0022" class="description-line">The modifying may include calculating a degree of visual alignment for each object type by matching the first image and the second image, and modifying the localization information to increase the degree of visual alignment based on the directional characteristic.</div>
    </li> <li> <para-num num="[0023]"> </para-num> <div id="p-0024" num="0023" class="description-line">The input image may include a driving image of a vehicle.</div>
    </li> <li> <para-num num="[0024]"> </para-num> <div id="p-0025" num="0024" class="description-line">The object may include any one or any combination of a line, a road surface marking, a traffic light, a sign, a curb stone, and a structure.</div>
    </li> <li> <para-num num="[0025]"> </para-num> <div id="p-0026" num="0025" class="description-line">In another general aspect, there is provided a learning method including receiving a learning image, generating a reference image including a directional characteristic corresponding to an object in the learning image, based on map data for the learning image, generating an inference image that infers the directional characteristic corresponding to the object in the learning image, using a neural network, and training the neural network based on a difference between the reference image and the inference image.</div>
    </li> <li> <para-num num="[0026]"> </para-num> <div id="p-0027" num="0026" class="description-line">The training may include training the neural network to minimize the difference between the reference image and the inference image.</div>
    </li> <li> <para-num num="[0027]"> </para-num> <div id="p-0028" num="0027" class="description-line">The directional characteristic may correspond to a probability distribution indicating a degree of closeness to the object.</div>
    </li> <li> <para-num num="[0028]"> </para-num> <div id="p-0029" num="0028" class="description-line">Each pixel in the reference image and the inference image may be configured to store a distance from the each pixel to closest a seed pixel.</div>
    </li> <li> <para-num num="[0029]"> </para-num> <div id="p-0030" num="0029" class="description-line">Each of the reference image and the inference image may be configured to classify the object based on a type of the object and to store the directional characteristic for each object type.</div>
    </li> <li> <para-num num="[0030]"> </para-num> <div id="p-0031" num="0030" class="description-line">The training may include training the neural network based on a type difference between the reference image and the inference image.</div>
    </li> <li> <para-num num="[0031]"> </para-num> <div id="p-0032" num="0031" class="description-line">The learning image may include a driving image of a vehicle.</div>
    </li> <li> <para-num num="[0032]"> </para-num> <div id="p-0033" num="0032" class="description-line">The object may include any one or any combination of a line, a road surface marking, a traffic light, a sign, a curb stone, and a structure.</div>
    </li> <li> <para-num num="[0033]"> </para-num> <div id="p-0034" num="0033" class="description-line">In another general aspect, there is provided a localization apparatus including sensors configured to acquire localization information of a device and an input image, and a processor configured to generate a first image including a directional characteristic corresponding to an object included in the input image, to generate a second image in which the object is projected, based on the localization information, on to map data corresponding to a location of the object, and to adjust the localization information based on visual alignment between the first image and the second image.</div>
    </li> <li> <para-num num="[0034]"> </para-num> <div id="p-0035" num="0034" class="description-line">In another general aspect, there is provided a localization method including acquiring an input image corresponding to a location of a device, receiving map data corresponding to a location of an object, generating second images in which the object is projected, based on plurality of respective candidate localization information, on to the map data, calculating a degree of visual alignment for each of the second images by matching the input image and the each of the second images, selecting a second image having the greatest degree of visual alignment from the second images, and updating localization information based on a candidate localization information corresponding to the selected second image.</div>
    </li> <li> <para-num num="[0035]"> </para-num> <div id="p-0036" num="0035" class="description-line">The localization method may include generating a first image comprising a probability map indicating a directional characteristic corresponding to the object, and wherein the calculating of the degree of visual alignment may include matching the first image and the each of the second images.</div>
    </li> <li> <para-num num="[0036]"> </para-num> <div id="p-0037" num="0036" class="description-line">In another general aspect, there is provided a localization apparatus including a first sensor configured to capture an image, a second sensor configured to acquire localization information of a device a head-up display (HUD), a processor configured to generate a first image including a directional characteristic corresponding to an object included in the image, generate a second image in which the object is projected, based on the localization information, on to map data corresponding to a location of the object, update the localization information based on visual alignment between the first image and the second image, and display the object and the input image on to the map data based on the adjusted localization information in the HUD for an augmented reality (AR) service.</div>
    </li> <li> <para-num num="[0037]"> </para-num> <div id="p-0038" num="0037" class="description-line">Other features and aspects will be apparent from the following detailed description, the drawings, and the claims.</div>
    
    
    </li> <description-of-drawings>
      <heading id="h-0006">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
      <li> <para-num num="[0038]"> </para-num> <div id="p-0039" num="0038" class="description-line"> <figref idrefs="DRAWINGS">FIGS. 1A, 1B, and 1C</figref> illustrate examples of a visual alignment result corresponding to a localization error.</div>
      </li> <li> <para-num num="[0039]"> </para-num> <div id="p-0040" num="0039" class="description-line"> <figref idrefs="DRAWINGS">FIG. 2</figref> is a diagram illustrating an example of a localization method.</div>
      </li> <li> <para-num num="[0040]"> </para-num> <div id="p-0041" num="0040" class="description-line"> <figref idrefs="DRAWINGS">FIG. 3</figref> illustrates an example of a localization method.</div>
      </li> <li> <para-num num="[0041]"> </para-num> <div id="p-0042" num="0041" class="description-line"> <figref idrefs="DRAWINGS">FIG. 4</figref> illustrates an example of a localization process.</div>
      </li> <li> <para-num num="[0042]"> </para-num> <div id="p-0043" num="0042" class="description-line"> <figref idrefs="DRAWINGS">FIG. 5</figref> illustrates an example of a process of generating a first image.</div>
      </li> <li> <para-num num="[0043]"> </para-num> <div id="p-0044" num="0043" class="description-line"> <figref idrefs="DRAWINGS">FIG. 6</figref> illustrates an example of a method of modifying localization information.</div>
      </li> <li> <para-num num="[0044]"> </para-num> <div id="p-0045" num="0044" class="description-line"> <figref idrefs="DRAWINGS">FIGS. 7A and 7B</figref> illustrate examples of a method of modifying localization information.</div>
      </li> <li> <para-num num="[0045]"> </para-num> <div id="p-0046" num="0045" class="description-line"> <figref idrefs="DRAWINGS">FIG. 8</figref> is a diagram illustrating an example of a learning method.</div>
      </li> <li> <para-num num="[0046]"> </para-num> <div id="p-0047" num="0046" class="description-line"> <figref idrefs="DRAWINGS">FIG. 9</figref> illustrates an example of a learning process.</div>
      </li> <li> <para-num num="[0047]"> </para-num> <div id="p-0048" num="0047" class="description-line"> <figref idrefs="DRAWINGS">FIG. 10</figref> illustrates an example of images for learning.</div>
      </li> <li> <para-num num="[0048]"> </para-num> <div id="p-0049" num="0048" class="description-line"> <figref idrefs="DRAWINGS">FIG. 11</figref> illustrates an example of a learning method.</div>
      </li> <li> <para-num num="[0049]"> </para-num> <div id="p-0050" num="0049" class="description-line"> <figref idrefs="DRAWINGS">FIG. 12</figref> illustrates an example of a localization updating process of <figref idrefs="DRAWINGS">FIG. 11</figref>.</div>
      </li> <li> <para-num num="[0050]"> </para-num> <div id="p-0051" num="0050" class="description-line"> <figref idrefs="DRAWINGS">FIG. 13</figref> is a diagram illustrating an example of a localization method.</div>
      </li> <li> <para-num num="[0051]"> </para-num> <div id="p-0052" num="0051" class="description-line"> <figref idrefs="DRAWINGS">FIG. 14</figref> is a diagram illustrating an example of a localization apparatus.</div>
    </li> </description-of-drawings>
    
    
    <li> <para-num num="[0052]"> </para-num> <div id="p-0053" num="0052" class="description-line">Throughout the drawings and the detailed description, unless otherwise described or provided, the same drawing reference numerals will be understood to refer to the same elements, features, and structures. The drawings may not be to scale, and the relative size, proportions, and depiction of elements in the drawings may be exaggerated for clarity, illustration, and convenience.</div>
    </li> <heading id="h-0007">DETAILED DESCRIPTION</heading>
    <li> <para-num num="[0053]"> </para-num> <div id="p-0054" num="0053" class="description-line">The following detailed description is provided to assist the reader in gaining a comprehensive understanding of the methods, apparatuses, and/or systems described herein. However, various changes, modifications, and equivalents of the methods, apparatuses, and/or systems described herein will be apparent after an understanding of the disclosure of this application. For example, the sequences of operations described herein are merely examples, and are not limited to those set forth herein, but may be changed as will be apparent after an understanding of the disclosure of this application, with the exception of operations necessarily occurring in a certain order. Also, descriptions of features that are known in the art may be omitted for increased clarity and conciseness.</div>
    </li> <li> <para-num num="[0054]"> </para-num> <div id="p-0055" num="0054" class="description-line">The features described herein may be embodied in different forms and are not to be construed as being limited to the examples described herein. Rather, the examples described herein have been provided merely to illustrate some of the many possible ways of implementing the methods, apparatuses, and/or systems described herein that will be apparent after an understanding of the disclosure of this application.</div>
    </li> <li> <para-num num="[0055]"> </para-num> <div id="p-0056" num="0055" class="description-line">Although terms such as first, second, third A, B, (a), and (b) may be used herein to describe various members, components, regions, layers, or sections, these members, components, regions, layers, or sections are not to be limited by these terms. Rather, these terms are only used to distinguish one member, component, region, layer, or section from another member, component, region, layer, or section. Thus, a first member, component, region, layer, or section referred to in examples described herein may also be referred to as a second member, component, region, layer, or section without departing from the teachings of the examples.</div>
    </li> <li> <para-num num="[0056]"> </para-num> <div id="p-0057" num="0056" class="description-line">If the specification states that one component is connected, coupled, or joined to a second component, the first component may be directly connected, coupled, or joined to the second component, or a third component may be connected, coupled, or joined between the first component and the second component. However, if the specification states that a first component is directly connected or directly joined to a second component, a third component may not be connected or joined between the first component and the second component. Similar expressions, for example, between and immediately between and adjacent to and immediately adjacent to, are also to be construed in this manner.</div>
    </li> <li> <para-num num="[0057]"> </para-num> <div id="p-0058" num="0057" class="description-line">The terminology used herein is for the purpose of describing particular examples only, and is not intended to limit the disclosure or claims. The singular forms a, an, and the include the plural forms as well, unless the context clearly indicates otherwise. The terms comprises, comprising, includes, and including specify the presence of stated features, numbers, operations, elements, components, or combinations thereof, but do not preclude the presence or addition of one or more other features, numbers, operations, elements, components, or combinations thereof.</div>
    </li> <li> <para-num num="[0058]"> </para-num> <div id="p-0059" num="0058" class="description-line">The use of the term may herein with respect to an example or embodiment, e.g., as to what an example or embodiment may include or implement, means that at least one example or embodiment exists where such a feature is included or implemented while all examples and embodiments are not limited thereto.</div>
    </li> <li> <para-num num="[0059]"> </para-num> <div id="p-0060" num="0059" class="description-line">Hereinafter, the example embodiments are described with reference to the accompanying drawings. Like reference numerals used herein may refer to like elements throughout.</div>
    </li> <li> <para-num num="[0060]"> </para-num> <div id="p-0061" num="0060" class="description-line"> <figref idrefs="DRAWINGS">FIGS. 1A, 1B, and 10</figref> illustrate examples of a visual alignment result corresponding to a localization error.</div>
    </li> <li> <para-num num="[0061]"> </para-num> <div id="p-0062" num="0061" class="description-line">Augmented reality (AR) refers to adding or augmenting information based on reality to images and providing the added or augmented information. For example, the AR may provide an image in which a virtual object corresponding to a virtual image is added to an image or a background image of a real world. Since the real world and the virtual world are harmonized in the AR, a user may experience sense of immersion that enables real-time interaction between the user and the virtual world, without recognizing that a virtual environment is distinct from a real environment. To match the virtual object with a real image, a location and a pose, i.e., localization information of a user device or the user to which the AR is to be provided should be verified.</div>
    </li> <li> <para-num num="[0062]"> </para-num> <div id="p-0063" num="0062" class="description-line">The localization information is used to locate a virtual object at a desired location in an image. In AR, a degree of visual alignment when projecting the virtual object onto a two-dimensional (2D) image is more important than an error occurring on an actual three-dimensional (3D) space or an error occurring in feature matching. The degree of visual alignment corresponds to, for example, an overlapping ratio or a matching ratio between the virtual object and the real image. The degree of visual alignment varies based on a localization error as shown in <figref idrefs="DRAWINGS">FIGS. 1A and 1B</figref>. Hereinafter, an example of displaying a driving guide lane corresponding to a virtual object on a road surface is described as an example.</div>
    </li> <li> <para-num num="[0063]"> </para-num> <div id="p-0064" num="0063" class="description-line">In the following description, the examples described herein may be used to generate information to support a driver or to control an autonomous vehicle. The examples described herein may also be used to interpret visual information in a device, such as, for example, an intelligent system installed for fully autonomous driving or driving assistance in a vehicle, and used to assist safe and comfortable driving. The examples described herein may be applicable to vehicles and vehicle management systems such as, for example, an autonomous vehicle, an automatic or autonomous driving system, an intelligent vehicle, an advanced driver assistance system (ADAS), a navigation system to assist a vehicle with safely maintaining a lane on which the vehicle is travelling, a smartphone, or a mobile device. The examples related to displaying a driving guide lane corresponding to a virtual object is provided as an example only, and other examples such as, for example, training, gaming, applications in healthcare, public safety, tourism, and marketing are considered to be well within the scope of the present disclosure.</div>
    </li> <li> <para-num num="[0064]"> </para-num> <div id="p-0065" num="0064" class="description-line">Referring to <figref idrefs="DRAWINGS">FIG. 1A</figref>, an <figure-callout id="120" label="AR image" filenames="US20210287438A1-20210916-D00001.png" state="{{state}}">AR image</figure-callout> <b>120</b> is based on a visual alignment result when a localization error is small. Referring to <figref idrefs="DRAWINGS">FIG. 1B</figref>, an <figure-callout id="140" label="AR image" filenames="US20210287438A1-20210916-D00001.png" state="{{state}}">AR image</figure-callout> <b>140</b> is based on a visual alignment result when the localization error is large.</div>
    </li> <li> <para-num num="[0065]"> </para-num> <div id="p-0066" num="0065" class="description-line">For example, a reference path of a vehicle is displayed on a road image based on localization information of an <figure-callout id="110" label="object" filenames="US20210287438A1-20210916-D00001.png" state="{{state}}">object</figure-callout> <b>110</b>. In an example, the <figure-callout id="110" label="object" filenames="US20210287438A1-20210916-D00001.png" state="{{state}}">object</figure-callout> <b>110</b> corresponds to a user terminal and/or the vehicle that performs localization. When a localization error of the <figure-callout id="110" label="object" filenames="US20210287438A1-20210916-D00001.png" state="{{state}}">object</figure-callout> <b>110</b> is small, a driving <figure-callout id="115" label="guide lane" filenames="US20210287438A1-20210916-D00001.png" state="{{state}}">guide lane</figure-callout> <b>115</b>, i. e., a virtual object to be displayed, may be visually well aligned with an actual road image as shown in the <figure-callout id="120" label="AR image" filenames="US20210287438A1-20210916-D00001.png" state="{{state}}">AR image</figure-callout> <b>120</b>. When a localization error of an <figure-callout id="130" label="object" filenames="US20210287438A1-20210916-D00001.png" state="{{state}}">object</figure-callout> <b>130</b> is large, a driving <figure-callout id="135" label="guide lane" filenames="US20210287438A1-20210916-D00001.png" state="{{state}}">guide lane</figure-callout> <b>135</b> that is a virtual object to be displayed may not be visually aligned with an actual road image as shown in the <figure-callout id="140" label="AR image" filenames="US20210287438A1-20210916-D00001.png" state="{{state}}">AR image</figure-callout> <b>140</b>.</div>
    </li> <li> <para-num num="[0066]"> </para-num> <div id="p-0067" num="0066" class="description-line">In an example, an accurate AR service may be provided by optimizing localization information to increase a degree of visual alignment when projecting a virtual object onto a two-dimensional (2D) image.</div>
    </li> <li> <para-num num="[0067]"> </para-num> <div id="p-0068" num="0067" class="description-line">Referring to <figref idrefs="DRAWINGS">FIG. 10</figref>, localization information includes a location and a pose of an apparatus. The location corresponds to 3D coordinates (x, y, z). Here, x coordinate denotes a lateral location t<sub>x</sub>, y coordinate denotes a vertical location t<sub>y</sub>, and z coordinate denotes a longitudinal location t<sub>z</sub>. Also, the pose corresponds to pitch r<sub>x</sub>, yaw r<sub>y</sub>, and roll r<sub>z</sub>. For example, the location is acquired using, for example, a geographical positioning system (GPS) sensor and a lidar, and the pose is acquired using, for example, an inertial measurement unit (IMU) sensor and a gyro sensor. The localization information may be understood to include 6 degrees of freedom (6DoF) that includes the location and the pose.</div>
    </li> <li> <para-num num="[0068]"> </para-num> <div id="p-0069" num="0068" class="description-line">In an example, the vehicle described herein refers to any mode of transportation, delivery, or communication such as, for example, an automobile, a truck, a tractor, a scooter, a motorcycle, a cycle, an amphibious vehicle, a snowmobile, a boat, a public transit vehicle, a bus, a monorail, a train, a tram, an autonomous or automated driving vehicle, an intelligent vehicle, a self-driving vehicle, an unmanned aerial vehicle, an electric vehicle (EV), a hybrid vehicle, a smart mobility device, a ADAS, or a drone. In an example, the smart mobility device includes mobility devices such as, for example, electric wheels, an electric kickboard, and an electric bike. In an example, vehicles include motorized and non-motorized vehicles, for example, a vehicle with a power engine (for example, a cultivator or a motorcycle), a bicycle or a handcart.</div>
    </li> <li> <para-num num="[0069]"> </para-num> <div id="p-0070" num="0069" class="description-line">The term road is a thoroughfare, route, or connection, between two places that has been improved to allow travel by foot or some form of conveyance, such as a vehicle. A road can include various types of roads such as, for example, highways, national roads, farm roads, local roads, or high-speed national roads. A road may include a single lane or a plurality of lanes. Lanes correspond to road spaces that are distinguished from each other by road lines marked on a surface of a road. In an example, a lane is a space of a plane on which a vehicle is traveling among a plurality of lanes, i.e., as a space occupied and used by the vehicle. One lane is distinguished from the other lanes by right and left markings of the lane.</div>
    </li> <li> <para-num num="[0070]"> </para-num> <div id="p-0071" num="0070" class="description-line">Also, the term line may be understood as various types of lines, for example, a solid line, a dotted line, a curved line, and a zigzagged line, which are marked in colors such as, white, blue, or yellow on the road surface. The line may correspond to a line on one side that distinguishes a single lane and may also be a pair of lines, that is, a left lane and a right lane corresponding to a lane boundary line that distinguishes a single lane a center line of road, and a stop line. In addition, a line may indicate an area prohibited for parking and stopping, a crosswalk, a towaway zone, and indication of speed limit.</div>
    </li> <li> <para-num num="[0071]"> </para-num> <div id="p-0072" num="0071" class="description-line">The following examples may be applied for an AR navigation device in a smart vehicle, for example. In an example, the AR navigation device is used to mark a line, to generate visual information to help steering of an autonomous driving vehicle, or to provide a variety of control information for driving of a vehicle. The AR navigation device may provide visual information to a display. In an example, the display is a head-up display (HUD), a vehicular infotainment system, a dashboard in a vehicle, or a screen in the vehicle that used augmented reality. The display is installed for driving assistance or complete autonomous driving of a vehicle and to assist safe and pleasant driving. In an example, the display may also be implemented as an eye glass display (EGD), which includes one-eyed glass or two-eyed glasses.</div>
    </li> <li> <para-num num="[0072]"> </para-num> <div id="p-0073" num="0072" class="description-line"> <figref idrefs="DRAWINGS">FIG. 2</figref> is a diagram illustrating an example of a localization method. The operations in <figref idrefs="DRAWINGS">FIG. 2</figref> may be performed in the sequence and manner as shown, although the order of some operations may be changed or some of the operations omitted without departing from the spirit and scope of the illustrative examples described. Many of the operations shown in <figref idrefs="DRAWINGS">FIG. 2</figref> may be performed in parallel or concurrently. One or more blocks of <figref idrefs="DRAWINGS">FIG. 2</figref>, and combinations of the blocks, can be implemented by special purpose hardware-based computer that perform the specified functions, or combinations of special purpose hardware and computer instructions. In addition to the description of <figref idrefs="DRAWINGS">FIG. 2</figref> below, the descriptions of <figref idrefs="DRAWINGS">FIG. 1</figref> are also applicable to <figref idrefs="DRAWINGS">FIG. 2</figref>, and are incorporated herein by reference. Thus, the above description may not be repeated here.</div>
    </li> <li> <para-num num="[0073]"> </para-num> <div id="p-0074" num="0073" class="description-line">Referring to <figref idrefs="DRAWINGS">FIG. 2</figref>, in <figure-callout id="210" label="operation" filenames="US20210287438A1-20210916-D00002.png" state="{{state}}">operation</figure-callout> <b>210</b>, a localization apparatus acquires localization information of a corresponding apparatus. Here, the apparatus refers to an apparatus that performs the localization method, such as, for example, a vehicle, a navigation device, and a user device such as a smartphone. The localization information may have 6DoF that includes a location and a pose of the apparatus. The localization information is acquired based on output of a sensor, such as, for example, an IMU sensor, a GPS sensor, a lidar sensor, and a radar. The localization information may be, for example, initial localization information of the localization apparatus.</div>
    </li> <li> <para-num num="[0074]"> </para-num> <div id="p-0075" num="0074" class="description-line">In <figure-callout id="220" label="operation" filenames="US20210287438A1-20210916-D00002.png" state="{{state}}">operation</figure-callout> <b>220</b>, the localization apparatus generates a first image that includes a directional characteristic corresponding to an object included in an input image. The input image may correspond to a background image or another image that is displayed with a virtual object for an AR service. For example, the input image includes a driving image of the vehicle. The driving image may be captured from, for example, a photographing device mounted to the vehicle. In an example, the driving image includes a plurality of frames. The localization apparatus acquires the input image based on output of the photographing device. The photographing device is fastened at a location, such as, a for example, a windshield, a dashboard, a front fender, and a rear-view mirror, to capture an image ahead of the vehicle. The photographing device may include, for example, a vision sensor, an image sensor, or a device that performs a similar function. The photographing device may capture a single image or may capture an image per frame if needed. In another example, the driving image may be captured from another apparatus, aside from the localization apparatus. The driving image may be an <figure-callout id="410" label="input image" filenames="US20210287438A1-20210916-D00004.png" state="{{state}}">input image</figure-callout> <b>410</b> of <figref idrefs="DRAWINGS">FIG. 4</figref>. In one example, objects include a line, a road surface marking, a traffic light, a sign, a curb stone, a pedestrian, other vehicles, and a structure.</div>
    </li> <li> <para-num num="[0075]"> </para-num> <div id="p-0076" num="0075" class="description-line">In <figure-callout id="220" label="operation" filenames="US20210287438A1-20210916-D00002.png" state="{{state}}">operation</figure-callout> <b>220</b>, the localization apparatus generates a probability map, for example, a distance field map, indicating directional characteristic using a pretrained neural network. In an example, directional characteristic corresponding to an object may correspond to a probability distribution indicating a degree of closeness to the object. Here, each of pixels included in the probability map stores a distance from the corresponding pixel to a seed pixel closest. The seed pixel may be a pixel corresponding to the object among pixels included in an image. The first image may be, for example, a <figure-callout id="550" label="distance field map" filenames="US20210287438A1-20210916-D00005.png" state="{{state}}">distance field map</figure-callout> <b>550</b> of <figref idrefs="DRAWINGS">FIG. 5</figref>. A method of generating the probability map using the localization apparatus will be further described with reference to <figref idrefs="DRAWINGS">FIG. 5</figref>.</div>
    </li> <li> <para-num num="[0076]"> </para-num> <div id="p-0077" num="0076" class="description-line">In <figure-callout id="230" label="operation" filenames="US20210287438A1-20210916-D00002.png" state="{{state}}">operation</figure-callout> <b>230</b>, the localization apparatus generates a second image in which the object is projected according to the localization information based on map data including a location of the object. In an example, the map data is high-density (HD) map data. An HD map refers to a three-dimensional (3D) map having high density, for example, centimeter-based density, for autonomous driving. Line-based information, for example, a center line of road and a boundary line, and information, for example, a traffic light, a sign, a curb stone, a road surface marking, and various structures, may be included in the HD map in a 3D digital format. The HD map may be built using, for example, a mobile mapping system (MMS). The MMS refers to a 3D spatial information investigation system including various sensors, and may include a moving object with a sensor, such as, for example, a camera, a lidar, and a GPS for measurement of a location and geographical features. Sensors of the MMS interact with each other flexibly and acquire various and precise location information.</div>
    </li> <li> <para-num num="[0077]"> </para-num> <div id="p-0078" num="0077" class="description-line">In <figure-callout id="230" label="operation" filenames="US20210287438A1-20210916-D00002.png" state="{{state}}">operation</figure-callout> <b>230</b>, generating the second image in which the object is projected according to the localization information based on the map data means, for example, that the localization apparatus places a virtual camera at a location included in the localization information, on the map data, adjusts a pose of the virtual camera based on a pose included in the localization information, and generates an image of a viewpoint at which the object is viewed from the virtual camera.</div>
    </li> <li> <para-num num="[0078]"> </para-num> <div id="p-0079" num="0078" class="description-line">In <figure-callout id="230" label="operation" filenames="US20210287438A1-20210916-D00002.png" state="{{state}}">operation</figure-callout> <b>230</b>, the localization information generates the second image using, for example, a transformer that transforms a coordinate system of map data to a coordinate system of the second image. Here, the transformer may be, for example, a homographic function representing a transformation relationship between corresponding points when projecting one plane onto another plane or an artificial neural network that performs the transformation. The localization apparatus extracts partial data from the map data based on the localization information and generates the second image from the extracted partial data using the transformer. The second image may be, for example, a <figure-callout id="430" label="second image" filenames="US20210287438A1-20210916-D00004.png" state="{{state}}">second image</figure-callout> <b>430</b> of <figref idrefs="DRAWINGS">FIG. 4</figref>.</div>
    </li> <li> <para-num num="[0079]"> </para-num> <div id="p-0080" num="0079" class="description-line">In <figure-callout id="240" label="operation" filenames="US20210287438A1-20210916-D00002.png" state="{{state}}">operation</figure-callout> <b>240</b>, the localization apparatus modifies or adjusts the localization information based on visual alignment between the first image and the second image. The localization apparatus calculates a degree of the visual alignment by matching the first image and the second image. For example, the localization apparatus adds up values of pixels corresponding to an object included in the second image among a plurality of pixels included in the first image and determines a result of the addition as the degree of visual alignment. The degree of visual alignment may be represented in, for example, a gradient descent form. In an example, the localization apparatus modifies the localization information to increase the degree of visual alignment based on the directional characteristic corresponding to the object. The localization apparatus modifies the localization information to transform, for example, move or rotate, the object included in the second image based on the directional characteristic. A method of modifying, by the localization apparatus, the localization information will be further described with reference to <figref idrefs="DRAWINGS">FIG. 6</figref>.</div>
    </li> <li> <para-num num="[0080]"> </para-num> <div id="p-0081" num="0080" class="description-line">The localization apparatus determines the virtual object on the map data for the AR service. For example, the virtual object may represent driving route information using an arrow indicator or a road marking indicating a direction of progress. The localization apparatus may display the virtual object and the input image on, for example, a head-up display (HUD), a navigation system, or a display of a user device based on the localization information modified in <figure-callout id="240" label="operation" filenames="US20210287438A1-20210916-D00002.png" state="{{state}}">operation</figure-callout> <b>240</b>.</div>
    </li> <li> <para-num num="[0081]"> </para-num> <div id="p-0082" num="0081" class="description-line"> <figref idrefs="DRAWINGS">FIG. 3</figref> illustrates an example of a localization method, and <figref idrefs="DRAWINGS">FIG. 4</figref> illustrates an example of describing a localization process. The operations in <figref idrefs="DRAWINGS">FIGS. 3-4</figref> may be performed in the sequence and manner as shown, although the order of some operations may be changed or some of the operations omitted without departing from the spirit and scope of the illustrative examples described. Many of the operations shown in <figref idrefs="DRAWINGS">FIGS. 3-4</figref> may be performed in parallel or concurrently. One or more blocks of <figref idrefs="DRAWINGS">FIGS. 3-4</figref>, and combinations of the blocks, can be implemented by special purpose hardware-based computer that perform the specified functions, or combinations of special purpose hardware and computer instructions. In addition to the description of <figref idrefs="DRAWINGS">FIGS. 3-4</figref> below, the descriptions of <figref idrefs="DRAWINGS">FIGS. 1-2</figref> are also applicable to <figref idrefs="DRAWINGS">FIGS. 3-4</figref>, and are incorporated herein by reference. Thus, the above description may not be repeated here.</div>
    </li> <li> <para-num num="[0082]"> </para-num> <div id="p-0083" num="0082" class="description-line">Referring to <figref idrefs="DRAWINGS">FIGS. 3 and 4</figref>, in <figure-callout id="310" label="operation" filenames="US20210287438A1-20210916-D00003.png" state="{{state}}">operation</figure-callout> <b>310</b>, the localization apparatus acquires the <figure-callout id="410" label="input image" filenames="US20210287438A1-20210916-D00004.png" state="{{state}}">input image</figure-callout> <b>410</b>. For example, the localization apparatus receives the <figure-callout id="410" label="input image" filenames="US20210287438A1-20210916-D00004.png" state="{{state}}">input image</figure-callout> <b>410</b> generated by capturing an object using an image sensor. Here, the <figure-callout id="410" label="input image" filenames="US20210287438A1-20210916-D00004.png" state="{{state}}">input image</figure-callout> <b>410</b> may be an image corresponding to a current location of an apparatus.</div>
    </li> <li> <para-num num="[0083]"> </para-num> <div id="p-0084" num="0083" class="description-line">In <figure-callout id="320" label="operation" filenames="US20210287438A1-20210916-D00003.png" state="{{state}}">operation</figure-callout> <b>320</b>, the localization apparatus receives or acquires map data that includes a location of the object.</div>
    </li> <li> <para-num num="[0084]"> </para-num> <div id="p-0085" num="0084" class="description-line">In <figure-callout id="330" label="operation" filenames="US20210287438A1-20210916-D00003.png" state="{{state}}">operation</figure-callout> <b>330</b>, the localization apparatus estimates the object from the <figure-callout id="410" label="input image" filenames="US20210287438A1-20210916-D00004.png" state="{{state}}">input image</figure-callout> <b>410</b> acquired in <figure-callout id="310" label="operation" filenames="US20210287438A1-20210916-D00003.png" state="{{state}}">operation</figure-callout> <b>310</b>. The localization apparatus may generate a <figure-callout id="420" label="first image" filenames="US20210287438A1-20210916-D00004.png" state="{{state}}">first image</figure-callout> <b>420</b> that includes a directional characteristic corresponding to the object based on the <figure-callout id="410" label="input image" filenames="US20210287438A1-20210916-D00004.png" state="{{state}}">input image</figure-callout> <b>410</b>. In an example, the localization apparatus generates the <figure-callout id="420" label="first image" filenames="US20210287438A1-20210916-D00004.png" state="{{state}}">first image</figure-callout> <b>420</b> using a pretrained neural network. The localization apparatus may use the pretrained neural network to stably estimate the object regardless of various obstacles, such as, for example, a vehicle, a pedestrian, and a street tree, in the <figure-callout id="410" label="input image" filenames="US20210287438A1-20210916-D00004.png" state="{{state}}">input image</figure-callout> <b>410</b>. For example, when the <figure-callout id="410" label="input image" filenames="US20210287438A1-20210916-D00004.png" state="{{state}}">input image</figure-callout> <b>410</b> is applied, the pretrained neural network generates the <figure-callout id="420" label="first image" filenames="US20210287438A1-20210916-D00004.png" state="{{state}}">first image</figure-callout> <b>420</b> by activating a portion corresponding to a line in the applied <figure-callout id="410" label="input image" filenames="US20210287438A1-20210916-D00004.png" state="{{state}}">input image</figure-callout> <b>410</b>. The <figure-callout id="420" label="first image" filenames="US20210287438A1-20210916-D00004.png" state="{{state}}">first image</figure-callout> <b>420</b> may include, for example, a 2D distance field map.</div>
    </li> <li> <para-num num="[0085]"> </para-num> <div id="p-0086" num="0085" class="description-line">In <figure-callout id="340" label="operation" filenames="US20210287438A1-20210916-D00003.png" state="{{state}}">operation</figure-callout> <b>340</b>, the localization apparatus performs initial localization. In <figure-callout id="350" label="operation" filenames="US20210287438A1-20210916-D00003.png" state="{{state}}">operation</figure-callout> <b>350</b>, the localization apparatus generates the <figure-callout id="430" label="second image" filenames="US20210287438A1-20210916-D00004.png" state="{{state}}">second image</figure-callout> <b>430</b> in which the object is projected based on the initial localization by applying localization information corresponding to the initial localization on the map data that is acquired in <figure-callout id="320" label="operation" filenames="US20210287438A1-20210916-D00003.png" state="{{state}}">operation</figure-callout> <b>320</b>.</div>
    </li> <li> <para-num num="[0086]"> </para-num> <div id="p-0087" num="0086" class="description-line">The localization apparatus performs visual alignment on the <figure-callout id="420" label="first image" filenames="US20210287438A1-20210916-D00004.png" state="{{state}}">first image</figure-callout> <b>420</b> and the <figure-callout id="430" label="second image" filenames="US20210287438A1-20210916-D00004.png" state="{{state}}">second image</figure-callout> <b>430</b>. The localization apparatus visually aligns the <figure-callout id="420" label="first image" filenames="US20210287438A1-20210916-D00004.png" state="{{state}}">first image</figure-callout> <b>420</b> and the <figure-callout id="430" label="second image" filenames="US20210287438A1-20210916-D00004.png" state="{{state}}">second image</figure-callout> <b>430</b>, as shown in an <figure-callout id="440" label="image" filenames="US20210287438A1-20210916-D00004.png" state="{{state}}">image</figure-callout> <b>440</b>.</div>
    </li> <li> <para-num num="[0087]"> </para-num> <div id="p-0088" num="0087" class="description-line">In <figure-callout id="360" label="operation" filenames="US20210287438A1-20210916-D00003.png" state="{{state}}">operation</figure-callout> <b>360</b>, the localization apparatus optimizes the visual alignment. The localization apparatus calculates a localization modification value so that the <figure-callout id="420" label="first image" filenames="US20210287438A1-20210916-D00004.png" state="{{state}}">first image</figure-callout> <b>420</b> and the <figure-callout id="430" label="second image" filenames="US20210287438A1-20210916-D00004.png" state="{{state}}">second image</figure-callout> <b>430</b> may maximally overlap through the visual alignment. The localization apparatus may optimize the visual alignment by changing the localization information to maximize overlapping between the <figure-callout id="420" label="first image" filenames="US20210287438A1-20210916-D00004.png" state="{{state}}">first image</figure-callout> <b>420</b> and the <figure-callout id="430" label="second image" filenames="US20210287438A1-20210916-D00004.png" state="{{state}}">second image</figure-callout> <b>430</b> based on the initial localization performed in <figure-callout id="340" label="operation" filenames="US20210287438A1-20210916-D00003.png" state="{{state}}">operation</figure-callout> <b>340</b>. In one example, gradient-based optimization may be readily performed using the <figure-callout id="420" label="first image" filenames="US20210287438A1-20210916-D00004.png" state="{{state}}">first image</figure-callout> <b>420</b> in which information is spread over the entire image, i.e., the distance field map.</div>
    </li> <li> <para-num num="[0088]"> </para-num> <div id="p-0089" num="0088" class="description-line">In <figure-callout id="370" label="operation" filenames="US20210287438A1-20210916-D00003.png" state="{{state}}">operation</figure-callout> <b>370</b>, the localization apparatus applies the localization modification value to the localization information and updates the localization information to optimize the visual alignment between the <figure-callout id="420" label="first image" filenames="US20210287438A1-20210916-D00004.png" state="{{state}}">first image</figure-callout> <b>420</b> and the <figure-callout id="430" label="second image" filenames="US20210287438A1-20210916-D00004.png" state="{{state}}">second image</figure-callout> <b>430</b>, as shown in an <figure-callout id="450" label="image" filenames="US20210287438A1-20210916-D00004.png" state="{{state}}">image</figure-callout> <b>450</b>.</div>
    </li> <li> <para-num num="[0089]"> </para-num> <div id="p-0090" num="0089" class="description-line"> <figref idrefs="DRAWINGS">FIG. 5</figref> illustrates an example of describing a process of generating a first image. A process of applying an <figure-callout id="510" label="input image" filenames="US20210287438A1-20210916-D00005.png" state="{{state}}">input image</figure-callout> <b>510</b> to a <figure-callout id="530" label="neural network" filenames="US20210287438A1-20210916-D00005.png" state="{{state}}">neural network</figure-callout> <b>530</b> and generating a <figure-callout id="550" label="distance field map" filenames="US20210287438A1-20210916-D00005.png" state="{{state}}">distance field map</figure-callout> <b>550</b> corresponding to a first image will be described with reference to <figref idrefs="DRAWINGS">FIG. 5</figref>.</div>
    </li> <li> <para-num num="[0090]"> </para-num> <div id="p-0091" num="0090" class="description-line">The <figure-callout id="530" label="neural network" filenames="US20210287438A1-20210916-D00005.png" state="{{state}}">neural network</figure-callout> <b>530</b> refers to a neural network that is pretrained to generate a first image including a directional characteristic corresponding to an object included in the <figure-callout id="510" label="input image" filenames="US20210287438A1-20210916-D00005.png" state="{{state}}">input image</figure-callout> <b>510</b>, based on the <figure-callout id="510" label="input image" filenames="US20210287438A1-20210916-D00005.png" state="{{state}}">input image</figure-callout> <b>510</b>. The <figure-callout id="530" label="neural network" filenames="US20210287438A1-20210916-D00005.png" state="{{state}}">neural network</figure-callout> <b>530</b> may be a deep neural network (DNN) or an n-layer neural network. The DNN or n-layer neural network may correspond to a convolutional neural network (CNN), a recurrent neural network (RNN), a deep belief network, a fully connected network, a bi-directional neural network, a restricted Boltzman machine, and a bidirectional long short term memory (BLSTM), or may include different or overlapping neural network portions respectively with full, convolutional, recurrent, and/or bi-directional connections. For example, the neural network <b>53</b>may be embodied as a CNN, but is not limited thereto.</div>
    </li> <li> <para-num num="[0091]"> </para-num> <div id="p-0092" num="0091" class="description-line">The <figure-callout id="530" label="neural network" filenames="US20210287438A1-20210916-D00005.png" state="{{state}}">neural network</figure-callout> <b>530</b> may be embodied as an architecture having a plurality of layers including an input image, feature maps, and an output. In the <figure-callout id="530" label="neural network" filenames="US20210287438A1-20210916-D00005.png" state="{{state}}">neural network</figure-callout> <b>530</b>, a convolution operation is performed on the input image with a filter referred to as a kernel, and as a result, the feature maps are output. The convolution operation is performed again on the output feature maps as input feature maps, with a kernel, and new feature maps are output. When the convolution operation is repeatedly performed as such, a recognition result with respect to features of the input image may be finally output through the <figure-callout id="530" label="neural network" filenames="US20210287438A1-20210916-D00005.png" state="{{state}}">neural network</figure-callout> <b>530</b>. In an example, in addition to the convolution layers, the <figure-callout id="530" label="neural network" filenames="US20210287438A1-20210916-D00005.png" state="{{state}}">neural network</figure-callout> <b>530</b> may include a pooling layer or a fully connected layer.</div>
    </li> <li> <para-num num="[0092]"> </para-num> <div id="p-0093" num="0092" class="description-line">The <figure-callout id="530" label="neural network" filenames="US20210287438A1-20210916-D00005.png" state="{{state}}">neural network</figure-callout> <b>530</b> estimates the object included in the <figure-callout id="510" label="input image" filenames="US20210287438A1-20210916-D00005.png" state="{{state}}">input image</figure-callout> <b>510</b> based on a form of the <figure-callout id="550" label="distance field map" filenames="US20210287438A1-20210916-D00005.png" state="{{state}}">distance field map</figure-callout> <b>550</b>. For example, when the first image includes directional characteristic information associated with a close object as in the <figure-callout id="550" label="distance field map" filenames="US20210287438A1-20210916-D00005.png" state="{{state}}">distance field map</figure-callout> <b>550</b>, a directional characteristic of optimization may be readily determined using a gradient descent scheme. When the probability distribution indicating a degree of closeness to the object is distributed over the overall image as in the <figure-callout id="550" label="distance field map" filenames="US20210287438A1-20210916-D00005.png" state="{{state}}">distance field map</figure-callout> <b>550</b>, an amount of data for learning may be increased. Performance of the <figure-callout id="530" label="neural network" filenames="US20210287438A1-20210916-D00005.png" state="{{state}}">neural network</figure-callout> <b>530</b> may be enhanced compared to learning by sparse data.</div>
    </li> <li> <para-num num="[0093]"> </para-num> <div id="p-0094" num="0093" class="description-line"> <figref idrefs="DRAWINGS">FIG. 6</figref> illustrates an example of describing a method of modifying localization information. <figref idrefs="DRAWINGS">FIG. 6</figref> illustrates an <figure-callout id="605" label="input image" filenames="US20210287438A1-20210916-D00006.png" state="{{state}}">input image</figure-callout> <b>605</b>, a <figure-callout id="610" label="first image" filenames="US20210287438A1-20210916-D00006.png" state="{{state}}">first image</figure-callout> <b>610</b>, and a <figure-callout id="620" label="second image" filenames="US20210287438A1-20210916-D00006.png" state="{{state}}">second image</figure-callout> <b>620</b>. The <figure-callout id="610" label="first image" filenames="US20210287438A1-20210916-D00006.png" state="{{state}}">first image</figure-callout> <b>610</b> is generated based on the <figure-callout id="605" label="input image" filenames="US20210287438A1-20210916-D00006.png" state="{{state}}">input image</figure-callout> <b>605</b>. The <figure-callout id="620" label="second image" filenames="US20210287438A1-20210916-D00006.png" state="{{state}}">second image</figure-callout> <b>620</b> is generated by projecting an object based on localization information (x, y, z, r<sub>x</sub>, r<sub>y</sub>, r<sub>z</sub>)<div class="patent-image small-patent-image"><a href="https://patentimages.storage.googleapis.com/2a/26/1c/b683b3a4e933e2/US20210287438A1-20210916-P00001.png"><img id="CUSTOM-CHARACTER-00001" he="3.22mm" wi="1.44mm" file="US20210287438A1-20210916-P00001.TIF" alt="Figure US20210287438A1-20210916-P00001" img-content="character" img-format="tif" orientation="portrait" inline="no" width="6" height="13" alt="Figure US20210287438A1-20210916-P00001" class="patent-full-image" src="https://patentimages.storage.googleapis.com/2a/26/1c/b683b3a4e933e2/US20210287438A1-20210916-P00001.png"/></a></div> corresponding to an initial localization, based on map data.</div>
    </li> <li> <para-num num="[0094]"> </para-num> <div id="p-0095" num="0094" class="description-line">The localization apparatus matches the <figure-callout id="610" label="first image" filenames="US20210287438A1-20210916-D00006.png" state="{{state}}">first image</figure-callout> <b>610</b> and the <figure-callout id="620" label="second image" filenames="US20210287438A1-20210916-D00006.png" state="{{state}}">second image</figure-callout> <b>620</b> to be an <figure-callout id="630" label="image" filenames="US20210287438A1-20210916-D00006.png" state="{{state}}">image</figure-callout> <b>630</b> and calculates a degree of visual alignment therebetween in a form of, for example, score <div class="patent-image small-patent-image"><a href="https://patentimages.storage.googleapis.com/2a/26/1c/b683b3a4e933e2/US20210287438A1-20210916-P00001.png"><img id="CUSTOM-CHARACTER-00002" he="3.22mm" wi="1.44mm" file="US20210287438A1-20210916-P00001.TIF" alt="Figure US20210287438A1-20210916-P00001" img-content="character" img-format="tif" orientation="portrait" inline="no" width="6" height="13" alt="Figure US20210287438A1-20210916-P00001" class="patent-full-image" src="https://patentimages.storage.googleapis.com/2a/26/1c/b683b3a4e933e2/US20210287438A1-20210916-P00001.png"/></a></div>. The localization apparatus adds up values of pixels corresponding to an object included in the <figure-callout id="620" label="second image" filenames="US20210287438A1-20210916-D00006.png" state="{{state}}">second image</figure-callout> <b>620</b> from among a plurality of pixels included in the <figure-callout id="610" label="first image" filenames="US20210287438A1-20210916-D00006.png" state="{{state}}">first image</figure-callout> <b>610</b> and calculates an addition result in the form of a score.</div>
    </li> <li> <para-num num="[0095]"> </para-num> <div id="p-0096" num="0095" class="description-line">For example, each of the plurality of pixels included in the <figure-callout id="610" label="first image" filenames="US20210287438A1-20210916-D00006.png" state="{{state}}">first image</figure-callout> <b>610</b> may have a value between 0 and 1 based on a distance from an object adjacent to the respective pixel. Each pixel may have a value close to 1 as the distance from the adjacent object decreases and may have a value close to 0 as the distance from the adjacent object increases. The localization apparatus extracts pixels that match the <figure-callout id="620" label="second image" filenames="US20210287438A1-20210916-D00006.png" state="{{state}}">second image</figure-callout> <b>620</b> from among the plurality of pixels included in the <figure-callout id="610" label="first image" filenames="US20210287438A1-20210916-D00006.png" state="{{state}}">first image</figure-callout> <b>610</b>, adds up values of the extracted pixels, and calculates a score.</div>
    </li> <li> <para-num num="[0096]"> </para-num> <div id="p-0097" num="0096" class="description-line">The localization apparatus modifies localization information to increase the degree of visual alignment, i.e., the score <div class="patent-image small-patent-image"><a href="https://patentimages.storage.googleapis.com/2a/26/1c/b683b3a4e933e2/US20210287438A1-20210916-P00001.png"><img id="CUSTOM-CHARACTER-00003" he="3.22mm" wi="1.44mm" file="US20210287438A1-20210916-P00001.TIF" alt="Figure US20210287438A1-20210916-P00001" img-content="character" img-format="tif" orientation="portrait" inline="no" width="6" height="13" alt="Figure US20210287438A1-20210916-P00001" class="patent-full-image" src="https://patentimages.storage.googleapis.com/2a/26/1c/b683b3a4e933e2/US20210287438A1-20210916-P00001.png"/></a></div> based on the directional characteristic of the <figure-callout id="610" label="first image" filenames="US20210287438A1-20210916-D00006.png" state="{{state}}">first image</figure-callout> <b>610</b>. The localization apparatus calculates a localization modification value so that the localization of the object included in the <figure-callout id="620" label="second image" filenames="US20210287438A1-20210916-D00006.png" state="{{state}}">second image</figure-callout> <b>620</b> fits the directional characteristic of the <figure-callout id="610" label="first image" filenames="US20210287438A1-20210916-D00006.png" state="{{state}}">first image</figure-callout> <b>610</b>. The localization apparatus updates the localization information to be <div class="patent-image small-patent-image"><a href="https://patentimages.storage.googleapis.com/6d/bd/8d/1b8df5a05c46f9/US20210287438A1-20210916-P00002.png"><img id="CUSTOM-CHARACTER-00004" he="3.22mm" wi="1.44mm" file="US20210287438A1-20210916-P00002.TIF" alt="Figure US20210287438A1-20210916-P00002" img-content="character" img-format="tif" orientation="portrait" inline="no" width="6" height="13" alt="Figure US20210287438A1-20210916-P00002" class="patent-full-image" src="https://patentimages.storage.googleapis.com/6d/bd/8d/1b8df5a05c46f9/US20210287438A1-20210916-P00002.png"/></a></div><div class="patent-image small-patent-image"><a href="https://patentimages.storage.googleapis.com/6d/bd/8d/1b8df5a05c46f9/US20210287438A1-20210916-P00002.png"><img id="CUSTOM-CHARACTER-00005" he="3.22mm" wi="1.44mm" file="US20210287438A1-20210916-P00002.TIF" alt="Figure US20210287438A1-20210916-P00002" img-content="character" img-format="tif" orientation="portrait" inline="no" width="6" height="13" alt="Figure US20210287438A1-20210916-P00002" class="patent-full-image" src="https://patentimages.storage.googleapis.com/6d/bd/8d/1b8df5a05c46f9/US20210287438A1-20210916-P00002.png"/></a></div> <b>640</b> by applying the localization modification value to the localization information corresponding to the initial localization. For example, the localization apparatus determines a direction in which the object of the <figure-callout id="620" label="second image" filenames="US20210287438A1-20210916-D00006.png" state="{{state}}">second image</figure-callout> <b>620</b> is to be moved to increase the score, based on the directional characteristic included in the <figure-callout id="610" label="first image" filenames="US20210287438A1-20210916-D00006.png" state="{{state}}">first image</figure-callout> <b>610</b>. Once the localization information is updated, the object of the <figure-callout id="620" label="second image" filenames="US20210287438A1-20210916-D00006.png" state="{{state}}">second image</figure-callout> <b>620</b> is moved. Thus, the localization apparatus updates the localization information based on the directional characteristic included in the <figure-callout id="610" label="first image" filenames="US20210287438A1-20210916-D00006.png" state="{{state}}">first image</figure-callout> <b>610</b>.</div>
    </li> <li> <para-num num="[0097]"> </para-num> <div id="p-0098" num="0097" class="description-line">The localization apparatus generates an updated <figure-callout id="650" label="second image" filenames="US20210287438A1-20210916-D00006.png" state="{{state}}">second image</figure-callout> <b>650</b> based on the updated localization information <div class="patent-image small-patent-image"><a href="https://patentimages.storage.googleapis.com/6d/bd/8d/1b8df5a05c46f9/US20210287438A1-20210916-P00002.png"><img id="CUSTOM-CHARACTER-00006" he="3.22mm" wi="1.44mm" file="US20210287438A1-20210916-P00002.TIF" alt="Figure US20210287438A1-20210916-P00002" img-content="character" img-format="tif" orientation="portrait" inline="no" width="6" height="13" alt="Figure US20210287438A1-20210916-P00002" class="patent-full-image" src="https://patentimages.storage.googleapis.com/6d/bd/8d/1b8df5a05c46f9/US20210287438A1-20210916-P00002.png"/></a></div>. The localization apparatus calculates a score <div class="patent-image small-patent-image"><a href="https://patentimages.storage.googleapis.com/6d/bd/8d/1b8df5a05c46f9/US20210287438A1-20210916-P00002.png"><img id="CUSTOM-CHARACTER-00007" he="3.22mm" wi="1.44mm" file="US20210287438A1-20210916-P00002.TIF" alt="Figure US20210287438A1-20210916-P00002" img-content="character" img-format="tif" orientation="portrait" inline="no" width="6" height="13" alt="Figure US20210287438A1-20210916-P00002" class="patent-full-image" src="https://patentimages.storage.googleapis.com/6d/bd/8d/1b8df5a05c46f9/US20210287438A1-20210916-P00002.png"/></a></div> by matching the updated <figure-callout id="650" label="second image" filenames="US20210287438A1-20210916-D00006.png" state="{{state}}">second image</figure-callout> <b>650</b> and the <figure-callout id="610" label="first image" filenames="US20210287438A1-20210916-D00006.png" state="{{state}}">first image</figure-callout> <b>610</b>.</div>
    </li> <li> <para-num num="[0098]"> </para-num> <div id="p-0099" num="0098" class="description-line">The localization apparatus calculates a localization modification value to maximize the score through the aforementioned process and outputs optimized localization information <div class="patent-image small-patent-image"><a href="https://patentimages.storage.googleapis.com/6d/bd/8d/1b8df5a05c46f9/US20210287438A1-20210916-P00002.png"><img id="CUSTOM-CHARACTER-00008" he="3.22mm" wi="1.44mm" file="US20210287438A1-20210916-P00002.TIF" alt="Figure US20210287438A1-20210916-P00002" img-content="character" img-format="tif" orientation="portrait" inline="no" width="6" height="13" alt="Figure US20210287438A1-20210916-P00002" class="patent-full-image" src="https://patentimages.storage.googleapis.com/6d/bd/8d/1b8df5a05c46f9/US20210287438A1-20210916-P00002.png"/></a></div>*.</div>
    </li> <li> <para-num num="[0099]"> </para-num> <div id="p-0100" num="0099" class="description-line"> <figref idrefs="DRAWINGS">FIGS. 7A and 7B</figref> illustrate examples of describing a method of modifying localization information.</div>
    </li> <li> <para-num num="[0100]"> </para-num> <div id="p-0101" num="0100" class="description-line"> <figref idrefs="DRAWINGS">FIG. 7A</figref> illustrates an example in which objects included in an input image is not classified for each type. For example, when a <figure-callout id="710" label="line" filenames="US20210287438A1-20210916-D00007.png" state="{{state}}">line</figure-callout> <b>710</b> and a <figure-callout id="730" label="line" filenames="US20210287438A1-20210916-D00007.png" state="{{state}}">line</figure-callout> <b>730</b> correspond to objects included in a first image and a <figure-callout id="720" label="line" filenames="US20210287438A1-20210916-D00007.png" state="{{state}}">line</figure-callout> <b>720</b> is included in a second image, the localization apparatus modifies localization information to increase a degree of visual alignment between the first image and the second image calculated by matching the first image and the second image. In one example, when each object type is not distinguished as illustrated in <figref idrefs="DRAWINGS">FIG. 7A</figref>, the localization apparatus may not accurately verify whether to match the <figure-callout id="720" label="line" filenames="US20210287438A1-20210916-D00007.png" state="{{state}}">line</figure-callout> <b>720</b> and the <figure-callout id="710" label="line" filenames="US20210287438A1-20210916-D00007.png" state="{{state}}">line</figure-callout> <b>710</b> or whether to match the <figure-callout id="720" label="line" filenames="US20210287438A1-20210916-D00007.png" state="{{state}}">line</figure-callout> <b>720</b> and the <figure-callout id="730" label="line" filenames="US20210287438A1-20210916-D00007.png" state="{{state}}">line</figure-callout> <b>730</b>, which may make it difficult to accurately modify the localization information.</div>
    </li> <li> <para-num num="[0101]"> </para-num> <div id="p-0102" num="0101" class="description-line"> <figref idrefs="DRAWINGS">FIG. 7B</figref> illustrates an example in which objects in an input image are classified according to a type of the object. The first image may classify the object based on a type of the object and may store a directional characteristic for each type of object. Also, the second image may classify the object based on a type of the object and may store a projected object for each object type. For example, a <figure-callout id="740" label="line" filenames="US20210287438A1-20210916-D00007.png" state="{{state}}">line</figure-callout> <b>740</b> and a <figure-callout id="760" label="line" filenames="US20210287438A1-20210916-D00007.png" state="{{state}}">line</figure-callout> <b>760</b> may correspond to objects included in the first image. The <figure-callout id="740" label="line" filenames="US20210287438A1-20210916-D00007.png" state="{{state}}">line</figure-callout> <b>740</b> may correspond to a first type (Type <b>1</b>) and the <figure-callout id="760" label="line" filenames="US20210287438A1-20210916-D00007.png" state="{{state}}">line</figure-callout> <b>760</b> may correspond to a second type (Type <b>2</b>). Also, a <figure-callout id="750" label="line" filenames="US20210287438A1-20210916-D00007.png" state="{{state}}">line</figure-callout> <b>750</b> may be included in the second image and correspond to the first type (Type <b>1</b>).</div>
    </li> <li> <para-num num="[0102]"> </para-num> <div id="p-0103" num="0102" class="description-line">Referring to <figref idrefs="DRAWINGS">FIG. 7B</figref>, when each of the objects is classified for each type, the localization apparatus matches the first image and the second image and calculates a degree of visual alignment for each object type. The localization apparatus modifies the localization information to increase the degree of visual alignment for each type based on the directional characteristic.</div>
    </li> <li> <para-num num="[0103]"> </para-num> <div id="p-0104" num="0103" class="description-line">For example, the localization apparatus may calculate a degree of visual alignments for objects, the <figure-callout id="740" label="lines" filenames="US20210287438A1-20210916-D00007.png" state="{{state}}"> <figure-callout id="750" label="lines" filenames="US20210287438A1-20210916-D00007.png" state="{{state}}">lines</figure-callout> </figure-callout> <b>740</b> and <b>750</b>, corresponding to the first type (Type <b>1</b>) and may modify localization information to increase the degree of visual alignment corresponding to the first type based on the directional characteristic. The localization apparatus may modify the localization information to match the objects that are the <figure-callout id="740" label="lines" filenames="US20210287438A1-20210916-D00007.png" state="{{state}}"> <figure-callout id="750" label="lines" filenames="US20210287438A1-20210916-D00007.png" state="{{state}}">lines</figure-callout> </figure-callout> <b>740</b> and <b>750</b>.</div>
    </li> <li> <para-num num="[0104]"> </para-num> <div id="p-0105" num="0104" class="description-line"> <figref idrefs="DRAWINGS">FIG. 8</figref> is a diagram illustrating an example of a learning method, and <figref idrefs="DRAWINGS">FIG. 9</figref> illustrates an example of a learning process. The operations in <figref idrefs="DRAWINGS">FIG. 8</figref> may be performed in the sequence and manner as shown, although the order of some operations may be changed or some of the operations omitted without departing from the spirit and scope of the illustrative examples described. Many of the operations shown in <figref idrefs="DRAWINGS">FIG. 8</figref> may be performed in parallel or concurrently. One or more blocks of <figref idrefs="DRAWINGS">FIG. 8</figref>, and combinations of the blocks, can be implemented by special purpose hardware-based computer that perform the specified functions, or combinations of special purpose hardware and computer instructions. A training of a neural network, by a learning apparatus, to generate a first image from an input image to optimize localization information for AR will be described with reference to <figref idrefs="DRAWINGS">FIGS. 8, 9 and 10</figref>. In addition to the description of <figref idrefs="DRAWINGS">FIG. 8</figref> below, the descriptions of <figref idrefs="DRAWINGS">FIGS. 1-7B</figref> are also applicable to <figref idrefs="DRAWINGS">FIG. 8</figref>, and are incorporated herein by reference. Thus, the above description may not be repeated here.</div>
    </li> <li> <para-num num="[0105]"> </para-num> <div id="p-0106" num="0105" class="description-line">Referring to <figref idrefs="DRAWINGS">FIGS. 8 and 9</figref>, in <figure-callout id="810" label="operation" filenames="US20210287438A1-20210916-D00008.png" state="{{state}}">operation</figure-callout> <b>810</b>, the learning apparatus receives a <figure-callout id="910" label="learning image" filenames="US20210287438A1-20210916-D00009.png" state="{{state}}">learning image</figure-callout> <b>910</b>. The <figure-callout id="910" label="learning image" filenames="US20210287438A1-20210916-D00009.png" state="{{state}}">learning image</figure-callout> <b>910</b> may include, for example, a driving image of a vehicle. The <figure-callout id="910" label="learning image" filenames="US20210287438A1-20210916-D00009.png" state="{{state}}">learning image</figure-callout> <b>910</b> may be, for example, a <figure-callout id="1010" label="learning image" filenames="US20210287438A1-20210916-D00010.png" state="{{state}}">learning image</figure-callout> <b>1010</b> of <figref idrefs="DRAWINGS">FIG. 10</figref>.</div>
    </li> <li> <para-num num="[0106]"> </para-num> <div id="p-0107" num="0106" class="description-line">In <figure-callout id="820" label="operation" filenames="US20210287438A1-20210916-D00008.png" state="{{state}}">operation</figure-callout> <b>820</b>, the learning apparatus generates a <figure-callout id="950" label="reference image" filenames="US20210287438A1-20210916-D00009.png" state="{{state}}">reference image</figure-callout> <b>950</b> that includes a directional characteristic corresponding to an object included in the <figure-callout id="910" label="learning image" filenames="US20210287438A1-20210916-D00009.png" state="{{state}}">learning image</figure-callout> <b>910</b>, based on <figure-callout id="940" label="map data" filenames="US20210287438A1-20210916-D00009.png" state="{{state}}">map data</figure-callout> <b>940</b> for the <figure-callout id="910" label="learning image" filenames="US20210287438A1-20210916-D00009.png" state="{{state}}">learning image</figure-callout> <b>910</b>. In an example, the directional characteristic corresponds to a probability distribution indicating a degree of closeness to an object. The <figure-callout id="950" label="reference image" filenames="US20210287438A1-20210916-D00009.png" state="{{state}}">reference image</figure-callout> <b>950</b> may correspond to a ground truth (GT) image. The <figure-callout id="950" label="reference image" filenames="US20210287438A1-20210916-D00009.png" state="{{state}}">reference image</figure-callout> <b>950</b> may be, for example, a <figure-callout id="1030" label="reference image" filenames="US20210287438A1-20210916-D00010.png" state="{{state}}">reference image</figure-callout> <b>1030</b> or a <figure-callout id="1040" label="reference image" filenames="US20210287438A1-20210916-D00010.png" state="{{state}}">reference image</figure-callout> <b>1040</b> of <figref idrefs="DRAWINGS">FIG. 10</figref>.</div>
    </li> <li> <para-num num="[0107]"> </para-num> <div id="p-0108" num="0107" class="description-line">In <figure-callout id="830" label="operation" filenames="US20210287438A1-20210916-D00008.png" state="{{state}}">operation</figure-callout> <b>830</b>, the learning apparatus generates an <figure-callout id="930" label="inference image" filenames="US20210287438A1-20210916-D00009.png" state="{{state}}">inference image</figure-callout> <b>930</b> that infers the directional characteristic corresponding to the object included in the <figure-callout id="910" label="learning image" filenames="US20210287438A1-20210916-D00009.png" state="{{state}}">learning image</figure-callout> <b>910</b>, using a neural network <b>920</b>. The neural network <b>920</b> may be, for example, the <figure-callout id="530" label="neural network" filenames="US20210287438A1-20210916-D00005.png" state="{{state}}">neural network</figure-callout> <b>530</b> of <figref idrefs="DRAWINGS">FIG. 5</figref>. A method of generating, by the learning apparatus, the <figure-callout id="930" label="inference image" filenames="US20210287438A1-20210916-D00009.png" state="{{state}}">inference image</figure-callout> <b>930</b> will be further described with reference to <figref idrefs="DRAWINGS">FIG. 10</figref>.</div>
    </li> <li> <para-num num="[0108]"> </para-num> <div id="p-0109" num="0108" class="description-line">In <figure-callout id="840" label="operation" filenames="US20210287438A1-20210916-D00008.png" state="{{state}}">operation</figure-callout> <b>840</b>, the learning apparatus trains the neural network <b>920</b> based on a difference, for example, a <figure-callout id="960" label="loss" filenames="US20210287438A1-20210916-D00009.png" state="{{state}}">loss</figure-callout> <b>960</b> between the <figure-callout id="950" label="reference image" filenames="US20210287438A1-20210916-D00009.png" state="{{state}}">reference image</figure-callout> <b>950</b> and the <figure-callout id="930" label="inference image" filenames="US20210287438A1-20210916-D00009.png" state="{{state}}">inference image</figure-callout> <b>930</b>. The learning apparatus may train the neural network <b>920</b> to minimize the difference between the <figure-callout id="950" label="reference image" filenames="US20210287438A1-20210916-D00009.png" state="{{state}}">reference image</figure-callout> <b>950</b> and the <figure-callout id="930" label="inference image" filenames="US20210287438A1-20210916-D00009.png" state="{{state}}">inference image</figure-callout> <b>930</b>. The learning apparatus may train the neural network <b>920</b> through, for example, supervised learning. The learning apparatus may update the neural network <b>920</b> through a gradient descent scheme based on the <figure-callout id="930" label="loss" filenames="US20210287438A1-20210916-D00009.png" state="{{state}}">loss</figure-callout> <b>930</b> that is back-propagated to the neural network <b>920</b> through back-propagation learning and output values of nodes included in the neural network <b>920</b>. The back-propagation learning refers to a method of estimating the <figure-callout id="960" label="loss" filenames="US20210287438A1-20210916-D00009.png" state="{{state}}">loss</figure-callout> <b>960</b> by performing forward computation on the <figure-callout id="950" label="reference image" filenames="US20210287438A1-20210916-D00009.png" state="{{state}}">reference image</figure-callout> <b>950</b> and updating the neural network <b>920</b> to reduce the <figure-callout id="960" label="loss" filenames="US20210287438A1-20210916-D00009.png" state="{{state}}">loss</figure-callout> <b>960</b> while propagating the estimated <figure-callout id="960" label="loss" filenames="US20210287438A1-20210916-D00009.png" state="{{state}}">loss</figure-callout> <b>960</b> starting from an output layer of the neural network <b>920</b> toward a hidden layer and an input layer.</div>
    </li> <li> <para-num num="[0109]"> </para-num> <div id="p-0110" num="0109" class="description-line"> <figref idrefs="DRAWINGS">FIG. 10</figref> illustrates an example of images for learning. <figref idrefs="DRAWINGS">FIG. 10</figref> illustrates the <figure-callout id="1010" label="learning image" filenames="US20210287438A1-20210916-D00010.png" state="{{state}}">learning image</figure-callout> <b>1010</b>, a <figure-callout id="1020" label="map data image" filenames="US20210287438A1-20210916-D00010.png" state="{{state}}">map data image</figure-callout> <b>1020</b>, and the <figure-callout id="1030" label="reference images" filenames="US20210287438A1-20210916-D00010.png" state="{{state}}"> <figure-callout id="1040" label="reference images" filenames="US20210287438A1-20210916-D00010.png" state="{{state}}">reference images</figure-callout> </figure-callout> <b>1030</b> and <b>1040</b>.</div>
    </li> <li> <para-num num="[0110]"> </para-num> <div id="p-0111" num="0110" class="description-line">Referring to <figref idrefs="DRAWINGS">FIG. 10</figref>, the learning apparatus trains a neural network to estimate the <figure-callout id="1030" label="reference images" filenames="US20210287438A1-20210916-D00010.png" state="{{state}}"> <figure-callout id="1040" label="reference images" filenames="US20210287438A1-20210916-D00010.png" state="{{state}}">reference images</figure-callout> </figure-callout> <b>1030</b> and <b>1040</b> from the <figure-callout id="1010" label="learning image" filenames="US20210287438A1-20210916-D00010.png" state="{{state}}">learning image</figure-callout> <b>1010</b>. In an example, the <figure-callout id="1020" label="map data image" filenames="US20210287438A1-20210916-D00010.png" state="{{state}}">map data image</figure-callout> <b>1020</b> represents objects in the <figure-callout id="1010" label="learning image" filenames="US20210287438A1-20210916-D00010.png" state="{{state}}">learning image</figure-callout> <b>1010</b> using a discrete binary value. Thus, when using the <figure-callout id="1020" label="map data image" filenames="US20210287438A1-20210916-D00010.png" state="{{state}}">map data image</figure-callout> <b>1020</b>, learning information may be too sparse to smoothly perform learning. In an example, learning may be performed using a distance field map, such as the <figure-callout id="1030" label="reference images" filenames="US20210287438A1-20210916-D00010.png" state="{{state}}"> <figure-callout id="1040" label="reference images" filenames="US20210287438A1-20210916-D00010.png" state="{{state}}">reference images</figure-callout> </figure-callout> <b>1030</b> and <b>1040</b>. Sparse learning information may be spread across the overall image through the distance field map. When learning information is present over the entire target image as in the distance field map, it is possible to train the neural network based on sufficient learning information.</div>
    </li> <li> <para-num num="[0111]"> </para-num> <div id="p-0112" num="0111" class="description-line">In an example, the learning apparatus generates the <figure-callout id="1030" label="reference image" filenames="US20210287438A1-20210916-D00010.png" state="{{state}}">reference image</figure-callout> <b>1030</b> or the <figure-callout id="1040" label="reference image" filenames="US20210287438A1-20210916-D00010.png" state="{{state}}">reference image</figure-callout> <b>1040</b> from the <figure-callout id="1020" label="map data image" filenames="US20210287438A1-20210916-D00010.png" state="{{state}}">map data image</figure-callout> <b>1020</b> by adjusting an importance of spread information in a distance field. For example, the learning apparatus may adjust an importance of spread information in the distance field, such as e<sup>0.02d</sup>. Here, d denotes a distance between a seed pixel corresponding to an object and a corresponding pixel.</div>
    </li> <li> <para-num num="[0112]"> </para-num> <div id="p-0113" num="0112" class="description-line"> <figref idrefs="DRAWINGS">FIG. 11</figref> illustrates an example of a learning method, and <figref idrefs="DRAWINGS">FIG. 12</figref> illustrates an example of a localization updating process of <figref idrefs="DRAWINGS">FIG. 11</figref>. The operations in <figref idrefs="DRAWINGS">FIG. 11</figref> may be performed in the sequence and manner as shown, although the order of some operations may be changed or some of the operations omitted without departing from the spirit and scope of the illustrative examples described. Many of the operations shown in <figref idrefs="DRAWINGS">FIG. 11</figref> may be performed in parallel or concurrently. One or more blocks of <figref idrefs="DRAWINGS">FIG. 11</figref>, and combinations of the blocks, can be implemented by special purpose hardware-based computer that perform the specified functions, or combinations of special purpose hardware and computer instructions. In addition to the description of <figref idrefs="DRAWINGS">FIG. 11</figref> below, the descriptions of <figref idrefs="DRAWINGS">FIGS. 1-10</figref> are also applicable to <figref idrefs="DRAWINGS">FIG. 11</figref>, and are incorporated herein by reference. Thus, the above description may not be repeated here.</div>
    </li> <li> <para-num num="[0113]"> </para-num> <div id="p-0114" num="0113" class="description-line">Referring to <figref idrefs="DRAWINGS">FIGS. 11 and 12</figref>, in <figure-callout id="1110" label="operation" filenames="US20210287438A1-20210916-D00011.png" state="{{state}}">operation</figure-callout> <b>1110</b>, the localization apparatus acquires an input image. In an example, the input image refers to an image corresponding to a current location of a corresponding apparatus.</div>
    </li> <li> <para-num num="[0114]"> </para-num> <div id="p-0115" num="0114" class="description-line">In <figure-callout id="1120" label="operation" filenames="US20210287438A1-20210916-D00011.png" state="{{state}}">operation</figure-callout> <b>1120</b>, the localization apparatus receives or acquires map data that includes a location of an object. In <figure-callout id="1140" label="operation" filenames="US20210287438A1-20210916-D00011.png" state="{{state}}">operation</figure-callout> <b>1140</b>, the localization apparatus applies a plurality of pieces of candidate localization information to the map data acquired in <figure-callout id="1120" label="operation" filenames="US20210287438A1-20210916-D00011.png" state="{{state}}">operation</figure-callout> <b>1120</b>. In <figure-callout id="1150" label="operation" filenames="US20210287438A1-20210916-D00011.png" state="{{state}}">operation</figure-callout> <b>1150</b>, the localization apparatus generates second candidate images each in which an object is projected based on the candidate localization information. For example, the localization apparatus may generate second candidate images, for example, a first candidate image (candidate <b>1</b>) <b>1210</b> and a second candidate image (candidate <b>2</b>) <b>1220</b> of <figref idrefs="DRAWINGS">FIG. 12</figref>, each to which the candidate localization information is applied.</div>
    </li> <li> <para-num num="[0115]"> </para-num> <div id="p-0116" num="0115" class="description-line">In <figure-callout id="1130" label="operation" filenames="US20210287438A1-20210916-D00011.png" state="{{state}}">operation</figure-callout> <b>1130</b>, the localization apparatus scores visual alignment between the input image and each of the second candidate images. For example, a degree of visual alignment between the input image and the <figure-callout id="1210" label="first candidate image" filenames="US20210287438A1-20210916-D00012.png" state="{{state}}">first candidate image</figure-callout> <b>1210</b> is scored as 0.43 and a degree of visual alignment between the input image and the <figure-callout id="1220" label="second candidate image" filenames="US20210287438A1-20210916-D00012.png" state="{{state}}">second candidate image</figure-callout> <b>1220</b> is scored as 0.98.</div>
    </li> <li> <para-num num="[0116]"> </para-num> <div id="p-0117" num="0116" class="description-line">In <figure-callout id="1160" label="operation" filenames="US20210287438A1-20210916-D00011.png" state="{{state}}">operation</figure-callout> <b>1160</b>, the localization apparatus searches for a best score having a highest value from among the scores output in <figure-callout id="1130" label="operation" filenames="US20210287438A1-20210916-D00011.png" state="{{state}}">operation</figure-callout> <b>1130</b>. Referring to <figref idrefs="DRAWINGS">FIG. 12</figref>, the localization apparatus retrieves 0.98 as the best score from among the scores 0.43 and 0.98. In <figure-callout id="1170" label="operation" filenames="US20210287438A1-20210916-D00011.png" state="{{state}}">operation</figure-callout> <b>1170</b>, the localization apparatus updates the localization information by selecting a candidate localization corresponding to the best score retrieved in <figure-callout id="1160" label="operation" filenames="US20210287438A1-20210916-D00011.png" state="{{state}}">operation</figure-callout> <b>1160</b>.</div>
    </li> <li> <para-num num="[0117]"> </para-num> <div id="p-0118" num="0117" class="description-line"> <figref idrefs="DRAWINGS">FIG. 13</figref> is a diagram illustrating an example of a localization method. The operations in <figref idrefs="DRAWINGS">FIG. 13</figref> may be performed in the sequence and manner as shown, although the order of some operations may be changed or some of the operations omitted without departing from the spirit and scope of the illustrative examples described. Many of the operations shown in <figref idrefs="DRAWINGS">FIG. 13</figref> may be performed in parallel or concurrently. One or more blocks of <figref idrefs="DRAWINGS">FIG. 13</figref>, and combinations of the blocks, can be implemented by special purpose hardware-based computer that perform the specified functions, or combinations of special purpose hardware and computer instructions. In addition to the description of <figref idrefs="DRAWINGS">FIG. 13</figref> below, the descriptions of <figref idrefs="DRAWINGS">FIGS. 1-12</figref> are also applicable to <figref idrefs="DRAWINGS">FIG. 13</figref>, and are incorporated herein by reference. Thus, the above description may not be repeated here.</div>
    </li> <li> <para-num num="[0118]"> </para-num> <div id="p-0119" num="0118" class="description-line">Referring to <figref idrefs="DRAWINGS">FIG. 13</figref>, the localization apparatus generates a first image, for example, a distance field map, from an input image by estimating an object in <figure-callout id="1330" label="operation" filenames="US20210287438A1-20210916-D00013.png" state="{{state}}">operation</figure-callout> <b>1330</b> prior to scoring a degree of visual alignment in <figure-callout id="1360" label="operation" filenames="US20210287438A1-20210916-D00013.png" state="{{state}}">operation</figure-callout> <b>1360</b>. The localization apparatus calculates scores between the first image and second candidate images.</div>
    </li> <li> <para-num num="[0119]"> </para-num> <div id="p-0120" num="0119" class="description-line"> <figref idrefs="DRAWINGS">FIG. 14</figref> is a diagram illustrating an example of a localization apparatus. Referring to <figref idrefs="DRAWINGS">FIG. 14</figref>, a <figure-callout id="1400" label="localization apparatus" filenames="US20210287438A1-20210916-D00014.png" state="{{state}}">localization apparatus</figure-callout> <b>1400</b> includes <figure-callout id="1410" label="sensors" filenames="US20210287438A1-20210916-D00014.png" state="{{state}}">sensors</figure-callout> <b>1410</b> and a <figure-callout id="1430" label="processor" filenames="US20210287438A1-20210916-D00014.png" state="{{state}}">processor</figure-callout> <b>1430</b>. The <figure-callout id="1400" label="localization apparatus" filenames="US20210287438A1-20210916-D00014.png" state="{{state}}">localization apparatus</figure-callout> <b>1400</b> further includes a <figure-callout id="1450" label="memory" filenames="US20210287438A1-20210916-D00014.png" state="{{state}}">memory</figure-callout> <b>1450</b>, a <figure-callout id="1470" label="communication interface" filenames="US20210287438A1-20210916-D00014.png" state="{{state}}">communication interface</figure-callout> <b>1470</b>, and a <figure-callout id="1490" label="display device" filenames="US20210287438A1-20210916-D00014.png" state="{{state}}">display device</figure-callout> <b>1490</b>. The <figure-callout id="1410" label="sensors" filenames="US20210287438A1-20210916-D00014.png" state="{{state}}">sensors</figure-callout> <b>1410</b>, the <figure-callout id="1430" label="processor" filenames="US20210287438A1-20210916-D00014.png" state="{{state}}">processor</figure-callout> <b>1430</b>, the <figure-callout id="1450" label="memory" filenames="US20210287438A1-20210916-D00014.png" state="{{state}}">memory</figure-callout> <b>1450</b>, the <figure-callout id="1470" label="communication interface" filenames="US20210287438A1-20210916-D00014.png" state="{{state}}">communication interface</figure-callout> <b>1470</b>, and the <figure-callout id="1490" label="display device" filenames="US20210287438A1-20210916-D00014.png" state="{{state}}">display device</figure-callout> <b>1490</b> are connected to each other through a <figure-callout id="1405" label="communication bus" filenames="US20210287438A1-20210916-D00014.png" state="{{state}}">communication bus</figure-callout> <b>1405</b>.</div>
    </li> <li> <para-num num="[0120]"> </para-num> <div id="p-0121" num="0120" class="description-line">The <figure-callout id="1410" label="sensors" filenames="US20210287438A1-20210916-D00014.png" state="{{state}}">sensors</figure-callout> <b>1410</b> may include, for example, an image sensor, a vision sensor, an accelerometer sensor, a gyro sensor, a GPS sensor, an IMU sensor, a radar, and a lidar. The sensor(s) <b>1410</b> may acquire an input image that includes a driving image of a vehicle. The sensor(s) <b>1410</b> may sense sensing information, for example, speed, acceleration, driving direction, handle steering angle of the vehicle, and a speed of the vehicle, in addition to localization information, for example, GPS coordinates, a location, and a pose of the vehicle.</div>
    </li> <li> <para-num num="[0121]"> </para-num> <div id="p-0122" num="0121" class="description-line">In an example, the <figure-callout id="1430" label="processor" filenames="US20210287438A1-20210916-D00014.png" state="{{state}}">processor</figure-callout> <b>1430</b> generates a first image that includes a directional characteristic corresponding to an object included in the input image. In an example, the <figure-callout id="1430" label="processor" filenames="US20210287438A1-20210916-D00014.png" state="{{state}}">processor</figure-callout> <b>1430</b> generates a second image in which the object is projected based on localization information, based on map data that includes the location of the object. In an example, the <figure-callout id="1430" label="processor" filenames="US20210287438A1-20210916-D00014.png" state="{{state}}">processor</figure-callout> <b>1430</b> modifies the localization information based on visual alignment between the first image and the second image.</div>
    </li> <li> <para-num num="[0122]"> </para-num> <div id="p-0123" num="0122" class="description-line">In an example, the <figure-callout id="1400" label="localization apparatus" filenames="US20210287438A1-20210916-D00014.png" state="{{state}}">localization apparatus</figure-callout> <b>1400</b> acquires a variety of sensing information including the input image from various sensors through the <figure-callout id="1470" label="communication interface" filenames="US20210287438A1-20210916-D00014.png" state="{{state}}">communication interface</figure-callout> <b>1470</b>. In one example, the <figure-callout id="1470" label="communication interface" filenames="US20210287438A1-20210916-D00014.png" state="{{state}}">communication interface</figure-callout> <b>1470</b> receives sensing information including a driving image from other sensors outside the <figure-callout id="1400" label="localization apparatus" filenames="US20210287438A1-20210916-D00014.png" state="{{state}}">localization apparatus</figure-callout> <b>1400</b>.</div>
    </li> <li> <para-num num="[0123]"> </para-num> <div id="p-0124" num="0123" class="description-line">The <figure-callout id="1430" label="processor" filenames="US20210287438A1-20210916-D00014.png" state="{{state}}">processor</figure-callout> <b>1430</b> provides an AR service by outputting the modified localization information through the <figure-callout id="1470" label="communication interface" filenames="US20210287438A1-20210916-D00014.png" state="{{state}}">communication interface</figure-callout> <b>1470</b> and/or the <figure-callout id="1490" label="display device" filenames="US20210287438A1-20210916-D00014.png" state="{{state}}">display device</figure-callout> <b>1490</b> or by displaying a virtual object and the input image on map data based on the modified localization information. Also, the <figure-callout id="1430" label="processor" filenames="US20210287438A1-20210916-D00014.png" state="{{state}}">processor</figure-callout> <b>1430</b> may perform the one or more methods described with reference to <figref idrefs="DRAWINGS">FIGS. 1 to 13</figref> or an algorithm corresponding thereto.</div>
    </li> <li> <para-num num="[0124]"> </para-num> <div id="p-0125" num="0124" class="description-line">The <figure-callout id="1430" label="processor" filenames="US20210287438A1-20210916-D00014.png" state="{{state}}">processor</figure-callout> <b>1430</b> refers to a data processing device configured as hardware with a circuitry in a physical structure to execute desired operations. For example, the desired operations may include codes or instructions included in a program. For example, the data processing device configured as hardware may include a microprocessor, a central processing unit (CPU), a processor core, a multicore processor, a multiprocessor, an application-specific integrated circuit (ASIC), and a field programmable gate array (FPGA). Further details on the <figure-callout id="1430" label="processor" filenames="US20210287438A1-20210916-D00014.png" state="{{state}}">processor</figure-callout> <b>1430</b> are provided below.</div>
    </li> <li> <para-num num="[0125]"> </para-num> <div id="p-0126" num="0125" class="description-line">The <figure-callout id="1430" label="processor" filenames="US20210287438A1-20210916-D00014.png" state="{{state}}">processor</figure-callout> <b>1430</b> executes the program and controls the <figure-callout id="1400" label="localization apparatus" filenames="US20210287438A1-20210916-D00014.png" state="{{state}}">localization apparatus</figure-callout> <b>1400</b>. The program code executed by the <figure-callout id="1430" label="processor" filenames="US20210287438A1-20210916-D00014.png" state="{{state}}">processor</figure-callout> <b>1430</b> may be stored in the <figure-callout id="1450" label="memory" filenames="US20210287438A1-20210916-D00014.png" state="{{state}}">memory</figure-callout> <b>1450</b>.</div>
    </li> <li> <para-num num="[0126]"> </para-num> <div id="p-0127" num="0126" class="description-line">The <figure-callout id="1450" label="memory" filenames="US20210287438A1-20210916-D00014.png" state="{{state}}">memory</figure-callout> <b>1450</b> stores the localization information of the <figure-callout id="1400" label="localization apparatus" filenames="US20210287438A1-20210916-D00014.png" state="{{state}}">localization apparatus</figure-callout> <b>1400</b>, the first image, the second image, and/or the modified localization information. The <figure-callout id="1450" label="memory" filenames="US20210287438A1-20210916-D00014.png" state="{{state}}">memory</figure-callout> <b>1450</b> stores a variety of information that is generated during a processing process of the <figure-callout id="1430" label="processor" filenames="US20210287438A1-20210916-D00014.png" state="{{state}}">processor</figure-callout> <b>1430</b>. In an example, the memory <b>14450</b> stores the map data. In addition, the <figure-callout id="1450" label="memory" filenames="US20210287438A1-20210916-D00014.png" state="{{state}}">memory</figure-callout> <b>1450</b> stores a variety of data and programs. The <figure-callout id="1450" label="memory" filenames="US20210287438A1-20210916-D00014.png" state="{{state}}">memory</figure-callout> <b>1450</b> may include, for example, a volatile memory or a non-volatile memory. The <figure-callout id="1450" label="memory" filenames="US20210287438A1-20210916-D00014.png" state="{{state}}">memory</figure-callout> <b>1450</b> may include a mass storage medium, such as a hard disk, to store a variety of data. Further details on the <figure-callout id="1450" label="memory" filenames="US20210287438A1-20210916-D00014.png" state="{{state}}">memory</figure-callout> <b>1450</b> are provided below.</div>
    </li> <li> <para-num num="[0127]"> </para-num> <div id="p-0128" num="0127" class="description-line">The <figure-callout id="1490" label="display device" filenames="US20210287438A1-20210916-D00014.png" state="{{state}}">display device</figure-callout> <b>1490</b> outputs the localization information modified by the <figure-callout id="1430" label="processor" filenames="US20210287438A1-20210916-D00014.png" state="{{state}}">processor</figure-callout> <b>1430</b>, or displays a virtual object with the input image on map data based on the modified localization information. In an example, the <figure-callout id="1490" label="display device" filenames="US20210287438A1-20210916-D00014.png" state="{{state}}">display device</figure-callout> <b>1490</b> is a physical structure that includes one or more hardware components that provide the ability to render a user interface and/or receive user input. In an example, the localization information or the virtual object with the input image on map data based on the modified localization information is displayed on a wind shield glass or a separate screen of the vehicle using a head-up display (HUD) or is displayed on an augmented reality head-up display (AR HUD). In an example, the <figure-callout id="1400" label="localization apparatus" filenames="US20210287438A1-20210916-D00014.png" state="{{state}}">localization apparatus</figure-callout> <b>1400</b> transmits the localization information to an electronic control unit (ECU) or a vehicle control unit (VCU) of a vehicle. The ECU or the VCU displays the localization information on <figure-callout id="1490" label="display device" filenames="US20210287438A1-20210916-D00014.png" state="{{state}}">display device</figure-callout> <b>1490</b> of the vehicle.</div>
    </li> <li> <para-num num="[0128]"> </para-num> <div id="p-0129" num="0128" class="description-line">However, the displaying of the object is not limited to the example described above, and any other instrument cluster, vehicular infotainment system, screen in the vehicle, or display panel in the vehicle may perform the display function. Other displays, such as, for example, smart phone and eye glass display (EGD) that are operatively connected to the <figure-callout id="1400" label="localization apparatus" filenames="US20210287438A1-20210916-D00014.png" state="{{state}}">localization apparatus</figure-callout> <b>1400</b> may be used without departing from the spirit and scope of the illustrative examples described.</div>
    </li> <li> <para-num num="[0129]"> </para-num> <div id="p-0130" num="0129" class="description-line">In one example, the localization apparatus may perform the localization method independent of a viewpoint by updating 3D localization information of the localization apparatus using a result of performing the localization method based on a photographing apparatus, although a viewpoint between the photographing device and the localization apparatus does not match, such as, for example, an HUD and AR glasses. Also, when the viewpoint between the photographing device and the localization information matches, such as, for example, a mobile terminal and a smartphone, the localization apparatus may update 3D localization information and, additionally, may directly use a 2D location in an image for modification.</div>
    </li> <li> <para-num num="[0130]"> </para-num> <div id="p-0131" num="0130" class="description-line">The localization apparatus, <figure-callout id="1430" label="processor" filenames="US20210287438A1-20210916-D00014.png" state="{{state}}">processor</figure-callout> <b>1430</b> and other apparatuses, units, modules, devices, and other components described herein are implemented by hardware components. Examples of hardware components that may be used to perform the operations described in this application where appropriate include controllers, sensors, generators, drivers, memories, comparators, arithmetic logic units, adders, subtractors, multipliers, dividers, integrators, and any other electronic components configured to perform the operations described in this application. In other examples, one or more of the hardware components that perform the operations described in this application are implemented by computing hardware, for example, by one or more processors or computers. A processor or computer may be implemented by one or more processing elements, such as an array of logic gates, a controller and an arithmetic logic unit, a digital signal processor, a microcomputer, a programmable logic controller, a field-programmable gate array, a programmable logic array, a microprocessor, or any other device or combination of devices that is configured to respond to and execute instructions in a defined manner to achieve a desired result. In one example, a processor or computer includes, or is connected to, one or more memories storing instructions or software that are executed by the processor or computer. Hardware components implemented by a processor or computer may execute instructions or software, such as an operating system (OS) and one or more software applications that run on the OS, to perform the operations described in this application. The hardware components may also access, manipulate, process, create, and store data in response to execution of the instructions or software. For simplicity, the singular term processor or computer may be used in the description of the examples described in this application, but in other examples multiple processors or computers may be used, or a processor or computer may include multiple processing elements, or multiple types of processing elements, or both. For example, a single hardware component or two or more hardware components may be implemented by a single processor, or two or more processors, or a processor and a controller. One or more hardware components may be implemented by one or more processors, or a processor and a controller, and one or more other hardware components may be implemented by one or more other processors, or another processor and another controller. One or more processors, or a processor and a controller, may implement a single hardware component, or two or more hardware components. A hardware component may have any one or more of different processing configurations, examples of which include a single processor, independent processors, parallel processors, single-instruction single-data (SISD) multiprocessing, single-instruction multiple-data (SIMD) multiprocessing, multiple-instruction single-data (MISD) multiprocessing, and multiple-instruction multiple-data (MIMD) multiprocessing.</div>
    </li> <li> <para-num num="[0131]"> </para-num> <div id="p-0132" num="0131" class="description-line">The methods that perform the operations described in this application are performed by computing hardware, for example, by one or more processors or computers, implemented as described above executing instructions or software to perform the operations described in this application that are performed by the methods. For example, a single operation or two or more operations may be performed by a single processor, or two or more processors, or a processor and a controller. One or more operations may be performed by one or more processors, or a processor and a controller, and one or more other operations may be performed by one or more other processors, or another processor and another controller. One or more processors, or a processor and a controller, may perform a single operation, or two or more operations.</div>
    </li> <li> <para-num num="[0132]"> </para-num> <div id="p-0133" num="0132" class="description-line">Instructions or software to control a processor or computer to implement the hardware components and perform the methods as described above are written as computer programs, code segments, instructions or any combination thereof, for individually or collectively instructing or configuring the processor or computer to operate as a machine or special-purpose computer to perform the operations performed by the hardware components and the methods as described above. In an example, the instructions or software includes at least one of an applet, a dynamic link library (DLL), middleware, firmware, a device driver, an application program storing the method of preventing the collision. In one example, the instructions or software include machine code that is directly executed by the processor or computer, such as machine code produced by a compiler. In another example, the instructions or software include higher-level code that is executed by the processor or computer using an interpreter. Programmers of ordinary skill in the art can readily write the instructions or software based on the block diagrams and the flow charts illustrated in the drawings and the corresponding descriptions in the specification, which disclose algorithms for performing the operations performed by the hardware components and the methods as described above.</div>
    </li> <li> <para-num num="[0133]"> </para-num> <div id="p-0134" num="0133" class="description-line">The instructions or software to control computing hardware, for example, one or more processors or computers, to implement the hardware components and perform the methods as described above, and any associated data, data files, and data structures, may be recorded, stored, or fixed in or on one or more non-transitory computer-readable storage media. Examples of a non-transitory computer-readable storage medium include read-only memory (ROM), random-access memory (RAM), CD-ROMs, CD-Rs, CD+Rs, CD-RWs, CD+RWs, DVD-ROMs, DVD-Rs, DVD+Rs, DVD-RWs, DVD+RWs, DVD-RAMs, BD-ROMs, BD-Rs, BD-R LTHs, BD-REs, magnetic tapes, floppy disks, magneto-optical data storage devices, optical data storage devices, hard disks, solid-state disks, and any other device that is configured to store the instructions or software and any associated data, data files, and data structures in a non-transitory manner and provide the instructions or software and any associated data, data files, and data structures to one or more processors or computers so that the one or more processors or computers can execute the instructions. In one example, the instructions or software and any associated data, data files, and data structures are distributed over network-coupled computer systems so that the instructions and software and any associated data, data files, and data structures are stored, accessed, and executed in a distributed fashion by the one or more processors or computers.</div>
    </li> <li> <para-num num="[0134]"> </para-num> <div id="p-0135" num="0134" class="description-line">While this disclosure includes specific examples, it will be apparent after an understanding of the disclosure of this application that various changes in form and details may be made in these examples without departing from the spirit and scope of the claims and their equivalents. The examples described herein are to be considered in a descriptive sense only, and not for purposes of limitation. Descriptions of features or aspects in each example are to be considered as being applicable to similar features or aspects in other examples. Suitable results may be achieved if the described techniques are performed in a different order, and/or if components in a described system, architecture, device, or circuit are combined in a different manner, and/or replaced or supplemented by other components or their equivalents. Therefore, the scope of the disclosure is defined not by the detailed description, but by the claims and their equivalents, and all variations within the scope of the claims and their equivalents are to be construed as being included in the disclosure.</div>
    
  </li> </ul>
  </div>
  </section>

  <section itemprop="claims" itemscope>
    <h2>Claims (<span itemprop="count">27</span>)</h2>
    
    <div itemprop="content" html><div mxw-id="PCLM298201748" lang="EN" load-source="patent-office" class="claims">
    <claim-statement>What is claimed is:</claim-statement>
    <div class="claim"> <div id="CLM-00001" num="00001" class="claim">
      <div class="claim-text"> <b>1</b>. A localization method comprising:
<div class="claim-text">generating a first image with a directional characteristic corresponding to a first object included in an input image, wherein pixel values in the first image indicate respective degrees of closeness to seed pixels of the first object;</div> <div class="claim-text">generating a second image to which a second object included in three-dimensional (3D) map data is projected dependent on acquired localization information of a device, wherein the second object is of a same object type as the first object; and</div> <div class="claim-text">updating the localization information based on a degree of visual alignment between the first image and the second image, so as to increase the degree of visual alignment between the first image and the second image,</div> <div class="claim-text">wherein the degree of visual alignment is dependent on a pooling of respective values of pixels, of the first image, corresponding to pixels of the second object of the second image.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00002" num="00002" class="claim">
      <div class="claim-text"> <b>2</b>. The localization method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the acquired localization information comprises a location of the device and a pose of the device.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00003" num="00003" class="claim">
      <div class="claim-text"> <b>3</b>. The localization method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the generating of the second image comprises:
<div class="claim-text">adjusting a pose of a virtual camera, corresponding to the location on the 3D map data, based on the pose of the device; and</div> <div class="claim-text">generating an image of a viewpoint at which the second object is viewed from the virtual camera.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00004" num="00004" class="claim">
      <div class="claim-text"> <b>4</b>. The localization method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the directional characteristic corresponds to a probability distribution indicating the respective degrees of closeness.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00005" num="00005" class="claim">
      <div class="claim-text"> <b>5</b>. The localization method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:
<div class="claim-text">determining a virtual object on the 3D map data for an augmented reality (AR) service; and</div> <div class="claim-text">displaying the virtual object and the input image based on the updated localization information.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00006" num="00006" class="claim">
      <div class="claim-text"> <b>6</b>. The localization method of <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein the virtual object represents driving route information.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00007" num="00007" class="claim">
      <div class="claim-text"> <b>7</b>. The localization method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the generating of the first image comprises generating, using a trained neural network, a probability map that represents the directional characteristic.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00008" num="00008" class="claim">
      <div class="claim-text"> <b>8</b>. The localization method of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein each pixel in the probability map is configured to store a distance from the each pixel to a corresponding closest seed pixel of the seed pixels.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00009" num="00009" class="claim">
      <div class="claim-text"> <b>9</b>. The localization method of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the seed pixels are pixel corresponding to the first object among pixels included in the input image.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00010" num="00010" class="claim">
      <div class="claim-text"> <b>10</b>. The localization method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the generating of the second image comprises generating the second image using a transformer configured to transform a coordinate system of the 3D map data to a coordinate system of the second image.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00011" num="00011" class="claim">
      <div class="claim-text"> <b>11</b>. The localization method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the first image is configured to classify the first object based on an object type and to store a directional characteristic for each object type, and
<div class="claim-text">the second image is configured to classify the second object based on the object type and to store the projected object for the each object type.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00012" num="00012" class="claim">
      <div class="claim-text"> <b>12</b>. A non-transitory computer-readable storage medium storing instructions that, when executed by a processor, cause the processor to perform the localization method of <claim-ref idref="CLM-00001">claim 1</claim-ref>.</div>
    </div>
    </div> <div class="claim"> <div id="CLM-00013" num="00013" class="claim">
      <div class="claim-text"> <b>13</b>. A localization apparatus comprising:
<div class="claim-text">a processor configured to:
<div class="claim-text">generate a first image with a directional characteristic corresponding to a first object included in an input image, wherein pixel values in the first image indicate respective degrees of closeness to seed pixels of the first object;</div>
<div class="claim-text">generate a second image to which a second object included in three-dimensional (3D) map data is projected dependent on acquired localization information, wherein the second object corresponds to the first object, and the second object is of a same object type as the first object; and</div>
<div class="claim-text">adjust the localization information based on a degree of visual alignment between the first image and the second image, so as to increase the degree of visual alignment between the first image and the second image,</div>
</div> <div class="claim-text">wherein the degree of visual alignment is calculated dependent on a pooling of respective values of pixels, of the first image, corresponding to pixels of the second object of the second image.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00014" num="00014" class="claim">
      <div class="claim-text"> <b>14</b>. The localization apparatus of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the directional characteristic corresponds to a probability distribution indicating the respective degrees of closeness.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00015" num="00015" class="claim">
      <div class="claim-text"> <b>15</b>. The localization apparatus of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the processor is further configured to
<div class="claim-text">determine a virtual object on the 3D map data for an augmented reality (AR) service, and</div> <div class="claim-text">synthesize the virtual object and the input image based on the adjusted localization information.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00016" num="00016" class="claim">
      <div class="claim-text"> <b>16</b>. The localization apparatus of <claim-ref idref="CLM-00015">claim 15</claim-ref>, further comprising a display,
<div class="claim-text">wherein, for the synthesizing of the virtual object and the input image, the processor is configured to control the display to display a result of the synthetization.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00017" num="00017" class="claim">
      <div class="claim-text"> <b>17</b>. The localization apparatus of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the virtual object represents driving route information.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00018" num="00018" class="claim">
      <div class="claim-text"> <b>18</b>. The localization apparatus of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the processor is further configured to generate, using a trained neural network, a probability map that represents the directional characteristic.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00019" num="00019" class="claim">
      <div class="claim-text"> <b>19</b>. The localization apparatus of <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein each pixel in the probability map is configured to store a distance from the each pixel to a corresponding closest seed pixel of the seed pixels.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00020" num="00020" class="claim">
      <div class="claim-text"> <b>20</b>. The localization apparatus of <claim-ref idref="CLM-00019">claim 19</claim-ref>, wherein the seed pixels are pixels corresponding to the first object among pixels included in the input image.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00021" num="00021" class="claim">
      <div class="claim-text"> <b>21</b>. The localization apparatus of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the first image is configured to classify the first object based on an object type and to store a directional characteristic for each object type, and
<div class="claim-text">the second image is configured to classify the second object based on the object type and to store the projected object for the each object type.</div> </div>
    </div>
    </div> <div class="claim"> <div id="CLM-00022" num="00022" class="claim">
      <div class="claim-text"> <b>22</b>. A device comprising:
<div class="claim-text">a processor configured to:
<div class="claim-text">generate a first image with a directional characteristic corresponding to a first object included in a captured image, wherein pixel values in the first image indicate respective degrees of closeness to seed pixels of the first object; and</div>
<div class="claim-text">adjust acquired localization information of the device to reflect a first degree of visual alignment, between the first image and first image information of a first projection of a second object dependent on the acquired localization information of the device, being less than a second degree of visual alignment between the first image and a second projection of the second object dependent on the adjusted localization information,</div>
</div> <div class="claim-text">wherein the first degree of visual alignment is dependent on a pooling of values of pixels of the first image corresponding to pixels of the first image information for the second object, and</div> <div class="claim-text">wherein the second object is a same object type as the first object, and the first projection of the second object dependent on the acquired localization information of the device is a projection of the second object as included in three-dimensional (3D) map data.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00023" num="00023" class="claim">
      <div class="claim-text"> <b>23</b>. The device of <claim-ref idref="CLM-00022">claim 22</claim-ref>, wherein the acquired localization information of the device reflects a location of the device and a pose of the device, and
<div class="claim-text">for the first projection of the second object the processor is configured to:
<div class="claim-text">adjust a pose of a virtual camera, corresponding to the location on the 3D map data, dependent on the pose of the device; and</div>
<div class="claim-text">generate a second image, including the first image information, to which the second object included in the three-dimensional (3D) map data is projected dependent on the acquired localization information of the device, by generating an image of a viewpoint at which the second object is viewed from the virtual camera.</div>
</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00024" num="00024" class="claim">
      <div class="claim-text"> <b>24</b>. The device of <claim-ref idref="CLM-00023">claim 23</claim-ref>, wherein the first degree of visual alignment is between the first image and the generated second image.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00025" num="00025" class="claim">
      <div class="claim-text"> <b>25</b>. The device of <claim-ref idref="CLM-00022">claim 22</claim-ref>, further comprising a display,
<div class="claim-text">wherein the processor is configured to:
<div class="claim-text">determine a virtual object on the 3D map data for an augmented reality (AR) provision, and</div>
<div class="claim-text">control the display to display the virtual object based on the adjusted localization information.</div>
</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00026" num="00026" class="claim">
      <div class="claim-text"> <b>26</b>. The device of <claim-ref idref="CLM-00025">claim 25</claim-ref>, wherein the display is a glass display.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00027" num="00027" class="claim">
      <div class="claim-text"> <b>27</b>. The device of <claim-ref idref="CLM-00025">claim 25</claim-ref>, further comprising:
<div class="claim-text">a camera, wherein the captured image is captured by the camera; and</div> <div class="claim-text">a localization information sensor, including any one or any combination of any two or more of an accelerometer sensor, a gyro sensor, a GPS, an inertial measurement unit (IMU) sensor, a radar, and a lidar, wherein the acquired localization information of the device is acquired using the localization information sensor.</div> </div>
    </div>
  </div> </div>
  </div>
  </section>

  <section itemprop="application" itemscope>

    <section itemprop="metadata" itemscope>
      <span itemprop="applicationNumber">US17/335,199</span>
      <span itemprop="priorityDate">2018-09-11</span>
      <span itemprop="filingDate">2021-06-01</span>
      <span itemprop="title">Localization method and apparatus of displaying virtual object in augmented reality 
       </span>
      <span itemprop="ifiStatus">Active</span>
      
      <a href="/patent/US11842447B2/en">
        <span itemprop="representativePublication">US11842447B2</span>
        (<span itemprop="primaryLanguage">en</span>)
      </a>
    </section>

    <h2>Priority Applications (1)</h2>
    <table>
      <thead>
        <tr>
          <th>Application Number</th>
          <th>Priority Date</th>
          <th>Filing Date</th>
          <th>Title</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="priorityApps" itemscope repeat>
          <td>
            <span itemprop="applicationNumber">US17/335,199</span>
            
            <a href="/patent/US11842447B2/en">
              <span itemprop="representativePublication">US11842447B2</span>
                (<span itemprop="primaryLanguage">en</span>)
            </a>
          </td>
          <td itemprop="priorityDate">2018-09-11</td>
          <td itemprop="filingDate">2021-06-01</td>
          <td itemprop="title">Localization method and apparatus of displaying virtual object in augmented reality 
       </td>
        </tr>
      </tbody>
    </table>

    <h2>Applications Claiming Priority (4)</h2>
    <table>
      <thead>
        <tr>
          <th>Application Number</th>
          <th>Priority Date</th>
          <th>Filing Date</th>
          <th>Title</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="appsClaimingPriority" itemscope repeat>
          <td>
            <span itemprop="applicationNumber">KR10-2018-0108252</span>
            
          </td>
          <td itemprop="priorityDate"></td>
          <td itemprop="filingDate">2018-09-11</td>
          <td itemprop="title"></td>
        </tr>
        <tr itemprop="appsClaimingPriority" itemscope repeat>
          <td>
            <span itemprop="applicationNumber">KR1020180108252A</span>
            <a href="/patent/KR20200029785A/en">
              <span itemprop="representativePublication">KR20200029785A</span>
                (<span itemprop="primaryLanguage">en</span>)
            </a>
          </td>
          <td itemprop="priorityDate">2018-09-11</td>
          <td itemprop="filingDate">2018-09-11</td>
          <td itemprop="title">Localization method and apparatus of displaying virtual object in augmented reality 
     </td>
        </tr>
        <tr itemprop="appsClaimingPriority" itemscope repeat>
          <td>
            <span itemprop="applicationNumber">US16/259,420</span>
            <a href="/patent/US11037368B2/en">
              <span itemprop="representativePublication">US11037368B2</span>
                (<span itemprop="primaryLanguage">en</span>)
            </a>
          </td>
          <td itemprop="priorityDate">2018-09-11</td>
          <td itemprop="filingDate">2019-01-28</td>
          <td itemprop="title">Localization method and apparatus of displaying virtual object in augmented reality 
       </td>
        </tr>
        <tr itemprop="appsClaimingPriority" itemscope repeat>
          <td>
            <span itemprop="applicationNumber">US17/335,199</span>
            <a href="/patent/US11842447B2/en">
              <span itemprop="representativePublication">US11842447B2</span>
                (<span itemprop="primaryLanguage">en</span>)
            </a>
          </td>
          <td itemprop="priorityDate">2018-09-11</td>
          <td itemprop="filingDate">2021-06-01</td>
          <td itemprop="title">Localization method and apparatus of displaying virtual object in augmented reality 
       </td>
        </tr>
      </tbody>
    </table>

    <h2>Related Parent Applications (1)</h2>
    <table>
      <thead>
        <tr>
          <th>Application Number</th>
          <th>Title</th>
          <th>Priority Date</th>
          <th>Filing Date</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="parentApps" itemscope repeat>
          <td>
            <span itemprop="applicationNumber">US16/259,420</span>
            <span itemprop="relationType">Continuation</span>
            <a href="/patent/US11037368B2/en">
              <span itemprop="representativePublication">US11037368B2</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
          </td>
          <td itemprop="priorityDate">2018-09-11</td>
          <td itemprop="filingDate">2019-01-28</td>
          <td itemprop="title">Localization method and apparatus of displaying virtual object in augmented reality 
       </td>
        </tr>
      </tbody>
    </table>

    

    <h2>Publications (2)</h2>
    <table>
      <thead>
        <tr>
          <th>Publication Number</th>
          <th>Publication Date</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="pubs" itemscope repeat>
          <td>
            <span itemprop="publicationNumber">US20210287438A1</span>
            
            <span itemprop="thisPatent">true</span>
            <a href="/patent/US20210287438A1/en">
              US20210287438A1
              (<span itemprop="primaryLanguage">en</span>)
            </a>
          </td>
          <td itemprop="publicationDate">2021-09-16</td>
        </tr>
        <tr itemprop="pubs" itemscope repeat>
          <td>
            <span itemprop="publicationNumber">US11842447B2</span>
            
            <a href="/patent/US11842447B2/en">
              US11842447B2
              (<span itemprop="primaryLanguage">en</span>)
            </a>
          </td>
          <td itemprop="publicationDate">2023-12-12</td>
        </tr>
      </tbody>
    </table>

  </section>

  <section itemprop="family" itemscope>
    <h1>Family</h1>
    <h2>ID=67253823</h2>

    <h2>Family Applications (2)</h2>
    <table>
      <thead>
        <tr>
          <th>Application Number</th>
          <th>Title</th>
          <th>Priority Date</th>
          <th>Filing Date</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="applications" itemscope repeat>
          <td>
            <span itemprop="applicationNumber">US16/259,420</span>
            <span itemprop="ifiStatus">Active</span>
            
            <a href="/patent/US11037368B2/en">
              <span itemprop="representativePublication">US11037368B2</span>
                (<span itemprop="primaryLanguage">en</span>)
            </a>
          </td>
          <td itemprop="priorityDate">2018-09-11</td>
          <td itemprop="filingDate">2019-01-28</td>
          <td itemprop="title">Localization method and apparatus of displaying virtual object in augmented reality 
       </td>
        </tr>
        <tr itemprop="applications" itemscope repeat>
          <td>
            <span itemprop="applicationNumber">US17/335,199</span>
            <span itemprop="ifiStatus">Active</span>
            
            <a href="/patent/US11842447B2/en">
              <span itemprop="representativePublication">US11842447B2</span>
                (<span itemprop="primaryLanguage">en</span>)
            </a>
          </td>
          <td itemprop="priorityDate">2018-09-11</td>
          <td itemprop="filingDate">2021-06-01</td>
          <td itemprop="title">Localization method and apparatus of displaying virtual object in augmented reality 
       </td>
        </tr>
      </tbody>
    </table>

    <h2>Family Applications Before (1)</h2>
    <table>
      <thead>
        <tr>
          <th>Application Number</th>
          <th>Title</th>
          <th>Priority Date</th>
          <th>Filing Date</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="beforeApplications" itemscope repeat>
          <td>
            <span itemprop="applicationNumber">US16/259,420</span>
            <span itemprop="ifiStatus">Active</span>
            
            <a href="/patent/US11037368B2/en">
                <span itemprop="representativePublication">US11037368B2</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
          </td>
          <td itemprop="priorityDate">2018-09-11</td>
          <td itemprop="filingDate">2019-01-28</td>
          <td itemprop="title">Localization method and apparatus of displaying virtual object in augmented reality 
       </td>
        </tr>
      </tbody>
    </table>

    

    <h2>Country Status (5)</h2>
    <table>
      <thead>
        <tr>
          <th>Country</th>
          <th>Link</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="countryStatus" itemscope repeat>
          <td>
            <span itemprop="countryCode">US</span>
            (<span itemprop="num">2</span>)
            <meta itemprop="thisCountry" content="true">
          </td>
          <td>
            <a href="/patent/US11037368B2/en">
              <span itemprop="representativePublication">US11037368B2</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
          </td>
        </tr>
        <tr itemprop="countryStatus" itemscope repeat>
          <td>
            <span itemprop="countryCode">EP</span>
            (<span itemprop="num">1</span>)
            
          </td>
          <td>
            <a href="/patent/EP3623761B1/en">
              <span itemprop="representativePublication">EP3623761B1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
          </td>
        </tr>
        <tr itemprop="countryStatus" itemscope repeat>
          <td>
            <span itemprop="countryCode">JP</span>
            (<span itemprop="num">1</span>)
            
          </td>
          <td>
            <a href="/patent/JP7269082B2/en">
              <span itemprop="representativePublication">JP7269082B2</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
          </td>
        </tr>
        <tr itemprop="countryStatus" itemscope repeat>
          <td>
            <span itemprop="countryCode">KR</span>
            (<span itemprop="num">1</span>)
            
          </td>
          <td>
            <a href="/patent/KR20200029785A/en">
              <span itemprop="representativePublication">KR20200029785A</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
          </td>
        </tr>
        <tr itemprop="countryStatus" itemscope repeat>
          <td>
            <span itemprop="countryCode">CN</span>
            (<span itemprop="num">1</span>)
            
          </td>
          <td>
            <a href="/patent/CN110889872A/en">
              <span itemprop="representativePublication">CN110889872A</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
          </td>
        </tr>
      </tbody>
    </table>

    

    <h2>Families Citing this family (15)</h2>
    <table>
      <caption>* Cited by examiner,  Cited by third party</caption>
      <thead>
        <tr>
          <th>Publication number</th>
          <th>Priority date</th>
          <th>Publication date</th>
          <th>Assignee</th>
          <th>Title</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="forwardReferencesFamily" itemscope repeat>
          <td>
            <a href="/patent/US10255529B2/en">
              <span itemprop="publicationNumber">US10255529B2</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            
            
          </td>
          <td itemprop="priorityDate">2016-03-11</td>
          <td itemprop="publicationDate">2019-04-09</td>
          <td><span itemprop="assigneeOriginal">Magic Leap, Inc.</span></td>
          <td itemprop="title">Structure learning in convolutional neural networks 
       </td>
        </tr>
        <tr itemprop="forwardReferencesFamily" itemscope repeat>
          <td>
            <a href="/patent/JP6772944B2/en">
              <span itemprop="publicationNumber">JP6772944B2</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            
            
          </td>
          <td itemprop="priorityDate">2017-04-19</td>
          <td itemprop="publicationDate">2020-10-21</td>
          <td><span itemprop="assigneeOriginal"></span></td>
          <td itemprop="title">
  Autonomous driving system
 
     </td>
        </tr>
        <tr itemprop="forwardReferencesFamily" itemscope repeat>
          <td>
            <a href="/patent/JP6847885B2/en">
              <span itemprop="publicationNumber">JP6847885B2</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2018-03-20</td>
          <td itemprop="publicationDate">2021-03-24</td>
          <td><span itemprop="assigneeOriginal"></span></td>
          <td itemprop="title">
  Information processing equipment, information processing methods and programs
 
     </td>
        </tr>
        <tr itemprop="forwardReferencesFamily" itemscope repeat>
          <td>
            <a href="/patent/KR102627453B1/en">
              <span itemprop="publicationNumber">KR102627453B1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2018-10-17</td>
          <td itemprop="publicationDate">2024-01-19</td>
          <td><span itemprop="assigneeOriginal"></span></td>
          <td itemprop="title">Method and device to estimate position 
       </td>
        </tr>
        <tr itemprop="forwardReferencesFamily" itemscope repeat>
          <td>
            <a href="/patent/US10824151B2/en">
              <span itemprop="publicationNumber">US10824151B2</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2019-01-31</td>
          <td itemprop="publicationDate">2020-11-03</td>
          <td><span itemprop="assigneeOriginal">StradVision, Inc.</span></td>
          <td itemprop="title">Method and device for providing personalized and calibrated adaptive deep learning model for the user of an autonomous vehicle 
       </td>
        </tr>
        <tr itemprop="forwardReferencesFamily" itemscope repeat>
          <td>
            <a href="/patent/US11775836B2/en">
              <span itemprop="publicationNumber">US11775836B2</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            
            
          </td>
          <td itemprop="priorityDate">2019-05-21</td>
          <td itemprop="publicationDate">2023-10-03</td>
          <td><span itemprop="assigneeOriginal">Magic Leap, Inc.</span></td>
          <td itemprop="title">Hand pose estimation 
       </td>
        </tr>
        <tr itemprop="forwardReferencesFamily" itemscope repeat>
          <td>
            <a href="/patent/US11829128B2/en">
              <span itemprop="publicationNumber">US11829128B2</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            
            
          </td>
          <td itemprop="priorityDate">2019-10-23</td>
          <td itemprop="publicationDate">2023-11-28</td>
          <td><span itemprop="assigneeOriginal">GM Global Technology Operations LLC</span></td>
          <td itemprop="title">Perception system diagnosis using predicted sensor data and perception results 
       </td>
        </tr>
        <tr itemprop="forwardReferencesFamily" itemscope repeat>
          <td>
            <a href="/patent/CN111459269B/en">
              <span itemprop="publicationNumber">CN111459269B</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2020-03-24</td>
          <td itemprop="publicationDate">2020-12-01</td>
          <td><span itemprop="assigneeOriginal">()</span></td>
          <td itemprop="title">Augmented reality display method, system and computer readable storage medium 
       </td>
        </tr>
        <tr itemprop="forwardReferencesFamily" itemscope repeat>
          <td>
            <a href="/patent/IT202000006472A1/en">
              <span itemprop="publicationNumber">IT202000006472A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2020-03-27</td>
          <td itemprop="publicationDate">2021-09-27</td>
          <td><span itemprop="assigneeOriginal">Invisible Cities S R L</span></td>
          <td itemprop="title">
  System configured to associate a virtual scenario with a real scenario during the movement of a vehicle within a geographical area of interest.
 
       </td>
        </tr>
        <tr itemprop="forwardReferencesFamily" itemscope repeat>
          <td>
            <a href="/patent/GB2594249A/en">
              <span itemprop="publicationNumber">GB2594249A</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            
            
          </td>
          <td itemprop="priorityDate">2020-04-20</td>
          <td itemprop="publicationDate">2021-10-27</td>
          <td><span itemprop="assigneeOriginal">Continental Automotive Gmbh</span></td>
          <td itemprop="title">Method for creating a virtual environment reconstruction of an actual location 
       </td>
        </tr>
        <tr itemprop="forwardReferencesFamily" itemscope repeat>
          <td>
            <a href="/patent/CN111623795B/en">
              <span itemprop="publicationNumber">CN111623795B</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2020-05-28</td>
          <td itemprop="publicationDate">2022-04-15</td>
          <td><span itemprop="assigneeOriginal">()</span></td>
          <td itemprop="title">Live-action navigation icon display method, device, equipment and medium 
       </td>
        </tr>
        <tr itemprop="forwardReferencesFamily" itemscope repeat>
          <td>
            <a href="/patent/CN112781620B/en">
              <span itemprop="publicationNumber">CN112781620B</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2020-12-30</td>
          <td itemprop="publicationDate">2022-03-18</td>
          <td><span itemprop="assigneeOriginal"></span></td>
          <td itemprop="title">AR-HUD image calibration adjustment system and method based on high-precision map system 
       </td>
        </tr>
        <tr itemprop="forwardReferencesFamily" itemscope repeat>
          <td>
            <a href="/patent/US11590423B2/en">
              <span itemprop="publicationNumber">US11590423B2</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            
            
          </td>
          <td itemprop="priorityDate">2021-03-29</td>
          <td itemprop="publicationDate">2023-02-28</td>
          <td><span itemprop="assigneeOriginal">Niantic, Inc.</span></td>
          <td itemprop="title">Multi-user route tracking in an augmented reality environment 
       </td>
        </tr>
        <tr itemprop="forwardReferencesFamily" itemscope repeat>
          <td>
            <a href="/patent/CN113434620A/en">
              <span itemprop="publicationNumber">CN113434620A</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2021-06-25</td>
          <td itemprop="publicationDate">2021-09-24</td>
          <td><span itemprop="assigneeOriginal">()</span></td>
          <td itemprop="title">Display method, device, equipment, storage medium and computer program product 
       </td>
        </tr>
        <tr itemprop="forwardReferencesFamily" itemscope repeat>
          <td>
            <a href="/patent/CN113566847B/en">
              <span itemprop="publicationNumber">CN113566847B</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2021-07-22</td>
          <td itemprop="publicationDate">2022-10-11</td>
          <td><span itemprop="assigneeOriginal"></span></td>
          <td itemprop="title">Navigation calibration method and device, electronic equipment and computer readable medium 
       </td>
        </tr>
      </tbody>
    </table>

    <h2>Citations (5)</h2>
    <table>
      <caption>* Cited by examiner,  Cited by third party</caption>
      <thead>
        <tr>
          <th>Publication number</th>
          <th>Priority date</th>
          <th>Publication date</th>
          <th>Assignee</th>
          <th>Title</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="backwardReferencesOrig" itemscope repeat>
          <td>
            <a href="/patent/US20050180602A1/en">
              <span itemprop="publicationNumber">US20050180602A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2004-02-17</td>
          <td itemprop="publicationDate">2005-08-18</td>
          <td>
            <span itemprop="assigneeOriginal">Ming-Hsuan Yang</span>
          </td>
          <td itemprop="title">Method, apparatus and program for detecting an object 
       </td>
        </tr>
        <tr itemprop="backwardReferencesOrig" itemscope repeat>
          <td>
            <a href="/patent/US20130294642A1/en">
              <span itemprop="publicationNumber">US20130294642A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2012-05-01</td>
          <td itemprop="publicationDate">2013-11-07</td>
          <td>
            <span itemprop="assigneeOriginal">Hulu Llc</span>
          </td>
          <td itemprop="title">Augmenting video with facial recognition 
       </td>
        </tr>
        <tr itemprop="backwardReferencesOrig" itemscope repeat>
          <td>
            <a href="/patent/US20150356741A1/en">
              <span itemprop="publicationNumber">US20150356741A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2014-06-04</td>
          <td itemprop="publicationDate">2015-12-10</td>
          <td>
            <span itemprop="assigneeOriginal">Canon Kabushiki Kaisha</span>
          </td>
          <td itemprop="title">Image transmission system, image processing apparatus, image storage apparatus, and control methods thereof 
       </td>
        </tr>
        <tr itemprop="backwardReferencesOrig" itemscope repeat>
          <td>
            <a href="/patent/US20190122115A1/en">
              <span itemprop="publicationNumber">US20190122115A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2017-10-24</td>
          <td itemprop="publicationDate">2019-04-25</td>
          <td>
            <span itemprop="assigneeOriginal">Vmaxx, Inc.</span>
          </td>
          <td itemprop="title">Image Quality Assessment Using Similar Scenes as Reference 
       </td>
        </tr>
        <tr itemprop="backwardReferencesOrig" itemscope repeat>
          <td>
            <a href="/patent/US20200119830A1/en">
              <span itemprop="publicationNumber">US20200119830A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2018-10-16</td>
          <td itemprop="publicationDate">2020-04-16</td>
          <td>
            <span itemprop="assigneeOriginal">Nec Laboratories America, Inc</span>
          </td>
          <td itemprop="title">Machine learning based classification of higher-order spatial modes 
     </td>
        </tr>
      </tbody>
    </table>

    <h2>Family Cites Families (25)</h2>
    <table>
      <caption>* Cited by examiner,  Cited by third party</caption>
      <thead>
        <tr>
          <th>Publication number</th>
          <th>Priority date</th>
          <th>Publication date</th>
          <th>Assignee</th>
          <th>Title</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="backwardReferencesFamily" itemscope repeat>
          <td>
            <a href="/patent/JP4696248B2/en">
              <span itemprop="publicationNumber">JP4696248B2</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2004-09-28</td>
          <td itemprop="publicationDate">2011-06-08</td>
          <td><span itemprop="assigneeOriginal">  </span></td>
          <td itemprop="title">
  MOBILE NAVIGATION INFORMATION DISPLAY METHOD AND MOBILE NAVIGATION INFORMATION DISPLAY DEVICE
 
       </td>
        </tr>
        <tr itemprop="backwardReferencesFamily" itemscope repeat>
          <td>
            <a href="/patent/KR100774591B1/en">
              <span itemprop="publicationNumber">KR100774591B1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            
            
          </td>
          <td itemprop="priorityDate">2006-03-31</td>
          <td itemprop="publicationDate">2007-11-09</td>
          <td><span itemprop="assigneeOriginal">()</span></td>
          <td itemprop="title">Navigation system and method of navigating using the same 
       </td>
        </tr>
        <tr itemprop="backwardReferencesFamily" itemscope repeat>
          <td>
            <a href="/patent/US8711206B2/en">
              <span itemprop="publicationNumber">US8711206B2</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            
            
          </td>
          <td itemprop="priorityDate">2011-01-31</td>
          <td itemprop="publicationDate">2014-04-29</td>
          <td><span itemprop="assigneeOriginal">Microsoft Corporation</span></td>
          <td itemprop="title">Mobile camera localization using depth maps 
       </td>
        </tr>
        <tr itemprop="backwardReferencesFamily" itemscope repeat>
          <td>
            <a href="/patent/US20120300020A1/en">
              <span itemprop="publicationNumber">US20120300020A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2011-05-27</td>
          <td itemprop="publicationDate">2012-11-29</td>
          <td><span itemprop="assigneeOriginal">Qualcomm Incorporated</span></td>
          <td itemprop="title">Real-time self-localization from panoramic images 
       </td>
        </tr>
        <tr itemprop="backwardReferencesFamily" itemscope repeat>
          <td>
            <a href="/patent/JP5968064B2/en">
              <span itemprop="publicationNumber">JP5968064B2</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            
            
          </td>
          <td itemprop="priorityDate">2012-05-08</td>
          <td itemprop="publicationDate">2016-08-10</td>
          <td><span itemprop="assigneeOriginal"></span></td>
          <td itemprop="title">
  Traveling lane recognition device and traveling lane recognition method
 
     </td>
        </tr>
        <tr itemprop="backwardReferencesFamily" itemscope repeat>
          <td>
            <a href="/patent/JP5805619B2/en">
              <span itemprop="publicationNumber">JP5805619B2</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2012-12-26</td>
          <td itemprop="publicationDate">2015-11-04</td>
          <td><span itemprop="assigneeOriginal"></span></td>
          <td itemprop="title">
  Boundary line recognition device
 
     </td>
        </tr>
        <tr itemprop="backwardReferencesFamily" itemscope repeat>
          <td>
            <a href="/patent/US20140323148A1/en">
              <span itemprop="publicationNumber">US20140323148A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            
            
          </td>
          <td itemprop="priorityDate">2013-04-30</td>
          <td itemprop="publicationDate">2014-10-30</td>
          <td><span itemprop="assigneeOriginal">Qualcomm Incorporated</span></td>
          <td itemprop="title">Wide area localization from slam maps 
       </td>
        </tr>
        <tr itemprop="backwardReferencesFamily" itemscope repeat>
          <td>
            <a href="/patent/KR102020629B1/en">
              <span itemprop="publicationNumber">KR102020629B1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            
            
          </td>
          <td itemprop="priorityDate">2013-05-09</td>
          <td itemprop="publicationDate">2019-11-04</td>
          <td><span itemprop="assigneeOriginal"> </span></td>
          <td itemprop="title">Method of improving Head Up Display using augmented reality and the system thereof 
       </td>
        </tr>
        <tr itemprop="backwardReferencesFamily" itemscope repeat>
          <td>
            <a href="/patent/US9524434B2/en">
              <span itemprop="publicationNumber">US9524434B2</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            
            
          </td>
          <td itemprop="priorityDate">2013-10-04</td>
          <td itemprop="publicationDate">2016-12-20</td>
          <td><span itemprop="assigneeOriginal">Qualcomm Incorporated</span></td>
          <td itemprop="title">Object tracking based on dynamically built environment map data 
       </td>
        </tr>
        <tr itemprop="backwardReferencesFamily" itemscope repeat>
          <td>
            <a href="/patent/KR101610502B1/en">
              <span itemprop="publicationNumber">KR101610502B1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2014-09-02</td>
          <td itemprop="publicationDate">2016-04-07</td>
          <td><span itemprop="assigneeOriginal"></span></td>
          <td itemprop="title">Apparatus and method for recognizing driving enviroment for autonomous vehicle 
       </td>
        </tr>
        <tr itemprop="backwardReferencesFamily" itemscope repeat>
          <td>
            <a href="/patent/US11370422B2/en">
              <span itemprop="publicationNumber">US11370422B2</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            
            
          </td>
          <td itemprop="priorityDate">2015-02-12</td>
          <td itemprop="publicationDate">2022-06-28</td>
          <td><span itemprop="assigneeOriginal">Honda Research Institute Europe Gmbh</span></td>
          <td itemprop="title">Method and system in a vehicle for improving prediction results of an advantageous driver assistant system 
       </td>
        </tr>
        <tr itemprop="backwardReferencesFamily" itemscope repeat>
          <td>
            <a href="/patent/JP6393214B2/en">
              <span itemprop="publicationNumber">JP6393214B2</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            
            
          </td>
          <td itemprop="priorityDate">2015-03-03</td>
          <td itemprop="publicationDate">2018-09-19</td>
          <td><span itemprop="assigneeOriginal"></span></td>
          <td itemprop="title">
  Lane recognition system and computer program
 
     </td>
        </tr>
        <tr itemprop="backwardReferencesFamily" itemscope repeat>
          <td>
            <a href="/patent/JP6550819B2/en">
              <span itemprop="publicationNumber">JP6550819B2</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2015-03-19</td>
          <td itemprop="publicationDate">2019-07-31</td>
          <td><span itemprop="assigneeOriginal"></span></td>
          <td itemprop="title">
  Selection support device and program
 
     </td>
        </tr>
        <tr itemprop="backwardReferencesFamily" itemscope repeat>
          <td>
            <a href="/patent/US9852547B2/en">
              <span itemprop="publicationNumber">US9852547B2</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2015-03-23</td>
          <td itemprop="publicationDate">2017-12-26</td>
          <td><span itemprop="assigneeOriginal">International Business Machines Corporation</span></td>
          <td itemprop="title">Path visualization for augmented reality display device based on received data and probabilistic analysis 
       </td>
        </tr>
        <tr itemprop="backwardReferencesFamily" itemscope repeat>
          <td>
            <a href="/patent/EP3078935A1/en">
              <span itemprop="publicationNumber">EP3078935A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            
            
          </td>
          <td itemprop="priorityDate">2015-04-10</td>
          <td itemprop="publicationDate">2016-10-12</td>
          <td><span itemprop="assigneeOriginal">The European Atomic Energy Community (EURATOM), represented by the European Commission</span></td>
          <td itemprop="title">Method and device for real-time mapping and localization 
       </td>
        </tr>
        <tr itemprop="backwardReferencesFamily" itemscope repeat>
          <td>
            <a href="/patent/US20160358383A1/en">
              <span itemprop="publicationNumber">US20160358383A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2015-06-05</td>
          <td itemprop="publicationDate">2016-12-08</td>
          <td><span itemprop="assigneeOriginal">Steffen Gauglitz</span></td>
          <td itemprop="title">Systems and methods for augmented reality-based remote collaboration 
       </td>
        </tr>
        <tr itemprop="backwardReferencesFamily" itemscope repeat>
          <td>
            <a href="/patent/JP6769440B2/en">
              <span itemprop="publicationNumber">JP6769440B2</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2015-09-18</td>
          <td itemprop="publicationDate">2020-10-14</td>
          <td><span itemprop="assigneeOriginal"></span></td>
          <td itemprop="title">
  Image processing equipment, image processing methods, programs and imaging systems
 
     </td>
        </tr>
        <tr itemprop="backwardReferencesFamily" itemscope repeat>
          <td>
            <a href="/patent/US10540768B2/en">
              <span itemprop="publicationNumber">US10540768B2</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2015-09-30</td>
          <td itemprop="publicationDate">2020-01-21</td>
          <td><span itemprop="assigneeOriginal">Samsung Electronics Co., Ltd.</span></td>
          <td itemprop="title">Apparatus and method to segment object from image 
       </td>
        </tr>
        <tr itemprop="backwardReferencesFamily" itemscope repeat>
          <td>
            <a href="/patent/US9727793B2/en">
              <span itemprop="publicationNumber">US9727793B2</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2015-12-15</td>
          <td itemprop="publicationDate">2017-08-08</td>
          <td><span itemprop="assigneeOriginal">Honda Motor Co., Ltd.</span></td>
          <td itemprop="title">System and method for image based vehicle localization 
       </td>
        </tr>
        <tr itemprop="backwardReferencesFamily" itemscope repeat>
          <td>
            <a href="/patent/US10198808B2/en">
              <span itemprop="publicationNumber">US10198808B2</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2016-01-15</td>
          <td itemprop="publicationDate">2019-02-05</td>
          <td><span itemprop="assigneeOriginal">Instrumental, Inc.</span></td>
          <td itemprop="title">Methods for automatically generating a common measurement across multiple assembly units 
       </td>
        </tr>
        <tr itemprop="backwardReferencesFamily" itemscope repeat>
          <td>
            <a href="/patent/CN106127120B/en">
              <span itemprop="publicationNumber">CN106127120B</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2016-06-16</td>
          <td itemprop="publicationDate">2018-03-13</td>
          <td><span itemprop="assigneeOriginal"></span></td>
          <td itemprop="title">Posture estimation method and device, computer system 
     </td>
        </tr>
        <tr itemprop="backwardReferencesFamily" itemscope repeat>
          <td>
            <a href="/patent/US10229215B2/en">
              <span itemprop="publicationNumber">US10229215B2</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2016-09-26</td>
          <td itemprop="publicationDate">2019-03-12</td>
          <td><span itemprop="assigneeOriginal">Disney Enterprises, Inc.</span></td>
          <td itemprop="title">Visualisation and navigation of transmedia content data 
       </td>
        </tr>
        <tr itemprop="backwardReferencesFamily" itemscope repeat>
          <td>
            <a href="/patent/CN108121764B/en">
              <span itemprop="publicationNumber">CN108121764B</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2016-11-26</td>
          <td itemprop="publicationDate">2022-03-11</td>
          <td><span itemprop="assigneeOriginal"></span></td>
          <td itemprop="title">Image processing device, image processing method, computer program, and computer-readable recording medium 
       </td>
        </tr>
        <tr itemprop="backwardReferencesFamily" itemscope repeat>
          <td>
            <a href="/patent/JP6669059B2/en">
              <span itemprop="publicationNumber">JP6669059B2</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            
            
          </td>
          <td itemprop="priorityDate">2016-12-27</td>
          <td itemprop="publicationDate">2020-03-18</td>
          <td><span itemprop="assigneeOriginal"></span></td>
          <td itemprop="title">
  Position calculation device
 
     </td>
        </tr>
        <tr itemprop="backwardReferencesFamily" itemscope repeat>
          <td>
            <a href="/patent/US10452927B2/en">
              <span itemprop="publicationNumber">US10452927B2</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2017-08-09</td>
          <td itemprop="publicationDate">2019-10-22</td>
          <td><span itemprop="assigneeOriginal">Ydrive, Inc.</span></td>
          <td itemprop="title">Object localization within a semantic domain 
       </td>
        </tr>
      </tbody>
    </table>

    <ul>
      <li itemprop="applicationsByYear" itemscope repeat>
        <span itemprop="year">2018</span>
        <ul>
          <li itemprop="application" itemscope repeat>
            <span itemprop="filingDate">2018-09-11</span>
            <span itemprop="countryCode">KR</span>
            <span itemprop="applicationNumber">KR1020180108252A</span>
            <a href="/patent/KR20200029785A/en"><span itemprop="documentId">patent/KR20200029785A/en</span></a>
            <span itemprop="legalStatusCat">not_active</span>
            <span itemprop="legalStatus">Application Discontinuation</span>
            
          </li>
        </ul>
      </li>
      <li itemprop="applicationsByYear" itemscope repeat>
        <span itemprop="year">2019</span>
        <ul>
          <li itemprop="application" itemscope repeat>
            <span itemprop="filingDate">2019-01-28</span>
            <span itemprop="countryCode">US</span>
            <span itemprop="applicationNumber">US16/259,420</span>
            <a href="/patent/US11037368B2/en"><span itemprop="documentId">patent/US11037368B2/en</span></a>
            <span itemprop="legalStatusCat">active</span>
            <span itemprop="legalStatus">Active</span>
            
          </li>
          <li itemprop="application" itemscope repeat>
            <span itemprop="filingDate">2019-03-27</span>
            <span itemprop="countryCode">CN</span>
            <span itemprop="applicationNumber">CN201910241914.XA</span>
            <a href="/patent/CN110889872A/en"><span itemprop="documentId">patent/CN110889872A/en</span></a>
            <span itemprop="legalStatusCat">active</span>
            <span itemprop="legalStatus">Pending</span>
            
          </li>
          <li itemprop="application" itemscope repeat>
            <span itemprop="filingDate">2019-04-15</span>
            <span itemprop="countryCode">JP</span>
            <span itemprop="applicationNumber">JP2019077030A</span>
            <a href="/patent/JP7269082B2/en"><span itemprop="documentId">patent/JP7269082B2/en</span></a>
            <span itemprop="legalStatusCat">active</span>
            <span itemprop="legalStatus">Active</span>
            
          </li>
          <li itemprop="application" itemscope repeat>
            <span itemprop="filingDate">2019-07-11</span>
            <span itemprop="countryCode">EP</span>
            <span itemprop="applicationNumber">EP19185859.6A</span>
            <a href="/patent/EP3623761B1/en"><span itemprop="documentId">patent/EP3623761B1/en</span></a>
            <span itemprop="legalStatusCat">active</span>
            <span itemprop="legalStatus">Active</span>
            
          </li>
        </ul>
      </li>
      <li itemprop="applicationsByYear" itemscope repeat>
        <span itemprop="year">2021</span>
        <ul>
          <li itemprop="application" itemscope repeat>
            <span itemprop="filingDate">2021-06-01</span>
            <span itemprop="countryCode">US</span>
            <span itemprop="applicationNumber">US17/335,199</span>
            <a href="/patent/US11842447B2/en"><span itemprop="documentId">patent/US11842447B2/en</span></a>
            <span itemprop="legalStatusCat">active</span>
            <span itemprop="legalStatus">Active</span>
            <span itemprop="thisApp" content="true" bool></span>
          </li>
        </ul>
      </li>
    </ul>

    </section>

  <section>
    <h2>Patent Citations (5)</h2>
    <table>
      <caption>* Cited by examiner,  Cited by third party</caption>
      <thead>
        <tr>
          <th>Publication number</th>
          <th>Priority date</th>
          <th>Publication date</th>
          <th>Assignee</th>
          <th>Title</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="backwardReferences" itemscope repeat>
          <td>
            <a href="/patent/US20050180602A1/en">
              <span itemprop="publicationNumber">US20050180602A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2004-02-17</td>
          <td itemprop="publicationDate">2005-08-18</td>
          <td><span itemprop="assigneeOriginal">Ming-Hsuan Yang</span></td>
          <td itemprop="title">Method, apparatus and program for detecting an object 
       </td>
        </tr>
        <tr itemprop="backwardReferences" itemscope repeat>
          <td>
            <a href="/patent/US20130294642A1/en">
              <span itemprop="publicationNumber">US20130294642A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2012-05-01</td>
          <td itemprop="publicationDate">2013-11-07</td>
          <td><span itemprop="assigneeOriginal">Hulu Llc</span></td>
          <td itemprop="title">Augmenting video with facial recognition 
       </td>
        </tr>
        <tr itemprop="backwardReferences" itemscope repeat>
          <td>
            <a href="/patent/US20150356741A1/en">
              <span itemprop="publicationNumber">US20150356741A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2014-06-04</td>
          <td itemprop="publicationDate">2015-12-10</td>
          <td><span itemprop="assigneeOriginal">Canon Kabushiki Kaisha</span></td>
          <td itemprop="title">Image transmission system, image processing apparatus, image storage apparatus, and control methods thereof 
       </td>
        </tr>
        <tr itemprop="backwardReferences" itemscope repeat>
          <td>
            <a href="/patent/US20190122115A1/en">
              <span itemprop="publicationNumber">US20190122115A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2017-10-24</td>
          <td itemprop="publicationDate">2019-04-25</td>
          <td><span itemprop="assigneeOriginal">Vmaxx, Inc.</span></td>
          <td itemprop="title">Image Quality Assessment Using Similar Scenes as Reference 
       </td>
        </tr>
        <tr itemprop="backwardReferences" itemscope repeat>
          <td>
            <a href="/patent/US20200119830A1/en">
              <span itemprop="publicationNumber">US20200119830A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2018-10-16</td>
          <td itemprop="publicationDate">2020-04-16</td>
          <td><span itemprop="assigneeOriginal">Nec Laboratories America, Inc</span></td>
          <td itemprop="title">Machine learning based classification of higher-order spatial modes 
     </td>
        </tr>
      </tbody>
    </table>
  </section>

  

  

  <section>
    <h2>Also Published As</h2>
    <table>
      <thead>
        <tr>
          <th>Publication number</th>
          <th>Publication date</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="docdbFamily" itemscope repeat>
          <td>
            <a href="/patent/EP3623761B1/en">
              <span itemprop="publicationNumber">EP3623761B1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
          </td>
          <td itemprop="publicationDate">2022-03-23</td>
        </tr>
        <tr itemprop="docdbFamily" itemscope repeat>
          <td>
            <a href="/patent/EP3623761A1/en">
              <span itemprop="publicationNumber">EP3623761A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
          </td>
          <td itemprop="publicationDate">2020-03-18</td>
        </tr>
        <tr itemprop="docdbFamily" itemscope repeat>
          <td>
            <a href="/patent/JP7269082B2/en">
              <span itemprop="publicationNumber">JP7269082B2</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
          </td>
          <td itemprop="publicationDate">2023-05-08</td>
        </tr>
        <tr itemprop="docdbFamily" itemscope repeat>
          <td>
            <a href="/patent/KR20200029785A/en">
              <span itemprop="publicationNumber">KR20200029785A</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
          </td>
          <td itemprop="publicationDate">2020-03-19</td>
        </tr>
        <tr itemprop="docdbFamily" itemscope repeat>
          <td>
            <a href="/patent/US11842447B2/en">
              <span itemprop="publicationNumber">US11842447B2</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
          </td>
          <td itemprop="publicationDate">2023-12-12</td>
        </tr>
        <tr itemprop="docdbFamily" itemscope repeat>
          <td>
            <a href="/patent/JP2020042002A/en">
              <span itemprop="publicationNumber">JP2020042002A</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
          </td>
          <td itemprop="publicationDate">2020-03-19</td>
        </tr>
        <tr itemprop="docdbFamily" itemscope repeat>
          <td>
            <a href="/patent/US20200082621A1/en">
              <span itemprop="publicationNumber">US20200082621A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
          </td>
          <td itemprop="publicationDate">2020-03-12</td>
        </tr>
        <tr itemprop="docdbFamily" itemscope repeat>
          <td>
            <a href="/patent/CN110889872A/en">
              <span itemprop="publicationNumber">CN110889872A</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
          </td>
          <td itemprop="publicationDate">2020-03-17</td>
        </tr>
        <tr itemprop="docdbFamily" itemscope repeat>
          <td>
            <a href="/patent/US11037368B2/en">
              <span itemprop="publicationNumber">US11037368B2</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
          </td>
          <td itemprop="publicationDate">2021-06-15</td>
        </tr>
      </tbody>
    </table>
  </section>

  <section>
    <h2>Similar Documents</h2>
    <table>
      <thead>
        <tr>
          <th>Publication</th>
          <th>Publication Date</th>
          <th>Title</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/US11842447B2/en">
                <span itemprop="publicationNumber">US11842447B2</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2023-12-12">2023-12-12</time>
            
            
          </td>
          <td itemprop="title">Localization method and apparatus of displaying virtual object in augmented reality 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/US10599930B2/en">
                <span itemprop="publicationNumber">US10599930B2</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2020-03-24">2020-03-24</time>
            
            
          </td>
          <td itemprop="title">Method and apparatus of detecting object of interest 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/EP3640599B1/en">
                <span itemprop="publicationNumber">EP3640599B1</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2022-12-21">2022-12-21</time>
            
            
          </td>
          <td itemprop="title">Vehicle localization method and apparatus 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/US11656091B2/en">
                <span itemprop="publicationNumber">US11656091B2</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2023-05-23">2023-05-23</time>
            
            
          </td>
          <td itemprop="title">Content visualizing method and apparatus 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/US11113544B2/en">
                <span itemprop="publicationNumber">US11113544B2</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2021-09-07">2021-09-07</time>
            
            
          </td>
          <td itemprop="title">Method and apparatus providing information for driving vehicle 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/US11468690B2/en">
                <span itemprop="publicationNumber">US11468690B2</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2022-10-11">2022-10-11</time>
            
            
          </td>
          <td itemprop="title">Map partition system for autonomous vehicles 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/US11227398B2/en">
                <span itemprop="publicationNumber">US11227398B2</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2022-01-18">2022-01-18</time>
            
            
          </td>
          <td itemprop="title">RGB point clouds based map generation system for autonomous vehicles 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/EP3707469B1/en">
                <span itemprop="publicationNumber">EP3707469B1</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2023-10-11">2023-10-11</time>
            
            
          </td>
          <td itemprop="title">A point clouds registration system for autonomous vehicles 
     </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/US11176719B2/en">
                <span itemprop="publicationNumber">US11176719B2</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2021-11-16">2021-11-16</time>
            
            
          </td>
          <td itemprop="title">Method and apparatus for localization based on images and map data 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/US11462023B2/en">
                <span itemprop="publicationNumber">US11462023B2</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2022-10-04">2022-10-04</time>
            
            
          </td>
          <td itemprop="title">Systems and methods for 3D object detection 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/US20210327128A1/en">
                <span itemprop="publicationNumber">US20210327128A1</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2021-10-21">2021-10-21</time>
            
            
          </td>
          <td itemprop="title">A point clouds ghosting effects detection system for autonomous driving vehicles 
     </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/US10891795B2/en">
                <span itemprop="publicationNumber">US10891795B2</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2021-01-12">2021-01-12</time>
            
            
          </td>
          <td itemprop="title">Localization method and apparatus based on 3D color map 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/US11720992B2/en">
                <span itemprop="publicationNumber">US11720992B2</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2023-08-08">2023-08-08</time>
            
            
          </td>
          <td itemprop="title">Method, apparatus, and computer program product for generating an overhead view of an environment from a perspective image 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/US11544507B2/en">
                <span itemprop="publicationNumber">US11544507B2</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2023-01-03">2023-01-03</time>
            
            
          </td>
          <td itemprop="title">Method and apparatus to train image recognition model, and image recognition method and apparatus 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/CN113916242A/en">
                <span itemprop="publicationNumber">CN113916242A</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2022-01-11">2022-01-11</time>
            
            
          </td>
          <td itemprop="title">Lane positioning method and device, storage medium and electronic equipment 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/CN115705693A/en">
                <span itemprop="publicationNumber">CN115705693A</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2023-02-17">2023-02-17</time>
            
            
          </td>
          <td itemprop="title">Method, system and storage medium for annotation of sensor data 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/US20220366706A1/en">
                <span itemprop="publicationNumber">US20220366706A1</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2022-11-17">2022-11-17</time>
            
            
          </td>
          <td itemprop="title">Vehicle environment modeling with a camera 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/JP7427556B2/en">
                <span itemprop="publicationNumber">JP7427556B2</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2024-02-05">2024-02-05</time>
            
            
          </td>
          <td itemprop="title">
  Operation control device, operation control method and program
 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/CN114972136A/en">
                <span itemprop="publicationNumber">CN114972136A</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2022-08-30">2022-08-30</time>
            
            
          </td>
          <td itemprop="title">Training method of 3D target detection model, and 3D target detection method and device 
       </td>
        </tr>
      </tbody>
    </table>
  </section>

  <section>
    <h2>Legal Events</h2>
    <table>
      <thead>
        <tr>
          <th>Date</th>
          <th>Code</th>
          <th>Title</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="legalEvents" itemscope repeat>
          <td><time itemprop="date" datetime="2021-06-01">2021-06-01</time></td>
          <td itemprop="code">FEPP</td>
          <td itemprop="title">Fee payment procedure</td>
          <td>
            <p itemprop="attributes" itemscope repeat>
              <strong itemprop="label">Free format text</strong>:
              <span itemprop="value">ENTITY STATUS SET TO UNDISCOUNTED (ORIGINAL EVENT CODE: BIG.); ENTITY STATUS OF PATENT OWNER: LARGE ENTITY</span>
            </p>
          </td>
        </tr>
        <tr itemprop="legalEvents" itemscope repeat>
          <td><time itemprop="date" datetime="2021-08-23">2021-08-23</time></td>
          <td itemprop="code">STPP</td>
          <td itemprop="title">Information on status: patent application and granting procedure in general</td>
          <td>
            <p itemprop="attributes" itemscope repeat>
              <strong itemprop="label">Free format text</strong>:
              <span itemprop="value">DOCKETED NEW CASE - READY FOR EXAMINATION</span>
            </p>
          </td>
        </tr>
        <tr itemprop="legalEvents" itemscope repeat>
          <td><time itemprop="date" datetime="2022-09-12">2022-09-12</time></td>
          <td itemprop="code">STPP</td>
          <td itemprop="title">Information on status: patent application and granting procedure in general</td>
          <td>
            <p itemprop="attributes" itemscope repeat>
              <strong itemprop="label">Free format text</strong>:
              <span itemprop="value">NON FINAL ACTION MAILED</span>
            </p>
          </td>
        </tr>
        <tr itemprop="legalEvents" itemscope repeat>
          <td><time itemprop="date" datetime="2022-12-03">2022-12-03</time></td>
          <td itemprop="code">STPP</td>
          <td itemprop="title">Information on status: patent application and granting procedure in general</td>
          <td>
            <p itemprop="attributes" itemscope repeat>
              <strong itemprop="label">Free format text</strong>:
              <span itemprop="value">RESPONSE TO NON-FINAL OFFICE ACTION ENTERED AND FORWARDED TO EXAMINER</span>
            </p>
          </td>
        </tr>
        <tr itemprop="legalEvents" itemscope repeat>
          <td><time itemprop="date" datetime="2023-05-04">2023-05-04</time></td>
          <td itemprop="code">STPP</td>
          <td itemprop="title">Information on status: patent application and granting procedure in general</td>
          <td>
            <p itemprop="attributes" itemscope repeat>
              <strong itemprop="label">Free format text</strong>:
              <span itemprop="value">NON FINAL ACTION MAILED</span>
            </p>
          </td>
        </tr>
        <tr itemprop="legalEvents" itemscope repeat>
          <td><time itemprop="date" datetime="2023-08-07">2023-08-07</time></td>
          <td itemprop="code">STPP</td>
          <td itemprop="title">Information on status: patent application and granting procedure in general</td>
          <td>
            <p itemprop="attributes" itemscope repeat>
              <strong itemprop="label">Free format text</strong>:
              <span itemprop="value">NOTICE OF ALLOWANCE MAILED -- APPLICATION RECEIVED IN OFFICE OF PUBLICATIONS</span>
            </p>
          </td>
        </tr>
        <tr itemprop="legalEvents" itemscope repeat>
          <td><time itemprop="date" datetime="2023-11-02">2023-11-02</time></td>
          <td itemprop="code">STPP</td>
          <td itemprop="title">Information on status: patent application and granting procedure in general</td>
          <td>
            <p itemprop="attributes" itemscope repeat>
              <strong itemprop="label">Free format text</strong>:
              <span itemprop="value">PUBLICATIONS -- ISSUE FEE PAYMENT RECEIVED</span>
            </p>
          </td>
        </tr>
        <tr itemprop="legalEvents" itemscope repeat>
          <td><time itemprop="date" datetime="2023-11-07">2023-11-07</time></td>
          <td itemprop="code">STPP</td>
          <td itemprop="title">Information on status: patent application and granting procedure in general</td>
          <td>
            <p itemprop="attributes" itemscope repeat>
              <strong itemprop="label">Free format text</strong>:
              <span itemprop="value">PUBLICATIONS -- ISSUE FEE PAYMENT VERIFIED</span>
            </p>
          </td>
        </tr>
        <tr itemprop="legalEvents" itemscope repeat>
          <td><time itemprop="date" datetime="2023-11-22">2023-11-22</time></td>
          <td itemprop="code">STCF</td>
          <td itemprop="title">Information on status: patent grant</td>
          <td>
            <p itemprop="attributes" itemscope repeat>
              <strong itemprop="label">Free format text</strong>:
              <span itemprop="value">PATENTED CASE</span>
            </p>
          </td>
        </tr>
      </tbody>
    </table>
  </section>

</article>

    </search-app>
    <script type="text/javascript" src="//www.gstatic.com/feedback/api.js"></script>
    <script type="text/javascript" src="//www.gstatic.com/feedback/js/help/prod/service/lazy.min.js"></script>
    <script type="text/javascript">
      if (window.help && window.help.service) {
        helpApi = window.help.service.Lazy.create(0, {apiKey: 'AIzaSyDTEI_0tLX4varJ7bwK8aT-eOI5qr3BmyI', locale: 'en-US'});
        window.requestedSurveys = new Set();
        window.requestSurvey = function(triggerId) {
          if (window.requestedSurveys.has(triggerId)) {
            return;
          }
          window.requestedSurveys.add(triggerId);
          helpApi.requestSurvey({
            triggerId: triggerId,
            enableTestingMode: false,
            callback: (requestSurveyCallbackParam) => {
              if (!requestSurveyCallbackParam.surveyData) {
                return;
              }
              helpApi.presentSurvey({
                productData: {
                  productVersion: window.version,
                  customData: {
                    "experiments": "72459301,72474719",
                  },
                },
                surveyData: requestSurveyCallbackParam.surveyData,
                colorScheme: 1,
                customZIndex: 10000,
              });
            }
          });
        };

        window.requestSurvey('YXTwAsvoW0kedxbuTdH0RArc9VhT');
      }
    </script>
    <script src="/sw/null_loader.js"></script>
  </body>
</html>
