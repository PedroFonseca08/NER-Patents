<!DOCTYPE html>
<html lang="en">
  <head>
    <title>US20230386192A1 - Deep neural network-based real-time inference method, and cloud device and edge device performing deep neural network-based real-time inference method 
      - Google Patents</title>

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta charset="UTF-8">
    <meta name="referrer" content="origin-when-crossorigin">
    <link rel="canonical" href="https://patents.google.com/patent/US20230386192A1/en">
    <meta name="description" content="
     The present disclosure relates to a deep neural network-based real-time inference apparatus, system, and method, and more particularly, to a deep neural network-based real-time inference apparatus, system, and method capable of accelerating image inference. 
   
   ">
    <meta name="DC.type" content="patent">
    <meta name="DC.title" content="Deep neural network-based real-time inference method, and cloud device and edge device performing deep neural network-based real-time inference method 
     ">
    <meta name="DC.date" content="2023-05-31" scheme="dateSubmitted">
    <meta name="DC.description" content="
     The present disclosure relates to a deep neural network-based real-time inference apparatus, system, and method, and more particularly, to a deep neural network-based real-time inference apparatus, system, and method capable of accelerating image inference. 
   
   ">
    <meta name="citation_patent_application_number" content="US:18/203,695">
    <meta name="citation_pdf_url" content="https://patentimages.storage.googleapis.com/eb/42/35/19c41f8c1d1b22/US20230386192A1.pdf">
    <meta name="citation_patent_publication_number" content="US:20230386192:A1">
    <meta name="DC.date" content="2023-11-30">
    <meta name="DC.contributor" content="Joo Chan LEE" scheme="inventor">
    <meta name="DC.contributor" content="Jong Hwan KO" scheme="inventor">
    <meta name="DC.contributor" content="Sungkyunkwan University Research and Business Foundation" scheme="assignee">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:400,400italic,500,500italic,700">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Product+Sans">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Google+Sans:wght@400;500;700">

    <style>
      body { transition: none; }
    </style>

    <script>
      window.version = 'patent-search.search_20240108_RC01';

      function sendFeedback() {
        userfeedback.api.startFeedback({
          'productId': '713680',
          'bucket': 'patent-search-web',
          'productVersion': window.version,
        });
      }

      window.experiments = {};
      window.experiments.patentCountries = "ae,ag,al,am,ao,ap,ar,at,au,aw,az,ba,bb,bd,be,bf,bg,bh,bj,bn,bo,br,bw,bx,by,bz,ca,cf,cg,ch,ci,cl,cm,cn,co,cr,cs,cu,cy,cz,dd,de,dj,dk,dm,do,dz,ea,ec,ee,eg,em,ep,es,fi,fr,ga,gb,gc,gd,ge,gh,gm,gn,gq,gr,gt,gw,hk,hn,hr,hu,ib,id,ie,il,in,ir,is,it,jo,jp,ke,kg,kh,km,kn,kp,kr,kw,kz,la,lc,li,lk,lr,ls,lt,lu,lv,ly,ma,mc,md,me,mg,mk,ml,mn,mo,mr,mt,mw,mx,my,mz,na,ne,ng,ni,nl,no,nz,oa,om,pa,pe,pg,ph,pl,pt,py,qa,ro,rs,ru,rw,sa,sc,sd,se,sg,si,sk,sl,sm,sn,st,su,sv,sy,sz,td,tg,th,tj,tm,tn,tr,tt,tw,tz,ua,ug,us,uy,uz,vc,ve,vn,wo,yu,za,zm,zw";
      
      
      window.experiments.keywordWizard = true;
      
      
      
      window.experiments.definitions = true;

      window.Polymer = {
        dom: 'shady',
        lazyRegister: true,
      };
    </script>

    <script src="//www.gstatic.com/patent-search/frontend/patent-search.search_20240108_RC01/scs/compiled_dir/webcomponentsjs/webcomponents-lite.min.js"></script>
    <link rel="import" href="//www.gstatic.com/patent-search/frontend/patent-search.search_20240108_RC01/scs/compiled_dir/search-app-vulcanized.html">
  </head>
  <body unresolved>
    <script src="//www.gstatic.com/patent-search/frontend/patent-search.search_20240108_RC01/scs/compiled_dir/search-app-vulcanized.js"></script>
    <search-app>
      
      

      <article class="result" itemscope itemtype="http://schema.org/ScholarlyArticle">
  <h1 itemprop="pageTitle">US20230386192A1 - Deep neural network-based real-time inference method, and cloud device and edge device performing deep neural network-based real-time inference method 
      - Google Patents</h1>
  <span itemprop="title">Deep neural network-based real-time inference method, and cloud device and edge device performing deep neural network-based real-time inference method 
     </span>

  <meta itemprop="type" content="patent">
  <a href="https://patentimages.storage.googleapis.com/eb/42/35/19c41f8c1d1b22/US20230386192A1.pdf" itemprop="pdfLink">Download PDF</a>
  <h2>Info</h2>

  <dl>
    <dt>Publication number</dt>
    <dd itemprop="publicationNumber">US20230386192A1</dd>
    <meta itemprop="numberWithoutCodes" content="20230386192">
    <meta itemprop="kindCode" content="A1">
    <meta itemprop="publicationDescription" content="Patent application publication">
    <span>US20230386192A1</span>
    <span>US18/203,695</span>
    <span>US202318203695A</span>
    <span>US2023386192A1</span>
    <span>US 20230386192 A1</span>
    <span>US20230386192 A1</span>
    <span>US 20230386192A1</span>
    <span>  </span>
    <span> </span>
    <span> </span>
    <span>US 202318203695 A</span>
    <span>US202318203695 A</span>
    <span>US 202318203695A</span>
    <span>US 2023386192 A1</span>
    <span>US2023386192 A1</span>
    <span>US 2023386192A1</span>

    <dt>Authority</dt>
    <dd itemprop="countryCode">US</dd>
    <dd itemprop="countryName">United States</dd>

    <dt>Prior art keywords</dt>
    <dd itemprop="priorArtKeywords" repeat>artificial intelligence</dd>
    <dd itemprop="priorArtKeywords" repeat>layer</dd>
    <dd itemprop="priorArtKeywords" repeat>intelligence model</dd>
    <dd itemprop="priorArtKeywords" repeat>feature</dd>
    <dd itemprop="priorArtKeywords" repeat>neural network</dd>

    <dt>Prior art date</dt>
    <dd><time itemprop="priorArtDate" datetime="2022-05-31">2022-05-31</time></dd>

    <dt>Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)</dt>
    <dd itemprop="legalStatusIfi" itemscope>
      <span itemprop="status">Pending</span>
    </dd>
  </dl>

  <dt>Application number</dt>
  <dd itemprop="applicationNumber">US18/203,695</dd>

  

  

  <dt>Inventor</dt>
  <dd itemprop="inventor" repeat>Joo Chan LEE</dd>
  <dd itemprop="inventor" repeat>Jong Hwan KO</dd>

  <dt>Current Assignee (The listed assignees may be inaccurate. Google has not performed a legal analysis and makes no representation or warranty as to the accuracy of the list.)</dt>
  <dd itemprop="assigneeCurrent" repeat>
    Sungkyunkwan University Research and Business Foundation
  </dd>

  <dt>Original Assignee</dt>
  <dd itemprop="assigneeOriginal" repeat>Sungkyunkwan University Research and Business Foundation</dd>

  <dt>Priority date (The priority date is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the date listed.)</dt>
  <dd><time itemprop="priorityDate" datetime="2022-05-31">2022-05-31</time></dd>

  <dt>Filing date</dt>
  <dd><time itemprop="filingDate" datetime="2023-05-31">2023-05-31</time></dd>

  <dt>Publication date</dt>
  <dd><time itemprop="publicationDate" datetime="2023-11-30">2023-11-30</time></dd>

  
  <dd itemprop="events" itemscope repeat>
    <time itemprop="date" datetime="2023-05-31">2023-05-31</time>
    <span itemprop="title">Application filed by Sungkyunkwan University Research and Business Foundation</span>
    <span itemprop="type">filed</span>
    <span itemprop="critical" content="true" bool>Critical</span>
    
    
    
    <span itemprop="assigneeSearch">Sungkyunkwan University Research and Business Foundation</span>
  </dd>
  <dd itemprop="events" itemscope repeat>
    <time itemprop="date" datetime="2023-05-31">2023-05-31</time>
    <span itemprop="title">Assigned to Research &amp; Business Foundation Sungkyunkwan University</span>
    <span itemprop="type">reassignment</span>
    
    
    
    
    <span itemprop="assigneeSearch">Research &amp; Business Foundation Sungkyunkwan University</span>
    <span itemprop="description" repeat>ASSIGNMENT OF ASSIGNORS INTEREST (SEE DOCUMENT FOR DETAILS).</span>
    <span itemprop="description" repeat>Assignors: KO, JONG HWAN, LEE, JOO CHAN</span>
  </dd>
  <dd itemprop="events" itemscope repeat>
    <time itemprop="date" datetime="2023-11-30">2023-11-30</time>
    <span itemprop="title">Publication of US20230386192A1</span>
    <span itemprop="type">publication</span>
    <span itemprop="critical" content="true" bool>Critical</span>
    
    
    <span itemprop="documentId">patent/US20230386192A1/en</span>
    
  </dd>
  <dd itemprop="events" itemscope repeat>
    <time itemprop="date">Status</time>
    <span itemprop="title">Pending</span>
    <span itemprop="type">legal-status</span>
    <span itemprop="critical" content="true" bool>Critical</span>
    <span itemprop="current" content="true" bool>Current</span>
    
    
    
  </dd>

  <h2>Links</h2>
  <ul>
    <li itemprop="links" itemscope repeat>
          <meta itemprop="id" content="usptoLink">
          <a href="https://appft.uspto.gov/netacgi/nph-Parser?Sect1=PTO1&Sect2=HITOFF&p=1&u=/netahtml/PTO/srchnum.html&r=1&f=G&l=50&d=PG01&s1=20230386192.PGNR." itemprop="url" target="_blank"><span itemprop="text">USPTO</span></a>
        </li>
        
        <li itemprop="links" itemscope repeat>
          <meta itemprop="id" content="usptoPatentCenterLink">
          <a href="https://patentcenter.uspto.gov/applications/18203695" itemprop="url" target="_blank"><span itemprop="text">USPTO PatentCenter</span></a>
        </li>
        <li itemprop="links" itemscope repeat>
          <meta itemprop="id" content="usptoAssignmentLink">
          <a href="https://assignment.uspto.gov/patent/index.html#/patent/search/resultFilter?searchInput=20230386192" itemprop="url" target="_blank"><span itemprop="text">USPTO Assignment</span></a>
        </li>

    <li itemprop="links" itemscope repeat>
        <meta itemprop="id" content="espacenetLink">
        <a href="https://worldwide.espacenet.com/publicationDetails/biblio?CC=US&amp;NR=2023386192A1&amp;KC=A1&amp;FT=D" itemprop="url" target="_blank"><span itemprop="text">Espacenet</span></a>
      </li>
      

    

    
      <li itemprop="links" itemscope repeat>
        <meta itemprop="id" content="globalDossierLink">
        <a href="https://globaldossier.uspto.gov/#/result/publication/US/20230386192/1" itemprop="url" target="_blank"><span itemprop="text">Global Dossier</span></a>
      </li>

      

      

      

      <li itemprop="links" itemscope repeat>
        <meta itemprop="id" content="stackexchangeLink">
        <a href="https://patents.stackexchange.com/questions/tagged/US20230386192" itemprop="url"><span itemprop="text">Discuss</span></a>
      </li>
      
  </ul>

  <ul itemprop="concept" itemscope>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000013528</span>
      <span itemprop="name">artificial neural network</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>title</span>
      <span itemprop="sections" repeat>claims</span>
      <span itemprop="sections" repeat>abstract</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">54</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000000034</span>
      <span itemprop="name">method</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>title</span>
      <span itemprop="sections" repeat>claims</span>
      <span itemprop="sections" repeat>abstract</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">29</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000013473</span>
      <span itemprop="name">artificial intelligence</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>claims</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">109</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000013139</span>
      <span itemprop="name">quantization</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>claims</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">34</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000009826</span>
      <span itemprop="name">distribution</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>claims</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">23</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000012545</span>
      <span itemprop="name">processing</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>claims</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">23</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000004458</span>
      <span itemprop="name">analytical method</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>claims</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">4</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000006870</span>
      <span itemprop="name">function</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">12</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000010586</span>
      <span itemprop="name">diagram</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">10</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000010606</span>
      <span itemprop="name">normalization</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">10</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000004891</span>
      <span itemprop="name">communication</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">7</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000011161</span>
      <span itemprop="name">development</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">7</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000007613</span>
      <span itemprop="name">environmental effect</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">6</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000001514</span>
      <span itemprop="name">detection method</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">5</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000011160</span>
      <span itemprop="name">research</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">5</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000005540</span>
      <span itemprop="name">biological transmission</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">4</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000004590</span>
      <span itemprop="name">computer program</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">4</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000005516</span>
      <span itemprop="name">engineering process</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">3</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000008569</span>
      <span itemprop="name">process</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">3</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000003860</span>
      <span itemprop="name">storage</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">3</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000000694</span>
      <span itemprop="name">effects</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">2</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000007781</span>
      <span itemprop="name">pre-processing</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">2</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000012549</span>
      <span itemprop="name">training</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">2</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000003491</span>
      <span itemprop="name">array</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000004364</span>
      <span itemprop="name">calculation method</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000004140</span>
      <span itemprop="name">cleaning</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000011156</span>
      <span itemprop="name">evaluation</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000004519</span>
      <span itemprop="name">manufacturing process</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000012986</span>
      <span itemprop="name">modification</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000004048</span>
      <span itemprop="name">modification</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000001151</span>
      <span itemprop="name">other effect</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000000644</span>
      <span itemprop="name">propagated effect</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000003252</span>
      <span itemprop="name">repetitive effect</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000004044</span>
      <span itemprop="name">response</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000005070</span>
      <span itemprop="name">sampling</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000000638</span>
      <span itemprop="name">solvent extraction</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat>description</span>
      <span itemprop="count">1</span>
    </li>
  </ul>

  <section>
    <h2>Images</h2>
    <ul>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/b0/2e/66/2157b105797a14/US20230386192A1-20231130-D00001.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/dd/c1/b8/44780b3dae0104/US20230386192A1-20231130-D00001.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="0">
            <meta itemprop="id" content="1">
            <meta itemprop="label" content="split point">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="858">
              <meta itemprop="top" content="379">
              <meta itemprop="right" content="886">
              <meta itemprop="bottom" content="418">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="0">
            <meta itemprop="id" content="100">
            <meta itemprop="label" content="edge device">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="18">
              <meta itemprop="top" content="848">
              <meta itemprop="right" content="95">
              <meta itemprop="bottom" content="883">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="0">
            <meta itemprop="id" content="200">
            <meta itemprop="label" content="cloud server">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1540">
              <meta itemprop="top" content="760">
              <meta itemprop="right" content="1631">
              <meta itemprop="bottom" content="791">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/42/4a/5b/d3f8bb114d2e47/US20230386192A1-20231130-D00002.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/b5/fa/30/35e4735049274e/US20230386192A1-20231130-D00002.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="1">
            <meta itemprop="id" content="1">
            <meta itemprop="label" content="split point">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="521">
              <meta itemprop="top" content="2094">
              <meta itemprop="right" content="566">
              <meta itemprop="bottom" content="2105">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="1">
            <meta itemprop="id" content="2">
            <meta itemprop="label" content="split paths">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1102">
              <meta itemprop="top" content="2084">
              <meta itemprop="right" content="1146">
              <meta itemprop="bottom" content="2106">
            </span>
          </li>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="1">
            <meta itemprop="id" content="3">
            <meta itemprop="label" content="split paths">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1575">
              <meta itemprop="top" content="2080">
              <meta itemprop="right" content="1621">
              <meta itemprop="bottom" content="2105">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/58/8d/30/1b6f2f48912961/US20230386192A1-20231130-D00003.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/05/c4/6e/2ac9e85d222e97/US20230386192A1-20231130-D00003.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="2">
            <meta itemprop="id" content="1">
            <meta itemprop="label" content="split point">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1698">
              <meta itemprop="top" content="2172">
              <meta itemprop="right" content="1734">
              <meta itemprop="bottom" content="2183">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/f5/11/05/f4260862456d5c/US20230386192A1-20231130-D00004.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/37/19/59/a5ed97b03ed539/US20230386192A1-20231130-D00004.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="3">
            <meta itemprop="id" content="4">
            <meta itemprop="label" content="split paths">
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="694">
              <meta itemprop="top" content="1986">
              <meta itemprop="right" content="746">
              <meta itemprop="bottom" content="2022">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/93/5b/24/2618c3c7506a21/US20230386192A1-20231130-D00005.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/3b/97/4a/846ab4ea861441/US20230386192A1-20231130-D00005.png">
        <ul>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/b6/ec/18/6f9f64437aa332/US20230386192A1-20231130-D00006.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/21/52/8d/8d1f48e5dbb460/US20230386192A1-20231130-D00006.png">
        <ul>
        </ul>
      </li>
    </ul>
  </section>

  <section>
    <h2>Classifications</h2>
    <ul>
      <li>
        <ul itemprop="classifications" itemscope repeat>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G</span>&mdash;<span itemprop="Description">PHYSICS</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06</span>&mdash;<span itemprop="Description">COMPUTING; CALCULATING OR COUNTING</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06N</span>&mdash;<span itemprop="Description">COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06N3/00</span>&mdash;<span itemprop="Description">Computing arrangements based on biological models</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06N3/02</span>&mdash;<span itemprop="Description">Neural networks</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06N3/04</span>&mdash;<span itemprop="Description">Architecture, e.g. interconnection topology</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06N3/045</span>&mdash;<span itemprop="Description">Combinations of networks</span>
            <meta itemprop="Leaf" content="true"><meta itemprop="FirstCode" content="true"><meta itemprop="IsCPC" content="true">
          </li>
        </ul>
      </li>
      <li>
        <ul itemprop="classifications" itemscope repeat>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G</span>&mdash;<span itemprop="Description">PHYSICS</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06</span>&mdash;<span itemprop="Description">COMPUTING; CALCULATING OR COUNTING</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06V</span>&mdash;<span itemprop="Description">IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06V10/00</span>&mdash;<span itemprop="Description">Arrangements for image or video recognition or understanding</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06V10/70</span>&mdash;<span itemprop="Description">Arrangements for image or video recognition or understanding using pattern recognition or machine learning</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06V10/82</span>&mdash;<span itemprop="Description">Arrangements for image or video recognition or understanding using pattern recognition or machine learning using neural networks</span>
            <meta itemprop="Leaf" content="true"><meta itemprop="FirstCode" content="true"><meta itemprop="IsCPC" content="true">
          </li>
        </ul>
      </li>
      <li>
        <ul itemprop="classifications" itemscope repeat>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G</span>&mdash;<span itemprop="Description">PHYSICS</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06</span>&mdash;<span itemprop="Description">COMPUTING; CALCULATING OR COUNTING</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06N</span>&mdash;<span itemprop="Description">COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06N3/00</span>&mdash;<span itemprop="Description">Computing arrangements based on biological models</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06N3/02</span>&mdash;<span itemprop="Description">Neural networks</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06N3/08</span>&mdash;<span itemprop="Description">Learning methods</span>
            <meta itemprop="Leaf" content="true"><meta itemprop="IsCPC" content="true">
          </li>
        </ul>
      </li>
      <li>
        <ul itemprop="classifications" itemscope repeat>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G</span>&mdash;<span itemprop="Description">PHYSICS</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06</span>&mdash;<span itemprop="Description">COMPUTING; CALCULATING OR COUNTING</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06N</span>&mdash;<span itemprop="Description">COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06N5/00</span>&mdash;<span itemprop="Description">Computing arrangements using knowledge-based models</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06N5/04</span>&mdash;<span itemprop="Description">Inference or reasoning models</span>
            <meta itemprop="Leaf" content="true"><meta itemprop="IsCPC" content="true">
          </li>
        </ul>
      </li>
      <li>
        <ul itemprop="classifications" itemscope repeat>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G</span>&mdash;<span itemprop="Description">PHYSICS</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06</span>&mdash;<span itemprop="Description">COMPUTING; CALCULATING OR COUNTING</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06V</span>&mdash;<span itemprop="Description">IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06V10/00</span>&mdash;<span itemprop="Description">Arrangements for image or video recognition or understanding</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06V10/20</span>&mdash;<span itemprop="Description">Image preprocessing</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06V10/28</span>&mdash;<span itemprop="Description">Quantising the image, e.g. histogram thresholding for discrimination between background and foreground patterns</span>
            <meta itemprop="Leaf" content="true"><meta itemprop="IsCPC" content="true">
          </li>
        </ul>
      </li>
      <li>
        <ul itemprop="classifications" itemscope repeat>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G</span>&mdash;<span itemprop="Description">PHYSICS</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06</span>&mdash;<span itemprop="Description">COMPUTING; CALCULATING OR COUNTING</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06V</span>&mdash;<span itemprop="Description">IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06V10/00</span>&mdash;<span itemprop="Description">Arrangements for image or video recognition or understanding</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06V10/94</span>&mdash;<span itemprop="Description">Hardware or software architectures specially adapted for image or video understanding</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06V10/95</span>&mdash;<span itemprop="Description">Hardware or software architectures specially adapted for image or video understanding structured as a network, e.g. client-server architectures</span>
            <meta itemprop="Leaf" content="true"><meta itemprop="IsCPC" content="true">
          </li>
        </ul>
      </li>
      <li>
        <ul itemprop="classifications" itemscope repeat>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G</span>&mdash;<span itemprop="Description">PHYSICS</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06</span>&mdash;<span itemprop="Description">COMPUTING; CALCULATING OR COUNTING</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06V</span>&mdash;<span itemprop="Description">IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06V2201/00</span>&mdash;<span itemprop="Description">Indexing scheme relating to image or video recognition or understanding</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope repeat>
            <span itemprop="Code">G06V2201/07</span>&mdash;<span itemprop="Description">Target detection</span>
            <meta itemprop="Leaf" content="true"><meta itemprop="Additional" content="true"><meta itemprop="IsCPC" content="true">
          </li>
        </ul>
      </li>
    </ul>
  </section>

  

  

  <section>
    <h2>Definitions</h2>
    <ul>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the present disclosure</span>
        <span itemprop="definition">relates to a deep neural network-based real-time inference apparatus, system, and method, and more particularly, to a deep neural network-based real-time inference apparatus, system, and method capable of accelerating image inference.</span>
        <meta itemprop="num_attr" content="0001">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">DNNs</span>
        <span itemprop="definition">deep neural networks</span>
        <meta itemprop="num_attr" content="0003">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">edge devices</span>
        <span itemprop="definition">due to resource constraints, it is still difficult for edge devices to acquire images in real time and perform real-time inference of DNN models with complex deep neural networks. In such a case, images obtained by edge devices can be transmitted to a cloud server equipped with a high-performance GPU for processing. However, due to the characteristics of edge devices that need to use a wireless network, it may take a long time to transmit images. In order to solve this problem, it is possible to use an edge-cloud server split inference technique in which an edge device uses a part of a deep neural network and transmits a feature smaller than the original image to the cloud server for processing.</span>
        <meta itemprop="num_attr" content="0000">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">transmission features</span>
        <span itemprop="definition">can be quantized to low bits.</span>
        <meta itemprop="num_attr" content="0004">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the model</span>
        <span itemprop="definition">When a model is trained by loading a low-bit quantization module on a specific layer, in particular, the model can operate normally only when splitting is performed in the layer during inference.</span>
        <meta itemprop="num_attr" content="0004">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">an object of the present disclosure proposed to solve the above problems</span>
        <span itemprop="definition">is to provide a deep neural network-based real-time inference apparatus, system, and method capable of accelerating image inference.</span>
        <meta itemprop="num_attr" content="0006">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a deep neural network-based real-time inference apparatus</span>
        <span itemprop="definition">including a cloud server configured to infer an acquired image along with an edge device in a split manner</span>
        <meta itemprop="num_attr" content="0008">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the apparatus</span>
        <span itemprop="definition">may comprise: a memory configured to store information of a second artificial intelligence model identical to a first artificial intelligence model of the edge device; and a processor executing one or more instructions stored in the memory, wherein the instructions, when executed by the processor, cause the processor to receive a quantized feature of an output of a first layer corresponding to a predetermined split point among a plurality of layers included in the first artificial intelligence model, and determine a processing result for the image based on the second artificial intelligence model by inputting the quantized feature to a second layer of the second artificial intelligence model corresponding a layer immediately after the first layer.</span>
        <meta itemprop="num_attr" content="0008">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the cloud server</span>
        <span itemprop="definition">may determine an object in the image by inputting the quantized feature to the artificial intelligence model.</span>
        <meta itemprop="num_attr" content="0009">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the first artificial intelligence model and the second artificial intelligence model</span>
        <span itemprop="definition">may include a deep neural network trained both with quantized and non-quantized features for each predetermined split layer.</span>
        <meta itemprop="num_attr" content="0010">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processor</span>
        <span itemprop="definition">may be configured to analyze at least one of a network resource between the edge device and the cloud server, a computing resource of the edge device, and a computing resource of the cloud server, and determine a location of the split point with respect to the first layer based on an analysis result.</span>
        <meta itemprop="num_attr" content="0011">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the first artificial intelligence model and the second artificial intelligence model</span>
        <span itemprop="definition">may include a quantization switch for switching between a path for quantizing a feature of each layer and a path for passing the feature of each layer without being quantized, wherein the quantization switch may be provided for each layer of the artificial intelligence models.</span>
        <meta itemprop="num_attr" content="0012">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the first artificial intelligence model and the second artificial intelligence model</span>
        <span itemprop="definition">may dynamically apply a feature distribution matching unit that normalizes a distribution of features output from the first layer immediately after the split point through mean and variance.</span>
        <meta itemprop="num_attr" content="0013">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the feature distribution matching unit</span>
        <span itemprop="definition">may apply a convolution layer for restoring feature precision to the quantized feature.</span>
        <meta itemprop="num_attr" content="0014">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a deep neural network-based real-time inference apparatus</span>
        <span itemprop="definition">including an edge device configured to transmit a quantized feature obtained by processing an acquired image to a cloud server</span>
        <meta itemprop="num_attr" content="0015">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the apparatus</span>
        <span itemprop="definition">may comprise: a memory configured to store information of a first artificial intelligence model identical to a second artificial intelligence model of the cloud server; and a processor executing one or more instructions stored in the memory, wherein the instructions, when executed by the processor, cause the processor to analyze at least one of resources, select a first layer corresponding to a predetermined split point from among a plurality of layers included in the first artificial intelligence model according to the at least one of resources, quantize only a feature of the first layer, and transmit the quantized feature to the cloud server.</span>
        <meta itemprop="num_attr" content="0015">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the cloud server</span>
        <span itemprop="definition">may determine a processing result for the image based on the second artificial intelligence model by inputting the quantized feature to a second layer of the second artificial intelligence model corresponding to a layer immediately after the first layer.</span>
        <meta itemprop="num_attr" content="0016">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the first artificial intelligence model and the second artificial intelligence model</span>
        <span itemprop="definition">may include a deep neural network trained both with quantized and non-quantized features for each predetermined split layer.</span>
        <meta itemprop="num_attr" content="0017">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">At least one of resources</span>
        <span itemprop="definition">may include a network resource between the edge device and the cloud server, a computing resource of the edge device, and a computing resource of the cloud server.</span>
        <meta itemprop="num_attr" content="0018">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the first artificial intelligence model and the second artificial intelligence model</span>
        <span itemprop="definition">may include a quantization switch for switching between a path for quantizing a feature of each layer and a path for passing the feature of each layer without being quantized, wherein the quantization switch may be provided for each layer of the artificial intelligence models.</span>
        <meta itemprop="num_attr" content="0019">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the first artificial intelligence model and the second artificial intelligence model</span>
        <span itemprop="definition">may dynamically apply a feature distribution matching unit that normalizes a distribution of features output from the first layer immediately after the split point through mean and variance.</span>
        <meta itemprop="num_attr" content="0020">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a deep neural network based real time inference method</span>
        <span itemprop="definition">may comprise: acquiring, by a processor included in a cloud server, an image from an edge device; analyzing, by a processor included in the edge device, at least one of resources related to the edge device and a cloud server; selecting, by the processor included in the edge device, a first layer corresponding to a split point from among a plurality of layers included in a pre-trained first artificial intelligence model of the edge device according to the at least one of resources; quantizing, by the processor included in the edge device, only a feature of the first layer corresponding to the split point; transmitting, by the processor included in the edge device, the quantized feature to the cloud server; inputting, by the processor included in the cloud server, the quantized feature to a second layer corresponding to a layer immediately after the first layer among a plurality of layers included in a second artificial intelligence model identical to the first artificial intelligence model; and determining, by the processor included in the cloud server, a</span>
        <meta itemprop="num_attr" content="0021">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">At least one of resources</span>
        <span itemprop="definition">may include a network resource between the edge device and the cloud server, a computing resource of the edge device, and a computing resource of the cloud server.</span>
        <meta itemprop="num_attr" content="0022">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the first artificial intelligence model and the second artificial intelligence model</span>
        <span itemprop="definition">may include a quantization switch for switching between a path for quantizing a feature of each layer and a path for passing the feature of each layer without being quantized, wherein the quantization switch may be provided for each layer of the artificial intelligence models.</span>
        <meta itemprop="num_attr" content="0023">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the first artificial intelligence model and the second artificial intelligence model</span>
        <span itemprop="definition">may dynamically apply a feature distribution matching unit that normalizes a distribution of features output from the first layer immediately after the split point through mean and variance.</span>
        <meta itemprop="num_attr" content="0024">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the feature distribution matching unit</span>
        <span itemprop="definition">may apply a convolution layer for restoring feature precision to the quantized feature.</span>
        <meta itemprop="num_attr" content="0025">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the first artificial intelligence model and the second artificial intelligence model</span>
        <span itemprop="definition">may include a deep neural network trained both with quantized and non-quantized features for each predetermined split layer.</span>
        <meta itemprop="num_attr" content="0026">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">image inference</span>
        <span itemprop="definition">can be accelerated.</span>
        <meta itemprop="num_attr" content="0027">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 1</span>
        <span itemprop="definition">is a block diagram showing a configuration of a deep neural network-based real-time inference system according to an embodiment of the present disclosure.</span>
        <meta itemprop="num_attr" content="0029">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 2</span>
        <span itemprop="definition">is a conceptual diagram for describing operation of the deep neural network-based real-time inference system according to an embodiment of the present disclosure.</span>
        <meta itemprop="num_attr" content="0030">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 3</span>
        <span itemprop="definition">is a diagram schematically illustrating an example of quantizing a feature for a layer corresponding to each split point according to an embodiment of the present disclosure.</span>
        <meta itemprop="num_attr" content="0031">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIGS. 4 A to 4 C</span>
        <span itemprop="definition">are conceptual diagrams for describing differences between a prior art and an embodiment of the present disclosure.</span>
        <meta itemprop="num_attr" content="0032">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIGS. 5 A and 5 B</span>
        <span itemprop="definition">are conceptual diagrams for describing differences between a prior art and an embodiment of the present disclosure.</span>
        <meta itemprop="num_attr" content="0033">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 6</span>
        <span itemprop="definition">is a flowchart illustrating a deep neural network-based real-time inference method according to an embodiment of the present disclosure.</span>
        <meta itemprop="num_attr" content="0034">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a term such as a âunitâ or a âportionâ used in the specification</span>
        <span itemprop="definition">means a software component or a hardware component such as FPGA or ASIC, and the âunitâ or the âportionâ performs a certain role.</span>
        <meta itemprop="num_attr" content="0039">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the âunitâ or the âportionâ</span>
        <span itemprop="definition">is not limited to software or hardware.</span>
        <meta itemprop="num_attr" content="0039">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the âportionâ or the âunitâ</span>
        <span itemprop="definition">may be configured to be in an addressable storage medium, or may be configured to reproduce one or more processors.</span>
        <meta itemprop="num_attr" content="0039">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the âunitâ or the âportionâ</span>
        <span itemprop="definition">includes components (such as software components, object-oriented software components, class components, and task components), processes, functions, properties, procedures, subroutines, segments of program code, drivers, firmware, microcode, circuits, data, database, data structures, tables, arrays, and variables.</span>
        <meta itemprop="num_attr" content="0039">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the functions provided in the components and âunitâ</span>
        <span itemprop="definition">may be combined into a smaller number of components and âunitsâ or may be further divided into additional components and âunitsâ.</span>
        <meta itemprop="num_attr" content="0039">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 1</span>
        <span itemprop="definition">is a block diagram showing a configuration of a deep neural network-based real-time inference system according to an embodiment of the present disclosure</span>
        <meta itemprop="num_attr" content="0041">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 2</span>
        <span itemprop="definition">is a conceptual diagram for describing operation of the deep neural network-based real-time inference system according to an embodiment of the present disclosure.</span>
        <meta itemprop="num_attr" content="0041">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the deep neural network-based real-time inference system 1</span>
        <span itemprop="definition">includes at least one edge devices 100 that executes edge computing, and a cloud server 200 that receives data from the edge device 100 , executes cloud server computing, and transmits execution results to the edge.</span>
        <meta itemprop="num_attr" content="0042">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the edge device 100</span>
        <span itemprop="definition">may correspond to a smart device, a drone, or a wearable device, but is not limited thereto.</span>
        <meta itemprop="num_attr" content="0043">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the edge device 100</span>
        <span itemprop="definition">may include a camera that acquires images, a memory that stores information on a pre-trained extractor, and a processor that controls components of the edge device 100 .</span>
        <meta itemprop="num_attr" content="0044">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the edge device 100</span>
        <span itemprop="definition">may collect data, refine data, perform preprocessing such as sampling, cleaning, and combining on data, and transmit preprocessing results to the cloud server 200 .</span>
        <meta itemprop="num_attr" content="0045">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the function of the edge device 100</span>
        <span itemprop="definition">can be designed in various ways.</span>
        <meta itemprop="num_attr" content="0046">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the edge device 100</span>
        <span itemprop="definition">may be designed to process data by itself without sending the data to the cloud server 200 .</span>
        <meta itemprop="num_attr" content="0046">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the present disclosure</span>
        <span itemprop="definition">focuses on an embodiment in which the edge device 100 and the cloud server 200 perform data processing in a split manner.</span>
        <meta itemprop="num_attr" content="0046">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the edge device 100</span>
        <span itemprop="definition">may analyze environmental conditions and select a first layer corresponding to a predetermined split point from among a plurality of layers included in a first artificial intelligence model according to results of analysis of the environmental conditions.</span>
        <meta itemprop="num_attr" content="0047">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the edge device 100</span>
        <span itemprop="definition">may reduce transmission overhead by quantizing only a feature of the first layer to decrease the bits of an intermediate feature and transmitting the quantized feature to the cloud server 200 .</span>
        <meta itemprop="num_attr" content="0048">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the edge device 100</span>
        <span itemprop="definition">may include the pre-trained first artificial intelligence model, and the first artificial intelligence model may include a plurality of layers.</span>
        <meta itemprop="num_attr" content="0049">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the first artificial intelligence model</span>
        <span itemprop="definition">may be a deep neural network trained both with quantized and non-quantized features for each predetermined split layer.</span>
        <meta itemprop="num_attr" content="0049">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the environmental conditions</span>
        <span itemprop="definition">may include a network speed between the edge device 100 and the cloud server 200 and at least one of the performances of the edge device 100 and the cloud server 200 .</span>
        <meta itemprop="num_attr" content="0050">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the edge device 100</span>
        <span itemprop="definition">may select a split point in a relatively previous layer of the first artificial intelligence model if the performance of the edge device 100 does not meet preset criteria, and the edge device 100 may select a split point in a relatively later layer of the first artificial intelligence model if the performance of the edge device 100 is higher than the preset criteria.</span>
        <meta itemprop="num_attr" content="0051">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the first artificial intelligence model</span>
        <span itemprop="definition">may further include a quantization switch 110 that switches between a path for quantizing a feature of each layer and a path for passing the feature of each layer without quantization of the feature, as shown in ( 1 ) of FIG. 2 .</span>
        <meta itemprop="num_attr" content="0052">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the quantization switch 110</span>
        <span itemprop="definition">may be applied to each layer of the first artificial intelligence model.</span>
        <meta itemprop="num_attr" content="0052">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 2</span>
        <span itemprop="definition">shows an example in which the last layer is determined as a split point, and the edge device 100 quantizes the highest level feature by selecting the last layer of the first artificial intelligence model as a split point and transmits the quantized feature to the cloud server 200 . That is, ( 2 ) of FIG. 2 illustrates a case where features are output without being quantized in previous layers of the first artificial intelligence model, and the feature is output after being quantized by the switch 110 in the last layer.</span>
        <meta itemprop="num_attr" content="0053">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 2</span>
        <span itemprop="definition">illustrates a case where the edge device 100 selects a relatively previous layer compared to the case of ( 1 ) as a split point, quantizes a low-level feature, and transmits the quantized feature to the cloud server 200 .</span>
        <meta itemprop="num_attr" content="0054">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 3</span>
        <span itemprop="definition">is a diagram schematically illustrating an example of quantizing a feature for a layer corresponding to each split point according to an embodiment of the present disclosure.</span>
        <meta itemprop="num_attr" content="0055">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the edge device 100</span>
        <span itemprop="definition">does not quantize features of layers by the quantization switch 110 until reaching a layer corresponding to a split point, sequentially inputs outputs of previous layers to next layers, and upon reaching the layer corresponding to the split point, performs quantization on the feature of the corresponding layer through the quantization switch 110 .</span>
        <meta itemprop="num_attr" content="0055">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the cloud server 200</span>
        <span itemprop="definition">may perform core processing, such as comprehensively performing tasks received from the edge device 100 or distributing some tasks to a specific edge device 100 .</span>
        <meta itemprop="num_attr" content="0056">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Results processed in the cloud server 200</span>
        <span itemprop="definition">may be transmitted to the edge device 100 .</span>
        <meta itemprop="num_attr" content="0057">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the cloud server 200</span>
        <span itemprop="definition">may derive a processing result for an image based on quantized features received from the edge device 100 . For example, if a second artificial intelligence model included in the cloud server 200 is an object detection model, object detection in an image may be derived as an image processing result.</span>
        <meta itemprop="num_attr" content="0058">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the cloud server 200</span>
        <span itemprop="definition">may include the pre-trained second artificial intelligence model, a memory for storing information on the second artificial intelligence model, and a processor for controlling components of the cloud server 200 .</span>
        <meta itemprop="num_attr" content="0059">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the second artificial intelligence model</span>
        <span itemprop="definition">has the same structure and function as the first artificial intelligence model included in the edge device 100 .</span>
        <meta itemprop="num_attr" content="0059">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the cloud server 200</span>
        <span itemprop="definition">may receive a feature quantized for an output of a first layer corresponding to a predetermined split point among the plurality of layers included in the first artificial intelligence model from the edge device 100 . Subsequently, the cloud server 200 may input the quantized feature to a second layer of the second artificial intelligence model corresponding to a layer immediately following the first layer in the second artificial intelligence model.</span>
        <meta itemprop="num_attr" content="0060">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the cloud server 200</span>
        <span itemprop="definition">can ascertain which layer corresponds to the quantized layer based on the shape of the quantized feature. To this end, the cloud server 200 may pre-store feature shape information of predetermined split points along with layer order information.</span>
        <meta itemprop="num_attr" content="0061">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the edge device 100</span>
        <span itemprop="definition">may transmit information on the order of the first layer to the cloud server 200 such that the cloud server 200 can determine a layer to which the quantized feature will be input.</span>
        <meta itemprop="num_attr" content="0062">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the cloud server 200</span>
        <span itemprop="definition">may derive image processing results through execution of the second to last layers of the second artificial intelligence model.</span>
        <meta itemprop="num_attr" content="0063">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIGS. 4 A to 4 C</span>
        <span itemprop="definition">are conceptual diagrams for describing differences between a prior art and an embodiment of the present disclosure.</span>
        <meta itemprop="num_attr" content="0064">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a model in which a split point is set</span>
        <span itemprop="definition">is illustrated as a prior art.</span>
        <meta itemprop="num_attr" content="0065">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a model</span>
        <span itemprop="definition">needs to be provided for each split point, and models need to be switched according to a determined split point.</span>
        <meta itemprop="num_attr" content="0065">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a storage space</span>
        <span itemprop="definition">is required depending on the number of split options, and weight reloading overhead occurs in order to execute and switch multiple independent models. This causes a considerable delay time in the edge device 100 with limited resources.</span>
        <meta itemprop="num_attr" content="0065">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 4 B</span>
        <span itemprop="definition">illustrates a case in which quantization modules are inserted at all split points.</span>
        <meta itemprop="num_attr" content="0066">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">quantization</span>
        <span itemprop="definition">when quantization is applied to all split layers, propagated features repeatedly lose representation thereof while passing through the layers, resulting in significant decrease in accuracy.</span>
        <meta itemprop="num_attr" content="0066">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">an embodiment of the present disclosure</span>
        <span itemprop="definition">proposes a quantization switching method of quantizing only a feature of a layer corresponding to a selected split point for an artificial intelligence model trained for quantized and non-quantized features for each layer in the deep neural network-based split inference system according to an embodiment of the present disclosure shown in FIG. 4 C .</span>
        <meta itemprop="num_attr" content="0067">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Quantization switching</span>
        <span itemprop="definition">supports multiple inference paths for various split points in a one-to-one correspondence, in which all paths share all layers of a model, but quantization is executed only at a corresponding split point in each path. Since every inference path allows quantization only once in a corresponding split layer, models can avoid repetitive information loss.</span>
        <meta itemprop="num_attr" content="0068">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIGS. 5 A and 5 B</span>
        <span itemprop="definition">are conceptual diagrams for describing differences between a prior art and an embodiment of the present disclosure.</span>
        <meta itemprop="num_attr" content="0069">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 5 A</span>
        <span itemprop="definition">illustrates a concept of performing quantization at all split points.</span>
        <meta itemprop="num_attr" content="0070">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 5 B</span>
        <span itemprop="definition">illustrates a concept of performing multi-path inference according to a selected split point by applying quantization switching to a single weight model trained for quantized and non-quantized features for each layer, as described above. Since all paths share convolutional and batch normalization layers, features of different paths are expected to show a consistent distribution in each layer of the model.</span>
        <meta itemprop="num_attr" content="0071">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">precision restoration</span>
        <span itemprop="definition">is performed for every split point (i.e., feature precision is restored through a precision restoration (PR) layer), and batch normalization is performed (i.e., the distribution of each path is individually normalized through a batch normalization (BN) layer).</span>
        <meta itemprop="num_attr" content="0073">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">PR</span>
        <span itemprop="definition">precision restoration</span>
        <meta itemprop="num_attr" content="0073">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">BN</span>
        <span itemprop="definition">batch normalization</span>
        <meta itemprop="num_attr" content="0073">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">split path 1</span>
        <span itemprop="definition">since quantization is performed at split point 1 , precision restoration (PR) is applied immediately after split layer 1 , and batch normalization is performed.</span>
        <meta itemprop="num_attr" content="0074">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">PR</span>
        <span itemprop="definition">precision restoration</span>
        <meta itemprop="num_attr" content="0074">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">split paths 2 , 3 , and 4</span>
        <span itemprop="definition">quantization is not performed at split point 1 , and thus only individual batch normalizations are performed on split paths 2 , 3 , and 4 after split layer 1 .</span>
        <meta itemprop="num_attr" content="0074">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the first artificial intelligence model</span>
        <span itemprop="definition">may dynamically apply a feature distribution matching unit that normalizes the distribution of features output from the first layer immediately after a split point through mean and variance.</span>
        <meta itemprop="num_attr" content="0076">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the feature distribution matching unit</span>
        <span itemprop="definition">may apply a convolution layer for restoring feature precision to quantized features.</span>
        <meta itemprop="num_attr" content="0077">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the batch normalization</span>
        <span itemprop="definition">is independently applied to each of split paths each of at split points.</span>
        <meta itemprop="num_attr" content="0078">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the bit precision of the features</span>
        <span itemprop="definition">remains low. Therefore, in order to maximize the effect of normalization applied to quantized features, feature precision is restored through a convolution layer (PR layer).</span>
        <meta itemprop="num_attr" content="0078">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">PR layer</span>
        <span itemprop="definition">convolution layer</span>
        <meta itemprop="num_attr" content="0078">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the PR layer</span>
        <span itemprop="definition">allows the feature of a split point to represent high precision in a normal distribution, and thus models are trained more stably.</span>
        <meta itemprop="num_attr" content="0079">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the deep neural network-based real-time inference system</span>
        <span itemprop="definition">aims to optimize the average accuracy in response to application of all quantization switches. Therefore, in an embodiment of the present disclosure, training is performed by summing losses of all split paths. At each iteration, gradients of all paths are computed and accumulated, and then weights of the model are updated. The number of paths is determined by a path option, which is a predefined hyperparameter. Since neural network operations in the cloud server 200 are much faster than those in the edge device 100 , it is efficient to execute more layers in the cloud server 200 if the cloud server 200 and the edge device 100 have the amount of transmission.</span>
        <meta itemprop="num_attr" content="0080">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the path option</span>
        <span itemprop="definition">may be defined as a set of first layers among layers having the same feature size.</span>
        <meta itemprop="num_attr" content="0081">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a model with a precision restoration layer (PR layer) and independent batch normalization (BN)</span>
        <span itemprop="definition">is loaded for all split paths.</span>
        <meta itemprop="num_attr" content="0082">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">PR layer</span>
        <span itemprop="definition">precision restoration layer</span>
        <meta itemprop="num_attr" content="0082">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">BN</span>
        <span itemprop="definition">independent batch normalization</span>
        <meta itemprop="num_attr" content="0082">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">a quantization module and the restoration layer</span>
        <span itemprop="definition">are activated only in a layer corresponding to a selected split point, and independent batch normalization (BN) of all split layers is switched according to a selected path.</span>
        <meta itemprop="num_attr" content="0082">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">FIG. 6</span>
        <span itemprop="definition">is a flowchart illustrating a deep neural network-based real-time inference method according to an embodiment of the present disclosure.</span>
        <meta itemprop="num_attr" content="0083">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the deep neural network-based real-time inference method</span>
        <span itemprop="definition">may be performed in substantially the same components as those of the system 1 of FIG. 1 . Accordingly, the same components as those of the system 1 of FIG. 1 are denoted by the same reference numerals and redundant descriptions are omitted.</span>
        <meta itemprop="num_attr" content="0084">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the edge device</span>
        <span itemprop="definition">when an edge device acquires an image (S 110 ), the edge device analyzes environmental conditions related to the edge device and a cloud server (S 120 ), and selects a first layer corresponding to a split point from among a plurality of layers included in a pre-trained first artificial intelligence model of the edge device according to a result of analysis of the environmental conditions (S 130 ).</span>
        <meta itemprop="num_attr" content="0085">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the edge device</span>
        <span itemprop="definition">quantizes only the feature of the first layer corresponding to the split point (S 140 ) and transmits the quantized feature to the cloud server (S 150 ).</span>
        <meta itemprop="num_attr" content="0085">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the environmental conditions</span>
        <span itemprop="definition">may include a network speed between the edge device and the cloud server and at least one of the performances of the edge device and the cloud server.</span>
        <meta itemprop="num_attr" content="0086">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the edge device</span>
        <span itemprop="definition">may select a split point in a relatively previous layer of the first artificial intelligence model, and if the performance of the edge device is higher than the preset criteria, the edge device may select a split point in a relatively later layer of the first artificial intelligence model.</span>
        <meta itemprop="num_attr" content="0087">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the first artificial intelligence model</span>
        <span itemprop="definition">may further include a quantization switch that switches between a path for quantizing a feature of each layer and a path for passing the feature of each layer without being quantized, as shown in ( 1 ) of FIG. 2 .</span>
        <meta itemprop="num_attr" content="0088">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the quantization switch</span>
        <span itemprop="definition">may be applied to each layer of the first artificial intelligence model.</span>
        <meta itemprop="num_attr" content="0088">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the cloud server</span>
        <span itemprop="definition">may derive an image processing result based on the second artificial intelligence model.</span>
        <meta itemprop="num_attr" content="0089">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">object detection in an image</span>
        <span itemprop="definition">may be derived as an image processing result.</span>
        <meta itemprop="num_attr" content="0090">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the cloud server</span>
        <span itemprop="definition">may receive a quantized feature of an output of the first layer corresponding to a predetermined split point among the plurality of layers included in the first artificial intelligence model from the edge device. Subsequently, the cloud server may input the quantized feature to the second layer of the second artificial intelligence model which corresponds to a layer immediately after the first layer.</span>
        <meta itemprop="num_attr" content="0091">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the cloud server</span>
        <span itemprop="definition">can ascertain which layer corresponds to the quantized layer based on the shape of the quantized feature.</span>
        <meta itemprop="num_attr" content="0092">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the cloud server 200</span>
        <span itemprop="definition">may pre-store feature shape information of predetermined split points along with layer order information.</span>
        <meta itemprop="num_attr" content="0092">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the edge device</span>
        <span itemprop="definition">may transmit information on the order of the first layer to the cloud server such that the cloud server can determine a layer to which the quantized feature will be input.</span>
        <meta itemprop="num_attr" content="0093">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the above-described deep neural network-based real-time inference system</span>
        <span itemprop="definition">may be implemented by a computing device including at least some of a processor, a memory, a user input device, and a presentation device.</span>
        <meta itemprop="num_attr" content="0094">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the memory</span>
        <span itemprop="definition">is a medium that stores computer-readable software, applications, program modules, routines, instructions, and/or data coded to perform a specific task when executed by the processor.</span>
        <meta itemprop="num_attr" content="0095">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the processor</span>
        <span itemprop="definition">may read and execute the computer-readable software, applications, program modules, routines, instructions, and/or data stored in the memory.</span>
        <meta itemprop="num_attr" content="0095">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the computing device</span>
        <span itemprop="definition">may include various devices such as smartphones, tablets, laptops, desktops, servers, and clients.</span>
        <meta itemprop="num_attr" content="0096">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the computing device</span>
        <span itemprop="definition">may be a single stand-alone device or may include multiple computing devices operating in a distributed environment consisting of multiple computing devices cooperating with each other over a communications network.</span>
        <meta itemprop="num_attr" content="0096">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the above-described deep neural network-based real-time inference method</span>
        <span itemprop="definition">may be performed by a computing device including a processor and a memory storing computer-readable software, applications, program modules, routines, instructions, and/or data structures coded to perform an object detection method using an artificial intelligence model when executed by the processor.</span>
        <meta itemprop="num_attr" content="0097">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">Combinations of steps in each flowchart attached to the present disclosure</span>
        <span itemprop="definition">may be executed by computer program instructions. Since the computer program instructions can be mounted on a processor of a general-purpose computer, a special purpose computer, or other programmable data processing equipment, the instructions executed by the processor of the computer or other programmable data processing equipment create a means for performing the functions described in each step of the flowchart.</span>
        <meta itemprop="num_attr" content="0098">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the computer program instructions</span>
        <span itemprop="definition">can also be stored on a computer-usable or computer-readable storage medium which can be directed to a computer or other programmable data processing equipment to implement a function in a specific manner. Accordingly, the instructions stored on the computer-usable or computer-readable recording medium can also produce an article of manufacture containing an instruction means which performs the functions described in each step of the flowchart.</span>
        <meta itemprop="num_attr" content="0098">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the computer program instructions</span>
        <span itemprop="definition">can also be mounted on a computer or other programmable data processing equipment. Accordingly, a series of operational steps are performed on a computer or other programmable data processing equipment to create a computer-executable process, and it is also possible for instructions to perform a computer or other programmable data processing equipment to provide steps for performing the functions described in each step of the flowchart.</span>
        <meta itemprop="num_attr" content="0098">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">each step</span>
        <span itemprop="definition">may represent a module, a segment, or a portion of codes which contains one or more executable instructions for executing the specified logical function(s).</span>
        <meta itemprop="num_attr" content="0099">
      </li>
      <li itemprop="definitions" itemscope repeat>
        <span itemprop="subject">the functions mentioned in the steps</span>
        <span itemprop="definition">may occur out of order. For example, two steps illustrated in succession may in fact be performed substantially simultaneously, or the steps may sometimes be performed in a reverse order depending on the corresponding function.</span>
        <meta itemprop="num_attr" content="0099">
      </li>
    </ul>
  </section>

  


  <section itemprop="abstract" itemscope>
    <h2>Abstract</h2>
    
    <div itemprop="content" html><abstract mxw-id="PA647998933" lang="EN" source="national office" load-source="docdb">
    <div class="abstract">The present disclosure relates to a deep neural network-based real-time inference apparatus, system, and method, and more particularly, to a deep neural network-based real-time inference apparatus, system, and method capable of accelerating image inference.</div>
  </abstract>
  </div>
  </section>

  <section itemprop="description" itemscope>
    <h2>Description</h2>
    
    <div itemprop="content" html><ul mxw-id="PDES442134956" lang="EN" load-source="patent-office" class="description">
    
    <heading id="h-0001">TECHNICAL FIELD</heading>
    <li> <para-num num="[0001]"> </para-num> <div id="p-0002" num="0001" class="description-line">The present disclosure relates to a deep neural network-based real-time inference apparatus, system, and method, and more particularly, to a deep neural network-based real-time inference apparatus, system, and method capable of accelerating image inference.</div>
    </li> <li> <para-num num="[0002]"> </para-num> <div id="p-0003" num="0002" class="description-line">This work was supported by Institute of Information &amp; communications Technology Planning &amp; Evaluation (IITP) grant funded by Korea government (MSIT) ([Project unique No.: 1711126132; Project No.: 2019-0-00421-003; R&amp;D project: Information Communication Broadcasting Innovative Talent Development Project; and Research Project Title: Artificial Intelligence Graduate School Program], [Project unique No.: 1711126102; Project No.: 2020-R&amp;D project: Information Communication Broadcasting Innovative Talent Development Project; and Research Project Title: Information &amp; Communications Technology Research and Education Project], [Project unique No.: 1711139517; Project No.: 2021-0-02068-001; R&amp;D project: Information Communication Broadcasting Innovative Talent Development Project; and Research Project Title: Development for Artificial Intelligence Innovative Hub], and [Project unique No.: 1711139247; Project No.: 2021-0-02052-001; R&amp;D project: Information Communication Broadcasting Innovative Talent Development Project; and Research Project Title: Development for Artificial Intelligence System on a Chip for Smart Mobility]).</div>
    </li> <heading id="h-0002">BACKGROUND</heading>
    <li> <para-num num="[0003]"> </para-num> <div id="p-0004" num="0003" class="description-line">With the recent development of deep neural networks (DNNs), excellent performance has been implemented in various tasks related to computer vision.</div>
    </li> <li> <div id="p-0005" num="0000" class="description-line">However, due to resource constraints, it is still difficult for edge devices to acquire images in real time and perform real-time inference of DNN models with complex deep neural networks. In such a case, images obtained by edge devices can be transmitted to a cloud server equipped with a high-performance GPU for processing. However, due to the characteristics of edge devices that need to use a wireless network, it may take a long time to transmit images. In order to solve this problem, it is possible to use an edge-cloud server split inference technique in which an edge device uses a part of a deep neural network and transmits a feature smaller than the original image to the cloud server for processing.</div>
    </li> <li> <para-num num="[0004]"> </para-num> <div id="p-0006" num="0004" class="description-line">In order to further reduce the amount of transmission in edge-cloud server partitioning inference situations, transmission features can be quantized to low bits. When a model is trained by loading a low-bit quantization module on a specific layer, in particular, the model can operate normally only when splitting is performed in the layer during inference.</div>
    </li> <li> <para-num num="[0005]"> </para-num> <div id="p-0007" num="0005" class="description-line">However, since the optimal split point varies depending on various conditions in split inference environments, there is a problem that the system needs to construct an independent model for each split point.</div>
    </li> <heading id="h-0003">SUMMARY</heading>
    <li> <para-num num="[0006]"> </para-num> <div id="p-0008" num="0006" class="description-line">Accordingly, an object of the present disclosure proposed to solve the above problems is to provide a deep neural network-based real-time inference apparatus, system, and method capable of accelerating image inference.</div>
    </li> <li> <para-num num="[0007]"> </para-num> <div id="p-0009" num="0007" class="description-line">Objects of the present disclosure are not limited to those mentioned above, and other objects not mentioned above will be clearly understood by those skilled in the art from the description below.</div>
    </li> <li> <para-num num="[0008]"> </para-num> <div id="p-0010" num="0008" class="description-line">In accordance with an aspect of the present disclosure, there is provided a deep neural network-based real-time inference apparatus including a cloud server configured to infer an acquired image along with an edge device in a split manner, the apparatus may comprise: a memory configured to store information of a second artificial intelligence model identical to a first artificial intelligence model of the edge device; and a processor executing one or more instructions stored in the memory, wherein the instructions, when executed by the processor, cause the processor to receive a quantized feature of an output of a first layer corresponding to a predetermined split point among a plurality of layers included in the first artificial intelligence model, and determine a processing result for the image based on the second artificial intelligence model by inputting the quantized feature to a second layer of the second artificial intelligence model corresponding a layer immediately after the first layer.</div>
    </li> <li> <para-num num="[0009]"> </para-num> <div id="p-0011" num="0009" class="description-line">The cloud server may determine an object in the image by inputting the quantized feature to the artificial intelligence model.</div>
    </li> <li> <para-num num="[0010]"> </para-num> <div id="p-0012" num="0010" class="description-line">The first artificial intelligence model and the second artificial intelligence model may include a deep neural network trained both with quantized and non-quantized features for each predetermined split layer.</div>
    </li> <li> <para-num num="[0011]"> </para-num> <div id="p-0013" num="0011" class="description-line">The processor may be configured to analyze at least one of a network resource between the edge device and the cloud server, a computing resource of the edge device, and a computing resource of the cloud server, and determine a location of the split point with respect to the first layer based on an analysis result.</div>
    </li> <li> <para-num num="[0012]"> </para-num> <div id="p-0014" num="0012" class="description-line">The first artificial intelligence model and the second artificial intelligence model may include a quantization switch for switching between a path for quantizing a feature of each layer and a path for passing the feature of each layer without being quantized, wherein the quantization switch may be provided for each layer of the artificial intelligence models.</div>
    </li> <li> <para-num num="[0013]"> </para-num> <div id="p-0015" num="0013" class="description-line">The first artificial intelligence model and the second artificial intelligence model may dynamically apply a feature distribution matching unit that normalizes a distribution of features output from the first layer immediately after the split point through mean and variance.</div>
    </li> <li> <para-num num="[0014]"> </para-num> <div id="p-0016" num="0014" class="description-line">The feature distribution matching unit may apply a convolution layer for restoring feature precision to the quantized feature.</div>
    </li> <li> <para-num num="[0015]"> </para-num> <div id="p-0017" num="0015" class="description-line">In accordance with another aspect of the present disclosure, there is provided a deep neural network-based real-time inference apparatus including an edge device configured to transmit a quantized feature obtained by processing an acquired image to a cloud server, the apparatus may comprise: a memory configured to store information of a first artificial intelligence model identical to a second artificial intelligence model of the cloud server; and a processor executing one or more instructions stored in the memory, wherein the instructions, when executed by the processor, cause the processor to analyze at least one of resources, select a first layer corresponding to a predetermined split point from among a plurality of layers included in the first artificial intelligence model according to the at least one of resources, quantize only a feature of the first layer, and transmit the quantized feature to the cloud server.</div>
    </li> <li> <para-num num="[0016]"> </para-num> <div id="p-0018" num="0016" class="description-line">The cloud server may determine a processing result for the image based on the second artificial intelligence model by inputting the quantized feature to a second layer of the second artificial intelligence model corresponding to a layer immediately after the first layer.</div>
    </li> <li> <para-num num="[0017]"> </para-num> <div id="p-0019" num="0017" class="description-line">The first artificial intelligence model and the second artificial intelligence model may include a deep neural network trained both with quantized and non-quantized features for each predetermined split layer.</div>
    </li> <li> <para-num num="[0018]"> </para-num> <div id="p-0020" num="0018" class="description-line">At least one of resources may include a network resource between the edge device and the cloud server, a computing resource of the edge device, and a computing resource of the cloud server.</div>
    </li> <li> <para-num num="[0019]"> </para-num> <div id="p-0021" num="0019" class="description-line">The first artificial intelligence model and the second artificial intelligence model may include a quantization switch for switching between a path for quantizing a feature of each layer and a path for passing the feature of each layer without being quantized, wherein the quantization switch may be provided for each layer of the artificial intelligence models.</div>
    </li> <li> <para-num num="[0020]"> </para-num> <div id="p-0022" num="0020" class="description-line">The first artificial intelligence model and the second artificial intelligence model may dynamically apply a feature distribution matching unit that normalizes a distribution of features output from the first layer immediately after the split point through mean and variance.</div>
    </li> <li> <para-num num="[0021]"> </para-num> <div id="p-0023" num="0021" class="description-line">In accordance with another aspect of the present disclosure, there is provided a deep neural network based real time inference method, the method may comprise: acquiring, by a processor included in a cloud server, an image from an edge device; analyzing, by a processor included in the edge device, at least one of resources related to the edge device and a cloud server; selecting, by the processor included in the edge device, a first layer corresponding to a split point from among a plurality of layers included in a pre-trained first artificial intelligence model of the edge device according to the at least one of resources; quantizing, by the processor included in the edge device, only a feature of the first layer corresponding to the split point; transmitting, by the processor included in the edge device, the quantized feature to the cloud server; inputting, by the processor included in the cloud server, the quantized feature to a second layer corresponding to a layer immediately after the first layer among a plurality of layers included in a second artificial intelligence model identical to the first artificial intelligence model; and determining, by the processor included in the cloud server, a processing result for the image based on the second artificial intelligence model.</div>
    </li> <li> <para-num num="[0022]"> </para-num> <div id="p-0024" num="0022" class="description-line">At least one of resources may include a network resource between the edge device and the cloud server, a computing resource of the edge device, and a computing resource of the cloud server.</div>
    </li> <li> <para-num num="[0023]"> </para-num> <div id="p-0025" num="0023" class="description-line">The first artificial intelligence model and the second artificial intelligence model may include a quantization switch for switching between a path for quantizing a feature of each layer and a path for passing the feature of each layer without being quantized, wherein the quantization switch may be provided for each layer of the artificial intelligence models.</div>
    </li> <li> <para-num num="[0024]"> </para-num> <div id="p-0026" num="0024" class="description-line">The first artificial intelligence model and the second artificial intelligence model may dynamically apply a feature distribution matching unit that normalizes a distribution of features output from the first layer immediately after the split point through mean and variance.</div>
    </li> <li> <para-num num="[0025]"> </para-num> <div id="p-0027" num="0025" class="description-line">The feature distribution matching unit may apply a convolution layer for restoring feature precision to the quantized feature.</div>
    </li> <li> <para-num num="[0026]"> </para-num> <div id="p-0028" num="0026" class="description-line">The first artificial intelligence model and the second artificial intelligence model may include a deep neural network trained both with quantized and non-quantized features for each predetermined split layer.</div>
    </li> <li> <para-num num="[0027]"> </para-num> <div id="p-0029" num="0027" class="description-line">According to the deep neural network-based real-time inference apparatus, system, and method according to embodiments of the present disclosure, image inference can be accelerated.</div>
    </li> <li> <para-num num="[0028]"> </para-num> <div id="p-0030" num="0028" class="description-line">Effects of the present disclosure are not limited to those mentioned above, and other effects not mentioned will be clearly understood by those skilled in the art from the description below.</div>
    
    
    </li> <description-of-drawings>
      <heading id="h-0004">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
      <li> <para-num num="[0029]"> </para-num> <div id="p-0031" num="0029" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>1</b> </figref> is a block diagram showing a configuration of a deep neural network-based real-time inference system according to an embodiment of the present disclosure.</div>
      </li> <li> <para-num num="[0030]"> </para-num> <div id="p-0032" num="0030" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>2</b> </figref> is a conceptual diagram for describing operation of the deep neural network-based real-time inference system according to an embodiment of the present disclosure.</div>
      </li> <li> <para-num num="[0031]"> </para-num> <div id="p-0033" num="0031" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>3</b> </figref> is a diagram schematically illustrating an example of quantizing a feature for a layer corresponding to each split point according to an embodiment of the present disclosure.</div>
      </li> <li> <para-num num="[0032]"> </para-num> <div id="p-0034" num="0032" class="description-line"> <figref idrefs="DRAWINGS">FIGS. <b>4</b>A to <b>4</b>C</figref> are conceptual diagrams for describing differences between a prior art and an embodiment of the present disclosure.</div>
      </li> <li> <para-num num="[0033]"> </para-num> <div id="p-0035" num="0033" class="description-line"> <figref idrefs="DRAWINGS">FIGS. <b>5</b>A and <b>5</b>B</figref> are conceptual diagrams for describing differences between a prior art and an embodiment of the present disclosure.</div>
      </li> <li> <para-num num="[0034]"> </para-num> <div id="p-0036" num="0034" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>6</b> </figref> is a flowchart illustrating a deep neural network-based real-time inference method according to an embodiment of the present disclosure.</div>
    </li> </description-of-drawings>
    
    
    <heading id="h-0005">DETAILED DESCRIPTION</heading>
    <li> <para-num num="[0035]"> </para-num> <div id="p-0037" num="0035" class="description-line">The advantages and features of the embodiments and the methods of accomplishing the embodiments will be clearly understood from the following description taken in conjunction with the accompanying drawings. However, embodiments are not limited to those embodiments described, as embodiments may be implemented in various forms. It should be noted that the present embodiments are provided to make a full disclosure and also to allow those skilled in the art to know the full range of the embodiments. Therefore, the embodiments are to be defined only by the scope of the appended claims.</div>
    </li> <li> <para-num num="[0036]"> </para-num> <div id="p-0038" num="0036" class="description-line">Terms used in the present specification will be briefly described, and the present disclosure will be described in detail.</div>
    </li> <li> <para-num num="[0037]"> </para-num> <div id="p-0039" num="0037" class="description-line">In terms used in the present disclosure, general terms currently as widely used as possible while considering functions in the present disclosure are used. However, the terms may vary according to the intention or precedent of a technician working in the field, the emergence of new technologies, and the like. In addition, in certain cases, there are terms arbitrarily selected by the applicant, and in this case, the meaning of the terms will be described in detail in the description of the corresponding invention. Therefore, the terms used in the present disclosure should be defined based on the meaning of the terms and the overall contents of the present disclosure, not just the name of the terms.</div>
    </li> <li> <para-num num="[0038]"> </para-num> <div id="p-0040" num="0038" class="description-line">When it is described that a part in the overall specification âincludesâ a certain component, this means that other components may be further included instead of excluding other components unless specifically stated to the contrary.</div>
    </li> <li> <para-num num="[0039]"> </para-num> <div id="p-0041" num="0039" class="description-line">In addition, a term such as a âunitâ or a âportionâ used in the specification means a software component or a hardware component such as FPGA or ASIC, and the âunitâ or the âportionâ performs a certain role. However, the âunitâ or the âportionâ is not limited to software or hardware. The âportionâ or the âunitâ may be configured to be in an addressable storage medium, or may be configured to reproduce one or more processors. Thus, as an example, the âunitâ or the âportionâ includes components (such as software components, object-oriented software components, class components, and task components), processes, functions, properties, procedures, subroutines, segments of program code, drivers, firmware, microcode, circuits, data, database, data structures, tables, arrays, and variables. The functions provided in the components and âunitâ may be combined into a smaller number of components and âunitsâ or may be further divided into additional components and âunitsâ.</div>
    </li> <li> <para-num num="[0040]"> </para-num> <div id="p-0042" num="0040" class="description-line">Hereinafter, the embodiment of the present disclosure will be described in detail with reference to the accompanying drawings so that those of ordinary skill in the art may easily implement the present disclosure. In the drawings, portions not related to the description are omitted in order to clearly describe the present disclosure.</div>
    </li> <li> <para-num num="[0041]"> </para-num> <div id="p-0043" num="0041" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>1</b> </figref> is a block diagram showing a configuration of a deep neural network-based real-time inference system according to an embodiment of the present disclosure, and <figref idrefs="DRAWINGS">FIG. <b>2</b> </figref> is a conceptual diagram for describing operation of the deep neural network-based real-time inference system according to an embodiment of the present disclosure.</div>
    </li> <li> <para-num num="[0042]"> </para-num> <div id="p-0044" num="0042" class="description-line">Referring to <figref idrefs="DRAWINGS">FIG. <b>1</b> </figref>, the deep neural network-based real-<figure-callout id="1" label="time inference system" filenames="US20230386192A1-20231130-D00001.png,US20230386192A1-20231130-D00002.png" state="{{state}}">time inference system</figure-callout> <b>1</b> according to an embodiment of the present disclosure includes at least one <figure-callout id="100" label="edge devices" filenames="US20230386192A1-20231130-D00001.png" state="{{state}}">edge devices</figure-callout> <b>100</b> that executes edge computing, and a <figure-callout id="200" label="cloud server" filenames="US20230386192A1-20231130-D00001.png" state="{{state}}">cloud server</figure-callout> <b>200</b> that receives data from the <figure-callout id="100" label="edge device" filenames="US20230386192A1-20231130-D00001.png" state="{{state}}">edge device</figure-callout> <b>100</b>, executes cloud server computing, and transmits execution results to the edge.</div>
    </li> <li> <para-num num="[0043]"> </para-num> <div id="p-0045" num="0043" class="description-line">For example, the <figure-callout id="100" label="edge device" filenames="US20230386192A1-20231130-D00001.png" state="{{state}}">edge device</figure-callout> <b>100</b> may correspond to a smart device, a drone, or a wearable device, but is not limited thereto.</div>
    </li> <li> <para-num num="[0044]"> </para-num> <div id="p-0046" num="0044" class="description-line">The <figure-callout id="100" label="edge device" filenames="US20230386192A1-20231130-D00001.png" state="{{state}}">edge device</figure-callout> <b>100</b> may include a camera that acquires images, a memory that stores information on a pre-trained extractor, and a processor that controls components of the <figure-callout id="100" label="edge device" filenames="US20230386192A1-20231130-D00001.png" state="{{state}}">edge device</figure-callout> <b>100</b>.</div>
    </li> <li> <para-num num="[0045]"> </para-num> <div id="p-0047" num="0045" class="description-line">Basically, the <figure-callout id="100" label="edge device" filenames="US20230386192A1-20231130-D00001.png" state="{{state}}">edge device</figure-callout> <b>100</b> may collect data, refine data, perform preprocessing such as sampling, cleaning, and combining on data, and transmit preprocessing results to the <figure-callout id="200" label="cloud server" filenames="US20230386192A1-20231130-D00001.png" state="{{state}}">cloud server</figure-callout> <b>200</b>.</div>
    </li> <li> <para-num num="[0046]"> </para-num> <div id="p-0048" num="0046" class="description-line">The function of the <figure-callout id="100" label="edge device" filenames="US20230386192A1-20231130-D00001.png" state="{{state}}">edge device</figure-callout> <b>100</b> can be designed in various ways. For example, the <figure-callout id="100" label="edge device" filenames="US20230386192A1-20231130-D00001.png" state="{{state}}">edge device</figure-callout> <b>100</b> may be designed to process data by itself without sending the data to the <figure-callout id="200" label="cloud server" filenames="US20230386192A1-20231130-D00001.png" state="{{state}}">cloud server</figure-callout> <b>200</b>. However, the present disclosure focuses on an embodiment in which the <figure-callout id="100" label="edge device" filenames="US20230386192A1-20231130-D00001.png" state="{{state}}">edge device</figure-callout> <b>100</b> and the <figure-callout id="200" label="cloud server" filenames="US20230386192A1-20231130-D00001.png" state="{{state}}">cloud server</figure-callout> <b>200</b> perform data processing in a split manner.</div>
    </li> <li> <para-num num="[0047]"> </para-num> <div id="p-0049" num="0047" class="description-line">In one embodiment, the <figure-callout id="100" label="edge device" filenames="US20230386192A1-20231130-D00001.png" state="{{state}}">edge device</figure-callout> <b>100</b> may analyze environmental conditions and select a first layer corresponding to a predetermined split point from among a plurality of layers included in a first artificial intelligence model according to results of analysis of the environmental conditions.</div>
    </li> <li> <para-num num="[0048]"> </para-num> <div id="p-0050" num="0048" class="description-line">Accordingly, the <figure-callout id="100" label="edge device" filenames="US20230386192A1-20231130-D00001.png" state="{{state}}">edge device</figure-callout> <b>100</b> may reduce transmission overhead by quantizing only a feature of the first layer to decrease the bits of an intermediate feature and transmitting the quantized feature to the <figure-callout id="200" label="cloud server" filenames="US20230386192A1-20231130-D00001.png" state="{{state}}">cloud server</figure-callout> <b>200</b>.</div>
    </li> <li> <para-num num="[0049]"> </para-num> <div id="p-0051" num="0049" class="description-line">Here, the <figure-callout id="100" label="edge device" filenames="US20230386192A1-20231130-D00001.png" state="{{state}}">edge device</figure-callout> <b>100</b> may include the pre-trained first artificial intelligence model, and the first artificial intelligence model may include a plurality of layers. Here, the first artificial intelligence model may be a deep neural network trained both with quantized and non-quantized features for each predetermined split layer.</div>
    </li> <li> <para-num num="[0050]"> </para-num> <div id="p-0052" num="0050" class="description-line">Here, the environmental conditions may include a network speed between the <figure-callout id="100" label="edge device" filenames="US20230386192A1-20231130-D00001.png" state="{{state}}">edge device</figure-callout> <b>100</b> and the <figure-callout id="200" label="cloud server" filenames="US20230386192A1-20231130-D00001.png" state="{{state}}">cloud server</figure-callout> <b>200</b> and at least one of the performances of the <figure-callout id="100" label="edge device" filenames="US20230386192A1-20231130-D00001.png" state="{{state}}">edge device</figure-callout> <b>100</b> and the <figure-callout id="200" label="cloud server" filenames="US20230386192A1-20231130-D00001.png" state="{{state}}">cloud server</figure-callout> <b>200</b>.</div>
    </li> <li> <para-num num="[0051]"> </para-num> <div id="p-0053" num="0051" class="description-line">For example, the <figure-callout id="100" label="edge device" filenames="US20230386192A1-20231130-D00001.png" state="{{state}}">edge device</figure-callout> <b>100</b> may select a split point in a relatively previous layer of the first artificial intelligence model if the performance of the <figure-callout id="100" label="edge device" filenames="US20230386192A1-20231130-D00001.png" state="{{state}}">edge device</figure-callout> <b>100</b> does not meet preset criteria, and the <figure-callout id="100" label="edge device" filenames="US20230386192A1-20231130-D00001.png" state="{{state}}">edge device</figure-callout> <b>100</b> may select a split point in a relatively later layer of the first artificial intelligence model if the performance of the <figure-callout id="100" label="edge device" filenames="US20230386192A1-20231130-D00001.png" state="{{state}}">edge device</figure-callout> <b>100</b> is higher than the preset criteria.</div>
    </li> <li> <para-num num="[0052]"> </para-num> <div id="p-0054" num="0052" class="description-line">As a component for selecting a split point, the first artificial intelligence model may further include a quantization switch <b>110</b> that switches between a path for quantizing a feature of each layer and a path for passing the feature of each layer without quantization of the feature, as shown in (<b>1</b>) of <figref idrefs="DRAWINGS">FIG. <b>2</b> </figref>. The quantization switch <b>110</b> may be applied to each layer of the first artificial intelligence model.</div>
    </li> <li> <para-num num="[0053]"> </para-num> <div id="p-0055" num="0053" class="description-line">(<b>2</b>) of <figref idrefs="DRAWINGS">FIG. <b>2</b> </figref> shows an example in which the last layer is determined as a split point, and the <figure-callout id="100" label="edge device" filenames="US20230386192A1-20231130-D00001.png" state="{{state}}">edge device</figure-callout> <b>100</b> quantizes the highest level feature by selecting the last layer of the first artificial intelligence model as a split point and transmits the quantized feature to the <figure-callout id="200" label="cloud server" filenames="US20230386192A1-20231130-D00001.png" state="{{state}}">cloud server</figure-callout> <b>200</b>. That is, (<b>2</b>) of <figref idrefs="DRAWINGS">FIG. <b>2</b> </figref> illustrates a case where features are output without being quantized in previous layers of the first artificial intelligence model, and the feature is output after being quantized by the switch <b>110</b> in the last layer.</div>
    </li> <li> <para-num num="[0054]"> </para-num> <div id="p-0056" num="0054" class="description-line">(<b>3</b>) of <figref idrefs="DRAWINGS">FIG. <b>2</b> </figref> illustrates a case where the <figure-callout id="100" label="edge device" filenames="US20230386192A1-20231130-D00001.png" state="{{state}}">edge device</figure-callout> <b>100</b> selects a relatively previous layer compared to the case of (<b>1</b>) as a split point, quantizes a low-level feature, and transmits the quantized feature to the <figure-callout id="200" label="cloud server" filenames="US20230386192A1-20231130-D00001.png" state="{{state}}">cloud server</figure-callout> <b>200</b>.</div>
    </li> <li> <para-num num="[0055]"> </para-num> <div id="p-0057" num="0055" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>3</b> </figref> is a diagram schematically illustrating an example of quantizing a feature for a layer corresponding to each split point according to an embodiment of the present disclosure. Referring to <figref idrefs="DRAWINGS">FIG. <b>3</b> </figref>, the <figure-callout id="100" label="edge device" filenames="US20230386192A1-20231130-D00001.png" state="{{state}}">edge device</figure-callout> <b>100</b> does not quantize features of layers by the quantization switch <b>110</b> until reaching a layer corresponding to a split point, sequentially inputs outputs of previous layers to next layers, and upon reaching the layer corresponding to the split point, performs quantization on the feature of the corresponding layer through the quantization switch <b>110</b>.</div>
    </li> <li> <para-num num="[0056]"> </para-num> <div id="p-0058" num="0056" class="description-line">The <figure-callout id="200" label="cloud server" filenames="US20230386192A1-20231130-D00001.png" state="{{state}}">cloud server</figure-callout> <b>200</b> may perform core processing, such as comprehensively performing tasks received from the <figure-callout id="100" label="edge device" filenames="US20230386192A1-20231130-D00001.png" state="{{state}}">edge device</figure-callout> <b>100</b> or distributing some tasks to a <figure-callout id="100" label="specific edge device" filenames="US20230386192A1-20231130-D00001.png" state="{{state}}">specific edge device</figure-callout> <b>100</b>.</div>
    </li> <li> <para-num num="[0057]"> </para-num> <div id="p-0059" num="0057" class="description-line">Results processed in the <figure-callout id="200" label="cloud server" filenames="US20230386192A1-20231130-D00001.png" state="{{state}}">cloud server</figure-callout> <b>200</b> may be transmitted to the <figure-callout id="100" label="edge device" filenames="US20230386192A1-20231130-D00001.png" state="{{state}}">edge device</figure-callout> <b>100</b>.</div>
    </li> <li> <para-num num="[0058]"> </para-num> <div id="p-0060" num="0058" class="description-line">In an embodiment, the <figure-callout id="200" label="cloud server" filenames="US20230386192A1-20231130-D00001.png" state="{{state}}">cloud server</figure-callout> <b>200</b> may derive a processing result for an image based on quantized features received from the <figure-callout id="100" label="edge device" filenames="US20230386192A1-20231130-D00001.png" state="{{state}}">edge device</figure-callout> <b>100</b>. For example, if a second artificial intelligence model included in the <figure-callout id="200" label="cloud server" filenames="US20230386192A1-20231130-D00001.png" state="{{state}}">cloud server</figure-callout> <b>200</b> is an object detection model, object detection in an image may be derived as an image processing result.</div>
    </li> <li> <para-num num="[0059]"> </para-num> <div id="p-0061" num="0059" class="description-line">To this end, the <figure-callout id="200" label="cloud server" filenames="US20230386192A1-20231130-D00001.png" state="{{state}}">cloud server</figure-callout> <b>200</b> may include the pre-trained second artificial intelligence model, a memory for storing information on the second artificial intelligence model, and a processor for controlling components of the <figure-callout id="200" label="cloud server" filenames="US20230386192A1-20231130-D00001.png" state="{{state}}">cloud server</figure-callout> <b>200</b>. Here, the second artificial intelligence model has the same structure and function as the first artificial intelligence model included in the <figure-callout id="100" label="edge device" filenames="US20230386192A1-20231130-D00001.png" state="{{state}}">edge device</figure-callout> <b>100</b>.</div>
    </li> <li> <para-num num="[0060]"> </para-num> <div id="p-0062" num="0060" class="description-line">The <figure-callout id="200" label="cloud server" filenames="US20230386192A1-20231130-D00001.png" state="{{state}}">cloud server</figure-callout> <b>200</b> may receive a feature quantized for an output of a first layer corresponding to a predetermined split point among the plurality of layers included in the first artificial intelligence model from the <figure-callout id="100" label="edge device" filenames="US20230386192A1-20231130-D00001.png" state="{{state}}">edge device</figure-callout> <b>100</b>. Subsequently, the <figure-callout id="200" label="cloud server" filenames="US20230386192A1-20231130-D00001.png" state="{{state}}">cloud server</figure-callout> <b>200</b> may input the quantized feature to a second layer of the second artificial intelligence model corresponding to a layer immediately following the first layer in the second artificial intelligence model.</div>
    </li> <li> <para-num num="[0061]"> </para-num> <div id="p-0063" num="0061" class="description-line">Here, the <figure-callout id="200" label="cloud server" filenames="US20230386192A1-20231130-D00001.png" state="{{state}}">cloud server</figure-callout> <b>200</b> can ascertain which layer corresponds to the quantized layer based on the shape of the quantized feature. To this end, the <figure-callout id="200" label="cloud server" filenames="US20230386192A1-20231130-D00001.png" state="{{state}}">cloud server</figure-callout> <b>200</b> may pre-store feature shape information of predetermined split points along with layer order information.</div>
    </li> <li> <para-num num="[0062]"> </para-num> <div id="p-0064" num="0062" class="description-line">Alternatively, the <figure-callout id="100" label="edge device" filenames="US20230386192A1-20231130-D00001.png" state="{{state}}">edge device</figure-callout> <b>100</b> may transmit information on the order of the first layer to the <figure-callout id="200" label="cloud server" filenames="US20230386192A1-20231130-D00001.png" state="{{state}}">cloud server</figure-callout> <b>200</b> such that the <figure-callout id="200" label="cloud server" filenames="US20230386192A1-20231130-D00001.png" state="{{state}}">cloud server</figure-callout> <b>200</b> can determine a layer to which the quantized feature will be input.</div>
    </li> <li> <para-num num="[0063]"> </para-num> <div id="p-0065" num="0063" class="description-line">Accordingly, the <figure-callout id="200" label="cloud server" filenames="US20230386192A1-20231130-D00001.png" state="{{state}}">cloud server</figure-callout> <b>200</b> may derive image processing results through execution of the second to last layers of the second artificial intelligence model.</div>
    </li> <li> <para-num num="[0064]"> </para-num> <div id="p-0066" num="0064" class="description-line"> <figref idrefs="DRAWINGS">FIGS. <b>4</b>A to <b>4</b>C</figref> are conceptual diagrams for describing differences between a prior art and an embodiment of the present disclosure.</div>
    </li> <li> <para-num num="[0065]"> </para-num> <div id="p-0067" num="0065" class="description-line">Referring to <figref idrefs="DRAWINGS">FIG. <b>4</b>A</figref>, a model in which a split point is set is illustrated as a prior art. When a split point is fixedly set for a certain layer of an artificial intelligence model, a model needs to be provided for each split point, and models need to be switched according to a determined split point. In such a case, a storage space is required depending on the number of split options, and weight reloading overhead occurs in order to execute and switch multiple independent models. This causes a considerable delay time in the <figure-callout id="100" label="edge device" filenames="US20230386192A1-20231130-D00001.png" state="{{state}}">edge device</figure-callout> <b>100</b> with limited resources.</div>
    </li> <li> <para-num num="[0066]"> </para-num> <div id="p-0068" num="0066" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>4</b>B</figref> illustrates a case in which quantization modules are inserted at all split points. However, in this case, when quantization is applied to all split layers, propagated features repeatedly lose representation thereof while passing through the layers, resulting in significant decrease in accuracy.</div>
    </li> <li> <para-num num="[0067]"> </para-num> <div id="p-0069" num="0067" class="description-line">In order to solve this problem, an embodiment of the present disclosure proposes a quantization switching method of quantizing only a feature of a layer corresponding to a selected split point for an artificial intelligence model trained for quantized and non-quantized features for each layer in the deep neural network-based split inference system according to an embodiment of the present disclosure shown in <figref idrefs="DRAWINGS">FIG. <b>4</b>C</figref>.</div>
    </li> <li> <para-num num="[0068]"> </para-num> <div id="p-0070" num="0068" class="description-line">Quantization switching supports multiple inference paths for various split points in a one-to-one correspondence, in which all paths share all layers of a model, but quantization is executed only at a corresponding split point in each path. Since every inference path allows quantization only once in a corresponding split layer, models can avoid repetitive information loss.</div>
    </li> <li> <para-num num="[0069]"> </para-num> <div id="p-0071" num="0069" class="description-line"> <figref idrefs="DRAWINGS">FIGS. <b>5</b>A and <b>5</b>B</figref> are conceptual diagrams for describing differences between a prior art and an embodiment of the present disclosure.</div>
    </li> <li> <para-num num="[0070]"> </para-num> <div id="p-0072" num="0070" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>5</b>A</figref> illustrates a concept of performing quantization at all split points.</div>
    </li> <li> <para-num num="[0071]"> </para-num> <div id="p-0073" num="0071" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>5</b>B</figref> illustrates a concept of performing multi-path inference according to a selected split point by applying quantization switching to a single weight model trained for quantized and non-quantized features for each layer, as described above. Since all paths share convolutional and batch normalization layers, features of different paths are expected to show a consistent distribution in each layer of the model.</div>
    </li> <li> <para-num num="[0072]"> </para-num> <div id="p-0074" num="0072" class="description-line">However, when quantization switching is applied, an imbalance occurs in the distribution at all split points. That is, an imbalance occurs between quantized and non-quantized features obtained from different paths. This imbalance prevents convergence of optimal weights of the model.</div>
    </li> <li> <para-num num="[0073]"> </para-num> <div id="p-0075" num="0073" class="description-line">Therefore, in order to solve this problem, in an embodiment of the present disclosure, precision restoration is performed for every split point (i.e., feature precision is restored through a precision restoration (PR) layer), and batch normalization is performed (i.e., the distribution of each path is individually normalized through a batch normalization (BN) layer).</div>
    </li> <li> <para-num num="[0074]"> </para-num> <div id="p-0076" num="0074" class="description-line">For example, in the case of <figure-callout id="1" label="split path" filenames="US20230386192A1-20231130-D00001.png,US20230386192A1-20231130-D00002.png" state="{{state}}">split path</figure-callout> <b>1</b>, since quantization is performed at <figure-callout id="1" label="split point" filenames="US20230386192A1-20231130-D00001.png,US20230386192A1-20231130-D00002.png" state="{{state}}">split point</figure-callout> <b>1</b>, precision restoration (PR) is applied immediately after <figure-callout id="1" label="split layer" filenames="US20230386192A1-20231130-D00001.png,US20230386192A1-20231130-D00002.png" state="{{state}}">split layer</figure-callout> <b>1</b>, and batch normalization is performed. On the other hand, in the case of <figure-callout id="2" label="split paths" filenames="US20230386192A1-20231130-D00002.png" state="{{state}}"> <figure-callout id="3" label="split paths" filenames="US20230386192A1-20231130-D00002.png" state="{{state}}"> <figure-callout id="4" label="split paths" filenames="US20230386192A1-20231130-D00004.png" state="{{state}}">split paths</figure-callout> </figure-callout> </figure-callout> <b>2</b>, <b>3</b>, and <b>4</b>, quantization is not performed at <figure-callout id="1" label="split point" filenames="US20230386192A1-20231130-D00001.png,US20230386192A1-20231130-D00002.png" state="{{state}}">split point</figure-callout> <b>1</b>, and thus only individual batch normalizations are performed on <figure-callout id="2" label="split paths" filenames="US20230386192A1-20231130-D00002.png" state="{{state}}"> <figure-callout id="3" label="split paths" filenames="US20230386192A1-20231130-D00002.png" state="{{state}}"> <figure-callout id="4" label="split paths" filenames="US20230386192A1-20231130-D00004.png" state="{{state}}">split paths</figure-callout> </figure-callout> </figure-callout> <b>2</b>, <b>3</b>, and <b>4</b> after <figure-callout id="1" label="split layer" filenames="US20230386192A1-20231130-D00001.png,US20230386192A1-20231130-D00002.png" state="{{state}}">split layer</figure-callout> <b>1</b>.</div>
    </li> <li> <para-num num="[0075]"> </para-num> <div id="p-0077" num="0075" class="description-line">In this manner, feature imbalance between split paths can be resolved at all split points.</div>
    </li> <li> <para-num num="[0076]"> </para-num> <div id="p-0078" num="0076" class="description-line">In an embodiment, the first artificial intelligence model may dynamically apply a feature distribution matching unit that normalizes the distribution of features output from the first layer immediately after a split point through mean and variance.</div>
    </li> <li> <para-num num="[0077]"> </para-num> <div id="p-0079" num="0077" class="description-line">In an embodiment, the feature distribution matching unit may apply a convolution layer for restoring feature precision to quantized features.</div>
    </li> <li> <para-num num="[0078]"> </para-num> <div id="p-0080" num="0078" class="description-line">Specifically, the batch normalization is independently applied to each of split paths each of at split points. Here, even if normalization is applied to quantized features, the bit precision of the features remains low. Therefore, in order to maximize the effect of normalization applied to quantized features, feature precision is restored through a convolution layer (PR layer).</div>
    </li> <li> <para-num num="[0079]"> </para-num> <div id="p-0081" num="0079" class="description-line">The PR layer allows the feature of a split point to represent high precision in a normal distribution, and thus models are trained more stably.</div>
    </li> <li> <para-num num="[0080]"> </para-num> <div id="p-0082" num="0080" class="description-line">Meanwhile, the deep neural network-based real-time inference system according to an embodiment of the present disclosure aims to optimize the average accuracy in response to application of all quantization switches. Therefore, in an embodiment of the present disclosure, training is performed by summing losses of all split paths. At each iteration, gradients of all paths are computed and accumulated, and then weights of the model are updated. The number of paths is determined by a path option, which is a predefined hyperparameter. Since neural network operations in the <figure-callout id="200" label="cloud server" filenames="US20230386192A1-20231130-D00001.png" state="{{state}}">cloud server</figure-callout> <b>200</b> are much faster than those in the <figure-callout id="100" label="edge device" filenames="US20230386192A1-20231130-D00001.png" state="{{state}}">edge device</figure-callout> <b>100</b>, it is efficient to execute more layers in the <figure-callout id="200" label="cloud server" filenames="US20230386192A1-20231130-D00001.png" state="{{state}}">cloud server</figure-callout> <b>200</b> if the <figure-callout id="200" label="cloud server" filenames="US20230386192A1-20231130-D00001.png" state="{{state}}">cloud server</figure-callout> <b>200</b> and the <figure-callout id="100" label="edge device" filenames="US20230386192A1-20231130-D00001.png" state="{{state}}">edge device</figure-callout> <b>100</b> have the amount of transmission.</div>
    </li> <li> <para-num num="[0081]"> </para-num> <div id="p-0083" num="0081" class="description-line">Accordingly, the path option may be defined as a set of first layers among layers having the same feature size.</div>
    </li> <li> <para-num num="[0082]"> </para-num> <div id="p-0084" num="0082" class="description-line">For training, a model with a precision restoration layer (PR layer) and independent batch normalization (BN) is loaded for all split paths. At the time of performing propagation and backpropagation for gradient calculation, a quantization module and the restoration layer are activated only in a layer corresponding to a selected split point, and independent batch normalization (BN) of all split layers is switched according to a selected path.</div>
    </li> <li> <para-num num="[0083]"> </para-num> <div id="p-0085" num="0083" class="description-line"> <figref idrefs="DRAWINGS">FIG. <b>6</b> </figref> is a flowchart illustrating a deep neural network-based real-time inference method according to an embodiment of the present disclosure.</div>
    </li> <li> <para-num num="[0084]"> </para-num> <div id="p-0086" num="0084" class="description-line">The deep neural network-based real-time inference method according to an embodiment of the present disclosure may be performed in substantially the same components as those of the <figure-callout id="1" label="system" filenames="US20230386192A1-20231130-D00001.png,US20230386192A1-20231130-D00002.png" state="{{state}}">system</figure-callout> <b>1</b> of <figref idrefs="DRAWINGS">FIG. <b>1</b> </figref>. Accordingly, the same components as those of the <figure-callout id="1" label="system" filenames="US20230386192A1-20231130-D00001.png,US20230386192A1-20231130-D00002.png" state="{{state}}">system</figure-callout> <b>1</b> of <figref idrefs="DRAWINGS">FIG. <b>1</b> </figref> are denoted by the same reference numerals and redundant descriptions are omitted.</div>
    </li> <li> <para-num num="[0085]"> </para-num> <div id="p-0087" num="0085" class="description-line">Referring to <figref idrefs="DRAWINGS">FIG. <b>6</b> </figref>, in the deep neural network-based real-time inference method according to an embodiment of the present disclosure, when an edge device acquires an image (S<b>110</b>), the edge device analyzes environmental conditions related to the edge device and a cloud server (S<b>120</b>), and selects a first layer corresponding to a split point from among a plurality of layers included in a pre-trained first artificial intelligence model of the edge device according to a result of analysis of the environmental conditions (S<b>130</b>). The edge device quantizes only the feature of the first layer corresponding to the split point (S<b>140</b>) and transmits the quantized feature to the cloud server (S<b>150</b>).</div>
    </li> <li> <para-num num="[0086]"> </para-num> <div id="p-0088" num="0086" class="description-line">Here, the environmental conditions may include a network speed between the edge device and the cloud server and at least one of the performances of the edge device and the cloud server.</div>
    </li> <li> <para-num num="[0087]"> </para-num> <div id="p-0089" num="0087" class="description-line">For example, if the performance of the edge device does not meet preset criteria, the edge device may select a split point in a relatively previous layer of the first artificial intelligence model, and if the performance of the edge device is higher than the preset criteria, the edge device may select a split point in a relatively later layer of the first artificial intelligence model.</div>
    </li> <li> <para-num num="[0088]"> </para-num> <div id="p-0090" num="0088" class="description-line">As a component for selecting a split point, the first artificial intelligence model may further include a quantization switch that switches between a path for quantizing a feature of each layer and a path for passing the feature of each layer without being quantized, as shown in (<b>1</b>) of <figref idrefs="DRAWINGS">FIG. <b>2</b> </figref>. The quantization switch may be applied to each layer of the first artificial intelligence model.</div>
    </li> <li> <para-num num="[0089]"> </para-num> <div id="p-0091" num="0089" class="description-line">Next, when the cloud server inputs the quantized feature to a second layer immediately after the first layer among a plurality of layers included in a second artificial intelligence model identical to the first artificial intelligence model, the cloud server may derive an image processing result based on the second artificial intelligence model.</div>
    </li> <li> <para-num num="[0090]"> </para-num> <div id="p-0092" num="0090" class="description-line">For example, when the second artificial intelligence model included in the cloud server is an object detection model, object detection in an image may be derived as an image processing result.</div>
    </li> <li> <para-num num="[0091]"> </para-num> <div id="p-0093" num="0091" class="description-line">Specifically, the cloud server may receive a quantized feature of an output of the first layer corresponding to a predetermined split point among the plurality of layers included in the first artificial intelligence model from the edge device. Subsequently, the cloud server may input the quantized feature to the second layer of the second artificial intelligence model which corresponds to a layer immediately after the first layer.</div>
    </li> <li> <para-num num="[0092]"> </para-num> <div id="p-0094" num="0092" class="description-line">Here, the cloud server can ascertain which layer corresponds to the quantized layer based on the shape of the quantized feature. To this end, the <figure-callout id="200" label="cloud server" filenames="US20230386192A1-20231130-D00001.png" state="{{state}}">cloud server</figure-callout> <b>200</b> may pre-store feature shape information of predetermined split points along with layer order information.</div>
    </li> <li> <para-num num="[0093]"> </para-num> <div id="p-0095" num="0093" class="description-line">Alternatively, the edge device may transmit information on the order of the first layer to the cloud server such that the cloud server can determine a layer to which the quantized feature will be input.</div>
    </li> <li> <para-num num="[0094]"> </para-num> <div id="p-0096" num="0094" class="description-line">The above-described deep neural network-based real-time inference system may be implemented by a computing device including at least some of a processor, a memory, a user input device, and a presentation device.</div>
    </li> <li> <para-num num="[0095]"> </para-num> <div id="p-0097" num="0095" class="description-line">The memory is a medium that stores computer-readable software, applications, program modules, routines, instructions, and/or data coded to perform a specific task when executed by the processor. The processor may read and execute the computer-readable software, applications, program modules, routines, instructions, and/or data stored in the memory.</div>
    </li> <li> <para-num num="[0096]"> </para-num> <div id="p-0098" num="0096" class="description-line">The computing device may include various devices such as smartphones, tablets, laptops, desktops, servers, and clients. The computing device may be a single stand-alone device or may include multiple computing devices operating in a distributed environment consisting of multiple computing devices cooperating with each other over a communications network.</div>
    </li> <li> <para-num num="[0097]"> </para-num> <div id="p-0099" num="0097" class="description-line">In addition, the above-described deep neural network-based real-time inference method may be performed by a computing device including a processor and a memory storing computer-readable software, applications, program modules, routines, instructions, and/or data structures coded to perform an object detection method using an artificial intelligence model when executed by the processor.</div>
    </li> <li> <para-num num="[0098]"> </para-num> <div id="p-0100" num="0098" class="description-line">Combinations of steps in each flowchart attached to the present disclosure may be executed by computer program instructions. Since the computer program instructions can be mounted on a processor of a general-purpose computer, a special purpose computer, or other programmable data processing equipment, the instructions executed by the processor of the computer or other programmable data processing equipment create a means for performing the functions described in each step of the flowchart. The computer program instructions can also be stored on a computer-usable or computer-readable storage medium which can be directed to a computer or other programmable data processing equipment to implement a function in a specific manner. Accordingly, the instructions stored on the computer-usable or computer-readable recording medium can also produce an article of manufacture containing an instruction means which performs the functions described in each step of the flowchart. The computer program instructions can also be mounted on a computer or other programmable data processing equipment. Accordingly, a series of operational steps are performed on a computer or other programmable data processing equipment to create a computer-executable process, and it is also possible for instructions to perform a computer or other programmable data processing equipment to provide steps for performing the functions described in each step of the flowchart.</div>
    </li> <li> <para-num num="[0099]"> </para-num> <div id="p-0101" num="0099" class="description-line">In addition, each step may represent a module, a segment, or a portion of codes which contains one or more executable instructions for executing the specified logical function(s). It should also be noted that in some alternative embodiments, the functions mentioned in the steps may occur out of order. For example, two steps illustrated in succession may in fact be performed substantially simultaneously, or the steps may sometimes be performed in a reverse order depending on the corresponding function.</div>
    </li> <li> <para-num num="[0100]"> </para-num> <div id="p-0102" num="0100" class="description-line">The above description is merely exemplary description of the technical scope of the present disclosure, and it will be understood by those skilled in the art that various changes and modifications can be made without departing from original characteristics of the present disclosure. Therefore, the embodiments disclosed in the present disclosure are intended to explain, not to limit, the technical scope of the present disclosure, and the technical scope of the present disclosure is not limited by the embodiments. The protection scope of the present disclosure should be interpreted based on the following claims and it should be appreciated that all technical scopes included within a range equivalent thereto are included in the protection scope of the present disclosure.</div>
    
  </li> </ul>
  </div>
  </section>

  <section itemprop="claims" itemscope>
    <h2>Claims (<span itemprop="count">19</span>)</h2>
    
    <div itemprop="content" html><div mxw-id="PCLM438280432" lang="EN" load-source="patent-office" class="claims">
    <claim-statement>What is claimed is:</claim-statement>
    <div class="claim"> <div id="CLM-00001" num="00001" class="claim">
      <div class="claim-text"> <b>1</b>. A deep neural network-based real-time inference apparatus including a cloud server configured to infer an acquired image along with an edge device in a split manner, the apparatus comprising:
<div class="claim-text">a memory configured to store information of a second artificial intelligence model identical to a first artificial intelligence model of the edge device; and</div> <div class="claim-text">a processor executing one or more instructions stored in the memory, wherein the instructions, when executed by the processor, cause the processor to receive a quantized feature of an output of a first layer corresponding to a predetermined split point among a plurality of layers included in the first artificial intelligence model, and determine a processing result for the image based on the second artificial intelligence model by inputting the quantized feature to a second layer of the second artificial intelligence model corresponding a layer immediately after the first layer.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00002" num="00002" class="claim">
      <div class="claim-text"> <b>2</b>. The deep neural network-based real-time inference apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the cloud server determines an object in the image by inputting the quantized feature to the artificial intelligence model.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00003" num="00003" class="claim">
      <div class="claim-text"> <b>3</b>. The deep neural network-based real-time inference apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the first artificial intelligence model and the second artificial intelligence model include a deep neural network trained both with quantized and non-quantized features for each predetermined split layer.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00004" num="00004" class="claim">
      <div class="claim-text"> <b>4</b>. The deep neural network-based real-time inference apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the processor is configured to analyze at least one of a network resource between the edge device and the cloud server, a computing resource of the edge device, and a computing resource of the cloud server, and determine a location of the split point with respect to the first layer based on an analysis result.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00005" num="00005" class="claim">
      <div class="claim-text"> <b>5</b>. The deep neural network-based real-time inference apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the first artificial intelligence model and the second artificial intelligence model further include a quantization switch for switching between a path for quantizing a feature of each layer and a path for passing the feature of each layer without being quantized, and
<div class="claim-text">wherein the quantization switch is provided for each layer of the artificial intelligence models.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00006" num="00006" class="claim">
      <div class="claim-text"> <b>6</b>. The deep neural network-based real-time inference apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the first artificial intelligence model and the second artificial intelligence model dynamically apply a feature distribution matching unit that normalizes a distribution of features output from the first layer immediately after the split point through mean and variance.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00007" num="00007" class="claim">
      <div class="claim-text"> <b>7</b>. The deep neural network-based real-time inference apparatus of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the feature distribution matching unit applies a convolution layer for restoring feature precision to the quantized feature.</div>
    </div>
    </div> <div class="claim"> <div id="CLM-00008" num="00008" class="claim">
      <div class="claim-text"> <b>8</b>. A deep neural network-based real-time inference apparatus including an edge device configured to transmit a quantized feature obtained by processing an acquired image to a cloud server, the apparatus comprising:
<div class="claim-text">a memory configured to store information of a first artificial intelligence model identical to a second artificial intelligence model of the cloud server; and</div> <div class="claim-text">a processor executing one or more instructions stored in the memory, wherein the instructions, when executed by the processor, cause the processor to analyze at least one of resources, select a first layer corresponding to a predetermined split point from among a plurality of layers included in the first artificial intelligence model according to the at least one of resources, quantize only a feature of the first layer, and transmit the quantized feature to the cloud server.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00009" num="00009" class="claim">
      <div class="claim-text"> <b>9</b>. The deep neural network-based real-time inference apparatus of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the cloud server determines a processing result for the image based on the second artificial intelligence model by inputting the quantized feature to a second layer of the second artificial intelligence model corresponding to a layer immediately after the first layer.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00010" num="00010" class="claim">
      <div class="claim-text"> <b>10</b>. The deep neural network-based real-time inference apparatus of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the first artificial intelligence model and the second artificial intelligence model includes a deep neural network trained both with quantized and non-quantized features for each predetermined split layer.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00011" num="00011" class="claim">
      <div class="claim-text"> <b>11</b>. The deep neural network-based real-time inference apparatus of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the at least one of resources includes a network resource between the edge device and the cloud server, a computing resource of the edge device, and a computing resource of the cloud server.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00012" num="00012" class="claim">
      <div class="claim-text"> <b>12</b>. The deep neural network-based real-time inference apparatus of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the first artificial intelligence model and the second artificial intelligence model further include a quantization switch for switching between a path for quantizing a feature of each layer and a path for passing the feature of each layer without being quantized, and
<div class="claim-text">wherein the quantization switch is provided for each layer of the artificial intelligence models.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00013" num="00013" class="claim">
      <div class="claim-text"> <b>13</b>. The deep neural network-based real-time inference apparatus of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the first artificial intelligence model and the second artificial intelligence model dynamically apply a feature distribution matching unit that normalizes a distribution of features output from the first layer immediately after the split point through mean and variance.</div>
    </div>
    </div> <div class="claim"> <div id="CLM-00014" num="00014" class="claim">
      <div class="claim-text"> <b>14</b>. A deep neural network-based real-time inference method, the method comprising:
<div class="claim-text">acquiring, by a processor included in a cloud server, an image from an edge device;</div> <div class="claim-text">analyzing, by a processor included in the edge device, at least one of resources related to the edge device and a cloud server;</div> <div class="claim-text">selecting, by the processor included in the edge device, a first layer corresponding to a split point from among a plurality of layers included in a pre-trained first artificial intelligence model of the edge device according to the at least one of resources;</div> <div class="claim-text">quantizing, by the processor included in the edge device, only a feature of the first layer corresponding to the split point;</div> <div class="claim-text">transmitting, by the processor included in the edge device, the quantized feature to the cloud server;</div> <div class="claim-text">inputting, by the processor included in the cloud server, the quantized feature to a second layer corresponding to a layer immediately after the first layer among a plurality of layers included in a second artificial intelligence model identical to the first artificial intelligence model; and</div> <div class="claim-text">determining, by the processor included in the cloud server, a processing result for the image based on the second artificial intelligence model.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00015" num="00015" class="claim">
      <div class="claim-text"> <b>15</b>. The deep neural network-based real-time inference method of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the at least one of resources includes a network resource between the edge device and the cloud server, a computing resource of the edge device, and a computing of the cloud server.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00016" num="00016" class="claim">
      <div class="claim-text"> <b>16</b>. The deep neural network-based real-time inference method of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the first artificial intelligence model and the second artificial intelligence model further include a quantization switch for switching between a path for quantizing a feature of each layer and a path for passing the feature of each layer without being quantized, and
<div class="claim-text">wherein the quantization switch is provided for each split layer of the artificial intelligence models.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00017" num="00017" class="claim">
      <div class="claim-text"> <b>17</b>. The deep neural network-based real-time inference method of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the first artificial intelligence model and the second artificial intelligence model dynamically apply a feature distribution matching unit that normalizes a distribution of features output from the first layer immediately after the split point through mean and variance.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00018" num="00018" class="claim">
      <div class="claim-text"> <b>18</b>. The deep neural network-based real-time inference method of <claim-ref idref="CLM-00017">claim 17</claim-ref>, wherein the feature distribution matching unit applies a convolution layer for restoring feature precision to the quantized feature.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00019" num="00019" class="claim">
      <div class="claim-text"> <b>19</b>. The deep neural network-based real-time inference method of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the first artificial intelligence model and the second artificial intelligence model include a deep neural network trained both with quantized and non-quantized features for each predetermined split layer.</div>
    </div>
  </div> </div>
  </div>
  </section>

  <section itemprop="application" itemscope>

    <section itemprop="metadata" itemscope>
      <span itemprop="applicationNumber">US18/203,695</span>
      <span itemprop="priorityDate">2022-05-31</span>
      <span itemprop="filingDate">2023-05-31</span>
      <span itemprop="title">Deep neural network-based real-time inference method, and cloud device and edge device performing deep neural network-based real-time inference method 
     </span>
      <span itemprop="ifiStatus">Pending</span>
      
      <a href="/patent/US20230386192A1/en">
        <span itemprop="representativePublication">US20230386192A1</span>
        (<span itemprop="primaryLanguage">en</span>)
      </a>
    </section>

    

    <h2>Applications Claiming Priority (2)</h2>
    <table>
      <thead>
        <tr>
          <th>Application Number</th>
          <th>Priority Date</th>
          <th>Filing Date</th>
          <th>Title</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="appsClaimingPriority" itemscope repeat>
          <td>
            <span itemprop="applicationNumber">KR1020220066704A</span>
            <a href="/patent/KR20230166569A/en">
              <span itemprop="representativePublication">KR20230166569A</span>
                (<span itemprop="primaryLanguage">en</span>)
            </a>
          </td>
          <td itemprop="priorityDate">2022-05-31</td>
          <td itemprop="filingDate">2022-05-31</td>
          <td itemprop="title">Apparatus, system and method for detecting object based on deep neural network 
       </td>
        </tr>
        <tr itemprop="appsClaimingPriority" itemscope repeat>
          <td>
            <span itemprop="applicationNumber">KR10-2022-0066704</span>
            
          </td>
          <td itemprop="priorityDate"></td>
          <td itemprop="filingDate">2022-05-31</td>
          <td itemprop="title"></td>
        </tr>
      </tbody>
    </table>

    

    

    <h2>Publications (1)</h2>
    <table>
      <thead>
        <tr>
          <th>Publication Number</th>
          <th>Publication Date</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="pubs" itemscope repeat>
          <td>
            <span itemprop="publicationNumber">US20230386192A1</span>
            
            <span itemprop="thisPatent">true</span>
            <a href="/patent/US20230386192A1/en">
              US20230386192A1
              (<span itemprop="primaryLanguage">en</span>)
            </a>
          </td>
          <td itemprop="publicationDate">2023-11-30</td>
        </tr>
      </tbody>
    </table>

  </section>

  <section itemprop="family" itemscope>
    <h1>Family</h1>
    <h2>ID=88876545</h2>

    <h2>Family Applications (1)</h2>
    <table>
      <thead>
        <tr>
          <th>Application Number</th>
          <th>Title</th>
          <th>Priority Date</th>
          <th>Filing Date</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="applications" itemscope repeat>
          <td>
            <span itemprop="applicationNumber">US18/203,695</span>
            <span itemprop="ifiStatus">Pending</span>
            
            <a href="/patent/US20230386192A1/en">
              <span itemprop="representativePublication">US20230386192A1</span>
                (<span itemprop="primaryLanguage">en</span>)
            </a>
          </td>
          <td itemprop="priorityDate">2022-05-31</td>
          <td itemprop="filingDate">2023-05-31</td>
          <td itemprop="title">Deep neural network-based real-time inference method, and cloud device and edge device performing deep neural network-based real-time inference method 
     </td>
        </tr>
      </tbody>
    </table>

    

    

    <h2>Country Status (2)</h2>
    <table>
      <thead>
        <tr>
          <th>Country</th>
          <th>Link</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="countryStatus" itemscope repeat>
          <td>
            <span itemprop="countryCode">US</span>
            (<span itemprop="num">1</span>)
            <meta itemprop="thisCountry" content="true">
          </td>
          <td>
            <a href="/patent/US20230386192A1/en">
              <span itemprop="representativePublication">US20230386192A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
          </td>
        </tr>
        <tr itemprop="countryStatus" itemscope repeat>
          <td>
            <span itemprop="countryCode">KR</span>
            (<span itemprop="num">1</span>)
            
          </td>
          <td>
            <a href="/patent/KR20230166569A/en">
              <span itemprop="representativePublication">KR20230166569A</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
          </td>
        </tr>
      </tbody>
    </table>

    

    

    

    <h2>Family Cites Families (2)</h2>
    <table>
      <caption>* Cited by examiner, â  Cited by third party</caption>
      <thead>
        <tr>
          <th>Publication number</th>
          <th>Priority date</th>
          <th>Publication date</th>
          <th>Assignee</th>
          <th>Title</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="backwardReferencesFamily" itemscope repeat>
          <td>
            <a href="/patent/KR102310187B1/en">
              <span itemprop="publicationNumber">KR102310187B1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            
            
          </td>
          <td itemprop="priorityDate">2019-09-25</td>
          <td itemprop="publicationDate">2021-10-08</td>
          <td><span itemprop="assigneeOriginal">íêµ­ì ìê¸°ì ì°êµ¬ì</span></td>
          <td itemprop="title">A distributed computing system including multiple edges and cloud, and method for providing model for using adaptive intelligence thereof 
       </td>
        </tr>
        <tr itemprop="backwardReferencesFamily" itemscope repeat>
          <td>
            <a href="/patent/KR20210062346A/en">
              <span itemprop="publicationNumber">KR20210062346A</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            
            
          </td>
          <td itemprop="priorityDate">2019-11-21</td>
          <td itemprop="publicationDate">2021-05-31</td>
          <td><span itemprop="assigneeOriginal">ìì¸ëíêµì°ííë ¥ë¨</span></td>
          <td itemprop="title">Artifical intelligence node and method for compressing feature map thereof 
     </td>
        </tr>
      </tbody>
    </table>

    <ul>
      <li itemprop="applicationsByYear" itemscope repeat>
        <span itemprop="year">2022</span>
        <ul>
          <li itemprop="application" itemscope repeat>
            <span itemprop="filingDate">2022-05-31</span>
            <span itemprop="countryCode">KR</span>
            <span itemprop="applicationNumber">KR1020220066704A</span>
            <a href="/patent/KR20230166569A/en"><span itemprop="documentId">patent/KR20230166569A/en</span></a>
            <span itemprop="legalStatusCat">unknown</span>
            <span itemprop="legalStatus"></span>
            
          </li>
        </ul>
      </li>
      <li itemprop="applicationsByYear" itemscope repeat>
        <span itemprop="year">2023</span>
        <ul>
          <li itemprop="application" itemscope repeat>
            <span itemprop="filingDate">2023-05-31</span>
            <span itemprop="countryCode">US</span>
            <span itemprop="applicationNumber">US18/203,695</span>
            <a href="/patent/US20230386192A1/en"><span itemprop="documentId">patent/US20230386192A1/en</span></a>
            <span itemprop="legalStatusCat">active</span>
            <span itemprop="legalStatus">Pending</span>
            <span itemprop="thisApp" content="true" bool></span>
          </li>
        </ul>
      </li>
    </ul>

    </section>

  

  

  

  <section>
    <h2>Also Published As</h2>
    <table>
      <thead>
        <tr>
          <th>Publication number</th>
          <th>Publication date</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="docdbFamily" itemscope repeat>
          <td>
            <a href="/patent/KR20230166569A/en">
              <span itemprop="publicationNumber">KR20230166569A</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
          </td>
          <td itemprop="publicationDate">2023-12-07</td>
        </tr>
      </tbody>
    </table>
  </section>

  <section>
    <h2>Similar Documents</h2>
    <table>
      <thead>
        <tr>
          <th>Publication</th>
          <th>Publication Date</th>
          <th>Title</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/CN110852421B/en">
                <span itemprop="publicationNumber">CN110852421B</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2023-01-17">2023-01-17</time>
            
            
          </td>
          <td itemprop="title">Model generation method and device 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/EP3380939B1/en">
                <span itemprop="publicationNumber">EP3380939B1</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2023-02-01">2023-02-01</time>
            
            
          </td>
          <td itemprop="title">Adaptive artificial neural network selection techniques 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/US20200311539A1/en">
                <span itemprop="publicationNumber">US20200311539A1</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2020-10-01">2020-10-01</time>
            
            
          </td>
          <td itemprop="title">Cloud computing data compression for allreduce in deep learning 
     </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/KR20220054861A/en">
                <span itemprop="publicationNumber">KR20220054861A</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2022-05-03">2022-05-03</time>
            
            
          </td>
          <td itemprop="title">
  Training methods for neural network models and related products
 
     </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/US11182457B2/en">
                <span itemprop="publicationNumber">US11182457B2</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2021-11-23">2021-11-23</time>
            
            
          </td>
          <td itemprop="title">Matrix-factorization based gradient compression 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/US20200013159A1/en">
                <span itemprop="publicationNumber">US20200013159A1</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2020-01-09">2020-01-09</time>
            
            
          </td>
          <td itemprop="title">Method and system of analytics system balancing lead time and accuracy of edge analytics modules 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/CN111563593A/en">
                <span itemprop="publicationNumber">CN111563593A</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2020-08-21">2020-08-21</time>
            
            
          </td>
          <td itemprop="title">Training method and device of neural network model 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/WO2023231350A1/en">
                <span itemprop="publicationNumber">WO2023231350A1</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2023-12-07">2023-12-07</time>
            
            
          </td>
          <td itemprop="title">Task processing method implemented by using integer programming solver, device, and medium 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/JP2018529143A/en">
                <span itemprop="publicationNumber">JP2018529143A</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2018-10-04">2018-10-04</time>
            
            
          </td>
          <td itemprop="title">
  A data processing device that uses a representation of values by the time interval between events
 
     </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/KR20220011065A/en">
                <span itemprop="publicationNumber">KR20220011065A</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2022-01-27">2022-01-27</time>
            
            
          </td>
          <td itemprop="title">Method and apparatus for recognizing voice 
     </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/US20230386192A1/en">
                <span itemprop="publicationNumber">US20230386192A1</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2023-11-30">2023-11-30</time>
            
            
          </td>
          <td itemprop="title">Deep neural network-based real-time inference method, and cloud device and edge device performing deep neural network-based real-time inference method 
     </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/KR20220097329A/en">
                <span itemprop="publicationNumber">KR20220097329A</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2022-07-07">2022-07-07</time>
            
            
          </td>
          <td itemprop="title">Method and algorithm of deep learning network quantization for variable precision 
     </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            
            <meta itemprop="isScholar" content="true">
              <meta itemprop="scholarID" content="5335782428151059663">
              <a href="/scholar/5335782428151059663"><span itemprop="scholarAuthors">Truong et al.</span></a>
            
          </td>
          <td>
            
            <time itemprop="publicationDate" datetime="2012">2012</time>
            
          </td>
          <td itemprop="title">Design and implementation of the PALM-3000 real-time control system</td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/CN111582476A/en">
                <span itemprop="publicationNumber">CN111582476A</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2020-08-25">2020-08-25</time>
            
            
          </td>
          <td itemprop="title">Automatic quantization strategy searching method, device, equipment and storage medium 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/CN113366510A/en">
                <span itemprop="publicationNumber">CN113366510A</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2021-09-07">2021-09-07</time>
            
            
          </td>
          <td itemprop="title">Performing multi-objective tasks via trained raw network and dual network 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/CN114240157B/en">
                <span itemprop="publicationNumber">CN114240157B</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2023-05-23">2023-05-23</time>
            
            
          </td>
          <td itemprop="title">Robot scheduling method, system, equipment and storage medium 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/US20230222004A1/en">
                <span itemprop="publicationNumber">US20230222004A1</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2023-07-13">2023-07-13</time>
            
            
          </td>
          <td itemprop="title">Data locality for big data on kubernetes 
     </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/US20180268290A1/en">
                <span itemprop="publicationNumber">US20180268290A1</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2018-09-20">2018-09-20</time>
            
            
          </td>
          <td itemprop="title">Model training by discarding relatively less relevant parameters 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/US11556827B2/en">
                <span itemprop="publicationNumber">US11556827B2</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2023-01-17">2023-01-17</time>
            
            
          </td>
          <td itemprop="title">Transferring large datasets by using data generalization 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/CN115113855A/en">
                <span itemprop="publicationNumber">CN115113855A</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2022-09-27">2022-09-27</time>
            
            
          </td>
          <td itemprop="title">Audio data processing method and device, electronic equipment and storage medium 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/CN113657468A/en">
                <span itemprop="publicationNumber">CN113657468A</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2021-11-16">2021-11-16</time>
            
            
          </td>
          <td itemprop="title">Pre-training model generation method and device, electronic equipment and storage medium 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/US20230368518A1/en">
                <span itemprop="publicationNumber">US20230368518A1</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2023-11-16">2023-11-16</time>
            
            
          </td>
          <td itemprop="title">Deep neural network-based object detection method, and cloud sever and edge device performing deep neural network-based object detection method 
     </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/CN111966361B/en">
                <span itemprop="publicationNumber">CN111966361B</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2024-04-05">2024-04-05</time>
            
            
          </td>
          <td itemprop="title">Method, device, equipment and storage medium for determining model to be deployed 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/KR102362717B1/en">
                <span itemprop="publicationNumber">KR102362717B1</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2022-02-15">2022-02-15</time>
            
            
          </td>
          <td itemprop="title">Method for providing topic-specific chatbot service and device using the same 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="/patent/CN110633596A/en">
                <span itemprop="publicationNumber">CN110633596A</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2019-12-31">2019-12-31</time>
            
            
          </td>
          <td itemprop="title">Method and device for predicting vehicle direction angle 
       </td>
        </tr>
      </tbody>
    </table>
  </section>

  <section>
    <h2>Legal Events</h2>
    <table>
      <thead>
        <tr>
          <th>Date</th>
          <th>Code</th>
          <th>Title</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="legalEvents" itemscope repeat>
          <td><time itemprop="date" datetime="2023-05-31">2023-05-31</time></td>
          <td itemprop="code">AS</td>
          <td itemprop="title">Assignment</td>
          <td>
            <p itemprop="attributes" itemscope repeat>
              <strong itemprop="label">Owner name</strong>:
              <span itemprop="value">RESEARCH &amp; BUSINESS FOUNDATION SUNGKYUNKWAN UNIVERSITY, KOREA, REPUBLIC OF</span>
            </p>
            <p itemprop="attributes" itemscope repeat>
              <strong itemprop="label">Free format text</strong>:
              <span itemprop="value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:LEE, JOO CHAN;KO, JONG HWAN;REEL/FRAME:063805/0174</span>
            </p>
            <p itemprop="attributes" itemscope repeat>
              <strong itemprop="label">Effective date</strong>:
              <span itemprop="value">20230526</span>
            </p>
          </td>
        </tr>
        <tr itemprop="legalEvents" itemscope repeat>
          <td><time itemprop="date" datetime="2023-06-28">2023-06-28</time></td>
          <td itemprop="code">STPP</td>
          <td itemprop="title">Information on status: patent application and granting procedure in general</td>
          <td>
            <p itemprop="attributes" itemscope repeat>
              <strong itemprop="label">Free format text</strong>:
              <span itemprop="value">DOCKETED NEW CASE - READY FOR EXAMINATION</span>
            </p>
          </td>
        </tr>
      </tbody>
    </table>
  </section>

</article>

    </search-app>
    <script type="text/javascript" src="//www.gstatic.com/feedback/api.js"></script>
    <script type="text/javascript" src="//www.gstatic.com/feedback/js/help/prod/service/lazy.min.js"></script>
    <script type="text/javascript">
      if (window.help && window.help.service) {
        helpApi = window.help.service.Lazy.create(0, {apiKey: 'AIzaSyDTEI_0tLX4varJ7bwK8aT-eOI5qr3BmyI', locale: 'en-US'});
        window.requestedSurveys = new Set();
        window.requestSurvey = function(triggerId) {
          if (window.requestedSurveys.has(triggerId)) {
            return;
          }
          window.requestedSurveys.add(triggerId);
          helpApi.requestSurvey({
            triggerId: triggerId,
            enableTestingMode: false,
            callback: (requestSurveyCallbackParam) => {
              if (!requestSurveyCallbackParam.surveyData) {
                return;
              }
              helpApi.presentSurvey({
                productData: {
                  productVersion: window.version,
                  customData: {
                    "experiments": "72459301,72474719",
                  },
                },
                surveyData: requestSurveyCallbackParam.surveyData,
                colorScheme: 1,
                customZIndex: 10000,
              });
            }
          });
        };

        window.requestSurvey('YXTwAsvoW0kedxbuTdH0RArc9VhT');
      }
    </script>
    <script src="/sw/null_loader.js"></script>
  </body>
</html>
