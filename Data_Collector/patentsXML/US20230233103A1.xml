<html xmlns="http://www.w3.org/1999/xhtml"><head><style id="xml-viewer-style">/* Copyright 2014 The Chromium Authors
 * Use of this source code is governed by a BSD-style license that can be
 * found in the LICENSE file.
 */

:root {
  color-scheme: light dark;
}

div.header {
    border-bottom: 2px solid black;
    padding-bottom: 5px;
    margin: 10px;
}

@media (prefers-color-scheme: dark) {
  div.header {
    border-bottom: 2px solid white;
  }
}

div.folder &gt; div.hidden {
    display:none;
}

div.folder &gt; span.hidden {
    display:none;
}

.pretty-print {
    margin-top: 1em;
    margin-left: 20px;
    font-family: monospace;
    font-size: 13px;
}

#webkit-xml-viewer-source-xml {
    display: none;
}

.opened {
    margin-left: 1em;
}

.comment {
    white-space: pre;
}

.folder-button {
    user-select: none;
    cursor: pointer;
    display: inline-block;
    margin-left: -10px;
    width: 10px;
    background-repeat: no-repeat;
    background-position: left top;
    vertical-align: bottom;
}

.fold {
    background: url("data:image/svg+xml,&lt;svg xmlns='http://www.w3.org/2000/svg' fill='%23909090' width='10' height='10'&gt;&lt;path d='M0 0 L8 0 L4 7 Z'/&gt;&lt;/svg&gt;");
    height: 10px;
}

.open {
    background: url("data:image/svg+xml,&lt;svg xmlns='http://www.w3.org/2000/svg' fill='%23909090' width='10' height='10'&gt;&lt;path d='M0 0 L0 8 L7 4 Z'/&gt;&lt;/svg&gt;");
    height: 10px;
}
</style></head><body><div id="webkit-xml-viewer-source-xml"><us-patent-application xmlns="" lang="EN" dtd-version="v4.6 2022-02-17" file="US20230233103A1-20230727.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20230710" date-publ="20230727">
<us-bibliographic-data-application lang="EN" country="US">
<publication-reference>
<document-id>
<country>US</country>
<doc-number>20230233103</doc-number>
<kind>A1</kind>
<date>20230727</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>18183923</doc-number>
<date>20230314</date>
</document-id>
</application-reference>
<us-application-series-code>18</us-application-series-code>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>A</section>
<class>61</class>
<subclass>B</subclass>
<main-group>5</main-group>
<subgroup>11</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20230727</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20210101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>A</section>
<class>61</class>
<subclass>B</subclass>
<main-group>5</main-group>
<subgroup>397</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20230727</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>A</section>
<class>61</class>
<subclass>B</subclass>
<main-group>5</main-group>
<subgroup>00</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20230727</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classifications-cpc>
<main-cpc>
<classification-cpc>
<cpc-version-indicator><date>20130101</date></cpc-version-indicator>
<section>A</section>
<class>61</class>
<subclass>B</subclass>
<main-group>5</main-group>
<subgroup>1116</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20230727</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
<scheme-origination-code>C</scheme-origination-code>
</classification-cpc>
</main-cpc>
<further-cpc>
<classification-cpc>
<cpc-version-indicator><date>20210101</date></cpc-version-indicator>
<section>A</section>
<class>61</class>
<subclass>B</subclass>
<main-group>5</main-group>
<subgroup>397</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20230727</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
<scheme-origination-code>C</scheme-origination-code>
</classification-cpc>
<classification-cpc>
<cpc-version-indicator><date>20130101</date></cpc-version-indicator>
<section>A</section>
<class>61</class>
<subclass>B</subclass>
<main-group>5</main-group>
<subgroup>7225</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20230727</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
<scheme-origination-code>C</scheme-origination-code>
</classification-cpc>
</further-cpc>
</classifications-cpc>
<invention-title id="d2e43">MOTION MONITORING METHODS AND SYSTEMS</invention-title>
<us-related-documents>
<continuation>
<relation>
<parent-doc>
<document-id>
<country>US</country>
<doc-number>PCT/CN2021/081931</doc-number>
<date>20210319</date>
</document-id>
<parent-status>PENDING</parent-status>
</parent-doc>
<child-doc>
<document-id>
<country>US</country>
<doc-number>18183923</doc-number>
</document-id>
</child-doc>
</relation>
</continuation>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee">
<addressbook>
<orgname>SHENZHEN SHOKZ CO., LTD.</orgname>
<address>
<city>Shenzhen</city>
<country>CN</country>
</address>
</addressbook>
<residence>
<country>CN</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="00" designation="us-only">
<addressbook>
<last-name>SU</last-name>
<first-name>Lei</first-name>
<address>
<city>Shenzhen</city>
<country>CN</country>
</address>
</addressbook>
</inventor>
<inventor sequence="01" designation="us-only">
<addressbook>
<last-name>ZHOU</last-name>
<first-name>Xin</first-name>
<address>
<city>Shenzhen</city>
<country>CN</country>
</address>
</addressbook>
</inventor>
<inventor sequence="02" designation="us-only">
<addressbook>
<last-name>LI</last-name>
<first-name>Meiqi</first-name>
<address>
<city>Shenzhen</city>
<country>CN</country>
</address>
</addressbook>
</inventor>
<inventor sequence="03" designation="us-only">
<addressbook>
<last-name>LIAO</last-name>
<first-name>Fengyun</first-name>
<address>
<city>Shenzhen</city>
<country>CN</country>
</address>
</addressbook>
</inventor>
</inventors>
</us-parties>
<assignees>
<assignee>
<addressbook>
<orgname>SHENZHEN SHOKZ CO., LTD.</orgname>
<role>03</role>
<address>
<city>Shenzhen</city>
<country>CN</country>
</address>
</addressbook>
</assignee>
</assignees>
</us-bibliographic-data-application>
<abstract id="abstract">
<p id="p-0001" num="0000">A motion monitoring method (<b>500</b>) is provided, which includes: obtaining a movement signal of a user during motion, wherein the movement signal includes at least an electromyographic signal or an attitude signal (<b>510</b>); and monitoring a movement of the user during motion based at least on feature information corresponding to the electromyographic signal or the feature information corresponding to the attitude signal (<b>520</b>).</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="119.80mm" wi="134.45mm" file="US20230233103A1-20230727-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="221.66mm" wi="136.48mm" file="US20230233103A1-20230727-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="192.36mm" wi="162.39mm" file="US20230233103A1-20230727-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="201.42mm" wi="135.47mm" orientation="landscape" file="US20230233103A1-20230727-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="214.04mm" wi="123.02mm" file="US20230233103A1-20230727-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="211.58mm" wi="135.55mm" file="US20230233103A1-20230727-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="232.16mm" wi="130.30mm" file="US20230233103A1-20230727-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="193.55mm" wi="145.54mm" file="US20230233103A1-20230727-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="145.97mm" wi="142.49mm" orientation="landscape" file="US20230233103A1-20230727-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="218.27mm" wi="154.35mm" file="US20230233103A1-20230727-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00010" num="00010">
<img id="EMI-D00010" he="226.82mm" wi="163.66mm" file="US20230233103A1-20230727-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00011" num="00011">
<img id="EMI-D00011" he="225.98mm" wi="142.66mm" file="US20230233103A1-20230727-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00012" num="00012">
<img id="EMI-D00012" he="225.89mm" wi="145.63mm" file="US20230233103A1-20230727-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00013" num="00013">
<img id="EMI-D00013" he="239.44mm" wi="156.80mm" file="US20230233103A1-20230727-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00014" num="00014">
<img id="EMI-D00014" he="239.27mm" wi="155.96mm" file="US20230233103A1-20230727-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00015" num="00015">
<img id="EMI-D00015" he="172.47mm" wi="147.32mm" file="US20230233103A1-20230727-D00015.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00016" num="00016">
<img id="EMI-D00016" he="194.73mm" wi="151.30mm" file="US20230233103A1-20230727-D00016.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00017" num="00017">
<img id="EMI-D00017" he="182.20mm" wi="149.52mm" orientation="landscape" file="US20230233103A1-20230727-D00017.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00018" num="00018">
<img id="EMI-D00018" he="145.03mm" wi="142.41mm" file="US20230233103A1-20230727-D00018.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00019" num="00019">
<img id="EMI-D00019" he="189.31mm" wi="155.11mm" file="US20230233103A1-20230727-D00019.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00020" num="00020">
<img id="EMI-D00020" he="224.79mm" wi="158.16mm" file="US20230233103A1-20230727-D00020.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?>
<heading id="h-0001" level="1">CROSS REFERENCE TO RELATED APPLICATIONS</heading>
<p id="p-0002" num="0001">This application is a Continuation of International Patent Application No. PCT/CN2021/081931, filed on Mar. 19, 2021, the entire contents of each of which are hereby incorporated by references.</p>
<?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?>
<?summary-of-invention description="Summary of Invention" end="lead"?>
<heading id="h-0002" level="1">TECHNOLOGY FIELD</heading>
<p id="p-0003" num="0002">The present disclosure relates to a technical field of wearable devices, and in particular, to a motion monitoring method and system.</p>
<heading id="h-0003" level="1">BACKGROUND</heading>
<p id="p-0004" num="0003">With people concerned about scientific exercise and physical health, motion monitoring devices are developing tremendously. At present, the motion monitoring devices mainly monitor some of the physiological parameter information (e.g., heart rate, body temperature, step frequency, blood oxygen, etc.) of a user during motion, but cannot accurately monitor user's movement and provide feedback on the movement. In practical scenarios, a process of monitoring and feeding the users' movement back often requires the participation of live professionals. For example, the user in the fitness scenario can only correct their movement under the guidance of a fitness instructor.</p>
<p id="p-0005" num="0004">Therefore, it is desirable to provide a motion monitoring device that can guide a person's motion and thereby helping the user achieve more scientifically exact exercises.</p>
<heading id="h-0004" level="1">SUMMARY</heading>
<p id="p-0006" num="0005">According to the embodiments of the present disclosure, a motion monitoring method is provided, including: obtaining a movement signal of a user during motion, the movement signal including at least an electromyographic signal or an attitude signal; and monitoring, at least based on feature information corresponding to the electromyographic signal or feature information corresponding to the attitude signal, a movement of the user during motion.</p>
<p id="p-0007" num="0006">In some embodiments, the monitoring, at least based on feature information corresponding to the electromyographic signal or feature information corresponding to the attitude signal, a movement of the user during motion: segmenting, based on the feature information corresponding to the electromyographic signal or the feature information corresponding to the attitude signal, the movement signal; and monitoring, based on at least one segment of the movement signal, the movement of the user during motion.</p>
<p id="p-0008" num="0007">In some embodiments, the feature information corresponding to the electromyographic signal includes at least frequency information or amplitude information, and the feature information corresponding to the attitude signal includes at least one of an angular velocity direction, an angular velocity value, an acceleration of an angular velocity, an angle, displacement information, and stress.</p>
<p id="p-0009" num="0008">In some embodiments, the segmenting, based on the feature information corresponding to the electromyographic signal or the feature information corresponding to the attitude signal, the movement signal includes: determining, based on a time domain window of the electromyographic signal or the attitude signal, at least one target feature point from the time domain window according to a preset condition; and segmenting, based on the at least one target feature point, the movement signal.</p>
<p id="p-0010" num="0009">In some embodiments, the at least one target feature point includes one of a movement start point, a movement middle point, and a movement end point.</p>
<p id="p-0011" num="0010">In some embodiments, the preset condition includes a change in the angular velocity direction corresponding to the attitude signal, the angular velocity corresponding to the attitude signal being greater than or equal to an angular velocity threshold, a changed value of the angular velocity value corresponding to the attitude signal being an extreme value, the angle corresponding to the attitude signal reaching an angular threshold, and the amplitude information corresponding to the electromyographic signal being greater than or equal to one or more electromyographic thresholds.</p>
<p id="p-0012" num="0011">In some embodiments, the preset condition further includes the acceleration of the angular velocity corresponding to the attitude signal being continuously greater than or equal to an acceleration threshold of the angular velocity for a first specific time range.</p>
<p id="p-0013" num="0012">In some embodiments, the preset condition further includes an amplitude corresponding to the electromyographic signal being continuously greater than the one or more electromyographic thresholds for a second specific time range.</p>
<p id="p-0014" num="0013">In some embodiments, the monitoring, at least based on feature information corresponding to the electromyographic signal or feature information corresponding to an attitude signal, a movement of the user during motion includes: pre-processing the electromyographic signal in a frequency domain or a time domain; obtaining, based on the pre-processed electromyographic signal, the feature information corresponding to the electromyographic signal; and monitoring, according to the feature information corresponding to the electromyographic signal or the feature information corresponding to the attitude signal, the movement of the user during motion.</p>
<p id="p-0015" num="0014">In some embodiments, the pre-processing of the electromyographic signal in a frequency domain or a time domain includes: filtering the electromyographic signal to select components of the electromyographic signal in a specific frequency range in the frequency domain.</p>
<p id="p-0016" num="0015">In some embodiments, the pre-processing of the electromyographic signal in a frequency domain or a time domain includes: performing a signal correction process on the electromyographic signal in the time domain.</p>
<p id="p-0017" num="0016">In some embodiments, the performing a signal correction processing on the electromyographic signal in the time domain includes: determining a singularity in the electromyographic signal, wherein the singularity corresponds to an abrupt signal of the electromyographic signal; and performing the signal correction processing on the singularity in the electromyographic signal.</p>
<p id="p-0018" num="0017">In some embodiments, the performing the signal correction processing on the singularity in the electromyographic signal includes removing the singularity, or correcting the singularity according to a signal around the singularity.</p>
<p id="p-0019" num="0018">In some embodiments, the singularity includes a burr signal, the determining the singularity in the electromyographic signal includes: selecting, based on the time domain window of the electromyographic signal, different time windows from the time domain window of the electromyographic signal, wherein the different time windows respectively cover different time ranges; and determining, based on the feature information corresponding to the electromyographic signal in the different time windows, the burr signal.</p>
<p id="p-0020" num="0019">In some embodiments, the method further includes determining, based on the attitude signal, the feature information corresponding to the attitude signal, wherein the attitude signal includes coordinate information in at least one original coordinate system; determining, based on the attitude signal, the feature information corresponding to the attitude signal includes: obtaining a target coordinate system and a conversion relationship between the target coordinate system and the at least one original coordinate system; converting, based on the conversion relationship, the coordinate information in the at least one original coordinate system to coordinate information in the target coordinate system; and determining, based on the coordinate information in the target coordinate system, the feature information corresponding to the attitude signal.</p>
<p id="p-0021" num="0020">In some embodiments, the attitude signal includes coordinate information generated by at least two sensors, the at least two sensors are located at different motion parts of the user and correspond to different original coordinate systems, the determining, based on the attitude signal, the feature information corresponding to the attitude signal includes: determining feature information corresponding to each of the at least two sensors based on the conversion relationship between different original coordinate systems and the target coordinate system; and determining, based on the feature information respectively corresponding to the at least two sensors, a relative motion between the motion parts of the user.</p>
<p id="p-0022" num="0021">In some embodiments, the conversion relationship between the at least one original coordinate system and the target coordinate system is obtained by a calibration process, the calibration process includes: constructing a specific coordinate system, the specific coordinate system being related to an orientation of the user during the calibration process; obtaining first coordinate information of the at least one original coordinate system when the user is in a first pose; obtaining second coordinate information of the at least one original coordinate system when the user is in a second pose; and determining the conversion relationship between the at least one original coordinate system and the specific coordinate system according to the first coordinate information, the second coordinate information, and the specific coordinate system.</p>
<p id="p-0023" num="0022">In some embodiments, the calibration process further includes: obtaining a conversion relationship between the specific coordinate system and the target coordinate system; and determining, according to the conversion relationship between the at least one original coordinate system and the specific coordinate system as well as the conversion relationship between the specific coordinate system and target coordinate system, the conversion relationship between the at least one original coordinate system and the target coordinate system.</p>
<p id="p-0024" num="0023">In some embodiments, the target coordinate system changes as the user's orientation changes.</p>
<p id="p-0025" num="0024">According to another aspect of the present disclosure, a method of training a movement recognition model is provided, including: obtaining sample information, the sample information including a movement signal of a user during motion, the movement signal including at least feature information corresponding to an electromyographic signal and feature information corresponding to an attitude signal; and training, based on the sample information, the movement recognition model.</p>
<p id="p-0026" num="0025">According to another aspect of the present disclosure, a motion monitoring and feedback method is provided, including: obtaining a movement signal of a user during motion, wherein the movement signal includes at least an electromyographic signal and an attitude signal; and monitoring, based on feature information corresponding to the electromyographic signal and feature information corresponding to the attitude signal, a movement of a user by a movement recognition model, and providing, based on an output of the movement recognition model, a movement feedback.</p>
<p id="p-0027" num="0026">In some embodiments, the movement recognition model includes a trained machine learning model or a preset model.</p>
<p id="p-0028" num="0027">In some embodiments, the movement feedback includes at least one of sending a prompt message, stimulating a movement part of the user, and outputting a motion record of the user during motion.</p>
<?summary-of-invention description="Summary of Invention" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0005" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0029" num="0028">The present disclosure is further illustrated in terms of exemplary embodiments, and these exemplary embodiments are described in detail with reference to the drawings. These embodiments are not limiting. In these embodiments, the same number indicates the same structure, wherein:</p>
<p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a schematic diagram illustrating an application scenario of a motion monitoring system according to some embodiments of the present disclosure;</p>
<p id="p-0031" num="0030"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a schematic diagram illustrating an exemplary hardware and/or software of a wearable device according to some embodiments of the present disclosure;</p>
<p id="p-0032" num="0031"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a schematic diagram illustrating an exemplary hardware and/or software of a computing device according to some embodiments of the present disclosure;</p>
<p id="p-0033" num="0032"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a structure diagram of an exemplary wearable device according to some embodiments of the present disclosure;</p>
<p id="p-0034" num="0033"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a flowchart of an exemplary motion monitoring method according to some embodiments of the present disclosure;</p>
<p id="p-0035" num="0034"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a flowchart of an exemplary process for monitoring a movement of user motion according to some embodiments of the present disclosure;</p>
<p id="p-0036" num="0035"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a flowchart of an exemplary process for segmenting a movement signal according to some embodiments of the present disclosure;</p>
<p id="p-0037" num="0036"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a diagram illustrating exemplary normalized results of segmenting a movement according to some embodiments of the present disclosure;</p>
<p id="p-0038" num="0037"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a flowchart of an exemplary process for pre-processing an electromyographic signal according to some embodiments of the present disclosure;</p>
<p id="p-0039" num="0038"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a flow chart illustrating an exemplary burr signal according to some embodiments of the present disclosure;</p>
<p id="p-0040" num="0039"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is a flowchart of an exemplary process for determining feature information corresponding to an attitude signal according to some embodiments of the present disclosure;</p>
<p id="p-0041" num="0040"><figref idref="DRAWINGS">FIG. <b>12</b></figref> is a flowchart of an exemplary process for determining relative motion between different motion parts of a user according to some embodiments of the present disclosure;</p>
<p id="p-0042" num="0041"><figref idref="DRAWINGS">FIG. <b>13</b></figref> is a flowchart of an exemplary process for determining a conversion relationship between an original coordinate system to a particular coordinate system according to some embodiments of the present disclosure;</p>
<p id="p-0043" num="0042"><figref idref="DRAWINGS">FIG. <b>14</b></figref> is a flowchart of an exemplary process for determining a conversion relationship between an original coordinate system and a target coordinate system according to some embodiments of the present disclosure;</p>
<p id="p-0044" num="0043"><figref idref="DRAWINGS">FIG. <b>15</b>A</figref> is an exemplary vector coordinate diagram illustrating Euler angle data in an original coordinate system at a position of a small arm of a human body according to some embodiments of the present disclosure;</p>
<p id="p-0045" num="0044"><figref idref="DRAWINGS">FIG. <b>15</b>B</figref> is an exemplary vector coordinate diagram illustrating Euler angle data in another original coordinate system for a position of a small arm of ae human body according to some embodiments of the present disclosure;</p>
<p id="p-0046" num="0045"><figref idref="DRAWINGS">FIG. <b>16</b>A</figref> is an exemplary vector coordinate diagram of Euler angle data in a target coordinate system at a position of a small arm of a human body according to some embodiments of the present disclosure;</p>
<p id="p-0047" num="0046"><figref idref="DRAWINGS">FIG. <b>16</b>B</figref> is an exemplary vector coordinate diagram of Euler angle data in a target coordinate system at another location of a small arm of a human body according to some embodiments of the present disclosure;</p>
<p id="p-0048" num="0047"><figref idref="DRAWINGS">FIG. <b>17</b></figref> is an exemplary vector coordinate diagram of Euler angle data in a target coordinate system of a multi-sensor according to some embodiments of the present disclosure;</p>
<p id="p-0049" num="0048"><figref idref="DRAWINGS">FIG. <b>18</b>A</figref> is a diagram illustrating exemplary results of an original angular velocity according to some embodiments of the present disclosure;</p>
<p id="p-0050" num="0049"><figref idref="DRAWINGS">FIG. <b>18</b>B</figref> is a diagram illustrating exemplary results of an angular velocity after filtering processing according to some embodiments of the present disclosure;</p>
<p id="p-0051" num="0050"><figref idref="DRAWINGS">FIG. <b>19</b></figref> is a flowchart illustrating an exemplary motion monitoring and feedback method according to some embodiments of the present disclosure; and</p>
<p id="p-0052" num="0051"><figref idref="DRAWINGS">FIG. <b>20</b></figref> is a flowchart illustrating exemplary process for model training according to some embodiments of the present disclosure.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?detailed-description description="Detailed Description" end="lead"?>
<heading id="h-0006" level="1">DETAILED DESCRIPTION</heading>
<p id="p-0053" num="0052">To more clearly illustrate the technical solutions related to the embodiments of the present disclosure, a brief introduction of the drawings referred to the description of the embodiments is provided below. Obviously, the accompanying drawing in the following description is merely some examples or embodiments of the present disclosure, for those skilled in the art, the present disclosure may further be applied in other similar situations according to the drawings without any creative effort. Unless obviously obtained from the context or the context illustrates otherwise, the same numeral in the drawings refers to the same structure or operation.</p>
<p id="p-0054" num="0053">It will be understood that the term “system,” “device,” “unit,” and/or “module” used herein are one method to distinguish different components, elements, parts, sections or assemblies of different levels in ascending order. However, if other words may achieve the same purpose, the words may be replaced by other expressions.</p>
<p id="p-0055" num="0054">As used in the disclosure and the appended claims, the singular forms “a,” “an,” and “the” include plural referents unless the content clearly dictates otherwise. Generally speaking, the terms “comprise,” “comprises,” and/or “comprising,” “include,” “includes,” and/or “including,” only imply that the clearly identified steps and elements are included, these steps and elements may not constitute an exclusive list, and the method or device may further include other steps or elements.</p>
<p id="p-0056" num="0055">Flowcharts are used throughout the present disclosure to illustrate the operations performed by the system according to embodiments of the present disclosure. It should be understood that the preceding or following operations are not necessarily performed in precise order. Instead, the individual steps may be processed in reverse order or simultaneously. Other operations may be added to these processes or a step or steps of operations may be removed from these processes.</p>
<p id="p-0057" num="0056">According to the present disclosure, a motion monitoring system is provided, which may obtain a movement signal of a user during motion. The movement signal includes at least an electromyographic signal, an attitude signal, an electro-cardio graphic signal, a respiratory rate signal, and the like. The motion monitoring system may monitor a movement of the user during motion based at least on feature information corresponding to the electromyographic signal or the feature information corresponding to an attitude signal. For example, the system may determine the type of movement of the user, the number of movement, the movement quality, movement time, or information of physiological parameters of the user when performing the movement through frequency information and amplitude information corresponding to the electromyographic signal, an angular velocity, an angular velocity direction and an angular velocity value of the angular velocity, an angle, displacement information, and stress, etc. corresponding to the attitude signal. In some embodiments, the motion monitoring system may further generate feedback to a user's fitness movement according to analysis results of the user's fitness movement to provide guidance to user's fitness. For example, when the user's fitness movement is not standard, the motion monitoring system can send a prompt message to the user (e.g., a voice prompt, a vibration prompt, current stimulation, etc.). The motion monitoring system may be applied to a wearable device (e.g., clothing, a wrist guard, a helmet), a medical testing device (e.g., an electromyography tester), a fitness device, etc. The motion monitoring system may accurately monitor and provide feedback on a user's movement by obtaining the movement signal of the user during motion without professional participation, which can improve the user's fitness efficiency and reduce a cost of the user fitness.</p>
<p id="p-0058" num="0057"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a schematic diagram illustrating an application scenario of a motion monitoring system according to some embodiments of the present disclosure. As shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the motion monitoring system <b>100</b> may include a processing device <b>110</b>, a network <b>120</b>, a wearable device <b>130</b>, and a mobile terminal device <b>140</b>. The motion monitoring system <b>100</b> may obtain a movement signal (e.g., an electromyographic signal, an attitude signal, an electro-cardio signal, a respiratory rate signal, etc.) representing a movement of user motion, and may monitor and provide feedback on the movement of the user during motion according to a user's movement signal.</p>
<p id="p-0059" num="0058">For example, the motion monitoring system <b>100</b> may monitor and provide feedback on the movement of the user during fitness. When the user wears the wearable device <b>130</b> for fitness, the wearable device <b>130</b> may obtain the user's movement signal. The processing device <b>110</b> or a mobile terminal device may receive and analyze the user's movement signal to determine whether the user's fitness movement is standard, thereby monitoring the user's movement. Specifically, the monitoring of the user's movement may include determining a type of movement, a count of movement, quality of the movement, and timing of the movement, or information about the physiological parameters of the user at the time the movement is performed. Further, the motion monitoring system <b>100</b> may generate feedback on the user's fitness movement according to the analysis results of the user's fitness movement to provide guidance to the user.</p>
<p id="p-0060" num="0059">Further, for example, the motion monitoring system <b>100</b> may monitor and provide feedback on the user's movement while running. For example, when the user wears the wearable device <b>130</b> for running exercise, the motion monitoring system <b>100</b> may monitor whether the user's running movement is standard and whether the running time meets a health standard. When a user's running time is too long or a running movement is incorrect, the fitness device may provide motion state to the user to prompt the user to adjust the running movement or the running time.</p>
<p id="p-0061" num="0060">In some embodiments, the processing device <b>110</b> may be configured to process information and/or data related to the user's movement. For example, the processing device <b>110</b> may receive the movement signal of the user (e.g., an electromyographic signal, an attitude signal, an electro-cardio signal, a respiratory rate signal, etc.) and further extract the feature information corresponding to the movement signal (e.g., feature information corresponding to the electromyographic signal in the movement signal, the feature information corresponding to the attitude signal). In some embodiments, the processing device <b>110</b> may perform a specific signal processing, such as signal segmentation, signal pre-processing (e.g., signal correction processing, filtering processing, etc.), etc., on the electromyographic signal or the attitude signal obtained by the wearable device <b>130</b>. In some embodiments, the processing device <b>110</b> may further determine whether the user movement is correct based on the user's movement signal. For example, the processing device <b>110</b> may determine whether the user movement is correct based on the feature information corresponding to the electromyographic signal (e.g., amplitude information, frequency information, etc.). For another example, the processing device <b>110</b> may determine whether the user movement is correct based on the feature information corresponding to the attitude signal (e.g., an angular velocity, a direction of angular velocity, an acceleration of angular velocity, an angle, displacement information, a stress, etc.). Further, for example, the processing device <b>110</b> may determine whether the user movement is correct based on the feature information corresponding to the electromyographic signal and the feature information corresponding to the attitude signal. In some embodiments, the processing device <b>110</b> may further determine whether information of physiological parameters of the user during motion meets the health standard. In some embodiments, the processing device <b>110</b> may further send a corresponding instruction configured to feed the user's movement back. For example, when the user is running and the motion monitoring system <b>100</b> monitors that the user's running time is too long, the processing device <b>110</b> may send the instruction to the mobile terminal device <b>140</b> to prompt the user to adjust the running time. It should be noted that the feature information corresponding to the attitude signal is not limited to above angular velocity, the direction of angular velocity, the acceleration of angular velocity, the angle, the displacement information, and the stress, etc., but can also be other feature information. For example, when an attitude sensor is a strain gauge sensor, a bending angle and a bending direction at a user's joint may be obtained by measuring the resistance in a strain gauge sensor that varies with a stretch length.</p>
<p id="p-0062" num="0061">In some embodiments, the processing device <b>110</b> may be local or remote. For example, the processing device <b>110</b> may access information and/or materials stored in the wearable device <b>130</b> and/or the mobile terminal device <b>140</b> through the network <b>120</b>. In some embodiments, the processing device <b>110</b> may be directly connected to the wearable device <b>130</b> and/or the mobile terminal device <b>140</b> to access the information and/or materials stored therein. For example, the processing device <b>110</b> may be located in the wearable device <b>130</b> and implement the information interact with the mobile terminal device <b>140</b> through the network <b>120</b>. Further, for example, the processing device <b>110</b> may be located in the mobile terminal device <b>140</b> and implement the information interact with the wearable device <b>130</b> through a network. In some embodiments, the processing device <b>110</b> may be executed on a cloud platform. For example, the cloud platform may include one of a private cloud, a public cloud, a hybrid cloud, a community cloud, a decentralized cloud, an internal cloud, or any combination thereof.</p>
<p id="p-0063" num="0062">In some embodiments, the processing device <b>110</b> may process data and/or information related to motion monitoring to perform one or more of the functions described in the present disclosure. In some embodiments, the processing device <b>110</b> may obtain the movement signal collected by the wearable device <b>130</b> while the user is in motion. In some embodiments, the processing device may send a control instruction to the wearable device <b>130</b> or the mobile terminal device <b>140</b>. The control instruction may control an on/off state of the wearable device <b>130</b> and its respective sensor, and also control the mobile terminal device <b>140</b> to send a prompt message. In some embodiments, processing device <b>110</b> may include one or more sub-processing devices (e.g., a single-core processing device or a multi-core processing device). Merely by way of example, the processing device <b>110</b> may include a central processing unit (CPU), an application-specific integrated circuit (ASIC), an application-specific instruction processor (ASIP), a graphic processing unit (GPU), a physics processing Unit (PPU), a digital signal processor (DSP), a field-programmable gate array (FPGA), an programmable logic device (PLD), a controller, a microcontroller unit Reduced Instruction Set Computer (RISC), and a microprocessor, etc. or any combination of the above.</p>
<p id="p-0064" num="0063">The network <b>120</b> may facilitate an exchange of data and/or information in the motion monitoring system <b>100</b>. In some embodiments, one or more components of the motion monitoring system <b>100</b> (e.g., the processing device <b>110</b>, the wearable device <b>130</b>, the mobile terminal device <b>140</b>) may send the data and/or the information to other components of the motion monitoring system <b>100</b> through network <b>120</b>. For example, the movement signal collected by the wearable device <b>130</b> may be transmitted to the processing device <b>110</b> through the network <b>120</b>. For another example, confirmation results regarding the movement signal in the processing device <b>110</b> may be transmitted to the mobile terminal device <b>140</b> through the network <b>120</b>. In some embodiments, the network <b>120</b> may be any type of a wired or wireless network. For example, the network <b>120</b> may include a cable network, a wired network, a fiber optic network, a telecommunications network, an internal network, an inter-network, a regional network (LAN), a wide area network (WAN), a wireless regional network (WLAN), a metropolitan area network (MAN), a public switched telephone network (PSTN), a Bluetooth™ network, a ZigBee™ network, and a near field communication (NFC) network, or any combination of the above. In some embodiments, the network <b>120</b> may include one or more network entry and exit points. For example, network <b>120</b> may include wired or wireless network entry and exit points, such as a base station and/or inter-network exchange points <b>120</b>-<b>1</b>, <b>120</b>-<b>2</b>, . . . , through the entry and exit points, one or more components of motion monitoring system <b>100</b> may connect to the network <b>120</b> to exchange the data and/or the information.</p>
<p id="p-0065" num="0064">The wearable device <b>130</b> is a garment or device that has a wearable function. In some embodiments, the wearable device <b>130</b> may include, but is not limited to, an upper garment device <b>130</b>-<b>1</b>, a pant device <b>130</b>-<b>2</b>, a wrist guard device <b>130</b>-<b>3</b>, and a shoe <b>130</b>-<b>4</b>, etc. In some embodiments, wearable device <b>130</b> may include a plurality of sensors. The sensors may obtain various movement signals (e.g., electromyographic signals, attitude signals, temperature information, heart rate, electro-cardio signals, etc.) from the user during motion. In some embodiments, the sensors may include, but are not limited to, one or more of an electromyographic sensor, an attitude sensor, a temperature sensor, a humidity sensor, an electro-cardio sensor, an oxygen saturation sensor, a Hall sensor, a Pico electric sensor, and a rotation sensor, etc. For example, an electromyographic sensor may be provided at a human muscle location (e.g., biceps, triceps, latissimus dorsi, trapezius, etc.) in an upper garment device <b>130</b>-<b>1</b>, and the electromyographic sensor may fit to user's skin and collect the electromyographic signal from the user during motion. For example, the upper garment device <b>130</b>-<b>1</b> may be provided with an electro-cardio sensor near the left pectoral muscle of the human body, and the electromyographic sensor may collect the electro-cardio signal of the user. Further, for example, the attitude sensor may be provided at a human body muscle location (e.g., gluteus maximus, lateral femoris, medial femoris, gastrocnemius, etc.) in a pants device <b>130</b>-<b>2</b>, and the attitude sensor may collect a user's attitude signal. In some embodiments, the wearable device <b>130</b> may further provide feedback on the user's movement. For example, if the user's movement of a body part during motion does not meet the standard, the electromyographic sensor corresponding to that part may generate a stimulation signal (e.g., a current stimulation or a strike signal) to prompt the user.</p>
<p id="p-0066" num="0065">It should be noted that the wearable device <b>130</b> is not limited to the upper garment device <b>130</b>-<b>1</b>, the pants device <b>130</b>-<b>2</b>, a wrist guard device <b>130</b>-<b>3</b>, and a shoe device <b>130</b>-<b>4</b> shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, but may further include a device that are applied to other devices that require motion monitoring, such as, for example, helmet devices, knee pads, etc., which will not be limited herein, and any device that can use the motion monitoring method contained in the disclosure is within the scope of protection of the present disclosure.</p>
<p id="p-0067" num="0066">In some embodiments, the mobile terminal device <b>140</b> may access information or data in the motion monitoring system <b>100</b>. In some embodiments, the mobile terminal device <b>140</b> may receive motion data processed by the processing device <b>110</b>, and feed motion records back based on processed motion data. An exemplary feedback manner may include, but are not limited to, a voice prompt, an image prompts, a video display, and a text prompt, etc. In some embodiments, the user may obtain movement records during an own movement through the mobile terminal device <b>140</b>. For example, the mobile terminal device <b>140</b> may be connected to the wearable device <b>130</b> through the network <b>120</b> (e.g., the wired connection, the wireless connection), and the user may obtain the movement records during the user's movement through the mobile terminal device <b>140</b>, which may be transmitted to the processing device <b>110</b> through the mobile terminal device <b>140</b>. In some embodiments, the mobile terminal device <b>140</b> may include a mobile device <b>140</b>-<b>1</b>, a tablet <b>140</b>-<b>2</b>, a laptop <b>140</b>-<b>3</b>, etc., or any combination thereof. In some embodiments, mobile device <b>140</b>-<b>1</b> may include a cell phone, a smart home device, a smart mobility device, a virtual reality device, an augmented reality device, etc., or any combination thereof. In some embodiments, the smart home device may include a control device of a smart appliance, a smart monitoring device, a smart TV, a smart camera, etc., or any combination thereof. In some embodiments, the smart mobility device may include a smart phone, a personal digital assistant (PDA), a gaming device, a navigation device, a POS device, etc., or any combination thereof. In some embodiments, a virtual reality device and/or an augmented reality device may include a virtual reality helmet, virtual reality glasses, a virtual reality eye-mask, an augmented reality helmet, an augmented reality glasses, and an augmented reality eye-mask, etc., or any combination thereof.</p>
<p id="p-0068" num="0067">In some embodiments, the motion monitoring system <b>100</b> may further include a database. The database may store the information (e.g., a threshold condition of an initially set, etc.) and/or the instruction (e.g., a feedback instruction). In some embodiments, the database may store the information obtained from the wearable device <b>130</b> and/or the mobile terminal device <b>140</b>. In some embodiments, the database may store the information and/or the instruction configured for the processing device <b>110</b> to execute or use to perform the exemplary methods described in the present disclosure. In some embodiments, the database may include a mass storage, a removable memory, a volatile read-write memory (e.g., random access memory RAM), a read-only memory (ROM), etc., or any combination thereof. In some embodiments, the database may be implemented on a cloud platform. For example, the cloud platform may include the private cloud, the public cloud, the hybrid cloud, the community cloud, the decentralized cloud, the internal cloud, or any combination thereof.</p>
<p id="p-0069" num="0068">In some embodiments, the database may be connected to the network <b>120</b> to communicate with one or more components of the motion monitoring system <b>100</b> (e.g., the processing device <b>110</b>, the wearable device <b>130</b>, the mobile terminal device <b>140</b>, etc.). The one or more components of the motion monitoring system <b>100</b> may access information or instruction stored in the database through the network <b>120</b>. In some embodiments, the database may be directly connected or communicate with one or more components of the motion monitoring system <b>100</b> (e.g., the processing device <b>110</b>, the wearable device <b>130</b>, the mobile terminal device <b>140</b>). In some embodiments, the database may be a part of the processing device <b>110</b>.</p>
<p id="p-0070" num="0069"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a schematic diagram illustrating an exemplary hardware and/or software of a wearable device according to some embodiments of the present disclosure. As shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the wearable device <b>130</b> may include an obtaining module <b>210</b>, a processing module <b>220</b> (also referred to as a processor), a control module <b>230</b> (also referred to as a master, MCU, a controller), a communication module <b>240</b>, a power supply module <b>250</b>, and an input/output module <b>260</b>.</p>
<p id="p-0071" num="0070">The obtaining module <b>210</b> may be configured to obtain a movement signal of a user during motion. In some embodiments, the obtaining module <b>210</b> may include a sensor unit, and the sensor unit may be configured to obtain one or more movement signals while the user is in motion. In some embodiments, the sensor unit may include, but is not limited to, one or more electromyographic sensors, attitude sensors, cardiac sensors, respiration sensors, temperature sensors, humidity sensors, inertial sensors, blood oxygen saturation sensors, Hall sensors, piezoelectric sensors, and rotation sensors, and the like. In some embodiments, the movement signal may include one or more electromyographic signals, attitude signals, cardiac signals, respiratory rates, temperature signals, and humidity signals, etc. The sensor unit may be placed at different locations of the wearable device <b>130</b> according to a type of a movement signal to be obtained. For example, in some embodiments, the electromyographic sensor (also referred to as an electrode element) may be placed at a human muscle location, and the electromyographic sensor may be configured to collect the electromyographic signal of the user during motion. The electromyographic signal and its corresponding feature information (e.g., frequency information, amplitude information, etc.) may reflect a state of muscle during a user's movement. The attitude sensor may be provided at different locations on a human body (e.g., locations of the wearable device <b>130</b> corresponding to the torso, limbs, and joints), and the attitude sensor may be configured to capture the attitude signal of the user during the user's movement. The attitude signal and its corresponding feature information (e.g., angular velocity direction, angular velocity value, acceleration value of angular velocity, angle, displacement information, stress, etc.) may reflect the attitude of the user's movement. The electromyographic sensor may be set at a location on the circumferential side of the human chest, and the electromyographic sensor may be configured to collect electro cardio data of the user during motion. The respiration sensor may be arranged on a circumferential side of the body's chest, and the respiration sensor may be configured to collect respiration data (e.g., respiration rate, respiration amplitude, etc.) from the user during motion. The temperature sensor may be configured to collect temperature data (e.g., a body surface temperature) of the user during motion. The humidity sensor may be configured to collect humidity data of an external environment of the user during motion.</p>
<p id="p-0072" num="0071">The processing module <b>220</b> may process data from the obtaining module <b>210</b>, the control module <b>230</b>, the communication module <b>240</b>, the power supply module <b>250</b>, and/or the input/output module <b>260</b>. For example, the processing module <b>220</b> may process the movement signal of the user during a process of motion from the obtaining module <b>210</b>. In some embodiments, the processing module <b>220</b> may pre-process the movement signal (e.g., the electromyographic signal, the attitude signal) obtained by the obtaining module <b>210</b>. For example, the processing module <b>220</b> segments the electromyographic signal or the attitude signal of the user during motion. For another example, the processing module <b>220</b> may perform a pre-processing (e.g., a filtering processing, a signal correction processing) on the electromyographic signal of the user during motion to improve quality of the electromyographic signal. Further, for example, the processing module <b>220</b> may determine the feature information corresponding to the attitude signal based on a user's attitude signal during motion. In some embodiments, the processing module <b>220</b> may process an instruction or operation from an input/output module <b>260</b>. In some embodiments, processed data may be stored in a memory or a hard disk. In some embodiments, the processing module <b>220</b> may transmit its processed data to one or more components in the motion monitoring system <b>100</b> through the communication module <b>240</b> or the network <b>120</b>. For example, the processing module <b>220</b> may send monitoring results of the user during motion to the control module <b>230</b>, which may execute subsequent operations or instructions according to motion determination results.</p>
<p id="p-0073" num="0072">The control module <b>230</b> may be connected to other modules in the wearable device <b>130</b>. In some embodiments, the control module <b>230</b> may control an operation state of other modules (e.g., the communication module <b>240</b>, the power supply module <b>250</b>, the input/output module <b>260</b>) in the wearable device <b>130</b>. For example, the control module <b>230</b> may control a power supply state (e.g., a normal mode, a power saving mode), power supply time, and the like, of the power supply module <b>250</b>. When remaining power of the power supply module <b>250</b> reaches a certain threshold (e.g., 10%) or less, the control module <b>230</b> may control the power supply module <b>250</b> to enter a power saving mode or send a prompt message about replenishment of power. For another example, the control module <b>230</b> may control the input/output module <b>260</b> based on user's movement determination results, and further control the mobile terminal device <b>140</b> to send feedback results of the user's movement. When there is a problem with the user's movement (e.g., movement not meeting the standard), the control module <b>230</b> may control the input/output module <b>260</b> to control the mobile terminal device <b>140</b> to provide feedback to the user, allowing the user to understand own motion movement in real time and make some adjustments. In some embodiments, the control module <b>230</b> may also control one or more sensors or other modules in the obtaining module <b>210</b> to provide feedback to the human body. For example, when a muscle of the user is exercising too strong during motion, the control module <b>230</b> may control an electrode module at a location of the muscle to stimulate the user to prompt the user to adjust the movement in time.</p>
<p id="p-0074" num="0073">In some embodiments, the communication module <b>240</b> may be configured for an exchange of information or data. In some embodiments, the communication module <b>240</b> may be configured for communication between components (e.g., the obtaining module <b>210</b>, the processing module <b>220</b>, the control module <b>230</b>, the power supply module <b>250</b>, the input/output module <b>260</b>) within a wearable device <b>130</b>. For example, the obtaining module <b>210</b> may send a movement signal (e.g., the electromyographic signal, the attitude signal, etc.) to the communication module <b>240</b>, and the communication module <b>240</b> may send the movement signal to the processing module <b>220</b>. For example, the communication module <b>240</b> may send state information (e.g., a switch state) of the wearable device <b>130</b> to the processing device <b>110</b>, and the processing device <b>110</b> may monitor the wearable device <b>130</b> based on the state information. The communication module <b>240</b> may employ wired, wireless, and hybrid wired/wireless technologies. The wired technology may be based on one or more combinations of fiber optic cables such as metallic cables, hybrid cables, fiber optic cables, etc. The wireless technologies may include Bluetooth (Bluetooth™), wireless network (Wi-Fi), purple bee (ZigBee™), Near Field Communication (NFC), Radio Frequency Identification (RFID), cellular networks (including GSM, CDMA, 3G, 4G, 5G, etc.), and cellular-based Narrow Band Internet of Things (NBIoT), etc. In some embodiments, the communication module <b>240</b> may use one or more coding methods to encode transmitted information, for example, the coding methods may include phase coding, non-zeroing coding, differential Manchester coding, and the like. In some embodiments, the communication module <b>240</b> may select different transmission and encoding methods according to a type of data or a type of network to be transmitted. In some embodiments, the communication module <b>240</b> may include one or more communication interfaces for different communication methods. In some embodiments, illustrated other modules of the motion monitoring system <b>100</b> may be dispersed on a plurality of devices, in this case, each of a plurality of other modules may each include one or more communication modules <b>240</b> for an inter-module information transmission. In some embodiments, the communication module <b>240</b> may include a receiver and a transmitter. In other embodiments, the communication module <b>240</b> may be a transceiver.</p>
<p id="p-0075" num="0074">In some embodiments, the power supply module <b>250</b> may provide power to other components in the motion monitoring system <b>100</b> (e.g., the obtaining module <b>210</b>, the processing module <b>220</b>, the control module <b>230</b>, the communication module <b>240</b>, and the input/output module <b>260</b>). The power supply module <b>250</b> may receive the control signal from the processing module <b>220</b> to control a power output of the wearable device <b>130</b>. For example, if the wearable device <b>130</b> does not receive any operation (e.g., no movement signal is detected by the obtaining module <b>210</b>) for a certain period (e.g., 1 s, 2 s, 3 s, or 4 s), the power supply module <b>250</b> may supply power to the memory merely, putting the wearable device <b>130</b> into a standby mode. For example, if the wearable device <b>130</b> does not receive any operation (e.g., no movement signal is detected by the obtaining module <b>210</b>) for a certain period (e.g., 1 s, 2 s, 3 s, or 4 s), the power supply module <b>250</b> may disconnect power to other components and the data in the motion monitoring system <b>100</b> may be transmitted to a hard disk, putting the wearable device <b>130</b> into the standby mode or a sleeping mode. In some embodiments, the power supply module <b>250</b> may include at least one battery. The battery may include one or more combinations of a dry cell, a lead battery, a lithium battery, a solar cell, a wind energy generation battery, a mechanical energy generation battery, a thermal energy generation battery, etc. Light energy maybe converted into electrical energy by the solar battery and stored in the power supply module <b>250</b>. Wind energy may be converted into the electrical energy by the wind power generation battery and stored in the power supply module <b>250</b>. Mechanical energy may be converted into the electrical energy by the mechanical energy generation battery and stored in the power supply module <b>250</b>. The solar cell may include a silicon solar cell, a thin film solar cell, a nanocrystalline chemical solar cell, a fuel sensitized solar cell, and a plastic solar cell, etc. The solar cell may be distributed on the wearable device <b>130</b> in a form of panel. A user's body temperature may be converted into the electrical energy by the thermal power cell and stored in the power supply module <b>250</b>. In some embodiments, the processing module <b>220</b> may send the control signal to the power supply module <b>250</b> when the power supply module <b>250</b> is less than a power threshold (e.g., 10% of the total power). The control signal may include information that the power supply module <b>250</b> is low on power. In some embodiments, the power supply module <b>250</b> may include a backup power source. In some embodiments, the power supply module <b>250</b> may further include a charging interface. For example, the power supply module <b>250</b> may be temporarily charged by using an electronic device (e.g., a cell phone, a tablet computer) or a rechargeable battery carried by the user to temporarily charge the power supply module <b>250</b> in an emergency (e.g., the power supply module <b>250</b> is at zero power and an external power system is out of power).</p>
<p id="p-0076" num="0075">The input/output module <b>260</b> may obtain, transmit, and send a signal. The input/output module <b>260</b> may connect or communicate with other components in the motion monitoring system <b>100</b>. The other components in the motion monitoring system <b>100</b> may be connected or communicated through the input/output module <b>260</b>. The input/output module <b>260</b> may be a wired USB interface, a serial communication interface, a parallel communication port, or a wireless Bluetooth, infrared-frequency identification, radio-frequency identification (RFID), WLAN Authentication and Privacy Infrastructure (WAPI), General Packet Radio Service (GPRS), Code Division Multiple Access (CDMA), or any combination thereof. In some embodiments, the input/output module <b>260</b> may be connected to the network <b>120</b> and obtain the information through the network <b>120</b>. For example, the input/output module <b>260</b> may obtain the movement signal from the obtaining module <b>210</b> of the user during motion and output user movement information through the network <b>120</b> or the communication module <b>240</b>. In some embodiments, the input/output module <b>260</b> may include VCC, GND, RS-232, RS-485 (e.g., RS485-A, RS485-B), and a universal network interface, or any combination thereof. In some embodiments, the input/output module <b>260</b> may transmit obtained user motion information, through the network <b>120</b>, to the obtaining module <b>210</b>. The encoding methods may include the phase coding, the non-zeroing system encoding, the differential Manchester encoding, etc., or any combination thereof.</p>
<p id="p-0077" num="0076">It should be understood that the system and its modules shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref> may be implemented by using a plurality of methods. For example, in some embodiments, the system and its modules may be implemented by hardware, software, or a combination of software and hardware. In particular, a hardware portion may be implemented by using dedicated logic. A software portion may be stored in memory and executed by an appropriate instruction execution system, such as a microprocessor or dedicated design hardware. Those skilled in the art may understand that the above methods and the system can be implemented by using a computer executable instruction and/or contained in a processor control code, for example, such encoding provided on a carrier medium such as a disk, CD or DVD-ROM, a programmable memory such as a read-only memory (firmware), or a data carrier such as an optical or electronic signal carrier. The system and its modules in one or more embodiments of the present disclosure may be implemented by a hardware circuit, e.g., ultra-large scale integrated circuit or gate array, a semiconductor such as a logic chip, a transistor, etc., or a programmable hardcore device such as a field programmable gate array, a programmable logic device, etc., implemented by software executed by various types of processors, or implemented by a combination of above hardware circuit and software (e.g., firmware).</p>
<p id="p-0078" num="0077">It should be noted that the above description of the motion monitoring system and its modules is merely for descriptive convenience and does not limit one or more embodiments of the present disclosure within the scope of the embodiments. Understandably, for those skilled in the art, after understanding a principle of the system, they may make any combination of the modules, or to form a sub-system to connect with other modules, or to omit one or more modules thereof, without departing from this principle. For example, the obtaining module <b>210</b> and the processing module <b>220</b> may be one module that may have a function of obtaining and processing the user movement signal. Another example is that the processing module <b>220</b> may not be provided in the wearable device <b>130</b>, but integrated in the processing device <b>110</b>. Variations such as these are within the scope of protection of one or more embodiments of the present disclosure.</p>
<p id="p-0079" num="0078"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a schematic diagram illustrating an exemplary hardware and/or software of a computing device according to some embodiments of the present disclosure. In some embodiments, the processing device <b>110</b> and/or the mobile terminal device <b>140</b> may be implemented on a computing device <b>300</b>. As shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the computing device <b>300</b> may include an internal communication bus <b>310</b>, a processor <b>320</b>, a read-only memory <b>330</b>, a random memory <b>340</b>, a communication port <b>350</b>, an input/output interface <b>360</b>, a hard disk <b>370</b>, and a user interface <b>380</b>.</p>
<p id="p-0080" num="0079">The internal communication bus <b>310</b> may enable data communication between components in the computing device <b>300</b>. For example, the processor <b>320</b> may send data to other hardware such as a memory or the input/output interface <b>360</b> through the internal communication bus <b>310</b>. In some embodiments, the internal communication bus <b>310</b> may be an industry standard architecture (ISA) bus, an extended industry standard architecture (EISA) bus, a video electronics standard architecture (VESA) bus, and a peripheral component interconnect (PCI) bus, etc. In some embodiments, the internal communication bus <b>310</b> may be configured to connect various modules (e.g., obtaining module <b>210</b>, processing module <b>220</b>, control module <b>230</b>, communication module <b>240</b>, input and output module <b>260</b>) of the motion monitoring system <b>100</b> shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>.</p>
<p id="p-0081" num="0080">The processor <b>320</b> may execute a computing instruction (a program code) and perform functions of the motion monitoring system <b>100</b> described in the present disclosure. The computing instruction may include a program, an object, a component, a data structure, process, modules, and functions (the functions refer to specific functions described in the present disclosure). For example, processor <b>320</b> may process the obtained movement signal (e.g., the electromyographic signal, the attitude signal) of a user during motion from the wearable device <b>130</b> or/and the mobile terminal device <b>140</b> of the motion monitoring system <b>100</b>, and monitor the movement of the user during motion based on the movement signal during motion. In some embodiments, the processor <b>320</b> may include a microcontroller, a microprocessor, a reduced instruction set computer (RISC), an application-specific integrated circuit (ASIC), an application-specific instruction-set processor (ASIP), a central processing unit (CPU), a graphics processing unit (GPU), a physical processing unit (PPU), a microcontroller unit, a digital signal processor (DSP), a field Programmable Gate Array (FPGA), an Advanced RISC Machine (ARM), a programmable logic device, and any circuit and processor capable of performing one or more functions, or any combination thereof. For illustrative purposes only, the computing device <b>300</b> in <figref idref="DRAWINGS">FIG. <b>3</b></figref> depicts only one processor, but it should be noted that the computing device <b>300</b> in the present disclosure may further include a plurality of processors.</p>
<p id="p-0082" num="0081">A memory of computing device <b>300</b> (e.g., a read-only memory (ROM) <b>330</b>, a Random Access Memory (RAM) <b>340</b>, a hard disk <b>370</b>, etc.) may store data/information obtained from any other components of the motion monitoring system <b>100</b>. In some embodiments, the memory of the computing device <b>300</b> may be located in the wearable device <b>130</b> or the processing device <b>110</b>. An exemplary ROM may include a mask ROM (MROM), a programmable ROM (PROM), an erasable programmable ROM (PEROM), an electrically erasable programmable ROM (EEPROM), a compact disk ROM (CD-ROM), and a digital versatile disk ROM, etc. An exemplary RAM may include a dynamic RAM (DRAM), a double-rate synchronous dynamic RAM (DDR SDRAM), a static RAM (SRAM), a thyristor RAM (T-RAM), and a zero-capacitor RAM (Z-RAM), etc.</p>
<p id="p-0083" num="0082">The input/output interface <b>360</b> may input or output signals, data, or information. In some embodiments, the input/output interface <b>360</b> may enable a user to interact with the motion monitoring system <b>100</b>. For example, the input/output interface <b>360</b> may include a communication module <b>240</b> to enable the communication function of the motion monitoring system <b>100</b>. In some embodiments, the input/output interface <b>360</b> may include an input device and an output device. Exemplary input devices may include a keyboard, a mouse, a touch screen, and a microphone, etc., or any combination thereof. Exemplary output devices may include a display device, a loudspeaker, a printer, a projector, etc., or any combination thereof. Example display devices may include a liquid crystal display (LCD), a light-emitting diode (LED)-based display, a flat panel display, a curved display, a television device, a cathode ray tubes (CRT), etc., or any combination thereof. The communication port <b>350</b> may be connected to a network for data communication. Connection may be a wired connection, a wireless connection, or a combination of both. The wired connection may include a cable, a fiber optic cable, or telephone line, or any combination thereof. The wireless connection may include Bluetooth™, Wi-Fi, WiMAX, WLAN, ZigBee™, a mobile network (e.g., 3G, 4G, or 5G, etc.), or any combination thereof. In some embodiments, the communication port <b>350</b> may be a standard port, such as RS232, RS485, etc. In some embodiments, the communication port <b>350</b> may be a specially designed port.</p>
<p id="p-0084" num="0083">The hard disk <b>370</b> may be configured to store the information and the data generated by or received from the processing device <b>110</b>. For example, the hard disk <b>370</b> may store confirmation information of a user. In some embodiments, the hard disk <b>370</b> may include a hard disk drive (HDD), a solid-state drive (SSD), or a hybrid hard disk (HHD), etc. In some embodiments, the hard disk <b>370</b> may be provided in the processing device <b>110</b> or in the wearable device <b>130</b>. The user interface <b>380</b> may enable an interact and information exchange between the computing device <b>300</b> and the user. In some embodiments, the user interface <b>380</b> may be configured to present motion recordings generated by the motion monitoring system <b>100</b> to the user. In some embodiments, the user interface <b>380</b> may include a physical display such as a display with speakers, an LCD display, an LED display, an OLED display, an electronic ink display (E-Ink), etc.</p>
<p id="p-0085" num="0084"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a structure diagram of an exemplary wearable device according to some embodiments of the present disclosure. To further describe the wearable device, the upper garment is illustrated as an example, as shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref>. The wearable device <b>400</b> may include an upper garment <b>410</b>. The upper garment <b>410</b> may include an upper garment substrate <b>4110</b>, at least one upper garment processing module <b>4120</b>, at least one upper garment feedback module <b>4130</b>, at least one upper garment obtaining module <b>4140</b>, etc. The upper garment substrate <b>4110</b> may refer to clothe worn on an upper body of a human body. In some embodiments, the upper garment substrate <b>4110</b> may include a short sleeve T-shirt, a long sleeve T-shirt, a shirt, and a jacket, etc. The at least one upper garment processing module <b>4120</b>, the at least one upper garment obtaining module <b>4140</b> may be located in areas of the upper garment substrate <b>4110</b> that fit to different parts of the human body. The at least one upper garment feedback module <b>4130</b> may be located at any location on the upper garment substrate <b>4110</b>, and the at least one upper garment feedback module <b>4130</b> may be configured to provide feedback on information about a user's upper body movement state. Exemplary feedback manners may include, but are not limited to, voice prompts, text prompts, pressure prompts, electrical stimulation, etc. In some embodiments, the at least one upper garment obtaining module <b>4140</b> may include, but is not limited to, one or more of an attitude sensor, an electro-cardio sensor, an electromyographic sensor, a temperature sensor, a humidity sensor, an inertial sensor, an acid-base sensor, an acoustic transducer, and etc. The sensor(s) in the upper garment obtaining module <b>4140</b> may be placed at different locations on user's body according to a signal to be measured. For example, when the attitude sensor is configured to obtain the attitude signal of a user during motion, the attitude sensor can be placed in the upper garment substrate <b>4110</b> at a location corresponding to the human torso, arms, and joints. For another example, when the electromyographic sensor is configured to obtain Electromyographic signal of the user during motion, the Electromyographic sensor may be located near the muscles to be measured. In some embodiments, the attitude sensor may include, but is not limited to, an acceleration triaxial sensor, an angular velocity tri-axial sensor, a magnetic sensor, etc., or any combination thereof. For example, an attitude sensor may include an acceleration triaxial sensor, an angular velocity triaxial sensor. In some embodiments, an attitude sensor may further include a strain gauge sensor. A strain gauge sensor may be a sensor based on strain generated by deformation of an object to be measured caused by a force. In some embodiments, the strain gauge sensor may include, but is not limited to, one or more of a strain-gauge force sensor, a strain-gauge pressure sensor, a strain-gauge torque sensor, a strain-gauge displacement sensor, a strain-gauge acceleration sensor, etc. For example, the strain gauge sensor may be arranged at a joint location of the user, and a bending angle and a bending direction at the user's joint can be obtained based on the resistance in the strain gauge sensor that varies with a stretch length at the joint. It should be understood that the upper garment <b>410</b> may include other modules, such as a power supply module, a communication module, an input/output module, and etc., in addition to the upper garment substrate <b>4110</b>, the upper garment processing module <b>4120</b>, the upper garment feedback module <b>4130</b>, and the upper garment obtaining module <b>4140</b> described above. The upper garment processing module <b>4120</b> is similar to the processing module <b>220</b> shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, and the upper garment obtaining module <b>4140</b> is similar to the obtaining module <b>210</b> shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref>. Specific descriptions regarding various modules in the upper garment <b>410</b> may be found in <figref idref="DRAWINGS">FIG. <b>2</b></figref> and its relevant descriptions of the present disclosure, which will not be repeated herein.</p>
<p id="p-0086" num="0085"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a flowchart illustrating an exemplary motion monitoring method according to some embodiments of the present disclosure. As shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, process <b>500</b> may include the following steps.</p>
<p id="p-0087" num="0086">In step <b>510</b>, obtaining a movement signal of a user during motion.</p>
<p id="p-0088" num="0087">In some embodiments, the step <b>510</b> may be performed by the obtaining module <b>210</b>. The movement signal refers to human body parameter information of the user during motion. In some embodiments, the human body parameter information may include, but is not limited to, one or more of an electromyographic signal, an attitude signal, an electro-cardio signal, a temperature signal, a humidity signal, a blood oxygen concentration, and a respiration rate, etc. In some embodiments, an electromyographic sensor in the obtaining module <b>210</b> may collect the electromyographic signal of the user during motion. For example, when the user performs a seated chest press, the electromyographic sensors in a wearable device corresponding to human pectoral muscles, latissimus dorsi, etc. may obtain the electromyographic signals of corresponding muscle positions of the user. For another example, when a user performs a deep squat, the electromyographic sensors in the wearable device corresponding to gluteus maximus and quadriceps can collect the electromyographic signals of the corresponding muscle positions. For another example, when the user is running, the electromyographic sensors in the wearable device corresponding to a gastrocnemius muscle and other positions can obtain the electromyographic signals of the corresponding muscle positions. In some embodiments, the attitude sensor in the obtaining module <b>210</b> may obtain an attitude signal of the user during motion. For example, when the user performs a barbell bench press, the attitude sensor in the wearable device corresponding to the human triceps, etc., can obtain the attitude signal of the triceps, etc. For example, when the user performs a dumbbell flyover, the attitude sensor set at a position such as a human deltoid muscle may obtain the attitude signal of the corresponding position. In some embodiments, a plurality of attitude sensors may obtain attitude signals of a plurality of portions of the user during motion, and the attitude signals of a plurality of portions may reflect a relative movement between different parts of the body. For example, an attitude signal at an arm and an attitude signal at a torso can reflect a movement condition of the arm relative to the torso. In some embodiments, the attitude signal is associated with a type of the attitude sensor. For example, when the attitude sensor is an angular velocity tri-axis sensor, an obtained attitude signal is angular velocity information. For another example, when the attitude sensor is the angular velocity tri-axis sensor and an acceleration tri-axis sensor, the obtained attitude signal is the angular velocity information and acceleration information. For example, when the attitude sensor is a strain gauge sensor, the strain gauge sensor can be arranged at a user's joint position, by measuring the resistance in the strain gauge sensor that varies with the stretch length, the obtained attitude signal may be displacement information, stress, etc., and a bending angle and a bending direction at the user's joint may be represented through these attitude signals. It is important to note that the parameter information configured to reflect the relative motion of the user's body may be feature information corresponding to the attitude signal, which can be obtained by using different types of attitude sensors according to the type of the feature information.</p>
<p id="p-0089" num="0088">In some embodiments, the movement signal may include the electromyographic signal and an attitude signal of a particular part of the user's body. The electromyographic signal and the attitude signal can reflect a movement state of the particular part of the user's body from different angles. In simple terms, the attitude signal of a specific part of the user's body can reflect the type of movement, movement amplitude, movement frequency, etc. of the specific part. The electromyographic signal may reflect a muscle state of the particular part during motion. In some embodiments, by measuring the electromyographic signal and/or the attitude signal of the same body part, whether the movement of that part is standard can be better assessed.</p>
<p id="p-0090" num="0089">In step <b>520</b>, monitoring the movement of the user during motion based at least on feature information corresponding to the electromyographic signal or feature information corresponding to the attitude signal.</p>
<p id="p-0091" num="0090">In some embodiments, the step <b>520</b> may be performed by the processing module <b>220</b> and/or the processing device <b>110</b>. In some embodiments, the feature information corresponding to the electromyographic signal may include, but is not limited to, one or more of frequency information, amplitude information, etc. The feature information corresponding to the attitude signal is parameter information configured to represent the relative motion of the user's body. In some embodiments, the feature information corresponding to the attitude signal may include, but is not limited to, one or more of an angular velocity direction, an angular velocity value, an acceleration value of angular velocity, etc. In some embodiments, the feature information corresponding to the attitude signal may further include an angle, displacement information (e.g., a stretch length in a strain gauge sensor), stress, etc. For example, when the attitude sensor is a strain gauge sensor, the strain gauge sensor may be set at the user's joint position, and by measuring the resistance in the strain gauge sensor that varies with the stretch length, the obtained attitude signal may be displacement information, stress, etc., which may represent the bending angle and the bending direction at the user's joint. In some embodiments, the processing module <b>220</b> and/or the processing device <b>110</b> may extract the feature information corresponding to the electromyographic signal (e.g., frequency information, amplitude information) or the feature information corresponding to the attitude signal (e.g., the angular velocity direction, the angular velocity value, the acceleration value of angular velocity, the angle, the displacement information, the stress, etc.), and monitor the movement of the user during motion based on the feature information corresponding to the electromyographic signal or the feature information corresponding to the attitude signal. The monitoring of the movement during motion includes user's movement-related information. In some embodiments, movement-related information may include one or more of a movement type, number of movements, a movement quality (e.g., whether the movement meets a standard), a movement time, etc. The movement type is a fitness movement performed by the user during motion. In some embodiments, the movement type may include, but is not limited to, one or more of seated chest presses, deep squats, hard pulls, plank supports, running, swimming, etc. The number of movements refers to the number of times the user performs the movement during motion. For example, if the user performs 10 seated chest clamps during motion, 10 is the number of movements. The movement quality refers to the standard degree of the fitness movement performed by the user related to a standard fitness movement. For example, when the user performs a deep squat movement, the processing device <b>110</b> may determine a movement type of the user based on the feature information corresponding to the movement signal (the electromyographic signal and the attitude signal) of a particular specific muscle location (gluteus maximus, quadriceps, etc.) and determine the movement quality of the user during performing the deep squat movement based on the movement signal. The movement time is the time corresponding to one or more movement types of the user or the total time of the movement process. Detailed descriptions of monitoring the movement of the user during motion based on the feature information corresponding to the electromyographic signal and/or the feature information corresponding to the attitude signal may be found in <figref idref="DRAWINGS">FIG. <b>6</b></figref> and its relevant descriptions of the present disclosure.</p>
<p id="p-0092" num="0091">In some embodiments, the processing device <b>110</b> may use one or more movement recognition models to recognize and monitor the movement of the user during motion. For example, the processing device <b>110</b> may input the feature information corresponding to the electromyographic signal and/or the feature information corresponding to the attitude signal into a movement recognition model, and the movement recognition model outputs information related to the user's movement. In some embodiments, the movement recognition model may include different types of movement recognition models, for example, a model configured to recognize the movement type of the user, or a model configured to identify movement quality of the user, etc.</p>
<p id="p-0093" num="0092">It should be noted that the above description regarding process <b>500</b> is for exemplary and illustrative purpose only, and does not limit the scope of application of the present disclosure. For those skilled in the art, various amendments and changes can be made to the process <b>500</b> under the guidance of the present disclosure. However, these amendments and changes remain within the scope of the present disclosure. For example, extraction of the feature information corresponding to the electromyographic signal or the feature information corresponding to the attitude signal in step <b>520</b> may be performed through the processing device <b>110</b>, or in some embodiments, by processing module <b>220</b>. For example, the user's movement signal is not limited to the above electromyographic signal, attitude signal, electro-cardio signal, temperature signal, humidity signal, blood oxygen concentration, respiration rate, but may also include other human physiological parameter signal, and the physiological parameter signals involved in human movement can be all considered as the movement signal in the embodiments of the present disclosure.</p>
<p id="p-0094" num="0093"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a flowchart of an exemplary process for monitoring a movement of a user during motion according to some embodiments of the present disclosure. As shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, process <b>600</b> may include the following steps.</p>
<p id="p-0095" num="0094">In step <b>610</b>, segmenting, based on the feature information corresponding to the electromyographic signal or the feature information corresponding to the attitude signal, the movement signal.</p>
<p id="p-0096" num="0095">In some embodiments, the step may be performed by the processing module <b>220</b> and/or the processing device <b>110</b>. The process of obtaining the movement signal (e.g., the electromyographic signal, the attitude signal) of the user during motion is continuous, and a movement of the user during motion may be a combination of a plurality of sets of movement or a combination of different movement types. To analyze each movement of the user during motion, the processing module <b>220</b> may segment the movement signal of the user based on the feature information corresponding to the electromyographic signal or the feature information corresponding to the attitude signal. The segmenting the movement signal of the user herein refers to dividing the movement signal into signal segments having same or different durations, or extract one or more signal segments having a specific duration from the movement signal. In some embodiments, each segment of the movement signal may correspond to one or more complete movement of the user. For example, when a user performs a deep squat, the user's movement from a standing position to a squat position and then getting up to return to the standing position can be considered as completing the deep squat, and the movement signal collected by the obtaining module <b>210</b> during this process can be considered as one segment (or one cycle) of the movement signal, after which the movement signal collected by the obtaining module <b>210</b> from the next deep squat completed by the user can be considered as another segment of the movement signal. In some embodiments, each movement signal may also correspond to a portion of the user's movement, where a portion of the movement may be understood as a portion of a complete movement. For example, when a user performs a deep squat, the user's movement from a standing position to a squat position may be considered as one segment of the movement, and getting up to return to the standing position may be considered as another segment of the movement. A change in each movement of the user during motion may cause the electromyographic signal and the attitude signal of a corresponding body part to change. For example, when the user performs a squat, the electromyographic signal and the attitude signal of the muscles in the corresponding parts of the user's body (e.g., arms, legs, hips, abdomen) fluctuate less when the user stands; when the user squats from the standing position, the electromyographic signal and the attitude signal of the muscles in the corresponding parts of the user's body fluctuate more, e.g., amplitude information corresponding to signals of different frequencies of the electromyographic signal becomes greater, or an angular velocity value, a direction of angular velocity, an acceleration value of angular velocity, an angle, displacement information, stress, etc. of the attitude signal may also change. When the user gets up from a squatting state to a standing state, the amplitude information corresponding to the electromyographic signal and the angular velocity value, the direction of angular velocity, the acceleration value of angular velocity, the angle, the displacement information, and the stress corresponding to the attitude signal may change again. Based on this situation, the processing module <b>220</b> may segment, based on the feature information corresponding to the electromyographic signal or the feature information corresponding to the attitude signal, the movement signal. Detailed descriptions of segmenting the movement signal based on the feature information corresponding to the electromyographic signal or the feature information corresponding to the attitude signal may be found in <figref idref="DRAWINGS">FIG. <b>7</b></figref> and <figref idref="DRAWINGS">FIG. <b>8</b></figref> of the present disclosure and their related descriptions.</p>
<p id="p-0097" num="0096">In step <b>620</b>, monitoring, based on at least one segment of the movement signal, the movement of the user during motion.</p>
<p id="p-0098" num="0097">The step may be performed by processing module <b>220</b> and/or processing device <b>110</b>. In some embodiments, monitoring of the movement of the user based on at least one segment of the movement signal may include matching the at least one segment of the movement signal with at least one segment of a preset movement signal to determine the movement type of the user. The at least one segment of the preset movement signal is standard movement signals corresponding to different movements that are preset in a database. In some embodiments, a movement type of the user during motion may be determined by determining a matching degree of the at least one segment of the movement signal and the at least one segment of the preset movement signal. Further, the movement type of the user may be determined by determining whether the matching degree of the movement signal and the preset movement signal is within a first matching threshold range (e.g., greater than 80%). If so, the movement type of the user during motion is determined based on the movement type corresponding to the preset movement signal. In some embodiments, monitoring the movement of the user during motion based on the at least one segment of the movement signal may further include determining the movement type of the user during motion by matching the feature information corresponding to the at least one segment of the electromyographic signal and feature information corresponding to an electromyographic signal of the at least one segment of the preset movement signal. For example, match degree(s) between one or more feature information (e.g., frequency information, amplitude information) of the segment of the electromyographic signal and the one or more feature information of the segment of the preset movement signal may be calculated respectively, and a determination is made as to whether a weighted matching degree of the one or more feature information or an average matching degree of the one or more feature information is within a first matching threshold. If so, the movement type of the user during motion is determined based on the movement type corresponding to the preset movement signal. In some embodiments, monitoring the movement of the user during motion based on the at least one segment of the movement signal may further include determining the movement type of the user during motion by matching the feature information corresponding to the at least one segment of the attitude signal with the feature information corresponding to the attitude signal of the at least one segment of the preset movement signal. For example, the matching degree of the one or more feature information (e.g., the angular velocity value, the angular velocity direction and the acceleration value of the angular velocity, the angle, the displacement information, the stress, etc.) of one segment of the attitude signal and the one or more feature information of one segment of the preset movement signal are calculated respectively to determine whether the weighted matching degree or the average matching degree of the one or more feature information is within the first matching threshold. If so, the movement type of the user is determined according to preset a movement type corresponding to the preset movement signal. In some embodiments, monitoring the movement of the user during motion based on the at least one segment of the movement signal may further include determining the movement type of the user during motion by matching the feature information corresponding to the electromyographic signal and the feature information corresponding to the attitude signal of the at least one segment of the movement signal and the feature information corresponding to the electromyographic signal and the feature information corresponding to the attitude signal of the at least one segment of the preset movement signal.</p>
<p id="p-0099" num="0098">In some embodiments, monitoring the movement of the user during motion based on the at least one segment of the movement signal may include determining the movement quality of the user by matching the at least one segment of the movement signal with the at least one segment of the preset movement signal. Further, if a matching degree of the movement signal and the preset movement signal is within a second matching threshold range (e.g., greater than 90%), the movement quality of the user during motion meets the standard. In some embodiments, determining the movement of the user during motion based on the movement signal of the at least one segment may include determining the movement quality of the user during motion by matching the one or more feature information of the movement signal of the at least one segment with the one or more feature information of the at least one segment of the preset movement signal. It should be noted that a segment of the movement signal may be a movement signal of a complete movement or a movement signal of a partial of a complete movement. In some embodiments, for a complex complete movement, there may be different ways of force generation at different stages of the complete movement, that is, there may be different movement signals at the different stages of the movement, and the user movement can be monitored in real time, and thus, the accuracy of the monitored movement signal at the different stages of the complete movement can be improved.</p>
<p id="p-0100" num="0099">It should be noted that the above description of the process <b>600</b> is for example and illustration purposes only and does not limit the scope of application of the present disclosure. For those skilled in the art, various amendments and changes can be made to process <b>600</b> under the guidance of the present disclosure. However, these amendments and changes remain within the scope of the present disclosure. For example, in some embodiments, the user's movement may also be determined through a movement recognition model or a manually preset model.</p>
<p id="p-0101" num="0100"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a flowchart of an exemplary process for segmenting a movement signal according to some embodiments of the present disclosure. As shown in <figref idref="DRAWINGS">FIG. <b>7</b></figref>, process <b>700</b> may include the following steps.</p>
<p id="p-0102" num="0101">In step <b>710</b>, determining, based on a time domain window of the electromyographic signal or the attitude signal, at least one target feature point from within the time domain window according to a preset condition.</p>
<p id="p-0103" num="0102">In some embodiments, the step may be performed by the processing module <b>220</b> and/or the processing device <b>110</b>. The time domain window of the electromyographic signal includes an electromyographic signal over a range of time, and the time domain window of the attitude signal includes an attitude signal over a same range of time. A target feature point refers to a signal of the movement signal with a target feature, which may represent a stage of the user's movement. For example, when a user performs a seated chest press, at the beginning, the user's arms are extended outward horizontally, begin to rotate internally, come together, and finally return to the extended state again in the horizontal direction, this process is a complete seated chest press movement. When the user performs a seated chest press movement, the feature information corresponding to the electromyographic signal or the attitude signal is different in each stage. By analyzing the feature information corresponding to the electromyographic signal (e.g., amplitude information, frequency information) or the feature information corresponding to the attitude signal (e.g., the angular velocity value, the direction of angular velocity, the acceleration value of angular velocity, the angle, the displacement information, the stress, etc.), the target feature point corresponding to a stage of the user's movement may be determined. In some embodiments, one or more target feature points may be determined from the time domain window based on the preset condition. In some embodiments, the preset condition may include one or more of a change in the direction of the angular velocity corresponding to the attitude signal, the angular velocity corresponding to the attitude signal being greater than or equal to an angular velocity threshold, the angle corresponding to the attitude signal reaching an angular threshold, the change of the angular velocity value corresponding to the attitude signal being the extreme value, and the amplitude information corresponding to the electromyographic signal being greater than or equal to an electromyographic threshold. In some embodiments, the target feature points at the different stages of a movement may correspond to different preset conditions. For example, in the seated chest press, a preset condition for a target feature point when the user's arms are horizontally extended outward and then start to internally rotate is different from a preset condition for a target feature point when the arms are brought together. In some embodiments, the target feature points of different movements may correspond to different preset conditions. For example, the chest press movement and bent-over movement are different, and the preset conditions regarding the respective preset target feature points in these two movements are also different. Exemplary descriptions of the preset condition may refer to the description of a movement start point, a movement middle point and a movement end point in the present disclosure.</p>
<p id="p-0104" num="0103">In other embodiments, the at least one target feature point may be determined, based on the both time domain windows of the electromyographic signal and the attitude signal, from the time domain windows according to the preset condition. The time domain windows of the electromyographic signal and the attitude signal both include the electromyographic signal and the attitude signal over a range of time. The time of the electromyographic signal corresponds to the time of the attitude signal. For example, a time point of the electromyographic signal when the user starts to move is the same as a time point of the attitude signal when the user starts to move. The target feature point here may be determined by combining the feature information corresponding to the electromyographic signal (e.g., the amplitude information) and the feature information corresponding to the attitude signal (e.g., the angular velocity value, the direction of angular velocity, the acceleration value of angular velocity, the angle, etc.).</p>
<p id="p-0105" num="0104">In step <b>720</b>, segmenting, based on the at least one target feature point, the movement signal.</p>
<p id="p-0106" num="0105">In some embodiments, the step <b>720</b> may be performed by the processing module <b>220</b> and/or the processing device <b>110</b>. In some embodiments, the target feature point in the electromyographic signal or the attitude signal may be one or more, and the movement signal may be divided into multiple segments by one or more target feature points. For example, when there is a target feature point in the electromyographic signal, the target feature point may divide the electromyographic signal into two segments, where the two segments may include the electromyographic signal before the target feature point and the electromyographic signal after the target feature point. Alternatively, the processing module <b>220</b> and/or the processing device <b>110</b> may extract the electromyographic signal for a certain time range around the target feature point as a segment of the electromyographic signal. For another example, when the electromyographic signal has a plurality of target feature points (e.g., n-target feature points, and the first target feature point is not a beginning of the time domain window and the n<sup>th </sup>target feature point is not an end of the time domain window), the electromyographic signal may be divided into (n+1) segments based on the n target feature points. For another example, when the electromyographic signal has the plurality of target feature points (e.g., n-target feature points, and the first target feature point is the beginning of the time domain window and the n<sup>th </sup>target feature point is not the end of the time domain window), the electromyographic signal may be divided into n segments based on the n target feature points. As a further example, when the electromyographic signal has the plurality of target feature points (e.g., n-target feature points, and the first target feature point is the beginning of the time domain window and the n<sup>th </sup>target feature point is the end of the time domain window), the electromyographic signal may be divided into (n−1) segments based on the n target feature points. It should be noted that the movement stage corresponding to the target feature point may include one or more types, and a plurality of movement stages corresponding to the target feature point may be used as a benchmark for segmenting the movement signal. For example, the movement stage corresponding to the target feature point may include the movement start point and the movement end point, with the movement start point preceding the movement end point, and the movement signal here between the movement start point and a next movement start point may be considered as a segment of the movement signal.</p>
<p id="p-0107" num="0106">In some embodiments, the target feature point may include one or more of the movement start point, the movement middle point, or the movement end point.</p>
<p id="p-0108" num="0107">To describe the segmentation of the movement signal, take the target feature point including all of the movement start point, the movement middle point and the movement end point as an exemplary illustration. The movement start point may be considered as a start point of a user movement cycle. In some embodiments, different movements may correspond to the different preset conditions. For example, in the seated chest press, the preset condition may be that the direction of the angular velocity of the movement after the movement start point changes relative to the direction of the angular velocity of the movement before the movement start point, or that the value of the angular velocity at the movement start point is approximately 0 and the acceleration value of the angular velocity at the movement start point is greater than 0. In other words, when the user performs the seated chest press, the movement starting point may be set to the point when the arms are extended outward horizontally and start to internally rotate. For another example, in a bent-over movement, the preset condition may be that the angle of arm lift is greater than or equal to an angle threshold. Specifically, when the user performs a bent-over movement, the angle of arm lift when the user's arm is horizontal is 0°, the angle of arm lift when the arm is down is negative, and the angle of arm lift when the arm is up is positive. When the user's arm is raised from the horizontal position, the arm is raised at an angle greater than 0. The point in time when the angle of the arm lift reaches the angle threshold may be considered as the movement start point. The angle threshold may be −70° to −20°, or as a preference, the angle threshold may be −50° to −25°. In some embodiments, to further ensure the accuracy of a selected movement start point, the preset condition may also include that the angular velocity of the arm within a specific range of time after the movement start point may be greater than or equal to an angular velocity threshold. The angular velocity threshold may range from 5°/s˜50°/s. According to preference of example, the angular velocity threshold may range from 10°/s˜30°/s. For example, when a user performs a bent-over movement, the angular velocity of the arm is continuously greater than the angular velocity threshold for a specific time range (e.g., 0.05 s, 0.1 s, 0.5 s) after an angular threshold is reached and the user's arm is continuously raised upward. In some embodiments, if the angular velocity of the selected movement start point according to the preset condition is less than the angular velocity threshold within a specific range of time, the preset condition continues until a movement start point is determined.</p>
<p id="p-0109" num="0108">In some embodiments, the movement middle point may be a point within one movement cycle from the start point. For example, when the user performs the seated chest press, a start point of the movement may be set to the time when the arms extend outward horizontally and begin to internally rotate, and the time when the arms come together may be used as a movement middle point of the user. In some embodiments, the preset condition may be that a direction of the angular velocity at the point in time after the movement middle point changes relative to a direction of the angular velocity at the point in time before the movement middle point, and an angular velocity value at the movement middle point is approximately zero, wherein the direction of the angular velocity at the movement middle point is opposite to the direction of the angular velocity at the movement start point. In some embodiments, to improve the accuracy of the selection of the movement middle point, a change of the angular velocity (acceleration of angular velocity) in a first specific time range after the movement middle point (e.g., 0.05 s, 0.1 s, 0.5 s) may be greater than an acceleration threshold of angular velocity (e.g., 0.05 rad/s). In some implementations, the amplitude information in the electromyographic signal corresponding to the movement middle point is greater than the electromyographic threshold while the movement middle point satisfies the preset condition described above. Since the different movements correspond to different electromyographic signals, the electromyographic threshold is related to the user movement and the target electromyographic signal. In the seated chest press, the electromyographic signal at the pectoral muscle is the target electromyographic signal. In some embodiments, the position corresponding to the middle point of the movement (also may be called as “middle position”) may be approximated as a maximum point of muscle force, where the electromyographic signal may have a relatively great value. It should be noted that the electromyographic signal at the part of the user's body when the user performs the movement during motion is substantially higher than the electromyographic signal at the part of the user's body when the user does not perform the movement during motion (when the muscle in the particular part may be considered as a resting state). For example, an amplitude of the electromyographic signal at the part of the user's body when the user's movement reaches the middle position is 10 times higher than that in the resting state. In addition, the relationship between the amplitude of the electromyographic signal at the part of the user when the movement position reaches the middle position (the movement middle point) and the amplitude of the electromyographic signal in the resting state may be different according to the different movement types performed by the user, and the relationship between the two may be adapted according to the actual movement. In some embodiments, to improve the accuracy of the selection of the movement middle point, the amplitude corresponding to a second specific time range after the movement middle point (e.g., 0.05 s, 0.1 s, 0.5 s) may be continuously greater than the electromyographic threshold. In some embodiments, in addition to the above preset condition (e.g., the angular velocity and an amplitude condition of the electromyographic signal), a Euler angle (also referred to as angle) of the movement middle point and the start position satisfies a certain condition preset to determine the movement middle point. For example, in the seated chest press, the Euler angle at the movement middle point relative to the movement start point may be greater than one or more Euler angle thresholds (also known as angle thresholds). For example, with a front-to-back direction of the human body as an X-axis, a left-right direction of the human body as a Y-axis, and a height direction of the human body as a Z-axis, an Euler angle changed in the X and Y directions may be less than 25°, and the Euler angle changed in the Z direction may be greater than 40° (the movement of the seated chest press is mainly related to the rotation at the Z-axis direction, the above parameters are only reference examples). In some embodiments, the electromyographic thresholds and/or the Euler angle thresholds may be stored in advance in the memory or hard drive of the wearable device <b>130</b>, or in the processing device <b>110</b>, or calculated based on an actual condition and adjusted in real time.</p>
<p id="p-0110" num="0109">In some embodiments, the processing module <b>220</b> may determine, based on the time domain window of the electromyographic signal or the attitude signal, the movement middle point from a time domain window at a time point after the movement start point according to a preset condition. In some implementations, after the movement middle point is determined, whether there are other time points that meet the preset condition within the time range from the movement start point to the movement middle point may be re-verified, and if so, a movement start point closest to the movement middle point may be selected as the best movement start point. In some embodiments, if the difference between the time of the movement middle point and the time of the movement start point is greater than a specific time threshold (e.g., ½ or ⅔ of a movement cycle), the movement middle point is invalid, and the movement start point and movement middle point are re-determined based on preset condition.</p>
<p id="p-0111" num="0110">In some embodiments, the movement end point may be a time point that is within one movement cycle from the movement start point and after the movement middle point. For example, the movement end point may be set to as a point that is one movement cycle from the movement start point, and the movement end point herein may be considered the end of a movement cycle of the user. For example, when the user performs the seated chest press, the movement start point may be set as a time point when the arms extend horizontally to the left and right and start internal rotation, the time point when the arms close together may be the movement middle point of the user, and the time point when the arms return to the extended state again from the horizontal direction may correspond to the movement end point of the user. In some embodiments, the preset condition may be that a changed angular velocity value corresponding to the attitude signal is an extreme value. In some embodiments, to prevent jitter misjudgment, the change in Euler angle should exceed a certain Euler angle threshold, e.g., 20°, in the time range from the movement middle point to the movement end point. In some embodiments, the processing module <b>220</b> may determine the movement end point from the time domain window after the movement middle point based on the time domain windows of the electromyographic signal and the attitude signal according to the preset condition. In some embodiments, if the difference between the time of the movement end point and the time of the movement middle point is greater than a specific time threshold (e.g., ½ of a movement cycle), the movement start point and the movement middle point are invalid, and the movement start point, movement middle point, and movement end point are re-determined based on the preset condition.</p>
<p id="p-0112" num="0111">In some embodiments, at least one set of the movement start point, the movement middle point, and the movement end point in the movement signal may be repeatedly determined, and the movement signal may be segmented based on the at least one set of the movement start point, the movement middle point, and the movement end point as the target feature points. The step may be performed by the processing module <b>220</b> and/or the processing device <b>110</b>. It should be noted that segmentation of the movement signal is not limited to be based on the above movement start point, movement middle point and movement end point, but may also include other time points. For example, for the seated chest press, 5 time points may be selected according to the above steps, a first time point may be a movement start point, a second time point may be a moment of the maximum angular velocity of the internal rotation, a third time point may be the movement middle point, a fourth time point may be the moment of the maximum angular velocity of external rotation, a fifth time point may be the moment when the arms return to extend left and right, and the angular velocity is 0, that is, the movement end point. In this example, compared to the movement start point, movement middle point and movement end point in the above steps, the second time point is added as a ¼ marker point of the movement cycle, the movement end point described in the above embodiments is used as the fourth time point for marking the ¾ position of the movement cycle, and the fifth time point is added as an end point of the complete movement. For the seated chest press, more time points are used here, and a recognition of the movement quality may be done based on the signal of the first ¾ of the movement cycle (i.e., the recognition of the movement quality for a single cycle does not depend on a complete analysis of the signal of a whole cycle), which can complete the monitoring and feedback of the user's movement without the end of a current cycle. At same time, all signals of the process of the whole movement may be completely recorded to be easily uploaded to the cloud or the mobile terminal device, thus more methods may be adopted to monitor the user's movement. For more complex movement, the cycle of the movement may be quite long, and the stages for the movement have different force pattern. In some embodiments, the above method of determining each time point may be adopted to divide the movement into multiple stages, and the signal for each stage may be recognized and fed back separately to improve timeliness of feedback of the user's movement.</p>
<p id="p-0113" num="0112">It should be noted that the above segmentation and monitoring of the movement signal based on the movement start point, movement middle point and movement end point as a set of target feature point is only an exemplary illustration. In some embodiments, the user's movement signal may also be segmented and monitored based on any one or more of the movement start point, the movement middle point and the movement end point as the target feature point. For example, the movement signal may be segmented and monitored by using the movement start point as the target feature point. For another example, the movement start point and the movement end point may be used as a set of target feature points to segment and monitor the movement signal, and other time point or time ranges that can be used as the target feature point are within the scope of protection of the present disclosure.</p>
<p id="p-0114" num="0113">It should be noted that the above description of the process <b>700</b> is for example and illustration purposes only and does not limit the scope of application of the present disclosure. For those skilled in the art, various amendments and changes can be made to the process <b>700</b> under the guidance of the present disclosure. However, these amendments and changes remain within the scope of the present disclosure. For example, step <b>710</b> and step <b>720</b> may be performed simultaneously in the processing module <b>220</b>. For another example, step <b>710</b> and step <b>720</b> may be performed simultaneously in the processing module <b>220</b> and the processing device <b>110</b>, respectively.</p>
<p id="p-0115" num="0114"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a diagram illustrating exemplary movement signal segmentation according to some embodiments of the present disclosure. A horizontal coordinate in <figref idref="DRAWINGS">FIG. <b>8</b></figref> may indicate a motion time of a user, and a vertical coordinate may indicate amplitude information of an electromyographic signal of a muscle part (e.g., pectoralis major) during seated chest press. Also included in <figref idref="DRAWINGS">FIG. <b>8</b></figref> are an angular velocity curve and a Euler angle curve corresponding to an attitude signal of the wrist position of the user during motion. The angular velocity curve is configured to represent a velocity change of the user during motion and the Euler angle curve is configured to represent a position situation of a user's body part during motion. As shown in <figref idref="DRAWINGS">FIG. <b>8</b></figref>, point A<b>1</b> is determined as the movement start point according to the preset condition. Specifically, a direction of the angular velocity at a time point after the user's movement start point A<b>1</b> changes relative to the direction of the angular velocity at a time point before the movement start point A<b>1</b>. Further, the angular velocity value at the movement start point A<b>1</b> is approximately 0, and an acceleration value of the angular velocity at the movement start point A<b>1</b> is greater than 0.</p>
<p id="p-0116" num="0115">Refer to <figref idref="DRAWINGS">FIG. <b>8</b></figref>, point B<b>1</b> is determined as the movement middle point according to the preset condition. Specifically, the direction of the angular velocity at the time point after the user's movement middle point B<b>1</b> changes relative to the direction of the angular velocity at the time point before the movement middle point B<b>1</b>, and the angular velocity value at the movement middle point B<b>1</b> is approximately 0. The direction of the angular velocity at the movement middle point B<b>1</b> is opposite to the direction of the angular velocity at the movement start point A<b>1</b>. In addition, the amplitude of the electromyographic signal (shown as the “electromyographic signal” in <figref idref="DRAWINGS">FIG. <b>8</b></figref>) corresponding to the movement middle point B<b>1</b> is greater than the electromyographic threshold.</p>
<p id="p-0117" num="0116">Continue to refer to <figref idref="DRAWINGS">FIG. <b>8</b></figref>, point C<b>1</b> is determined as the movement end point according to the preset condition. Specifically, a changed angular velocity value at the movement end point C<b>1</b> is the extreme value from the movement start point A<b>1</b> to the movement end point C<b>1</b>. In some embodiments, the process <b>700</b> may complete the movement segmentation shown in <figref idref="DRAWINGS">FIG. <b>8</b></figref>, such that the movement signal from the movement start point A<b>1</b> to the movement end point C<b>1</b> shown in <figref idref="DRAWINGS">FIG. <b>8</b></figref> may be considered as a segment of the motion.</p>
<p id="p-0118" num="0117">It is noted that in some embodiments, if a time interval between the movement middle point and the movement start point is greater than a specific time threshold (e.g., ½ of a movement cycle), the processing module <b>220</b> may re-determine the movement start point to improve the accuracy of the movement segmentation. The specific time threshold here may be stored in the memory or the hard drive of the wearable device <b>130</b>, or in the processing device <b>110</b>, or calculated or adjusted based on the actual situation of the user during motion. For example, if the time interval between the movement start point A<b>1</b> and the movement middle point B<b>1</b> in <figref idref="DRAWINGS">FIG. <b>8</b></figref> is greater than a specific time threshold, the processing module <b>220</b> may re-determine the movement start point, thereby improving the accuracy of the movement segmentation. In addition, the segmentation of the movement signal is not limited to be based on the above movement start point A<b>1</b>, movement middle point B<b>1</b> and movement end point C<b>1</b>, but may also include other time points, and selection of the time points may be made according to complexity of the movement.</p>
<p id="p-0119" num="0118">When obtaining the user's movement signal, other physiological parameter information of the user (e.g., a heart rate signal), external condition such as a relative movement of the obtaining module <b>210</b> and the human body during motion or compression of the obtaining module <b>210</b> may affect the quality of the movement signal, for example, resulting in an abrupt change in the electromyographic signal, thereby affecting the monitoring of the movement. For ease of description, an abrupt electromyographic signal may be described by using a singularity, and an exemplary singularity may include a burr signal, a discontinuous signal, etc. In some embodiments, monitoring the movement of the user during motion based at least on the feature information corresponding to the electromyographic signal or the feature information corresponding to the attitude signal may further include: pre-processing the electromyographic signal in a frequency domain or a time domain, obtaining, based on the pre-processed electromyographic signal, the feature information corresponding to the electromyographic signal, and monitoring, based on the feature information corresponding to the electromyographic signal or the feature information corresponding to the attitude signal, the movement of the user during motion. In some embodiments, pre-processing the electromyographic signal in the frequency domain or the time domain may include filtering the electromyographic signal in the frequency domain to select or retain components of the electromyographic signal in a particular frequency range in the frequency domain. In some embodiments, the obtaining module <b>210</b> may obtain an electromyographic signal in a frequency range of 1 Hz-1000 Hz, filter the electromyographic signal and select an electromyographic signal in a specific frequency range (e.g., 30 Hz-150 Hz) for subsequent processing. In some embodiments, the specific frequency range may be 10 Hz-500 Hz. According to preference of example, the specific frequency range may be 15 Hz-300 Hz or 30 Hz-150 Hz. In some embodiments, a filtering process may include a low-pass filter processing. In some embodiments, the low-pass filter may include an LC passive filter, an RC passive filter, an RC active filter, a passive filter composed of special elements. In some embodiments, the passive filter composed of the special elements may include one or more of a piezoelectric ceramic filter, a crystal filter, and an acoustic surface filter. It should be noted that the specific frequency range is not limited to the above range, but may also be other ranges, which may be selected according to the actual situation. More descriptions of monitoring, according to the feature information corresponding to the electromyographic signal or the feature information corresponding to the attitude signal, the movement of the user during motion may be found in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, <figref idref="DRAWINGS">FIG. <b>6</b></figref> of the present disclosure and their relevant descriptions.</p>
<p id="p-0120" num="0119">In some embodiments, pre-processing the electromyographic signal in the frequency domain or the time domain may further include signal correction processing of the electromyographic signal in the time domain. The signal correction processing refers to a correction to the singularity (e.g., the burr signal, the discontinuous signal, etc.) in the electromyographic signal. In some embodiments, the signal correction processing of the electromyographic signal in the time domain may include determining the singularity in the electromyographic signal, i.e., determining the abrupt signal in the electromyographic signal. The singularity may be a sudden change in the amplitude of an electromyographic signal within a certain moment, causing a discontinuity in the signal. For another example, the electromyographic signal is morphologically smooth and there is no abrupt change in the amplitude of the electromyographic signal, but there is the abrupt change in the first-order differential of the electromyographic signal, and the first-order differential is discontinuous. In some embodiments, the method of determining the singularity in the electromyographic signal may include, but is not limited to, one or more of Fourier transform, wavelet transform, fractal dimension, etc. In some embodiments, the signal correction processing of the electromyographic signal in the time domain may include removing the singularity in the electromyographic signal, for example, removing signals within a period of time at and near the singularity. Alternatively, the signal correction processing of the electromyographic signal in the time domain may include correcting the singularity of the electromyographic signal according to the feature information of the electromyographic signal in the specific time range, such as adjusting the amplitude of the singularity based on the signals around the singularity. In some embodiments, the feature information of the electromyographic signal may include the amplitude information, the statistic information of the amplitude information, etc. The statistic information of amplitude information (also known as amplitude entropy) refers to a distribution of the amplitude information of the electromyographic signal in the time domain. In some embodiments, after a location (e.g., the time point) of the singularity in the electromyographic signal is determined through a signal processing algorithm (e.g., the Fourier transform, the wavelet transform, the fractal dimension), the singularity may be corrected based on the electromyographic signal in the specific time range before or after the location of the singularity. For example, when the singularity is an abrupt trough, the electromyographic signal at the abrupt trough can be supplemented based on the feature information (e.g., the amplitude information, the statistic information of the amplitude information) of the electromyographic signal in a specific time range (e.g., 5 ms-60 ms) before or after the abrupt trough.</p>
<p id="p-0121" num="0120">Exemplary illustration with the singularity as the burr signal, <figref idref="DRAWINGS">FIG. <b>9</b></figref> is a flowchart of an exemplary process for pre-processing an electromyographic signal according to some embodiments of the present disclosure. As shown in <figref idref="DRAWINGS">FIG. <b>9</b></figref>, the process <b>900</b> may include:</p>
<p id="p-0122" num="0121">Step <b>910</b>, selecting, based on the time domain window of the electromyographic signal, different time windows from the time domain window of the electromyographic signal, wherein the different time windows respectively cover different time ranges.</p>
<p id="p-0123" num="0122">In some embodiments, the step may be performed by the processing module <b>220</b> and/or the processing device <b>110</b>. In some embodiments, the different windows may include at least one specific window. A specific window is a window with a specific time length selected from the time domain window. For example, a time length of the specific window may be 100 ms when the time length of the time domain window of the electromyographic signal is 3 s. In some embodiments, a specific window may include a plurality of different time windows. Merely as way of exemplary illustration, the specific window may include a first time window and a second time window, and the first time window may refer to a window corresponding to a partial time length of the specific window, for example, when the time length of the specific window is 100 ms, the time length of the first time window may be 80 ms. The second time window may be another window corresponding to the partial time length of the specific window. For example, when the specific window is 100 ms, the second time window may be 20 ms. In some embodiments, the first time window and the second time window may be consecutive time windows within a same specific window. In some embodiments, the first time window and the second time window may also be two discrete or overlapping time windows within the same specific window. For example, when the time length of the specific window is 100 ms, the time length of the first time window may be 80 ms and the time length of the second time window may be 25 ms, in which case the second time window is overlapped with the first time window in 5 ms. In some embodiments, the processing module <b>220</b> may slide and update the specific window sequentially from an initially time point of the time domain window of the electromyographic signal according to the specific time length based on the time domain window of the electromyographic signal, and may continue to divide an updated specific window into the first time window and the second time window. The specific time length mentioned here may be less than 1 s, 2 s, 3 s, etc. For example, the processing module <b>220</b> may select a specific window of a specific time length of 100 ms and divide that specific window into a first time window of 80 ms and a second time window of 20 ms. Further, the specific window may be updated by sliding along the time direction. A sliding distance here may be a time length of the second time window (e.g., 20 ms) or other suitable time lengths, e.g., 30 ms, 40 ms, etc.</p>
<p id="p-0124" num="0123">Step <b>920</b>, determining, based on the feature information corresponding to the electromyographic signal in the different time windows, the burr signal.</p>
<p id="p-0125" num="0124">In some embodiments, the step may be performed by the processing module <b>220</b> and/or the processing device <b>110</b>. In some embodiments, the feature information corresponding to the electromyographic signal may include at least one of the amplitude information, the statistic information of the amplitude information. In some embodiments, the processing module <b>220</b> may obtain the amplitude information or the statistic information of the amplitude information corresponding to the electromyographic signal in different time windows (e.g., the first time window, the second time window) to determine the location of the burr signal. Detailed descriptions of determining, based on the feature information corresponding to the electromyographic signal in different time windows, the location of the burr signal may be found in <figref idref="DRAWINGS">FIG. <b>10</b></figref> and its relevant descriptions.</p>
<p id="p-0126" num="0125">It should be noted that the above description of the process <b>900</b> is for example and illustration purposes only and does not limit the scope of application of the present disclosure. For those skilled in the art, various amendments and changes can be made to process <b>900</b> under the guidance of the present disclosure. For example, the specific window is not limited to include the first time window and the second time window described above, but may also include other time windows, for example, a third time window, a fourth time window, etc. In addition, the specific range of moments before or after the position of the burr signal may be adapted according to the length of the burr signal, which will not be further limited herein. However, these amendments and changes remain within the scope of the present disclosure.</p>
<p id="p-0127" num="0126"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a flow chart illustrating an exemplary process for determining a burr signal according to some embodiments of the present disclosure.</p>
<p id="p-0128" num="0127">Step <b>1010</b>, determining first amplitude information corresponding to the electromyographic signal within the first time window and second amplitude information corresponding to the electromyographic signal within the second time window.</p>
<p id="p-0129" num="0128">In some embodiments, the step may be performed by the processing module <b>220</b> and/or the processing device <b>110</b>. In some embodiments, the processing module <b>220</b> may select the time length of the first time window and the second time window and extract the first amplitude information corresponding to the electromyographic signal during the time length of the first time window and the second amplitude information corresponding to the electromyographic signal during the time length of the second time window. In some embodiments, the first amplitude information may include an average amplitude of the electromyographic signal during the first time window, and the second amplitude information may include the average amplitude of the electromyographic signal during the second time window. For example, the processing module <b>220</b> may select a time length of a first time window as 80 ms and extract the first amplitude information corresponding to the electromyographic signal within the first time window, and the processing module <b>220</b> may select a time length of a second time window as 20 ms and extract the second amplitude information corresponding to the electromyographic signal within the second time window.</p>
<p id="p-0130" num="0129">In some embodiments, a selection of the time length of the first time window and the time length of the second time window is related to the shortest burr signal length and amount of computation of the system. In some embodiments, the time length of the first time window and the time length of the second time window may be selected according to the feature of the burr signal. The time length of an electro-cardio burr signal is 40 ms-100 ms, the time interval between two burr signals in the electro-cardio signal may be about 1 s, a peak point of the burr signal is basically symmetrical on both sides, an amplitude distribution of the burr signal is relatively even on both sides, etc. In some embodiments, when the burr signal is the electro-cardio signal, a time length less than the length of the burr signal, e.g., half the length of the burr signal, may be selected as the time length of the second time window, and the time length of the first time window may be greater than (e.g., four times) the time length of the second time window. In some embodiments, the time length of the first time window may be within a range of an interval (about 1 s) between burr signals minus the time length of the second time window. It should also be noted that the above selected time length of the first time window and the time length of the second time window are not limited to the above description, as long as a sum of the time length of the second time window and the time length of the first time window is less than time intervals of adjacent two burr signals, or the time length of the second time window is less than the single burr signal length, or an amplitude of the electromyographic signal within the second time window and an amplitude of the electromyographic signal the first time window may be discriminated.</p>
<p id="p-0131" num="0130">Step <b>1020</b>, judging whether a ratio of the second amplitude information to the first amplitude information is greater than a threshold.</p>
<p id="p-0132" num="0131">In some embodiments, the step may be performed by the processing module <b>220</b> and/or the processing device <b>110</b>. In some embodiments, the processing module <b>220</b> may determine whether the ratio of the second amplitude information corresponding to the electromyographic signal in the second time window to the first amplitude information corresponding to the electromyographic signal in the first time window is greater than the threshold. The threshold here may be stored in the memory or the hard drive of the wearable device <b>130</b>, or in the processing device <b>110</b>, or adjusted according to the actual situation. In some embodiments, the step <b>1020</b> may proceed to step <b>1030</b> if the processing module <b>220</b> judges that the ratio of the second amplitude information to the first amplitude information is greater than the threshold. In other embodiments, if the processing module <b>220</b> determines that the ratio of the second amplitude information to the first amplitude information is not greater than the threshold, step <b>1020</b> may proceed to step <b>1040</b>.</p>
<p id="p-0133" num="0132">Step <b>1030</b>, performing a signal correction processing on the electromyographic signal within the second time window.</p>
<p id="p-0134" num="0133">In some embodiments, the step may be performed by the processing module <b>220</b> and/or the processing device <b>110</b>. In some embodiments, the processing module <b>220</b> may perform the signal correction processing on the electromyographic signal within the second time window based on the comparison result of the ratio of the second amplitude information to the first amplitude information and the threshold in step <b>1020</b>. For example, in some embodiments, if the ratio of the second amplitude information to the first amplitude information is greater than the threshold, then the electromyographic signal in the second time window corresponding to the second amplitude information is a burr signal. In some embodiments, processing the electromyographic signal within the second time window may include performing signal correction processing on the electromyographic signal within the second time window based on the electromyographic signal within a specific time range before or after the second time window. In some embodiments, the signal correction processing of the electromyographic signal within the second time window may include, but is not limited to, padding, interpolation, etc. In some embodiments, the specific time range herein may be 5 ms-60 ms. According to preference of example, the specific time range may be 10 ms-50 ms or 20 ms-40 ms. It should be noted that the specific time range is not limited to the above range, for example, the specific time range may be greater than 60 ms, less than 5 ms, or other ranges. In practical application scenarios, the specific time range may be adapted based on the duration of the burr signal.</p>
<p id="p-0135" num="0134">In step <b>1040</b>, retaining an electromyographic signal within the second time window.</p>
<p id="p-0136" num="0135">In some embodiments, the step may be performed by the processing module <b>220</b> and/or the processing device <b>110</b>. In some embodiments, the processing module <b>220</b> may perform retention on the electromyographic signal within the second time window according to the comparison result of the ratio of the second amplitude information to the first amplitude information and the threshold in step <b>1020</b>. For example, in some embodiments, the ratio of the second amplitude information to the first amplitude information is not greater than the threshold, then the electromyographic signal within the second time window corresponding to the second amplitude information is a normal electromyographic signal, and the normal electromyographic signal may be retained, i.e., the electromyographic signal within the second time window is retained.</p>
<p id="p-0137" num="0136">It should be noted that the amplitude of the electromyographic signal is gradually increasing since electrical charges gradually accumulates during muscular exertion, so that the amplitude of the electromyographic signal within two adjacent time windows (e.g., the first time window and the second time window) does not change abruptly in the absence of a burr signal. In some embodiments, whether there is the burr signal in the electromyographic signal may be determined and the burr signal may be removed based on the process <b>1000</b> to realize a real-time processing of the burr signal, thereby enabling the wearable device <b>130</b> or the mobile terminal device <b>140</b> to provide a real-time feedback of the motion state to the user, and helping the user to perform motion more scientifically.</p>
<p id="p-0138" num="0137">In some embodiments, the time length corresponding to the first time window may be greater than the time length corresponding to the second time window. In some embodiments, a specific time length corresponding to a specific window may be less than 1 s. In some embodiments, the ratio of the time length corresponding to the first time window to the time length corresponding to the second time window may be greater than 2. In some embodiments, the time length corresponding to the first time window, the time length corresponding to the second time window, and the specific time length corresponding to the specific window are selected to ensure that the shortest burr signal (e.g., 40 ms) can be removed, and the system has a high signal-to-noise ratio, calculation volume of the system can be decreased, repeated calculation of the system can be avoided, the time complexity can be reduced, thereby improving calculation efficiency and calculation accuracy of the system.</p>
<p id="p-0139" num="0138">It should be noted that the above description of the process <b>1000</b> is for example and illustration purposes only, and does not limit the scope of application of the present disclosure. For those skilled in the art, various amendments and changes may be made to process <b>1000</b> under the guidance of the present disclosure. For example, the above process <b>1000</b> is only an example where the singularity is the burr signal, and when the singularity is a trough signal, each of the above steps (e.g., step <b>1010</b>, step <b>1020</b>, step <b>1030</b>, etc.) and the technical schemes may be adjusted or other methods may be used to perform signal correction processing. However, these amendments and changes remain within the scope of the present disclosure.</p>
<p id="p-0140" num="0139">In some embodiments, the signal correction processing on the singularity of the electromyographic signal may further be performed by the other methods, e.g., a high-pass method, a low-pass method, a band-pass method, a wavelet transform reconstruction method, etc. In some embodiments, for an application scenario where a low-frequency signal is not sensitive, a 100 Hz high-pass filter may be used for a removal of the burr signal. In some embodiments, in addition to the signal correction processing of the electromyographic signal, the other methods of the signal processing of the electromyographic signal, such as a filtering processing, a signal amplification, a phase adjustment, etc., may also be performed. In some embodiments, the electromyographic signal of the user collected by the electromyographic sensor may be converted into a digital electromyographic signal by an analog-to-digital converter (ADC), and the converted digital electromyographic signal may be subjected to a filtering process, which can filter out an industrial frequency signal and its harmonic signal, etc. In some embodiments, the processing of the electromyographic signal may further include removing motion artifacts of the user. The motion artifacts here refer to signal noise generated by a relative movement of the muscles at the position to be measured relative to the electromyographic module during an obtaining process of the electromyographic signal while the user in motion.</p>
<p id="p-0141" num="0140">In some embodiments, the attitude signal may be obtained by the attitude sensor on the wearable device <b>130</b>. The attitude sensor on the wearable device <b>130</b> may be distributed on the limb areas (e.g., arms, legs, etc.), the trunk areas (e.g., chest, abdomen, back, waist, etc.), and the head, etc. The attitude sensor enables the collection of the attitude signal from other parts of the body such as limb parts and trunk parts. In some embodiments, the attitude sensor may be a sensor of an Attitude and heading reference system (AHRS) with an attitude fusion algorithm. The attitude fusion algorithm may fuse data from a nine-axis inertial measurement unit (IMU) with a three-axis acceleration sensor, a three-axis angular velocity sensor, and a three-axis geomagnetic sensor into Euler angles or quaternions to obtain the attitude signal of the user's body part where the attitude sensor is located. In some embodiments, the processing module <b>220</b> and/or the processing device <b>110</b> may determine the feature information corresponding to the attitude based on the attitude signal. In some embodiments, the feature information corresponding to the attitude signal may include, but is not limited to, the angular velocity value, the direction of angular velocity, the acceleration value of angular velocity, etc. In some embodiments, the attitude sensor may be a strain sensor, and the strain sensor may obtain a bending direction and bending angle at the user's joints, thereby obtaining the attitude signal during the user's motion. For example, the strain sensor may be set at the knee joint of the user, and when the user is in motion, the user's body part acts on the strain sensor, and the bending direction and the bending angle at the knee joint of the user may be calculated based on the change in resistance or length of the strain sensor, thereby obtaining the attitude signal of the user's leg. In some embodiments, the attitude sensor may also include a fiber optic sensor, and the attitude signal may be represented by a change in direction after bending of a fiber from the fiber optic sensor. In some embodiments, the attitude sensor may also be a magnetic flux sensor, and the attitude signal may be represented by transformation of the magnetic flux. It should be noted that the type of attitude sensor is not limited to the above sensors, but can also be other sensors, the sensors that can obtain the user's attitude signal are within the scope of the attitude sensor of the present disclosure.</p>
<p id="p-0142" num="0141"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is a flowchart of an exemplary process for determining feature information corresponding to an attitude signal according to some embodiments of the present disclosure. As shown in <figref idref="DRAWINGS">FIG. <b>11</b></figref>, the process <b>1100</b> may include:</p>
<p id="p-0143" num="0142">Step <b>1110</b>, obtaining a target coordinate system and a conversion relationship between the target coordinate system and at least one original coordinate system.</p>
<p id="p-0144" num="0143">In some embodiments, the step may be performed by the processing module <b>220</b> and/or the processing device <b>110</b>. In some embodiments, the original coordinate system is a coordinate system corresponding to the attitude sensor set on the human body. When the user uses the wearable device <b>130</b>, each attitude sensor on the wearable device <b>130</b> is distributed on different parts of the human body, so that installation angles of the attitude sensors are different, and the attitude sensors in different parts use their own coordinate systems as the original coordinate systems, so the attitude sensors in different parts have different original coordinate systems. In some embodiments, an obtained attitude signal of the each attitude sensor may be represented in its corresponding original coordinate system. By transforming the attitude signal in different original coordinate systems into a same coordinate system (e.g., the target coordinate system), it is easy to determine relative motion between different parts of the human body. In some embodiments, the target coordinate system refers to a human coordinate system established based on the human body. For example, a length direction of the human torso (i.e., a direction perpendicular to a transverse plane of the body) can be used as the Z-axis, an anterior-posterior direction of the human torso (i.e., the direction perpendicular to the coronal plane of the body) as the X-axis, and the left-right direction of the human torso (i.e., the direction perpendicular to the sagittal plane of the body) as the Y-axis in the target coordinate system. In some embodiments, there is a conversion relationship between the target coordinate system and the original coordinate system by which the coordinate information in the original coordinate system can be converted to the coordinate information in the target coordinate system. In some embodiments, the conversion relationship may be expressed as one or more rotation matrices. More descriptions of determining the conversion relationship between the target coordinate system and the original coordinate system may be found in <figref idref="DRAWINGS">FIG. <b>13</b></figref> of the present disclosure and its relevant descriptions.</p>
<p id="p-0145" num="0144">Step <b>1120</b>, converting, based on the conversion relationship, the coordinate information in the at least one original coordinate system to the coordinate information in the target coordinate system.</p>
<p id="p-0146" num="0145">In some embodiments, the step may be performed by the processing module <b>220</b> and/or the processing device <b>110</b>. The coordinate information in the original coordinate system is three-dimensional coordinate information in the original coordinate system. The coordinate information in the target coordinate system is the three-dimensional coordinate information in the target coordinate system. Merely as way of exemplary illustration, the coordinate information v<sub>1 </sub>in the original coordinate system may be converted to the coordinate information v<sub>2 </sub>in the target coordinate system according to the conversion relationship. Specifically, a conversion between the coordinate information v<sub>1 </sub>and the coordinate information v<sub>2 </sub>may be performed by using a rotation matrix, the rotation matrix here can be understood as the conversion relationship between the original coordinate system and the target coordinate system. Specifically, the coordinate information v<sub>1 </sub>in the original coordinate system may be converted to coordinate information v<sub>1</sub>−1 by a first rotation matrix, the coordinate information v<sub>1</sub>−1 may be converted to coordinate information v<sub>1</sub>−2 by a second rotation matrix, and the coordinate information v<sub>1</sub>−2 may be converted to coordinate information v<sub>1</sub>−3 by a third rotation matrix. The coordinate information v<sub>1</sub>−3 is the coordinate information v<sub>2 </sub>in the target coordinate system. It should be noted that the rotation matrices are not limited to the above first rotation matrix, the second rotation matrix and the third rotation matrix, but may also include fewer or more rotation matrices. In some alternative embodiments, the rotation matrix may be a rotation matrix or a combination of a plurality of rotation matrices.</p>
<p id="p-0147" num="0146">Step <b>1130</b>, determining, based on the coordinate information in the target coordinate system, the feature information corresponding to the attitude signal.</p>
<p id="p-0148" num="0147">In some embodiments, the step may be performed by the processing module <b>220</b> and/or the processing device <b>110</b>. In some embodiments, determining, based on the coordinate information in the target coordinate system, the feature information corresponding to the attitude signal comprises determining based on a plurality of coordinate information in the target coordinate system of the user during motion, the feature information corresponding to the attitude signal of the user. For example, when the user performs a seated chest press, the user's arm may correspond to the first coordinate information in the target coordinate system when the user's arm is held forward, and the user's arm can correspond to the second coordinate information in the target coordinate system when the user's arm is opened in a same plane as the torso. Based on the first coordinate information and the second coordinate information, the feature information (for example, the angular velocity, the angular velocity direction, and the acceleration value of the angular velocity) corresponding to the attitude signal may be calculated.</p>
<p id="p-0149" num="0148">It should be noted that the above description of the process <b>1100</b> is for example and illustration purposes only and does not limit the scope of application of the present disclosure. For those skilled in the art, various amendments and changes can be made to process <b>1100</b> under the guidance of the present disclosure. However, these amendments and changes remain within the scope of the present disclosure.</p>
<p id="p-0150" num="0149">In some embodiments, the relative motion between different motion parts of the user's body may be determined by the feature information corresponding to the attitude sensors located at the different motion parts of the user's body. For example, by using the feature information corresponding to the attitude sensor at the user's arm and the feature information corresponding to the attitude sensor at the user's torso, the relative motion between the user's arm and torso during motion can be determined. <figref idref="DRAWINGS">FIG. <b>12</b></figref> is a flowchart of an exemplary process for determining relative motion between the different motion parts of the user according to some embodiments of the present disclosure. As shown in <figref idref="DRAWINGS">FIG. <b>12</b></figref>, the process <b>1200</b> may include:</p>
<p id="p-0151" num="0150">Step <b>1210</b>, determining, based on the conversion relationships between the different original coordinate systems and the target coordinate system, the feature information corresponding to at least two sensors respectively.</p>
<p id="p-0152" num="0151">In some embodiments, the step may be performed by the processing module <b>220</b> and/or the processing device <b>110</b>. In some embodiments, different sensors have different conversion relationships between the original coordinate systems corresponding to the sensors and the target coordinate system due to the different installation positions at the human body. In some embodiments, the processing device <b>110</b> may convert the coordinate information in the original coordinate systems corresponding to the sensors of different parts of the user (e.g., small arm, large arm, torso, etc.) to the coordinate information in the target coordinate system, respectively, so that the feature information corresponding to at least two sensors can be determined respectively. More descriptions of the conversion of the coordinate information in the original coordinate system to coordinate information in the target coordinate system may be found elsewhere in the present disclosure, e.g., <figref idref="DRAWINGS">FIG. <b>11</b></figref>, which will not be repeated herein.</p>
<p id="p-0153" num="0152">Step <b>1220</b>, determining, based on the feature information corresponding to the at least two sensors respectively, the relative motion between the different motion parts.</p>
<p id="p-0154" num="0153">In some embodiments, the step may be performed by the processing module <b>220</b> and/or the processing device <b>110</b>. In some embodiments, a motion part may refer to a limb on the human body that can move independently, for example, a small arm, a large arm, a small leg, a thigh, etc. Merely as way of exemplary illustration, when the user performs an arm lifting dumbbell, the coordinate information in the target coordinate system corresponding to the sensor set at the small arm part and the coordinate information in the target coordinate system corresponding to the sensor set at the large arm part are combined to determine the relative motion between the small arm and the large arm of the user, thereby determining the arm lifting dumbbell movement of the user.</p>
<p id="p-0155" num="0154">In some embodiments, a same motion part of the user may be arranged with a plurality of sensors of the same or different types, and the coordinate information in the original coordinate systems corresponding to a plurality of sensors of same or different types may be converted to the coordinate information in the target coordinate system, respectively. For example, a plurality of sensors of the same or different types can be arranged at different locations of the user's small arm part, and a plurality of coordinates in the target coordinate system corresponding to a plurality of sensors of the same or different types may simultaneously represent the movement of the user's small arm part. For example, the coordinate information in the target coordinate systems corresponding to a plurality of sensors of the same type can be averaged, thereby improving the accuracy of the coordinate information of the motion parts during the user's motion. For example, the coordinate information in the target coordinate system can be obtained by performing a fusion algorithm (e.g., Kalman filtering, etc.) on the coordinate information in coordinate systems corresponding to a plurality of the different types of sensors.</p>
<p id="p-0156" num="0155">It should be noted that the above description of the process <b>1100</b> is for example and illustration purposes only and does not limit the scope of application of the present disclosure. For those skilled in the art, various amendments and changes can be made to process <b>1100</b> under the guidance of the present disclosure. However, these amendments and changes remain within the scope of the present disclosure.</p>
<p id="p-0157" num="0156"><figref idref="DRAWINGS">FIG. <b>13</b></figref> is a flowchart of an exemplary process for determining a conversion relationship between an original coordinate system to a specific coordinate system according to some embodiments of the present disclosure. In some embodiments, the process of determining the conversion relationship between the original coordinate system to a specific coordinate system may also be called a calibration process. As shown in <figref idref="DRAWINGS">FIG. <b>13</b></figref>, the process <b>1300</b> may include:</p>
<p id="p-0158" num="0157">Step <b>1310</b>, constructing the specific coordinate system.</p>
<p id="p-0159" num="0158">In some embodiments, the step may be performed by the processing module <b>220</b> and/or the processing device <b>110</b>. In some embodiments, the conversion relationship between at least one original coordinate system and the target coordinate system may be obtained by the calibration process. The specific coordinate system is a reference coordinate system configured to determine the conversion relationship between the original coordinate system and the target coordinate system during the calibration process. In some embodiments, a constructed specific coordinate system may have the length direction of the torso when the human body is standing as the Z-axis, the front-to-back direction of the human body as the X-axis, and the left-to-right direction of the human torso as the Y-axis. In some embodiments, the specific coordinate system is related to the orientation of the user during the calibration process. For example, if the user's body is facing a fixed direction (e.g., north) during the calibration process, the direction in front of the body (north) is the X-axis.</p>
<p id="p-0160" num="0159">Step <b>1320</b>, obtaining the first coordinate information in the at least one original coordinate system when the user is in a first pose.</p>
<p id="p-0161" num="0160">In some embodiments, the step may be performed by the obtaining module <b>210</b>. The first pose may be a pose that the user approximately remains standing. The obtaining module <b>210</b> (e.g., the sensor) may obtain the first coordinate information in the original coordinate system based on the user's first pose.</p>
<p id="p-0162" num="0161">Step <b>1330</b>, obtaining the second coordinate information in the at least one original coordinate system when the user is in a second pose.</p>
<p id="p-0163" num="0162">In some embodiments, the step may be performed by the obtaining module <b>210</b>. The second pose may be a pose that the user's body part (e.g., arm) where the sensor is located is tilted forward. In some embodiments, the obtaining module <b>210</b> (e.g., the sensor) may obtain the second coordinate information in the original coordinate system based on the user's second pose (e.g., a forward leaning pose).</p>
<p id="p-0164" num="0163">Step <b>1340</b>, determining, according to the first coordinate information, the second coordinate information, and the specific coordinate system, the relationship between the at least one original coordinate system and the specific coordinate system.</p>
<p id="p-0165" num="0164">In some embodiments, the step may be performed by the processing module <b>220</b> and/or processing device <b>110</b>. In some embodiments, the first rotation matrix may be determined through the first coordinate information corresponding to the first pose. In the first pose, since the Euler angle in a X and Y direction of the specific coordinate system in a ZYX rotation order are 0, and the Euler angle in the X and Y direction of the original coordinate system is not necessarily 0, then the first rotation matrix is the rotation matrix obtained by reversing the original coordinate system around the X-axis and then around the Y-axis. In some embodiments, the second rotation matrix may be determined through the second coordinate information of the second pose (e.g., the body part where the sensor is located is tilted forward). Specifically, in the second pose, it is known that the Euler angle of the specific coordinate system in a Y and Z<sub>3 </sub>direction is 0 under the ZYZ rotation order, and the Euler angle of the original coordinate system in a Y and Z<sub>3 </sub>direction is not necessarily 0, then the second rotation matrix is the rotation matrix obtained by reversing the original coordinate system around the Y direction and then around the Z<sub>3 </sub>direction. The conversion relationship between the original coordinate system and the specific coordinate system may be determined through the above first rotation matrix and second rotation matrix. In some embodiments, when there are a plurality of original coordinate systems (sensors), the above method may be configured to determine the conversion relationship between each original coordinate system and the specific coordinate system.</p>
<p id="p-0166" num="0165">It should be noted that the above first pose is not limited to an approximately standing pose, and the second pose is not limited to the pose that the user's body part (e.g., arm) where the sensor is located is tilted forward, the first and second poses herein may be approximated as being stationary during the calibration process. In some embodiments, the first pose and/or the second pose may also be a dynamic pose during the calibration process. For example, the user's walking attitude is a relatively fixed attitude, the angle and angular velocity of the arms, legs and feet during walking can be extracted to recognize the movement, such as forward stride, forward arm swing and the like, and the user's forward walking attitude can be used as the second pose in the calibration process. In some embodiments, the second pose is not limited to one movement, but a plurality of movements can also be extracted as the second pose. For example, the coordinate information of a plurality of movements may be fused to obtain a more accurate rotation matrix.</p>
<p id="p-0167" num="0166">In some embodiments, the rotation matrix may be dynamically corrected during the calibration process by using some signal processing algorithms (e.g., using Kalman filtering algorithm) to obtain a better transformation matrix throughout the calibration process.</p>
<p id="p-0168" num="0167">In some embodiments, machine learning algorithms, or other algorithms may be configured for automatic recognition of some specific movements to update the rotation matrix in real time. For example, if the machine learning algorithm recognizes that a current user is walking, or standing, the calibration process is automatically started. In this case, the wearable device does not need an explicit calibration process anymore, and the rotation matrix is dynamically updated when the user uses the wearable device.</p>
<p id="p-0169" num="0168">In some embodiments, the installation position of the attitude sensor may be relatively fixed and a rotation matrix may be preset, which can make the recognition process of the specific movement more accurate. Further, the rotation matrix continues to be corrected as the user using the wearable device, so that an obtained rotation matrix is closer to the real situation.</p>
<p id="p-0170" num="0169">It should be noted that the above description of the process <b>1300</b> is for example and illustration purposes only, and does not limit the scope of application of the present disclosure. For those skilled in the art, various amendments and changes can be made to process <b>1300</b> under the guidance of the present disclosure. However, these amendments and changes remain within the scope of the present disclosure.</p>
<p id="p-0171" num="0170"><figref idref="DRAWINGS">FIG. <b>14</b></figref> is a flowchart of an exemplary process for determining a conversion relationship between an original coordinate system and a target coordinate system according to some embodiments of the present disclosure. As shown in <figref idref="DRAWINGS">FIG. <b>14</b></figref>, the process <b>1400</b> may include:</p>
<p id="p-0172" num="0171">Step <b>1410</b>, obtaining the conversion relationship between the specific coordinate system and the target coordinate system.</p>
<p id="p-0173" num="0172">In some embodiments, the step may be performed by the processing module <b>220</b> and/or the processing device <b>110</b>. Both the specific coordinate system and the target coordinate system take the length direction of the human torso as the Z-axis, so that through the conversion relationship between the X-axis of the specific coordinate system and the X-axis of the target coordinate system and the conversion relationship between the Y-axis of the specific coordinate system and the Y-axis of the target coordinate system, the conversion relationship between the specific coordinate relationship and the target coordinate system can be obtained. The principle of obtaining the conversion relationship between the specific coordinate relationship and the target coordinate system may be found in <figref idref="DRAWINGS">FIG. <b>13</b></figref> and its relevant descriptions.</p>
<p id="p-0174" num="0173">In some embodiments, the specific coordinate system may take the length direction of the human torso as the Z-axis and a front-to-back direction of the human body as a calibrated X-axis. Since the front-to-back direction of the user's body changes during motion (e.g., a turning movement) and cannot be fixed in the calibrated coordinate system, it is necessary to determine the coordinate system that can rotate with the body, i.e., the target coordinate system. In some embodiments, the target coordinate system may change as the user's orientation changes, with the X-axis of the target coordinate system always being directly in front of the human torso.</p>
<p id="p-0175" num="0174">Step <b>1420</b>, determining, according to the conversion relationship between the at least one original coordinate system and the specific coordinate system, and the conversion relationship between the specific coordinate system and the target coordinate system, the conversion relationship between the at least one original coordinate system and the target coordinate system.</p>
<p id="p-0176" num="0175">In some embodiments, the step may be performed by the processing module <b>220</b> and/or the processing device <b>110</b>. In some embodiments, the processing device <b>110</b> may determine the conversion relationship between the at least one original coordinate system and the target coordinate system according to the conversion relationship between the at least one original coordinate system and the specific coordinate system determined in the process <b>1300</b> and the conversion relationship between the specific coordinate system and the target coordinate system determined in step <b>1410</b>, such that the coordinate information in the original coordinate system may be converted to the target coordinate information in the target coordinate system.</p>
<p id="p-0177" num="0176">It should be noted that the above description of the process <b>1400</b> is for example and illustration purposes only and does not limit the scope of application of the present disclosure. For those skilled in the art, various amendments and changes can be made to the process <b>1400</b> under the guidance of the present disclosure. However, these amendments and changes remain within the scope of the present disclosure.</p>
<p id="p-0178" num="0177">In some embodiments, the position of the attitude sensors set on the wearable device <b>130</b> may change and/or the attitude sensors may be installed at different angles on the human body, so that the user performs the same motion, the attitude data returned by the attitude sensors may have a relatively big difference.</p>
<p id="p-0179" num="0178"><figref idref="DRAWINGS">FIG. <b>15</b>A</figref> is an exemplary vector coordinate diagram illustrating Euler angle data in an original coordinate system at a position of a small arm of a human body according to some embodiments of the present disclosure. A boxed part may represent the Euler angle data (the coordinate information) in the original coordinate system corresponding to the position of the small arm at the time the user does the same movement. As shown in <figref idref="DRAWINGS">FIG. <b>15</b>A</figref>, the results of the Euler angle vector in the Z-axis direction (shown as “Z” in <figref idref="DRAWINGS">FIG. <b>15</b>A</figref>) in the boxed part are approximately in the range of −180° to (−80°). The results of the Euler angle vector in the Y-axis direction (shown as “Y” in <figref idref="DRAWINGS">FIG. <b>15</b>A</figref>) fluctuate approximately around 0°, and the results of the Euler angle vector in the X-axis direction (shown as “X” in <figref idref="DRAWINGS">FIG. <b>15</b>A</figref>) fluctuate approximately around −80°. A fluctuation range here may be 20°.</p>
<p id="p-0180" num="0179"><figref idref="DRAWINGS">FIG. <b>15</b>B</figref> is an exemplary vector coordinate diagram illustrating Euler angle data in another original coordinate system at a position of a small arm of a human body according to some embodiments of the present disclosure. The boxed part may represent the Euler angle data in the original coordinate system corresponding to the other position of the small arm when the user performs the same movement (the same movement as shown in <figref idref="DRAWINGS">FIG. <b>15</b>A</figref>). As shown in <figref idref="DRAWINGS">FIG. <b>15</b>B</figref>, the results of the Euler angle vector in the Z-axis direction (shown as “Z′” in <figref idref="DRAWINGS">FIG. <b>15</b>B</figref>) in the boxed section are approximately in a range of −180° to 180°. The results of the Euler angle vector in the Y-axis direction (shown as “Y′” in <figref idref="DRAWINGS">FIG. <b>15</b>B</figref>) fluctuate approximately around 0°. And the results of the Euler angle vector in the X-axis direction (shown as “X′” in <figref idref="DRAWINGS">FIG. <b>15</b>B</figref>) fluctuate approximately around −150°. The fluctuation range here may be 20°.</p>
<p id="p-0181" num="0180">The Euler angle data shown in <figref idref="DRAWINGS">FIG. <b>15</b>A</figref> and <figref idref="DRAWINGS">FIG. <b>15</b>B</figref> are the Euler angle data (coordinate information) respectively obtained in the original coordinate system when the user performs the same movement at different positions of the human small arm (which can also be interpreted as different installation angles of the attitude sensor at the human small arm position). Comparing <figref idref="DRAWINGS">FIG. <b>15</b>A</figref> with <figref idref="DRAWINGS">FIG. <b>15</b>B</figref>, it can be seen that the when the user does the same movement, the angles at which the attitude sensor is installed on the human body are different, causing difference in the Euler angle data in the original coordinate system returned by the attitude sensor. For example, the results of the Euler angle vector in the Z-axis direction in <figref idref="DRAWINGS">FIG. <b>15</b>A</figref> are approximately in the range of −180°-(−80°), and the results of the Euler angle vector in the Z-axis direction in <figref idref="DRAWINGS">FIG. <b>15</b>B</figref> are approximately in the range of −180°-180°, which are quite different from each other.</p>
<p id="p-0182" num="0181">In some embodiments, the Euler angle data in the original coordinate system corresponding to sensors with different installation angles may be converted to the Euler angle data in the target coordinate system, thereby facilitating analysis of the attitude signal of the sensors at different positions. Merely as way of exemplary illustration, a line where the left arm is located can be abstracted as a unit vector pointing from the elbow to the wrist, which is a coordinate value in the target coordinate system. The target coordinate system here includes the axis pointing to the rear of the body as the X-axis, the axis pointing to the right side of the body as the Y-axis, and the axis pointing to the top of the body as the Z-axis, which conforms to the right-handed coordinate system. For example, a coordinate value [−1, 0, 0] in the target coordinate system indicates that the arm is held forward flat. A coordinate value [0, −1, 0] of the target coordinate system indicates that the arm is held flat to the left. <figref idref="DRAWINGS">FIG. <b>16</b>A</figref> is a curve obtained based on the vector coordinates in the target coordinate system converted from the Euler angle data of the small arm in the original coordinates in <figref idref="DRAWINGS">FIG. <b>15</b>A</figref>. The boxed portion can represent the Euler angle data in the target coordinate system at the position of the small arm when the user performs the movement. As shown in <figref idref="DRAWINGS">FIG. <b>16</b>A</figref>, a small arm vector [x, y, z] in the boxed portion moves reciprocally between the first position and the second position, where a first position is [0.2, −0.9, −0.38] and the second position is [0.1, −0.95, −0.3]. It should be noted that for each reciprocal movement of the small arm, there will be a small deviation between the first position and the second position.</p>
<p id="p-0183" num="0182"><figref idref="DRAWINGS">FIG. <b>16</b>B</figref> is an exemplary vector coordinate diagram of Euler angle data in a target coordinate system at another location of a small arm of a human body according to some embodiments of the present disclosure. <figref idref="DRAWINGS">FIG. <b>16</b>B</figref> is a curve obtained based on the vector coordinates in the target coordinate system converted from Euler angle data of the small arm in the original coordinates in <figref idref="DRAWINGS">FIG. <b>15</b>B</figref>. The boxed part may represent the Euler angle data in the target coordinate system at another location of the small arm when the user performs the same movement (the same movement as the movement shown in <figref idref="DRAWINGS">FIG. <b>16</b>A</figref>). As shown in <figref idref="DRAWINGS">FIG. <b>16</b>B</figref>, a small arm vector [x, y, z] similarly reciprocates between the first position and the second position, where a first position is [0.2, −0.9, −0.38] and a second position is [0.1, −0.95, −0.3].</p>
<p id="p-0184" num="0183">Combining <figref idref="DRAWINGS">FIG. <b>15</b>A</figref> to <figref idref="DRAWINGS">FIG. <b>16</b>B</figref>, it can be seen from <figref idref="DRAWINGS">FIGS. <b>15</b>A and <b>15</b>B</figref> that the Euler angles in the original coordinate system have a great difference in the range of values and fluctuation forms due to the different installation positions of the two attitude sensors. After converting the coordinate information of the original coordinate system corresponding to the two attitude sensors to the vector coordinates corresponding to the target coordinate system (e.g., the vector coordinates in <figref idref="DRAWINGS">FIGS. <b>16</b>A and <b>16</b>B</figref>) respectively, two approximately same vector coordinates may be obtained. That is to say, the method may ensure the feature information corresponding to the attitude signal to be independent of the sensor installation position. Specifically, in <figref idref="DRAWINGS">FIG. <b>16</b>A</figref> and <figref idref="DRAWINGS">FIG. <b>16</b>B</figref>, it can be seen that the two attitude sensors are installed in different positions on the small arm, and after the above coordinate conversion, the same vector coordinates are obtained, i.e., during the process of the seated chest press, they can represent the process of switching back and forth between the two states, state <b>1</b> (arm held flat to the right) and state <b>2</b> (arm held flat to the front).</p>
<p id="p-0185" num="0184"><figref idref="DRAWINGS">FIG. <b>17</b></figref> is an exemplary vector coordinate diagram of a limb vector in a target coordinate system according to some embodiments of the present disclosure. As shown in <figref idref="DRAWINGS">FIG. <b>17</b></figref>, the vector coordinates of the attitude sensors in the target coordinate system at the positions of the left small arm (<b>17</b>-<b>1</b>), right small arm (<b>17</b>-<b>2</b>), left large arm (<b>17</b>-<b>3</b>), right large arm (<b>17</b>-<b>4</b>), and torso (<b>17</b>-<b>5</b>) of the human body can be represented from top to bottom, respectively. The vector coordinates of each position (e.g., <b>17</b>-<b>1</b>, <b>17</b>-<b>2</b>, <b>17</b>-<b>3</b>, <b>17</b>-<b>4</b>, <b>17</b>-<b>5</b>) in the target coordinate system of human during motion are illustrated in <figref idref="DRAWINGS">FIG. <b>17</b></figref>. The first <b>4200</b> points in <figref idref="DRAWINGS">FIG. <b>17</b></figref> correspond to the calibration movements needed to calibrate the limbs, such as standing, torso forward, arm forward, arm side planks, etc. To use the first <b>4200</b> points corresponding to the calibration movements to calibrate, raw data collected by the attitude sensors may be converted to the Euler angles in the target coordinate system. To facilitate performing analysis on the data, the coordinate vector of the arm vector in the target coordinate system may be further converted. The target coordinate system here is pointing to the front of the torso as the X-axis, to the left of the torso as the Y-axis, and to the top of the torso as the Z-axis. The reciprocal movements in <figref idref="DRAWINGS">FIG. <b>17</b></figref> are, from left to right, movement <b>1</b>, movement <b>2</b>, movement <b>3</b>, movement <b>4</b>, movement <b>5</b>, and movement <b>6</b>: seated chest press, high pull-down, seated chest thrust, seated shoulder thrust, barbell dip head curl, and seated chest press, respectively. As can be seen in <figref idref="DRAWINGS">FIG. <b>17</b></figref>, different movements have different movement patterns, which can be clearly recognized by using the limb vectors. At the same time, the same movement also has good repeatability, for example, the movement <b>1</b> and the movement <b>6</b> both represent the seated chest press, and the curves of these two movements have the good repeatability.</p>
<p id="p-0186" num="0185">In some embodiments, the attitude data (e.g., the Euler angles, the angular velocities, etc.) directly output in the original coordinate system may be converted to the attitude data in the target coordinate system by the processes <b>1300</b> and <b>1400</b>, so that highly consistent attitude data (e.g., Euler angles, angular velocities, limb vector coordinates, etc.) can be obtained.</p>
<p id="p-0187" num="0186"><figref idref="DRAWINGS">FIG. <b>18</b>A</figref> is a diagram illustrating an exemplary coordinate vector of an original angular velocity according to some embodiments of the present disclosure. The original angular velocity may be understood as the conversion of the Euler angle data in the original coordinate systems corresponding to the sensors with different installation angles to the Euler angle data in the target coordinate system. In some embodiments, factors such as jitter during user movement may affect the results of the angular velocity in the attitude data. As shown in <figref idref="DRAWINGS">FIG. <b>18</b>A</figref>, the original angular velocity shows a more obvious unsmooth curve in its vector coordinate curve under an influence of jitter, etc. For example, a presence of an abrupt signal in the vector coordinate curve of the original angular velocity makes the vector coordinate curve of the original angular velocity unsmooth. In some embodiments, a jittered angular velocity needs to be corrected to obtain a smooth vector coordinate curve because of an effect of jitter, etc. on the angular velocity results. In some embodiments, the original angular velocity may be filtered by using a 1 Hz-3 Hz low-pass filtering method. <figref idref="DRAWINGS">FIG. <b>18</b>B</figref> is an exemplary diagram illustrating results of an angular velocity after filtering processing according to some embodiments of the present disclosure. As shown in <figref idref="DRAWINGS">FIG. <b>18</b>B</figref>, performing a low-pass filtering from 1 Hz to 3 Hz on the original angular velocity may eliminate the effect of jitter and other effects on the angular velocity (e.g., abrupt signals), so that the vector coordinate curve corresponding to the angular velocity is displayed smoother. In some embodiments, performing the low-pass filtering from 1 Hz to 3 Hz on the angular velocity may effectively prevent the effects of jitter, etc. on the attitude data (e.g., the Euler angles, the angular velocity, etc.), which makes it easier to follow the process of segmenting the signal. In some embodiments, the filtering process may also filter out an industrial frequency signal and its harmonic wave signal, burr signal, etc. from the movement signal. It should be noted that low-pass filtering at 1 Hz-3 Hz introduces time delay, which makes a movement point of the attitude signal and a movement point of a real electromyographic signal misaligned in time. Therefore, the time delay generated during the low-pass filtering process is subtracted from the vector coordinate curve after the low-pass filtering processing to ensure synchronization of the attitude signal and the electromyographic signal in time. In some embodiments, the time delay is associated with a center frequency of the filter, and when the attitude signal and the electromyographic signal are processed with different filters, and the time delay is adapted according to the center frequency of the filter. In some embodiments, since the angular range of the Euler angle is [−180°, +180° ], an obtained Euler angle may have a change of −180° to +180° or +180° to −180° when an actual Euler angle is not in this angular range. For example, when the angle is −181°, the Euler angle changes to 179°. In the practical application the angle change can affect the calculation of the angle difference, and it is necessary to correct the angle change first.</p>
<p id="p-0188" num="0187">In some embodiments, a movement recognition model may also be configured to analyze the user's movement signal or the feature information corresponding to the movement signal to recognize the user's movement. In some embodiments, the movement recognition model includes a trained machine learning model configured to recognize the user's movement. In some embodiments, the movement recognition model may include one or more machine learning models. In some embodiments, the movement recognition model may include, but is not limited to, one or more of a machine learning model that classifies the user's movement signal, a machine learning model that recognizes the movement quality of the user, a machine learning model that recognizes the number of the user's movements, and a machine learning model that recognizes a fatigue index of the user performing the movement. In some embodiments, the machine learning model may include one or more of a linear classification model (LR), a support vector machine model (SVM), a plain Bayesian model (NB), a K-nearest neighbor model (KNN), a decision tree model (DT), ae random forest/a gradient boosting decision tree (RF/GDBT, etc.), etc. More descriptions regarding the movement recognition model may be found elsewhere in the present disclosure, such as <figref idref="DRAWINGS">FIG. <b>20</b></figref> and its relevant descriptions.</p>
<p id="p-0189" num="0188"><figref idref="DRAWINGS">FIG. <b>19</b></figref> is a flowchart illustrating an exemplary motion monitoring and feedback method according to some embodiments of the present disclosure. As shown in <figref idref="DRAWINGS">FIG. <b>19</b></figref>, the process <b>1900</b> may include:</p>
<p id="p-0190" num="0189">Step <b>1910</b>, obtaining the movement signal of the user during motion.</p>
<p id="p-0191" num="0190">In some embodiments, the step may be performed by the obtaining module <b>210</b>. In some embodiments, the movement signal includes at least the feature information corresponding to the electromyographic signal and the feature information corresponding to the attitude signal. The movement signal refers to human body parameter information of the user during motion. In some embodiments, the human body parameter information may include, but is not limited to, one or more of the electromyographic signals, the attitude signals, the heart rate signals, the temperature signals, the humidity signals, the blood oxygen concentration, etc. In some embodiments, the movement signal may include at least the electromyographic signal and the attitude signal. In some embodiments, the electromyographic sensor in the obtaining module <b>210</b> may collect the electromyographic signal of the user during motion, and the attitude sensor in the obtaining module <b>210</b> may collect the attitude signal of the user during motion.</p>
<p id="p-0192" num="0191">Step <b>1920</b>, monitoring, based on the movement signal, the user's movement during motion through the movement recognition model, and giving, based on the output of the movement recognition model, the movement feedback.</p>
<p id="p-0193" num="0192">In some embodiments, the step may be performed by the processing module <b>220</b> and/or the processing device <b>110</b>. In some embodiments, the output of the movement recognition model may include, but is not limited to, one or more of the movement type, the movement quality, the number of movements, a fatigue index, etc. For example, the movement recognition model may recognize the user's movement type as the seated chest press based on the movement signal. For another example, one machine learning model of the movement recognition model may first recognize the user's movement type as the seated chest press based on the movement signal, and another machine learning model of the movement recognition model may output the movement quality of the user's movement as a standard movement or an incorrect movement according to the movement signal (e.g., amplitude information of the electromyographic signal, the frequency information, and/or the angular velocity, the angular velocity direction, and the acceleration value of angular velocity of the attitude signal). In some embodiments, the movement feedback may include sending the prompt message. In some embodiments, the prompt message may include, but is not limited to, the voice prompt, the message prompt, the image prompt, the video prompt, etc. For example, if the output result of the movement recognition model is the incorrect movement, the processing device <b>110</b> may control the wearable device <b>130</b> or the mobile terminal device <b>140</b> to send a voice prompt (e.g., a message such as “nonstandard movement”) to the user to remind the user to adjust the fitness movement in a timely manner. For another example, if the output of the movement recognition model is the standard movement, the wearable device <b>130</b> or the mobile terminal device <b>140</b> may not send a prompt message, or send a prompt message like “standard movement”. In some embodiments, the motion feedback may also include the wearable device <b>130</b> stimulating the corresponding movement part of the user. For example, the components of the wearable device <b>130</b> stimulate the corresponding parts of the user's movements through a vibration feedback, an electrical stimulation feedback, a pressure feedback, etc. For example, the output results of the movement recognition model are the incorrect movement, and the processing device <b>110</b> may control the components of the wearable device <b>130</b> to stimulate the corresponding parts of the user's movement. In some embodiments, the movement feedback may also include outputting a motion record of the user during motion. The motion record here may refer to one or more of the user's movement type, exercise duration, number of movements, movement quality, fatigue index, physiological parameter information during motion, etc. Descriptions regarding the movement recognition model may be found elsewhere in the present disclosure and will not be repeated herein.</p>
<p id="p-0194" num="0193">It should be noted that the above description of the process <b>1900</b> is for example and illustration purposes only and does not limit the scope of application of the present disclosure. For those skilled in the art, various amendments and changes can be made to process <b>1900</b> under the guidance of the present disclosure. However, these amendments and changes remain within the scope of the present disclosure.</p>
<p id="p-0195" num="0194"><figref idref="DRAWINGS">FIG. <b>20</b></figref> is a flowchart illustrating an exemplary process for model training according to some embodiments of the present disclosure.</p>
<p id="p-0196" num="0195">In step <b>2010</b>, obtaining the sample information.</p>
<p id="p-0197" num="0196">In some embodiments, the step may be performed by the obtaining module <b>210</b>. In some embodiments, the sample information may include the movement signal of professionals (e.g., fitness trainers) and/or non-professionals during motion. For example, the sample information may include the electromyographic signals and/or the attitude signals generated by the professionals and/or the non-professionals while performing the same movement type (e.g., the seated chest press). In some embodiments, the electromyographic signal and/or attitude signal in the sample information may undergo the segmentation processing of the process <b>700</b>, the burr processing of the process <b>900</b>, and the conversion processing of the process <b>1300</b>, etc., to form at least one segment of the electromyographic signal and/or the attitude signal. The at least one segment of the electromyographic signal and/or the attitude signal may be used as the input of the machine learning model to train the machine learning model. In some embodiments, the feature information corresponding to the at least one segment of the electromyographic signal and/or the feature information corresponding to the attitude signal may also be used as the input of the machine learning model to train the machine learning model. For example, the frequency information and the amplitude information of the electromyographic signal can be used as the input of the machine learning model. For another example, the angular velocity of the attitude signal and the angular velocity direction/the acceleration value of the angular velocity can be used as the input of the machine learning model. For another example, the movement start point, the movement middle point and the movement end point signal can be used as the inputs to the machine learning model. In some embodiments, the sample information may be obtained from the storage device of the processing device <b>110</b>. In some embodiments, the sample information may be obtained from the obtaining module <b>210</b>.</p>
<p id="p-0198" num="0197">In step <b>2020</b>, training the movement recognition model.</p>
<p id="p-0199" num="0198">The step may be performed by the processing device <b>110</b>. In some embodiments, the movement recognition model may include one or more machine learning models. For example, the movement recognition model may include, but is not limited to, one or more of the machine learning model that classifies the user's movement signal, the machine learning model that recognizes the movement quality of the user, the machine learning model that recognizes the number of user's movement, and the machine learning model that recognizes the fatigue level of the user performing the movement. In some embodiments, the machine learning model may include one or more of the linear classification model (LR), the support vector machine model (SVM), the Native Bayesian model (NB), the K-nearest neighbor model (KNN), the decision tree model (DT), the random forest/the gradient boosting decision tree (RF/GDBT, etc.), etc.</p>
<p id="p-0200" num="0199">In some embodiments, training of the machine learning model may include obtaining the sample information. In some embodiments, the sample information may include the movement signal of the professionals (e.g., fitness trainers) and/or non-professionals during motion. For example, the sample information may include electromyographic signal and/or postural signal generated by professionals and/or the non-professionals while performing the same movement type (e.g., the seated chest press). In some embodiments, the electromyographic signal and/or the attitude signal in the sample information may undergo the segmentation processing of the process <b>700</b>, the burr processing of the process <b>900</b>, and the conversion processing of the process <b>1300</b>, etc., to generate at least one segment of the electromyographic signal and/or the attitude signal. The at least one segment of the electromyographic signal and/or the attitude signal may be used as the input to the machine learning model to train the machine learning model. In some embodiments, the feature information corresponding to the at least one segment of the electromyographic signal and/or the feature information corresponding to the attitude signal may also be used as the input of the machine learning model to train the machine learning model. For example, the frequency information and the amplitude information of the electromyographic signal can be used as the input of the machine learning model. For another example, the angular velocity of the attitude signal and the angular velocity direction/acceleration value of the velocity angle can be used as the input of the machine learning model. For another example, the signal corresponding to the movement start point, the movement middle point, and/or the movement end point signal (including the electromyographic signal and/or the attitude signal) can be used as the input of the machine learning model.</p>
<p id="p-0201" num="0200">In some embodiments, when training a machine learning model for recognizing the user's movement type, the sample information from the different movement types (per segment of the electromyographic signal or/and the attitude signal) may be labelled and processed. For example, the sample information from the electromyographic signal and/or the attitude signal generated by the user performing a seated chest press may be marked as “1”, where “1” is configured to represent the “seated chest press”. The sample information from the electromyographic signal and/or the attitude signal generated when the user performs the bicep lifting maybe marked as “2”, where “2” is configured to represent the “bicep lifting”. The different movement types correspond to the different feature information (e.g., the frequency information, the amplitude information) of electromyographic signals, and feature information (e.g., angular velocity, angular velocity direction, angular velocity value of angular velocity) of attitude signals. Labeled sample information (e.g., feature information corresponding to electromyographic signal and/or attitude signal in the sample information) is used as the input of the machine learning model to train the machine learning model, so that the movement recognition model configured to recognize the user's movement type may be obtained, and by inputting the movement signal in the machine learning model, a corresponding movement type may be output.</p>
<p id="p-0202" num="0201">In some embodiments, the movement recognition model may further include the machine learning model for determining the quality of the user's movement. The sample information here may include both the standard movement signal (also known as a positive sample) and a non-standard movement signal (also known as negative samples). The standard movement signal may include the movement signal generated by the professional performing the standard movement. For example, the movement signal generated by a professional performing the standard seated chest press is the standard movement signal. The non-standard movement signal may include the movement signal generated by the user performing the non-standard movement (e.g., an incorrect movement). In some embodiments, the electromyographic signal and/or the attitude signal in the sample information may undergo the segmentation processing of the process <b>700</b>, the burr processing of the process <b>900</b>, and the conversion processing of the process <b>1300</b>, etc., to generate at least one segment of the electromyographic signal and/or the attitude signal. The at least one segment of the electromyographic signal and/or the attitude signal may be used as the input of the machine learning model to train the machine learning model. In some embodiments, the positive and negative samples of the sample information (per segment of the electromyographic signal or/the attitude signal) may be tagged. For example, a positive sample is marked as “1” and a negative sample is marked as “0”. The “1” here is configured to represent the user's movement as a standard movement, and the “0” here is configured to represent the user's movement as a wrong movement. The trained machine learning model may output different labels based on the input sample information (e.g., the positive sample, the negative sample). It should be noted that the movement recognition model may include one or more machine learning models for analyzing and recognizing the quality of the user movement, and different machine learning models may analyze and recognize the sample information from the different movement types, respectively.</p>
<p id="p-0203" num="0202">In some embodiments, the movement recognition model may also include a model that recognizes the number of movements of the user's fitness motion. For example, the movement signal (e.g., the electromyographic signal and/or the attitude signal) in the sample information is segmented by the process <b>700</b> to obtain at least one set of a movement start point, a movement middle point, and a movement end point, and each set of the movement start point, the movement middle point, and the movement end point is marked, for example, the movement start point is marked as 1, the movement middle point is marked as 2, and the movement end point is marked as 3, and the marks are used as the input to the machine learning model, and a set of consecutive “1”, “2” and “3” are input to the machine learning model to output one movement. For example, three consecutive sets of “1”, “2”, and “3” are input into a machine learning model to output three movements.</p>
<p id="p-0204" num="0203">In some embodiments, the movement recognition model may also include a machine learning model for identifying a user's fatigue index. The sample information here may also include signals of other physiological parameters such as the electro-cardio signals, the respiratory rates, the temperature signals, the humidity signals, etc. For example, different frequency ranges of the electro-cardio signal can be used as the input data for the machine learning model, with electro-cardio signal in the range of 60 beats/min-100 beats/min marked as “1” (normal) and less than 60 beats/min or more than 100 beats/min marked as “2” (abnormal). In some embodiments, a further segmentation can be performed and different indices can be labeled as the input data based on the user's electro-cardio signal frequency, and the trained machine learning model can output a corresponding fatigue index according to the frequency of the electro-cardio signal. In some embodiments, the machine learning model may also be trained in conjunction with the physiological parameter signal such as the respiratory rate and the temperature signal. In some embodiments, the sample information may be obtained from the storage device of processing device <b>110</b>. In some embodiments, the sample information may be obtained from the obtaining module <b>210</b>. It should be noted that the movement recognition model can be any one of the above machine learning models or a combination of a plurality of above machine learning models, or include other machine learning models, which can be selected according to the actual situation. In addition, a training input to the machine learning model is not limited to one segment (one cycle) of the movement signal, but can also be part of a segment of the movement signal, or a plurality of segments of the movement signal, etc.</p>
<p id="p-0205" num="0204">Step <b>2030</b>, extracting the movement recognition model.</p>
<p id="p-0206" num="0205">In some embodiments, the step may be performed by the processing device <b>110</b>. In some embodiments, the processing device <b>110</b> and/or the processing module <b>220</b> may extract the movement recognition model. In some embodiments, the movement recognition model may be stored to the processing device <b>110</b>, the processing module <b>220</b>, or the mobile terminal.</p>
<p id="p-0207" num="0206">Step <b>2040</b>, obtaining the user's movement signal.</p>
<p id="p-0208" num="0207">In some embodiments, the step may be performed by the obtaining module <b>210</b>. For example, in some embodiments, the electromyographic sensor in the obtaining module <b>210</b> may obtain the electromyographic signal of the user, and the attitude sensor in the obtaining module <b>210</b> may obtain the attitude signal of the user. In some embodiments, the user movement signal may also include other physiological parameter signals such as the electro-cardio signal, the respiration signal, the temperature signal, the humidity signal, etc. of the user during motion. In some embodiments, the obtained movement signal (e.g., the electromyographic signal and/or the attitude signal) may be subjected to the segmentation processing of the process <b>700</b>, the burr processing of process the <b>900</b>, and the conversion processing of the process <b>1300</b>, etc., to form at least one segment of the electromyographic signal and/or the attitude signal.</p>
<p id="p-0209" num="0208">Step <b>2050</b>, judging, based on the user's movement signal, the movement through the movement recognition model.</p>
<p id="p-0210" num="0209">The step may be performed by the processing device <b>110</b> and/or the processing module <b>220</b>. In some embodiments, the processing device <b>110</b> and/or the processing module <b>220</b> may determine the user movement based on the movement recognition model. In some embodiments, the trained movement recognition model may include one or more machine learning models. In some embodiments, the movement recognition model may include, but is not limited to, one or more of the machine learning model that classifies the user's movement signal, the machine learning model that recognizes the movement of the user, the machine learning model that recognizes the number of user's movement, and the machine learning model that recognizes the fatigue index of the user performing the movements. The different machine learning models may have different recognition effects. For example, a machine learning model for classifying the movement signal may use the user's movement signal as input data and output the corresponding movement type. For example, a machine learning model that recognizes the quality of the user's movement can use the user's movement signal as input data and output the movement quality (e.g., standard movement, wrong movement). For example, the machine learning model that recognizes the fatigue index of a user performing a movement can use the user's movement signal (e.g., the electro-cardio signal frequency) as the input data and output the user's fatigue index. In some embodiments, the user's movement signal and the judgment results (output) of the machine learning model may also be used as the sample information of training the movement recognition model to optimize relevant parameters of the movement recognition model. It should be noted that the movement recognition model is not limited to the trained machine learning model described above, but can also be a preset model, e.g., a manually predefined conditional judgment algorithm or add an artificially added parameter (e.g., confidence level) to the trained machine learning model, etc.</p>
<p id="p-0211" num="0210">Step <b>2060</b>, providing, based on the judgment results, feedback for the user's movement.</p>
<p id="p-0212" num="0211">In some embodiments, the step may be performed by the wearable device <b>130</b> and/or the mobile terminal device <b>140</b>. Further, the processing device <b>110</b> and/or the processing module <b>220</b> sends a feedback instruction to the wearable device <b>130</b> and/or the mobile terminal device <b>140</b> based on the judgment results of the user's movement, and the wearable device <b>130</b> and/or the mobile terminal device <b>140</b> provides the feedback to the user based on the feedback instruction. In some embodiments, the feedback may include sending prompt messages (e.g., text information, picture information, video information, voice information, indicator information, etc.) and/or stimulating the user's body when performing the movement (in a form of electrical stimulation, vibration, pressure changes, heat change, etc.). For example, when a user performs a sit-up movement, the user's movement signal is monitored and it is determined that the user is exerting too much force on the oblique muscles during motion (i.e., a user's head and neck movement are not standard), in which case the input/output module <b>260</b> (e.g., a vibration prompter) in the wearable device <b>130</b> and the mobile terminal device <b>140</b> (e.g., a smartwatch, smartphone etc.) provide a corresponding feedback (e.g., perform the vibration on the user's body part, send the voice prompt, etc.) to prompt the user to adjust the force-exerting part of body in time. In some embodiments, during the user's movement, by monitoring the movement signal during the user's movement and determining the movement type, the movement quality, and the number of the user's movements during motion, the mobile terminal device <b>140</b> can output the corresponding movement record so that the user can understand its motion situation during motion.</p>
<p id="p-0213" num="0212">In some embodiments, when the feedback is given to the user, the feedback may be matched to user perception. For example, if the user's movement is not standard, the user can know that the movement is not standard based on the vibration stimulation in the area corresponding to the user's movement, and the vibration stimulation is in an acceptable range of the user. Further, a matching model may be constructed based on user's movement signal and the user perception to find the best balance between the user perception and a real feedback.</p>
<p id="p-0214" num="0213">In some embodiments, the movement recognition model may further be trained based on the user's movement signals. In some embodiments, training the movement recognition model according to the user's movement signal may include evaluating the user's movement signal to determine a confidence level of the user's movement signal. The confidence level may indicate the quality of the user's movement signal. For example, the higher the confidence level, the better the quality of the user's movement signal. In some embodiments, evaluation of the user's movement signal may be performed at the stages of the movement signal obtaining, pre-processing, segmentation, and/or recognition.</p>
<p id="p-0215" num="0214">In some embodiments, training the movement recognition model according to the user's movement signal may further include determining whether the confidence level is greater than a confidence level threshold (e.g., <b>80</b>), and if the confidence level is greater than or equal to the confidence level threshold, the movement recognition model is trained by using the user's movement signal corresponding to that confidence level as sample data. If the confidence level is less than the confidence level threshold, the user's movement signal corresponding to the confidence level is not used as sample data to train the movement recognition model. In some embodiments, the confidence level may include, but is not limited to, a confidence level at any of the stages of the movement signal obtaining, the movement signal pre-processing, movement signal segmentation, or the movement signal recognition. For example, the confidence level of the movement signal collected by the obtaining module <b>210</b> is used as a judgment criterion. In some embodiments, the confidence level may further be a combined confidence level at any of the above stages. The combined confidence level may be obtained by averaging or weighting the confidence levels of the stages, etc. In some embodiments, the movement recognition model according to the user's movement signal may be trained in real time, periodically (e.g., a day, a week, a month, etc.), or when a certain data size is met.</p>
<p id="p-0216" num="0215">It should be noted that the above description of the process <b>1700</b> is merely provided for the purpose of illustration, and is not intended to limit the scope of the present disclosure. For those skilled in the art, various of amendments and changes may be made to the process <b>1700</b> under the guidance of the present disclosure. However, these amendments and changes remain within the scope of this disclosure.</p>
<p id="p-0217" num="0216">The basic concepts have been described. Obviously, for those skilled in the art, the detailed disclosure may be only an example and does not constitute a limitation to the present disclosure. Although not explicitly stated here, those skilled in the art may make various modifications, improvements, and amendments to the present disclosure. These alterations, improvements, and modifications are intended to be suggested by this disclosure, and are within the spirit and scope of the exemplary embodiments of this disclosure.</p>
<p id="p-0218" num="0217">Moreover, certain terminology has been used to describe embodiments of the present disclosure. For example, the terms “one embodiment,” “an embodiment,” and/or “some embodiments” mean that a particular feature, structure or characteristic described in connection with the embodiment is included in at least one embodiment of the present disclosure. Therefore, it is emphasized and should be appreciated that two or more references to “an embodiment” or “one embodiment” or “an alternative embodiment” in various parts of the present disclosure are not necessarily all referring to the same embodiment. In addition, some features, structures, or features in the present disclosure of one or more embodiments may be appropriately combined.</p>
<p id="p-0219" num="0218">In addition, those skilled in the art can understand that various aspects of the present disclosure can be illustrated and described through several patentable categories or situations, including any new and useful processes, machines, products, or combinations of materials, or any new and useful improvements. Accordingly, all aspects of the present disclosure may be performed entirely by hardware, may be performed entirely by software (including firmware, resident software, microcode, etc.), or may be performed by a combination of hardware and software. The above hardware or software can be referred to as “data block”, “module”, “engine”, “unit”, “component” or “system”. In addition, aspects of the present disclosure may appear as a computer product located in one or more computer-readable media, the product including computer-readable program code.</p>
<p id="p-0220" num="0219">The computer storage medium may include a propagation data signal containing a computer program encoding, such as on a baseband or as part of a carrier. The propagation signal may have a variety of expressions, including electromagnetic form, optical form, or suitable combination form. The computer storage medium can be any computer-readable medium other than the computer-readable storage medium, which can be used to perform systems, devices, or devices to implement communication, propagating, or devices by connecting to an instruction. The program code located on the computer storage medium may be propagated through any suitable medium, including radio, cable, fiber optic cable, RF, or similar media, or any combination of the foregoing.</p>
<p id="p-0221" num="0220">Computer program code for carrying out operations for aspects of the present disclosure may be written in any combination of one or more programming languages, including an object-oriented programming language such as Java, Scala, Smalltalk, Eiffel, JADE, Emerald, C++, C #, VB.NET, Python or the like, conventional procedural programming languages, such as the “C” programming language, Visual Basic, Fortran 2003, Perl, COBOL 2002, PHP, ABAP, dynamic programming languages such as Python, Ruby, and Groovy, or other programming languages. The program code may execute entirely on the user's computer, partly on the user's computer, as a stand-alone software package, partly on the user's computer, partly on a remote computer, or entirely on the remote computer or server. In the case of subsequent cases, the remote computer can be connected to the user computer through any network, such as a local area network (LAN) or a wide area network (WAN), or connected to an external computer (e.g., through the Internet), or in the cloud computing environment, or as a service Use Software, SaaS.</p>
<p id="p-0222" num="0221">Moreover, unless otherwise specified in the claims, the sequence of the processing elements and sequences of the present disclosure, the use of digital letters, or other names are not used to define the order of the application flow and methods. Although the above disclosure discusses through various examples what is currently considered to be a variety of useful embodiments of the disclosure, it is to be understood that such detail is solely for that purpose and that the appended claims are not limited to the disclosed embodiments, but, on the contrary, are intended to cover modifications and equivalent arrangements that are within the spirit and scope of the disclosed embodiments. For example, although the implementation of various components described above may be embodied in a hardware device, it may also be implemented as a software-only solution, e.g., an installation on an existing server or mobile device.</p>
<p id="p-0223" num="0222">Similarly, it should be appreciated that in the foregoing description of embodiments of the present disclosure, various features are sometimes grouped together in a single embodiment, figure, or description thereof for the purpose of streamlining the disclosure and aiding in the understanding of one or more of the various embodiments. However, this disclosure does not mean that the present disclosure object requires more features than the features mentioned in the claims. Rather, claimed subject matter may lie in less than all features of a single foregoing disclosed embodiment.</p>
<p id="p-0224" num="0223">In some embodiments, numbers expressing quantities of ingredients, properties, and so forth, configured to describe and claim certain embodiments of the application are to be understood as being modified in some instances by the term “about,” “approximate,” or “substantially”. Unless otherwise stated, “approximately”, “approximately” or “substantially” indicates that the number is allowed to vary by ±20%. Correspondingly, in some embodiments, the value parameters used in the present disclosure and claims are approximate values. The approximate values may be changed according to the characteristics of individual embodiments. In some embodiments, the numerical parameters should be construed in light of the number of reported significant digits and by applying ordinary rounding techniques. Although the numerical domains and parameters used in the present application are used to confirm the range of ranges, the settings of this type are as accurate in the feasible range within the feasible range in the specific embodiments.</p>
<p id="p-0225" num="0224">For each patent, patent application, patent application publication, and other materials cited in the present disclosure, such as articles, books, specifications, publications, documents, etc., the entire contents are hereby incorporated by reference into the present disclosure. Except for application history documents that are inconsistent with or conflict with the contents of the present disclosure, the documents with the most limited scope of the claims of the present disclosure (current or later appended to the present disclosure) are also excluded. It should be noted that if the description, definition, and/or terms used in the appended application of the present disclosure are inconsistent or conflicting with the content described in the present disclosure, the use of the description, definition, and/or terms of the present disclosure shall prevail.</p>
<p id="p-0226" num="0225">At last, it should be understood that the embodiments described in the present disclosure are merely illustrative of the principles of the embodiments of the present disclosure. Other modifications that may be employed may be within the scope of the present disclosure. Thus, by way of example, but not of limitation, alternative configurations of the embodiments of the present disclosure may be utilized in accordance with the teachings herein. Accordingly, the embodiments of the present disclosure are not limited to that precisely as shown and described.</p>
<?detailed-description description="Detailed Description" end="tail"?>
</description>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text><b>1</b>. A motion monitoring method, comprising:
<claim-text>obtaining a movement signal of a user during motion, the movement signal comprising at least an electromyographic signal or an attitude signal; and</claim-text>
<claim-text>monitoring, at least based on feature information corresponding to the electromyographic signal or feature information corresponding to the attitude signal, a movement of the user during motion, wherein the feature information corresponding to the electromyographic signal includes at least frequency information or amplitude information, and the feature information corresponding to the attitude signal includes at least one of an angular velocity direction, an angular velocity value, an acceleration of an angular velocity, an angle, displacement information, and stress.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text><b>2</b>. The motion monitoring method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, comprising:
<claim-text>segmenting, based on the feature information corresponding to the electromyographic signal or the feature information corresponding to the attitude signal, the movement signal; and</claim-text>
<claim-text>monitoring, based on at least one segment of the movement signal, the movement of the user during motion.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text><b>3</b>. (canceled)</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text><b>4</b>. The motion monitoring method of <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein the segmenting, based on the feature information corresponding to the electromyographic signal or the feature information corresponding to the attitude signal, the movement signal includes:
<claim-text>determining, based on a time domain window of the electromyographic signal or the attitude signal, at least one target feature point from the time domain window according to a preset condition; and</claim-text>
<claim-text>segmenting, based on the at least one target feature point, the movement signal.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text><b>5</b>. The motion monitoring method of <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the at least one target feature point includes one of a movement start point, a movement middle point, and a movement end point.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text><b>6</b>. The motion monitoring method of <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein the preset condition includes one or more of a change in the angular velocity direction corresponding to the attitude signal; the angular velocity corresponding to the attitude signal being greater than or equal to an angular velocity threshold; a changed value of the angular velocity value corresponding to the attitude signal being an extreme value; the angle corresponding to the attitude signal reaching an angular threshold; and the amplitude information corresponding to the electromyographic signal being greater than or equal to one or more electromyographic thresholds.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text><b>7</b>. The motion monitoring method of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the preset condition further includes the acceleration of the angular velocity corresponding to the attitude signal being continuously greater than or equal to an acceleration threshold of the angular velocity for a first specific time range.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text><b>8</b>. The motion monitoring method of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the preset condition further includes an amplitude corresponding to the electromyographic signal being continuously greater than the one or more electromyographic thresholds for a second specific time range.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text><b>9</b>. The motion monitoring method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the monitoring, at least based on feature information corresponding to the electromyographic signal or feature information corresponding to an attitude signal, a movement of the user during motion comprises:
<claim-text>pre-processing the electromyographic signal in a frequency domain or a time domain;</claim-text>
<claim-text>obtaining, based on the pre-processed electromyographic signal, the feature information corresponding to the electromyographic signal; and</claim-text>
<claim-text>monitoring, according to the feature information corresponding to the electromyographic signal or the feature information corresponding to the attitude signal, the movement of the user during motion.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text><b>10</b>. The motion monitoring method of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein the pre-processing the electromyographic signal in a frequency domain or a time domain includes:
<claim-text>filtering the electromyographic signal to select components of the electromyographic signal in a specific frequency range in the frequency domain.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text><b>11</b>. The motion monitoring method of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein the pre-processing the electromyographic signal in a frequency domain or a time domain includes:
<claim-text>performing a signal correction processing on the electromyographic signal in the time domain.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text><b>12</b>. The motion monitoring method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the performing a signal correction processing on the electromyographic signal in the time domain includes:
<claim-text>determining a singularity in the electromyographic signal, wherein the singularity corresponds to an abrupt signal of the electromyographic signal; and</claim-text>
<claim-text>performing the signal correction processing on the singularity in the electromyographic signal.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text><b>13</b>. The motion monitoring method of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the performing the signal correction processing on the singularity in the electromyographic signal includes removing the singularity or performing the signal correction processing on the singularity according to a signal around the singularity includes:
<claim-text>removing the singularity, or correcting the singularity according to a signal around the singularity.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text><b>14</b>. The motion monitoring method of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the singularity includes a burr signal, the determining the singularity in the electromyographic signal includes:
<claim-text>selecting, based on the time domain window of the electromyographic signal, different time windows from the time domain window of the electromyographic signal, wherein the different time windows respectively cover different time ranges; and</claim-text>
<claim-text>determining, based on the feature information corresponding to the electromyographic signal in the different time windows, the burr signal.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text><b>15</b>. The motion monitoring method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising determining, based on the attitude signal, the feature information corresponding to the attitude signal, wherein the attitude signal comprises coordinate information in at least one original coordinate system; and
<claim-text>determining, based on the attitude signal, the feature information corresponding to the attitude signal comprises:</claim-text>
<claim-text>obtaining a target coordinate system and a conversion relationship between the target coordinate system and the at least one original coordinate system;</claim-text>
<claim-text>converting, based on the conversion relationship, the coordinate information in the at least one original coordinate system to coordinate information in the target coordinate system; and</claim-text>
<claim-text>determining, based on the coordinate information in the target coordinate system, the feature information corresponding to the attitude signal.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text><b>16</b>. The motion monitoring method of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the attitude signal includes coordinate information generated by at least two sensors, the at least two sensors are located at different motion parts of the user and correspond to different original coordinate systems, the determining, based on the attitude signal, the feature information corresponding to the attitude signal includes:
<claim-text>determining feature information corresponding to each of the at least two sensors based on the conversion relationship between different original coordinate systems and the target coordinate system; and</claim-text>
<claim-text>determining, based on the feature information respectively corresponding to the at least two sensors, a relative motion between the motion parts of the user.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text><b>17</b>. The motion monitoring method of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the conversion relationship between the at least one original coordinate system and the target coordinate system is obtained by a calibration process including:
<claim-text>constructing a specific coordinate system, the specific coordinate system being related to an orientation of the user during the calibration process;</claim-text>
<claim-text>obtaining first coordinate information of the at least one original coordinate system when the user is in a first pose;</claim-text>
<claim-text>obtaining second coordinate information of the at least one original coordinate system when the user is in a second pose; and</claim-text>
<claim-text>determining the conversion relationship between the at least one original coordinate system and the specific coordinate system according to the first coordinate information, the second coordinate information, and the specific coordinate system.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text><b>18</b>. The motion monitoring method of <claim-ref idref="CLM-00017">claim 17</claim-ref>, where the calibration process further includes:
<claim-text>obtaining a conversion relationship between the specific coordinate system and the target coordinate system; and</claim-text>
<claim-text>determining, according to the conversion relationship between the at least one original coordinate system and the specific coordinate system as well as the conversion relationship between the specific coordinate system and target coordinate system, the conversion relationship between the at least one original coordinate system and the target coordinate system.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text><b>19</b>. The motion monitoring method of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the target coordinate system changes as the user's orientation changes.</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text><b>20</b>. (canceled)</claim-text>
</claim>
<claim id="CLM-00021" num="00021">
<claim-text><b>21</b>. A motion monitoring and feedback method, comprising:
<claim-text>obtaining movement signal of a user during motion, wherein the movement signal includes at least an electromyographic signal and an attitude signal; and</claim-text>
<claim-text>monitoring, based on feature information corresponding to the electromyographic signal and feature information corresponding to the attitude signal, a movement of a user by a movement recognition model, and providing, based on an output of the movement recognition model, a movement feedback.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00022" num="00022">
<claim-text><b>22</b>. (canceled)</claim-text>
</claim>
<claim id="CLM-00023" num="00023">
<claim-text><b>23</b>. The motion monitoring and feedback method of <claim-ref idref="CLM-00021">claim 21</claim-ref>, wherein the movement feedback includes at least one of sending a prompt message, stimulating a movement part of the user, and outputting a motion record of the user during motion.</claim-text>
</claim>
</claims>
</us-patent-application></div><div class="header"><span>This XML file does not appear to have any style information associated with it. The document tree is shown below.</span><br /></div><div class="pretty-print"><div class="folder" id="folder0"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;us-patent-application<span class="html-attribute"> <span class="html-attribute-name">lang</span>="<span class="html-attribute-value">EN</span>"</span><span class="html-attribute"> <span class="html-attribute-name">dtd-version</span>="<span class="html-attribute-value">v4.6 2022-02-17</span>"</span><span class="html-attribute"> <span class="html-attribute-name">file</span>="<span class="html-attribute-value">US20230233103A1-20230727.XML</span>"</span><span class="html-attribute"> <span class="html-attribute-name">status</span>="<span class="html-attribute-value">PRODUCTION</span>"</span><span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">us-patent-application</span>"</span><span class="html-attribute"> <span class="html-attribute-name">country</span>="<span class="html-attribute-value">US</span>"</span><span class="html-attribute"> <span class="html-attribute-name">date-produced</span>="<span class="html-attribute-value">20230710</span>"</span><span class="html-attribute"> <span class="html-attribute-name">date-publ</span>="<span class="html-attribute-value">20230727</span>"</span>&gt;</span></div><div class="opened"><span>
</span><div class="folder" id="folder1"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;us-bibliographic-data-application<span class="html-attribute"> <span class="html-attribute-name">lang</span>="<span class="html-attribute-value">EN</span>"</span><span class="html-attribute"> <span class="html-attribute-name">country</span>="<span class="html-attribute-value">US</span>"</span>&gt;</span></div><div class="opened"><span>
</span><div class="folder" id="folder2"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;publication-reference&gt;</span></div><div class="opened"><span>
</span><div class="folder" id="folder3"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;document-id&gt;</span></div><div class="opened"><span>
</span><div class="line"><span class="html-tag">&lt;country&gt;</span><span>US</span><span class="html-tag">&lt;/country&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;doc-number&gt;</span><span>20230233103</span><span class="html-tag">&lt;/doc-number&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;kind&gt;</span><span>A1</span><span class="html-tag">&lt;/kind&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;date&gt;</span><span>20230727</span><span class="html-tag">&lt;/date&gt;</span></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/document-id&gt;</span></div></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/publication-reference&gt;</span></div></div><span>
</span><div class="folder" id="folder4"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;application-reference<span class="html-attribute"> <span class="html-attribute-name">appl-type</span>="<span class="html-attribute-value">utility</span>"</span>&gt;</span></div><div class="opened"><span>
</span><div class="folder" id="folder5"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;document-id&gt;</span></div><div class="opened"><span>
</span><div class="line"><span class="html-tag">&lt;country&gt;</span><span>US</span><span class="html-tag">&lt;/country&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;doc-number&gt;</span><span>18183923</span><span class="html-tag">&lt;/doc-number&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;date&gt;</span><span>20230314</span><span class="html-tag">&lt;/date&gt;</span></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/document-id&gt;</span></div></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/application-reference&gt;</span></div></div><span>
</span><div class="line"><span class="html-tag">&lt;us-application-series-code&gt;</span><span>18</span><span class="html-tag">&lt;/us-application-series-code&gt;</span></div><span>
</span><div class="folder" id="folder6"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;classifications-ipcr&gt;</span></div><div class="opened"><span>
</span><div class="folder" id="folder7"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;classification-ipcr&gt;</span></div><div class="opened"><span>
</span><div class="folder" id="folder8"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;ipc-version-indicator&gt;</span></div><div class="opened"><div class="line"><span class="html-tag">&lt;date&gt;</span><span>20060101</span><span class="html-tag">&lt;/date&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/ipc-version-indicator&gt;</span></div></div><span>
</span><div class="line"><span class="html-tag">&lt;classification-level&gt;</span><span>A</span><span class="html-tag">&lt;/classification-level&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;section&gt;</span><span>A</span><span class="html-tag">&lt;/section&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;class&gt;</span><span>61</span><span class="html-tag">&lt;/class&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;subclass&gt;</span><span>B</span><span class="html-tag">&lt;/subclass&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;main-group&gt;</span><span>5</span><span class="html-tag">&lt;/main-group&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;subgroup&gt;</span><span>11</span><span class="html-tag">&lt;/subgroup&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;symbol-position&gt;</span><span>F</span><span class="html-tag">&lt;/symbol-position&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;classification-value&gt;</span><span>I</span><span class="html-tag">&lt;/classification-value&gt;</span></div><span>
</span><div class="folder" id="folder9"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;action-date&gt;</span></div><div class="opened"><div class="line"><span class="html-tag">&lt;date&gt;</span><span>20230727</span><span class="html-tag">&lt;/date&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/action-date&gt;</span></div></div><span>
</span><div class="folder" id="folder10"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;generating-office&gt;</span></div><div class="opened"><div class="line"><span class="html-tag">&lt;country&gt;</span><span>US</span><span class="html-tag">&lt;/country&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/generating-office&gt;</span></div></div><span>
</span><div class="line"><span class="html-tag">&lt;classification-status&gt;</span><span>B</span><span class="html-tag">&lt;/classification-status&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;classification-data-source&gt;</span><span>H</span><span class="html-tag">&lt;/classification-data-source&gt;</span></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/classification-ipcr&gt;</span></div></div><span>
</span><div class="folder" id="folder11"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;classification-ipcr&gt;</span></div><div class="opened"><span>
</span><div class="folder" id="folder12"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;ipc-version-indicator&gt;</span></div><div class="opened"><div class="line"><span class="html-tag">&lt;date&gt;</span><span>20210101</span><span class="html-tag">&lt;/date&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/ipc-version-indicator&gt;</span></div></div><span>
</span><div class="line"><span class="html-tag">&lt;classification-level&gt;</span><span>A</span><span class="html-tag">&lt;/classification-level&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;section&gt;</span><span>A</span><span class="html-tag">&lt;/section&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;class&gt;</span><span>61</span><span class="html-tag">&lt;/class&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;subclass&gt;</span><span>B</span><span class="html-tag">&lt;/subclass&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;main-group&gt;</span><span>5</span><span class="html-tag">&lt;/main-group&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;subgroup&gt;</span><span>397</span><span class="html-tag">&lt;/subgroup&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;symbol-position&gt;</span><span>L</span><span class="html-tag">&lt;/symbol-position&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;classification-value&gt;</span><span>I</span><span class="html-tag">&lt;/classification-value&gt;</span></div><span>
</span><div class="folder" id="folder13"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;action-date&gt;</span></div><div class="opened"><div class="line"><span class="html-tag">&lt;date&gt;</span><span>20230727</span><span class="html-tag">&lt;/date&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/action-date&gt;</span></div></div><span>
</span><div class="folder" id="folder14"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;generating-office&gt;</span></div><div class="opened"><div class="line"><span class="html-tag">&lt;country&gt;</span><span>US</span><span class="html-tag">&lt;/country&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/generating-office&gt;</span></div></div><span>
</span><div class="line"><span class="html-tag">&lt;classification-status&gt;</span><span>B</span><span class="html-tag">&lt;/classification-status&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;classification-data-source&gt;</span><span>H</span><span class="html-tag">&lt;/classification-data-source&gt;</span></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/classification-ipcr&gt;</span></div></div><span>
</span><div class="folder" id="folder15"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;classification-ipcr&gt;</span></div><div class="opened"><span>
</span><div class="folder" id="folder16"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;ipc-version-indicator&gt;</span></div><div class="opened"><div class="line"><span class="html-tag">&lt;date&gt;</span><span>20060101</span><span class="html-tag">&lt;/date&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/ipc-version-indicator&gt;</span></div></div><span>
</span><div class="line"><span class="html-tag">&lt;classification-level&gt;</span><span>A</span><span class="html-tag">&lt;/classification-level&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;section&gt;</span><span>A</span><span class="html-tag">&lt;/section&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;class&gt;</span><span>61</span><span class="html-tag">&lt;/class&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;subclass&gt;</span><span>B</span><span class="html-tag">&lt;/subclass&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;main-group&gt;</span><span>5</span><span class="html-tag">&lt;/main-group&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;subgroup&gt;</span><span>00</span><span class="html-tag">&lt;/subgroup&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;symbol-position&gt;</span><span>L</span><span class="html-tag">&lt;/symbol-position&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;classification-value&gt;</span><span>I</span><span class="html-tag">&lt;/classification-value&gt;</span></div><span>
</span><div class="folder" id="folder17"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;action-date&gt;</span></div><div class="opened"><div class="line"><span class="html-tag">&lt;date&gt;</span><span>20230727</span><span class="html-tag">&lt;/date&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/action-date&gt;</span></div></div><span>
</span><div class="folder" id="folder18"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;generating-office&gt;</span></div><div class="opened"><div class="line"><span class="html-tag">&lt;country&gt;</span><span>US</span><span class="html-tag">&lt;/country&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/generating-office&gt;</span></div></div><span>
</span><div class="line"><span class="html-tag">&lt;classification-status&gt;</span><span>B</span><span class="html-tag">&lt;/classification-status&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;classification-data-source&gt;</span><span>H</span><span class="html-tag">&lt;/classification-data-source&gt;</span></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/classification-ipcr&gt;</span></div></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/classifications-ipcr&gt;</span></div></div><span>
</span><div class="folder" id="folder19"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;classifications-cpc&gt;</span></div><div class="opened"><span>
</span><div class="folder" id="folder20"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;main-cpc&gt;</span></div><div class="opened"><span>
</span><div class="folder" id="folder21"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;classification-cpc&gt;</span></div><div class="opened"><span>
</span><div class="folder" id="folder22"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;cpc-version-indicator&gt;</span></div><div class="opened"><div class="line"><span class="html-tag">&lt;date&gt;</span><span>20130101</span><span class="html-tag">&lt;/date&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/cpc-version-indicator&gt;</span></div></div><span>
</span><div class="line"><span class="html-tag">&lt;section&gt;</span><span>A</span><span class="html-tag">&lt;/section&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;class&gt;</span><span>61</span><span class="html-tag">&lt;/class&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;subclass&gt;</span><span>B</span><span class="html-tag">&lt;/subclass&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;main-group&gt;</span><span>5</span><span class="html-tag">&lt;/main-group&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;subgroup&gt;</span><span>1116</span><span class="html-tag">&lt;/subgroup&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;symbol-position&gt;</span><span>F</span><span class="html-tag">&lt;/symbol-position&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;classification-value&gt;</span><span>I</span><span class="html-tag">&lt;/classification-value&gt;</span></div><span>
</span><div class="folder" id="folder23"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;action-date&gt;</span></div><div class="opened"><div class="line"><span class="html-tag">&lt;date&gt;</span><span>20230727</span><span class="html-tag">&lt;/date&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/action-date&gt;</span></div></div><span>
</span><div class="folder" id="folder24"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;generating-office&gt;</span></div><div class="opened"><div class="line"><span class="html-tag">&lt;country&gt;</span><span>US</span><span class="html-tag">&lt;/country&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/generating-office&gt;</span></div></div><span>
</span><div class="line"><span class="html-tag">&lt;classification-status&gt;</span><span>B</span><span class="html-tag">&lt;/classification-status&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;classification-data-source&gt;</span><span>H</span><span class="html-tag">&lt;/classification-data-source&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;scheme-origination-code&gt;</span><span>C</span><span class="html-tag">&lt;/scheme-origination-code&gt;</span></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/classification-cpc&gt;</span></div></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/main-cpc&gt;</span></div></div><span>
</span><div class="folder" id="folder25"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;further-cpc&gt;</span></div><div class="opened"><span>
</span><div class="folder" id="folder26"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;classification-cpc&gt;</span></div><div class="opened"><span>
</span><div class="folder" id="folder27"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;cpc-version-indicator&gt;</span></div><div class="opened"><div class="line"><span class="html-tag">&lt;date&gt;</span><span>20210101</span><span class="html-tag">&lt;/date&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/cpc-version-indicator&gt;</span></div></div><span>
</span><div class="line"><span class="html-tag">&lt;section&gt;</span><span>A</span><span class="html-tag">&lt;/section&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;class&gt;</span><span>61</span><span class="html-tag">&lt;/class&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;subclass&gt;</span><span>B</span><span class="html-tag">&lt;/subclass&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;main-group&gt;</span><span>5</span><span class="html-tag">&lt;/main-group&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;subgroup&gt;</span><span>397</span><span class="html-tag">&lt;/subgroup&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;symbol-position&gt;</span><span>L</span><span class="html-tag">&lt;/symbol-position&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;classification-value&gt;</span><span>I</span><span class="html-tag">&lt;/classification-value&gt;</span></div><span>
</span><div class="folder" id="folder28"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;action-date&gt;</span></div><div class="opened"><div class="line"><span class="html-tag">&lt;date&gt;</span><span>20230727</span><span class="html-tag">&lt;/date&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/action-date&gt;</span></div></div><span>
</span><div class="folder" id="folder29"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;generating-office&gt;</span></div><div class="opened"><div class="line"><span class="html-tag">&lt;country&gt;</span><span>US</span><span class="html-tag">&lt;/country&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/generating-office&gt;</span></div></div><span>
</span><div class="line"><span class="html-tag">&lt;classification-status&gt;</span><span>B</span><span class="html-tag">&lt;/classification-status&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;classification-data-source&gt;</span><span>H</span><span class="html-tag">&lt;/classification-data-source&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;scheme-origination-code&gt;</span><span>C</span><span class="html-tag">&lt;/scheme-origination-code&gt;</span></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/classification-cpc&gt;</span></div></div><span>
</span><div class="folder" id="folder30"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;classification-cpc&gt;</span></div><div class="opened"><span>
</span><div class="folder" id="folder31"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;cpc-version-indicator&gt;</span></div><div class="opened"><div class="line"><span class="html-tag">&lt;date&gt;</span><span>20130101</span><span class="html-tag">&lt;/date&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/cpc-version-indicator&gt;</span></div></div><span>
</span><div class="line"><span class="html-tag">&lt;section&gt;</span><span>A</span><span class="html-tag">&lt;/section&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;class&gt;</span><span>61</span><span class="html-tag">&lt;/class&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;subclass&gt;</span><span>B</span><span class="html-tag">&lt;/subclass&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;main-group&gt;</span><span>5</span><span class="html-tag">&lt;/main-group&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;subgroup&gt;</span><span>7225</span><span class="html-tag">&lt;/subgroup&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;symbol-position&gt;</span><span>L</span><span class="html-tag">&lt;/symbol-position&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;classification-value&gt;</span><span>I</span><span class="html-tag">&lt;/classification-value&gt;</span></div><span>
</span><div class="folder" id="folder32"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;action-date&gt;</span></div><div class="opened"><div class="line"><span class="html-tag">&lt;date&gt;</span><span>20230727</span><span class="html-tag">&lt;/date&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/action-date&gt;</span></div></div><span>
</span><div class="folder" id="folder33"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;generating-office&gt;</span></div><div class="opened"><div class="line"><span class="html-tag">&lt;country&gt;</span><span>US</span><span class="html-tag">&lt;/country&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/generating-office&gt;</span></div></div><span>
</span><div class="line"><span class="html-tag">&lt;classification-status&gt;</span><span>B</span><span class="html-tag">&lt;/classification-status&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;classification-data-source&gt;</span><span>H</span><span class="html-tag">&lt;/classification-data-source&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;scheme-origination-code&gt;</span><span>C</span><span class="html-tag">&lt;/scheme-origination-code&gt;</span></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/classification-cpc&gt;</span></div></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/further-cpc&gt;</span></div></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/classifications-cpc&gt;</span></div></div><span>
</span><div class="line"><span class="html-tag">&lt;invention-title<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">d2e43</span>"</span>&gt;</span><span>MOTION MONITORING METHODS AND SYSTEMS</span><span class="html-tag">&lt;/invention-title&gt;</span></div><span>
</span><div class="folder" id="folder34"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;us-related-documents&gt;</span></div><div class="opened"><span>
</span><div class="folder" id="folder35"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;continuation&gt;</span></div><div class="opened"><span>
</span><div class="folder" id="folder36"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;relation&gt;</span></div><div class="opened"><span>
</span><div class="folder" id="folder37"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;parent-doc&gt;</span></div><div class="opened"><span>
</span><div class="folder" id="folder38"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;document-id&gt;</span></div><div class="opened"><span>
</span><div class="line"><span class="html-tag">&lt;country&gt;</span><span>US</span><span class="html-tag">&lt;/country&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;doc-number&gt;</span><span>PCT/CN2021/081931</span><span class="html-tag">&lt;/doc-number&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;date&gt;</span><span>20210319</span><span class="html-tag">&lt;/date&gt;</span></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/document-id&gt;</span></div></div><span>
</span><div class="line"><span class="html-tag">&lt;parent-status&gt;</span><span>PENDING</span><span class="html-tag">&lt;/parent-status&gt;</span></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/parent-doc&gt;</span></div></div><span>
</span><div class="folder" id="folder39"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;child-doc&gt;</span></div><div class="opened"><span>
</span><div class="folder" id="folder40"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;document-id&gt;</span></div><div class="opened"><span>
</span><div class="line"><span class="html-tag">&lt;country&gt;</span><span>US</span><span class="html-tag">&lt;/country&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;doc-number&gt;</span><span>18183923</span><span class="html-tag">&lt;/doc-number&gt;</span></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/document-id&gt;</span></div></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/child-doc&gt;</span></div></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/relation&gt;</span></div></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/continuation&gt;</span></div></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/us-related-documents&gt;</span></div></div><span>
</span><div class="folder" id="folder41"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;us-parties&gt;</span></div><div class="opened"><span>
</span><div class="folder" id="folder42"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;us-applicants&gt;</span></div><div class="opened"><span>
</span><div class="folder" id="folder43"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;us-applicant<span class="html-attribute"> <span class="html-attribute-name">sequence</span>="<span class="html-attribute-value">00</span>"</span><span class="html-attribute"> <span class="html-attribute-name">app-type</span>="<span class="html-attribute-value">applicant</span>"</span><span class="html-attribute"> <span class="html-attribute-name">designation</span>="<span class="html-attribute-value">us-only</span>"</span><span class="html-attribute"> <span class="html-attribute-name">applicant-authority-category</span>="<span class="html-attribute-value">assignee</span>"</span>&gt;</span></div><div class="opened"><span>
</span><div class="folder" id="folder44"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;addressbook&gt;</span></div><div class="opened"><span>
</span><div class="line"><span class="html-tag">&lt;orgname&gt;</span><span>SHENZHEN SHOKZ CO., LTD.</span><span class="html-tag">&lt;/orgname&gt;</span></div><span>
</span><div class="folder" id="folder45"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;address&gt;</span></div><div class="opened"><span>
</span><div class="line"><span class="html-tag">&lt;city&gt;</span><span>Shenzhen</span><span class="html-tag">&lt;/city&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;country&gt;</span><span>CN</span><span class="html-tag">&lt;/country&gt;</span></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/address&gt;</span></div></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/addressbook&gt;</span></div></div><span>
</span><div class="folder" id="folder46"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;residence&gt;</span></div><div class="opened"><span>
</span><div class="line"><span class="html-tag">&lt;country&gt;</span><span>CN</span><span class="html-tag">&lt;/country&gt;</span></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/residence&gt;</span></div></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/us-applicant&gt;</span></div></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/us-applicants&gt;</span></div></div><span>
</span><div class="folder" id="folder47"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;inventors&gt;</span></div><div class="opened"><span>
</span><div class="folder" id="folder48"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;inventor<span class="html-attribute"> <span class="html-attribute-name">sequence</span>="<span class="html-attribute-value">00</span>"</span><span class="html-attribute"> <span class="html-attribute-name">designation</span>="<span class="html-attribute-value">us-only</span>"</span>&gt;</span></div><div class="opened"><span>
</span><div class="folder" id="folder49"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;addressbook&gt;</span></div><div class="opened"><span>
</span><div class="line"><span class="html-tag">&lt;last-name&gt;</span><span>SU</span><span class="html-tag">&lt;/last-name&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;first-name&gt;</span><span>Lei</span><span class="html-tag">&lt;/first-name&gt;</span></div><span>
</span><div class="folder" id="folder50"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;address&gt;</span></div><div class="opened"><span>
</span><div class="line"><span class="html-tag">&lt;city&gt;</span><span>Shenzhen</span><span class="html-tag">&lt;/city&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;country&gt;</span><span>CN</span><span class="html-tag">&lt;/country&gt;</span></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/address&gt;</span></div></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/addressbook&gt;</span></div></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/inventor&gt;</span></div></div><span>
</span><div class="folder" id="folder51"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;inventor<span class="html-attribute"> <span class="html-attribute-name">sequence</span>="<span class="html-attribute-value">01</span>"</span><span class="html-attribute"> <span class="html-attribute-name">designation</span>="<span class="html-attribute-value">us-only</span>"</span>&gt;</span></div><div class="opened"><span>
</span><div class="folder" id="folder52"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;addressbook&gt;</span></div><div class="opened"><span>
</span><div class="line"><span class="html-tag">&lt;last-name&gt;</span><span>ZHOU</span><span class="html-tag">&lt;/last-name&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;first-name&gt;</span><span>Xin</span><span class="html-tag">&lt;/first-name&gt;</span></div><span>
</span><div class="folder" id="folder53"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;address&gt;</span></div><div class="opened"><span>
</span><div class="line"><span class="html-tag">&lt;city&gt;</span><span>Shenzhen</span><span class="html-tag">&lt;/city&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;country&gt;</span><span>CN</span><span class="html-tag">&lt;/country&gt;</span></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/address&gt;</span></div></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/addressbook&gt;</span></div></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/inventor&gt;</span></div></div><span>
</span><div class="folder" id="folder54"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;inventor<span class="html-attribute"> <span class="html-attribute-name">sequence</span>="<span class="html-attribute-value">02</span>"</span><span class="html-attribute"> <span class="html-attribute-name">designation</span>="<span class="html-attribute-value">us-only</span>"</span>&gt;</span></div><div class="opened"><span>
</span><div class="folder" id="folder55"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;addressbook&gt;</span></div><div class="opened"><span>
</span><div class="line"><span class="html-tag">&lt;last-name&gt;</span><span>LI</span><span class="html-tag">&lt;/last-name&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;first-name&gt;</span><span>Meiqi</span><span class="html-tag">&lt;/first-name&gt;</span></div><span>
</span><div class="folder" id="folder56"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;address&gt;</span></div><div class="opened"><span>
</span><div class="line"><span class="html-tag">&lt;city&gt;</span><span>Shenzhen</span><span class="html-tag">&lt;/city&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;country&gt;</span><span>CN</span><span class="html-tag">&lt;/country&gt;</span></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/address&gt;</span></div></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/addressbook&gt;</span></div></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/inventor&gt;</span></div></div><span>
</span><div class="folder" id="folder57"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;inventor<span class="html-attribute"> <span class="html-attribute-name">sequence</span>="<span class="html-attribute-value">03</span>"</span><span class="html-attribute"> <span class="html-attribute-name">designation</span>="<span class="html-attribute-value">us-only</span>"</span>&gt;</span></div><div class="opened"><span>
</span><div class="folder" id="folder58"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;addressbook&gt;</span></div><div class="opened"><span>
</span><div class="line"><span class="html-tag">&lt;last-name&gt;</span><span>LIAO</span><span class="html-tag">&lt;/last-name&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;first-name&gt;</span><span>Fengyun</span><span class="html-tag">&lt;/first-name&gt;</span></div><span>
</span><div class="folder" id="folder59"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;address&gt;</span></div><div class="opened"><span>
</span><div class="line"><span class="html-tag">&lt;city&gt;</span><span>Shenzhen</span><span class="html-tag">&lt;/city&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;country&gt;</span><span>CN</span><span class="html-tag">&lt;/country&gt;</span></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/address&gt;</span></div></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/addressbook&gt;</span></div></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/inventor&gt;</span></div></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/inventors&gt;</span></div></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/us-parties&gt;</span></div></div><span>
</span><div class="folder" id="folder60"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;assignees&gt;</span></div><div class="opened"><span>
</span><div class="folder" id="folder61"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;assignee&gt;</span></div><div class="opened"><span>
</span><div class="folder" id="folder62"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;addressbook&gt;</span></div><div class="opened"><span>
</span><div class="line"><span class="html-tag">&lt;orgname&gt;</span><span>SHENZHEN SHOKZ CO., LTD.</span><span class="html-tag">&lt;/orgname&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;role&gt;</span><span>03</span><span class="html-tag">&lt;/role&gt;</span></div><span>
</span><div class="folder" id="folder63"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;address&gt;</span></div><div class="opened"><span>
</span><div class="line"><span class="html-tag">&lt;city&gt;</span><span>Shenzhen</span><span class="html-tag">&lt;/city&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;country&gt;</span><span>CN</span><span class="html-tag">&lt;/country&gt;</span></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/address&gt;</span></div></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/addressbook&gt;</span></div></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/assignee&gt;</span></div></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/assignees&gt;</span></div></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/us-bibliographic-data-application&gt;</span></div></div><span>
</span><div class="folder" id="folder64"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;abstract<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">abstract</span>"</span>&gt;</span></div><div class="opened"><span>
</span><div class="folder" id="folder65"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0001</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0000</span>"</span>&gt;</span></div><div class="opened"><span>A motion monitoring method (</span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>500</span><span class="html-tag">&lt;/b&gt;</span></div><span>) is provided, which includes: obtaining a movement signal of a user during motion, wherein the movement signal includes at least an electromyographic signal or an attitude signal (</span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>510</span><span class="html-tag">&lt;/b&gt;</span></div><span>); and monitoring a movement of the user during motion based at least on feature information corresponding to the electromyographic signal or the feature information corresponding to the attitude signal (</span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>520</span><span class="html-tag">&lt;/b&gt;</span></div><span>).</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/abstract&gt;</span></div></div><span>
</span><div class="folder" id="folder66"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;drawings<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>
</span><div class="folder" id="folder67"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figure<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">Fig-EMI-D00000</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">00000</span>"</span>&gt;</span></div><div class="opened"><span>
</span><div class="line"><span class="html-tag">&lt;img<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">EMI-D00000</span>"</span><span class="html-attribute"> <span class="html-attribute-name">he</span>="<span class="html-attribute-value">119.80mm</span>"</span><span class="html-attribute"> <span class="html-attribute-name">wi</span>="<span class="html-attribute-value">134.45mm</span>"</span><span class="html-attribute"> <span class="html-attribute-name">file</span>="<span class="html-attribute-value">US20230233103A1-20230727-D00000.TIF</span>"</span><span class="html-attribute"> <span class="html-attribute-name">alt</span>="<span class="html-attribute-value">embedded image</span>"</span><span class="html-attribute"> <span class="html-attribute-name">img-content</span>="<span class="html-attribute-value">drawing</span>"</span><span class="html-attribute"> <span class="html-attribute-name">img-format</span>="<span class="html-attribute-value">tif</span>"</span>/&gt;</span></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figure&gt;</span></div></div><span>
</span><div class="folder" id="folder68"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figure<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">Fig-EMI-D00001</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">00001</span>"</span>&gt;</span></div><div class="opened"><span>
</span><div class="line"><span class="html-tag">&lt;img<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">EMI-D00001</span>"</span><span class="html-attribute"> <span class="html-attribute-name">he</span>="<span class="html-attribute-value">221.66mm</span>"</span><span class="html-attribute"> <span class="html-attribute-name">wi</span>="<span class="html-attribute-value">136.48mm</span>"</span><span class="html-attribute"> <span class="html-attribute-name">file</span>="<span class="html-attribute-value">US20230233103A1-20230727-D00001.TIF</span>"</span><span class="html-attribute"> <span class="html-attribute-name">alt</span>="<span class="html-attribute-value">embedded image</span>"</span><span class="html-attribute"> <span class="html-attribute-name">img-content</span>="<span class="html-attribute-value">drawing</span>"</span><span class="html-attribute"> <span class="html-attribute-name">img-format</span>="<span class="html-attribute-value">tif</span>"</span>/&gt;</span></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figure&gt;</span></div></div><span>
</span><div class="folder" id="folder69"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figure<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">Fig-EMI-D00002</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">00002</span>"</span>&gt;</span></div><div class="opened"><span>
</span><div class="line"><span class="html-tag">&lt;img<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">EMI-D00002</span>"</span><span class="html-attribute"> <span class="html-attribute-name">he</span>="<span class="html-attribute-value">192.36mm</span>"</span><span class="html-attribute"> <span class="html-attribute-name">wi</span>="<span class="html-attribute-value">162.39mm</span>"</span><span class="html-attribute"> <span class="html-attribute-name">file</span>="<span class="html-attribute-value">US20230233103A1-20230727-D00002.TIF</span>"</span><span class="html-attribute"> <span class="html-attribute-name">alt</span>="<span class="html-attribute-value">embedded image</span>"</span><span class="html-attribute"> <span class="html-attribute-name">img-content</span>="<span class="html-attribute-value">drawing</span>"</span><span class="html-attribute"> <span class="html-attribute-name">img-format</span>="<span class="html-attribute-value">tif</span>"</span>/&gt;</span></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figure&gt;</span></div></div><span>
</span><div class="folder" id="folder70"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figure<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">Fig-EMI-D00003</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">00003</span>"</span>&gt;</span></div><div class="opened"><span>
</span><div class="line"><span class="html-tag">&lt;img<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">EMI-D00003</span>"</span><span class="html-attribute"> <span class="html-attribute-name">he</span>="<span class="html-attribute-value">201.42mm</span>"</span><span class="html-attribute"> <span class="html-attribute-name">wi</span>="<span class="html-attribute-value">135.47mm</span>"</span><span class="html-attribute"> <span class="html-attribute-name">orientation</span>="<span class="html-attribute-value">landscape</span>"</span><span class="html-attribute"> <span class="html-attribute-name">file</span>="<span class="html-attribute-value">US20230233103A1-20230727-D00003.TIF</span>"</span><span class="html-attribute"> <span class="html-attribute-name">alt</span>="<span class="html-attribute-value">embedded image</span>"</span><span class="html-attribute"> <span class="html-attribute-name">img-content</span>="<span class="html-attribute-value">drawing</span>"</span><span class="html-attribute"> <span class="html-attribute-name">img-format</span>="<span class="html-attribute-value">tif</span>"</span>/&gt;</span></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figure&gt;</span></div></div><span>
</span><div class="folder" id="folder71"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figure<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">Fig-EMI-D00004</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">00004</span>"</span>&gt;</span></div><div class="opened"><span>
</span><div class="line"><span class="html-tag">&lt;img<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">EMI-D00004</span>"</span><span class="html-attribute"> <span class="html-attribute-name">he</span>="<span class="html-attribute-value">214.04mm</span>"</span><span class="html-attribute"> <span class="html-attribute-name">wi</span>="<span class="html-attribute-value">123.02mm</span>"</span><span class="html-attribute"> <span class="html-attribute-name">file</span>="<span class="html-attribute-value">US20230233103A1-20230727-D00004.TIF</span>"</span><span class="html-attribute"> <span class="html-attribute-name">alt</span>="<span class="html-attribute-value">embedded image</span>"</span><span class="html-attribute"> <span class="html-attribute-name">img-content</span>="<span class="html-attribute-value">drawing</span>"</span><span class="html-attribute"> <span class="html-attribute-name">img-format</span>="<span class="html-attribute-value">tif</span>"</span>/&gt;</span></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figure&gt;</span></div></div><span>
</span><div class="folder" id="folder72"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figure<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">Fig-EMI-D00005</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">00005</span>"</span>&gt;</span></div><div class="opened"><span>
</span><div class="line"><span class="html-tag">&lt;img<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">EMI-D00005</span>"</span><span class="html-attribute"> <span class="html-attribute-name">he</span>="<span class="html-attribute-value">211.58mm</span>"</span><span class="html-attribute"> <span class="html-attribute-name">wi</span>="<span class="html-attribute-value">135.55mm</span>"</span><span class="html-attribute"> <span class="html-attribute-name">file</span>="<span class="html-attribute-value">US20230233103A1-20230727-D00005.TIF</span>"</span><span class="html-attribute"> <span class="html-attribute-name">alt</span>="<span class="html-attribute-value">embedded image</span>"</span><span class="html-attribute"> <span class="html-attribute-name">img-content</span>="<span class="html-attribute-value">drawing</span>"</span><span class="html-attribute"> <span class="html-attribute-name">img-format</span>="<span class="html-attribute-value">tif</span>"</span>/&gt;</span></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figure&gt;</span></div></div><span>
</span><div class="folder" id="folder73"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figure<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">Fig-EMI-D00006</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">00006</span>"</span>&gt;</span></div><div class="opened"><span>
</span><div class="line"><span class="html-tag">&lt;img<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">EMI-D00006</span>"</span><span class="html-attribute"> <span class="html-attribute-name">he</span>="<span class="html-attribute-value">232.16mm</span>"</span><span class="html-attribute"> <span class="html-attribute-name">wi</span>="<span class="html-attribute-value">130.30mm</span>"</span><span class="html-attribute"> <span class="html-attribute-name">file</span>="<span class="html-attribute-value">US20230233103A1-20230727-D00006.TIF</span>"</span><span class="html-attribute"> <span class="html-attribute-name">alt</span>="<span class="html-attribute-value">embedded image</span>"</span><span class="html-attribute"> <span class="html-attribute-name">img-content</span>="<span class="html-attribute-value">drawing</span>"</span><span class="html-attribute"> <span class="html-attribute-name">img-format</span>="<span class="html-attribute-value">tif</span>"</span>/&gt;</span></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figure&gt;</span></div></div><span>
</span><div class="folder" id="folder74"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figure<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">Fig-EMI-D00007</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">00007</span>"</span>&gt;</span></div><div class="opened"><span>
</span><div class="line"><span class="html-tag">&lt;img<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">EMI-D00007</span>"</span><span class="html-attribute"> <span class="html-attribute-name">he</span>="<span class="html-attribute-value">193.55mm</span>"</span><span class="html-attribute"> <span class="html-attribute-name">wi</span>="<span class="html-attribute-value">145.54mm</span>"</span><span class="html-attribute"> <span class="html-attribute-name">file</span>="<span class="html-attribute-value">US20230233103A1-20230727-D00007.TIF</span>"</span><span class="html-attribute"> <span class="html-attribute-name">alt</span>="<span class="html-attribute-value">embedded image</span>"</span><span class="html-attribute"> <span class="html-attribute-name">img-content</span>="<span class="html-attribute-value">drawing</span>"</span><span class="html-attribute"> <span class="html-attribute-name">img-format</span>="<span class="html-attribute-value">tif</span>"</span>/&gt;</span></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figure&gt;</span></div></div><span>
</span><div class="folder" id="folder75"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figure<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">Fig-EMI-D00008</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">00008</span>"</span>&gt;</span></div><div class="opened"><span>
</span><div class="line"><span class="html-tag">&lt;img<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">EMI-D00008</span>"</span><span class="html-attribute"> <span class="html-attribute-name">he</span>="<span class="html-attribute-value">145.97mm</span>"</span><span class="html-attribute"> <span class="html-attribute-name">wi</span>="<span class="html-attribute-value">142.49mm</span>"</span><span class="html-attribute"> <span class="html-attribute-name">orientation</span>="<span class="html-attribute-value">landscape</span>"</span><span class="html-attribute"> <span class="html-attribute-name">file</span>="<span class="html-attribute-value">US20230233103A1-20230727-D00008.TIF</span>"</span><span class="html-attribute"> <span class="html-attribute-name">alt</span>="<span class="html-attribute-value">embedded image</span>"</span><span class="html-attribute"> <span class="html-attribute-name">img-content</span>="<span class="html-attribute-value">drawing</span>"</span><span class="html-attribute"> <span class="html-attribute-name">img-format</span>="<span class="html-attribute-value">tif</span>"</span>/&gt;</span></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figure&gt;</span></div></div><span>
</span><div class="folder" id="folder76"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figure<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">Fig-EMI-D00009</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">00009</span>"</span>&gt;</span></div><div class="opened"><span>
</span><div class="line"><span class="html-tag">&lt;img<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">EMI-D00009</span>"</span><span class="html-attribute"> <span class="html-attribute-name">he</span>="<span class="html-attribute-value">218.27mm</span>"</span><span class="html-attribute"> <span class="html-attribute-name">wi</span>="<span class="html-attribute-value">154.35mm</span>"</span><span class="html-attribute"> <span class="html-attribute-name">file</span>="<span class="html-attribute-value">US20230233103A1-20230727-D00009.TIF</span>"</span><span class="html-attribute"> <span class="html-attribute-name">alt</span>="<span class="html-attribute-value">embedded image</span>"</span><span class="html-attribute"> <span class="html-attribute-name">img-content</span>="<span class="html-attribute-value">drawing</span>"</span><span class="html-attribute"> <span class="html-attribute-name">img-format</span>="<span class="html-attribute-value">tif</span>"</span>/&gt;</span></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figure&gt;</span></div></div><span>
</span><div class="folder" id="folder77"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figure<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">Fig-EMI-D00010</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">00010</span>"</span>&gt;</span></div><div class="opened"><span>
</span><div class="line"><span class="html-tag">&lt;img<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">EMI-D00010</span>"</span><span class="html-attribute"> <span class="html-attribute-name">he</span>="<span class="html-attribute-value">226.82mm</span>"</span><span class="html-attribute"> <span class="html-attribute-name">wi</span>="<span class="html-attribute-value">163.66mm</span>"</span><span class="html-attribute"> <span class="html-attribute-name">file</span>="<span class="html-attribute-value">US20230233103A1-20230727-D00010.TIF</span>"</span><span class="html-attribute"> <span class="html-attribute-name">alt</span>="<span class="html-attribute-value">embedded image</span>"</span><span class="html-attribute"> <span class="html-attribute-name">img-content</span>="<span class="html-attribute-value">drawing</span>"</span><span class="html-attribute"> <span class="html-attribute-name">img-format</span>="<span class="html-attribute-value">tif</span>"</span>/&gt;</span></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figure&gt;</span></div></div><span>
</span><div class="folder" id="folder78"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figure<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">Fig-EMI-D00011</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">00011</span>"</span>&gt;</span></div><div class="opened"><span>
</span><div class="line"><span class="html-tag">&lt;img<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">EMI-D00011</span>"</span><span class="html-attribute"> <span class="html-attribute-name">he</span>="<span class="html-attribute-value">225.98mm</span>"</span><span class="html-attribute"> <span class="html-attribute-name">wi</span>="<span class="html-attribute-value">142.66mm</span>"</span><span class="html-attribute"> <span class="html-attribute-name">file</span>="<span class="html-attribute-value">US20230233103A1-20230727-D00011.TIF</span>"</span><span class="html-attribute"> <span class="html-attribute-name">alt</span>="<span class="html-attribute-value">embedded image</span>"</span><span class="html-attribute"> <span class="html-attribute-name">img-content</span>="<span class="html-attribute-value">drawing</span>"</span><span class="html-attribute"> <span class="html-attribute-name">img-format</span>="<span class="html-attribute-value">tif</span>"</span>/&gt;</span></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figure&gt;</span></div></div><span>
</span><div class="folder" id="folder79"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figure<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">Fig-EMI-D00012</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">00012</span>"</span>&gt;</span></div><div class="opened"><span>
</span><div class="line"><span class="html-tag">&lt;img<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">EMI-D00012</span>"</span><span class="html-attribute"> <span class="html-attribute-name">he</span>="<span class="html-attribute-value">225.89mm</span>"</span><span class="html-attribute"> <span class="html-attribute-name">wi</span>="<span class="html-attribute-value">145.63mm</span>"</span><span class="html-attribute"> <span class="html-attribute-name">file</span>="<span class="html-attribute-value">US20230233103A1-20230727-D00012.TIF</span>"</span><span class="html-attribute"> <span class="html-attribute-name">alt</span>="<span class="html-attribute-value">embedded image</span>"</span><span class="html-attribute"> <span class="html-attribute-name">img-content</span>="<span class="html-attribute-value">drawing</span>"</span><span class="html-attribute"> <span class="html-attribute-name">img-format</span>="<span class="html-attribute-value">tif</span>"</span>/&gt;</span></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figure&gt;</span></div></div><span>
</span><div class="folder" id="folder80"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figure<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">Fig-EMI-D00013</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">00013</span>"</span>&gt;</span></div><div class="opened"><span>
</span><div class="line"><span class="html-tag">&lt;img<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">EMI-D00013</span>"</span><span class="html-attribute"> <span class="html-attribute-name">he</span>="<span class="html-attribute-value">239.44mm</span>"</span><span class="html-attribute"> <span class="html-attribute-name">wi</span>="<span class="html-attribute-value">156.80mm</span>"</span><span class="html-attribute"> <span class="html-attribute-name">file</span>="<span class="html-attribute-value">US20230233103A1-20230727-D00013.TIF</span>"</span><span class="html-attribute"> <span class="html-attribute-name">alt</span>="<span class="html-attribute-value">embedded image</span>"</span><span class="html-attribute"> <span class="html-attribute-name">img-content</span>="<span class="html-attribute-value">drawing</span>"</span><span class="html-attribute"> <span class="html-attribute-name">img-format</span>="<span class="html-attribute-value">tif</span>"</span>/&gt;</span></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figure&gt;</span></div></div><span>
</span><div class="folder" id="folder81"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figure<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">Fig-EMI-D00014</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">00014</span>"</span>&gt;</span></div><div class="opened"><span>
</span><div class="line"><span class="html-tag">&lt;img<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">EMI-D00014</span>"</span><span class="html-attribute"> <span class="html-attribute-name">he</span>="<span class="html-attribute-value">239.27mm</span>"</span><span class="html-attribute"> <span class="html-attribute-name">wi</span>="<span class="html-attribute-value">155.96mm</span>"</span><span class="html-attribute"> <span class="html-attribute-name">file</span>="<span class="html-attribute-value">US20230233103A1-20230727-D00014.TIF</span>"</span><span class="html-attribute"> <span class="html-attribute-name">alt</span>="<span class="html-attribute-value">embedded image</span>"</span><span class="html-attribute"> <span class="html-attribute-name">img-content</span>="<span class="html-attribute-value">drawing</span>"</span><span class="html-attribute"> <span class="html-attribute-name">img-format</span>="<span class="html-attribute-value">tif</span>"</span>/&gt;</span></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figure&gt;</span></div></div><span>
</span><div class="folder" id="folder82"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figure<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">Fig-EMI-D00015</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">00015</span>"</span>&gt;</span></div><div class="opened"><span>
</span><div class="line"><span class="html-tag">&lt;img<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">EMI-D00015</span>"</span><span class="html-attribute"> <span class="html-attribute-name">he</span>="<span class="html-attribute-value">172.47mm</span>"</span><span class="html-attribute"> <span class="html-attribute-name">wi</span>="<span class="html-attribute-value">147.32mm</span>"</span><span class="html-attribute"> <span class="html-attribute-name">file</span>="<span class="html-attribute-value">US20230233103A1-20230727-D00015.TIF</span>"</span><span class="html-attribute"> <span class="html-attribute-name">alt</span>="<span class="html-attribute-value">embedded image</span>"</span><span class="html-attribute"> <span class="html-attribute-name">img-content</span>="<span class="html-attribute-value">drawing</span>"</span><span class="html-attribute"> <span class="html-attribute-name">img-format</span>="<span class="html-attribute-value">tif</span>"</span>/&gt;</span></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figure&gt;</span></div></div><span>
</span><div class="folder" id="folder83"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figure<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">Fig-EMI-D00016</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">00016</span>"</span>&gt;</span></div><div class="opened"><span>
</span><div class="line"><span class="html-tag">&lt;img<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">EMI-D00016</span>"</span><span class="html-attribute"> <span class="html-attribute-name">he</span>="<span class="html-attribute-value">194.73mm</span>"</span><span class="html-attribute"> <span class="html-attribute-name">wi</span>="<span class="html-attribute-value">151.30mm</span>"</span><span class="html-attribute"> <span class="html-attribute-name">file</span>="<span class="html-attribute-value">US20230233103A1-20230727-D00016.TIF</span>"</span><span class="html-attribute"> <span class="html-attribute-name">alt</span>="<span class="html-attribute-value">embedded image</span>"</span><span class="html-attribute"> <span class="html-attribute-name">img-content</span>="<span class="html-attribute-value">drawing</span>"</span><span class="html-attribute"> <span class="html-attribute-name">img-format</span>="<span class="html-attribute-value">tif</span>"</span>/&gt;</span></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figure&gt;</span></div></div><span>
</span><div class="folder" id="folder84"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figure<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">Fig-EMI-D00017</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">00017</span>"</span>&gt;</span></div><div class="opened"><span>
</span><div class="line"><span class="html-tag">&lt;img<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">EMI-D00017</span>"</span><span class="html-attribute"> <span class="html-attribute-name">he</span>="<span class="html-attribute-value">182.20mm</span>"</span><span class="html-attribute"> <span class="html-attribute-name">wi</span>="<span class="html-attribute-value">149.52mm</span>"</span><span class="html-attribute"> <span class="html-attribute-name">orientation</span>="<span class="html-attribute-value">landscape</span>"</span><span class="html-attribute"> <span class="html-attribute-name">file</span>="<span class="html-attribute-value">US20230233103A1-20230727-D00017.TIF</span>"</span><span class="html-attribute"> <span class="html-attribute-name">alt</span>="<span class="html-attribute-value">embedded image</span>"</span><span class="html-attribute"> <span class="html-attribute-name">img-content</span>="<span class="html-attribute-value">drawing</span>"</span><span class="html-attribute"> <span class="html-attribute-name">img-format</span>="<span class="html-attribute-value">tif</span>"</span>/&gt;</span></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figure&gt;</span></div></div><span>
</span><div class="folder" id="folder85"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figure<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">Fig-EMI-D00018</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">00018</span>"</span>&gt;</span></div><div class="opened"><span>
</span><div class="line"><span class="html-tag">&lt;img<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">EMI-D00018</span>"</span><span class="html-attribute"> <span class="html-attribute-name">he</span>="<span class="html-attribute-value">145.03mm</span>"</span><span class="html-attribute"> <span class="html-attribute-name">wi</span>="<span class="html-attribute-value">142.41mm</span>"</span><span class="html-attribute"> <span class="html-attribute-name">file</span>="<span class="html-attribute-value">US20230233103A1-20230727-D00018.TIF</span>"</span><span class="html-attribute"> <span class="html-attribute-name">alt</span>="<span class="html-attribute-value">embedded image</span>"</span><span class="html-attribute"> <span class="html-attribute-name">img-content</span>="<span class="html-attribute-value">drawing</span>"</span><span class="html-attribute"> <span class="html-attribute-name">img-format</span>="<span class="html-attribute-value">tif</span>"</span>/&gt;</span></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figure&gt;</span></div></div><span>
</span><div class="folder" id="folder86"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figure<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">Fig-EMI-D00019</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">00019</span>"</span>&gt;</span></div><div class="opened"><span>
</span><div class="line"><span class="html-tag">&lt;img<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">EMI-D00019</span>"</span><span class="html-attribute"> <span class="html-attribute-name">he</span>="<span class="html-attribute-value">189.31mm</span>"</span><span class="html-attribute"> <span class="html-attribute-name">wi</span>="<span class="html-attribute-value">155.11mm</span>"</span><span class="html-attribute"> <span class="html-attribute-name">file</span>="<span class="html-attribute-value">US20230233103A1-20230727-D00019.TIF</span>"</span><span class="html-attribute"> <span class="html-attribute-name">alt</span>="<span class="html-attribute-value">embedded image</span>"</span><span class="html-attribute"> <span class="html-attribute-name">img-content</span>="<span class="html-attribute-value">drawing</span>"</span><span class="html-attribute"> <span class="html-attribute-name">img-format</span>="<span class="html-attribute-value">tif</span>"</span>/&gt;</span></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figure&gt;</span></div></div><span>
</span><div class="folder" id="folder87"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figure<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">Fig-EMI-D00020</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">00020</span>"</span>&gt;</span></div><div class="opened"><span>
</span><div class="line"><span class="html-tag">&lt;img<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">EMI-D00020</span>"</span><span class="html-attribute"> <span class="html-attribute-name">he</span>="<span class="html-attribute-value">224.79mm</span>"</span><span class="html-attribute"> <span class="html-attribute-name">wi</span>="<span class="html-attribute-value">158.16mm</span>"</span><span class="html-attribute"> <span class="html-attribute-name">file</span>="<span class="html-attribute-value">US20230233103A1-20230727-D00020.TIF</span>"</span><span class="html-attribute"> <span class="html-attribute-name">alt</span>="<span class="html-attribute-value">embedded image</span>"</span><span class="html-attribute"> <span class="html-attribute-name">img-content</span>="<span class="html-attribute-value">drawing</span>"</span><span class="html-attribute"> <span class="html-attribute-name">img-format</span>="<span class="html-attribute-value">tif</span>"</span>/&gt;</span></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figure&gt;</span></div></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/drawings&gt;</span></div></div><span>
</span><div class="folder" id="folder88"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;description<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">description</span>"</span>&gt;</span></div><div class="opened"><span>
</span><div class="line"><span class="comment html-comment">&lt;?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;heading<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">h-0001</span>"</span><span class="html-attribute"> <span class="html-attribute-name">level</span>="<span class="html-attribute-value">1</span>"</span>&gt;</span><span>CROSS REFERENCE TO RELATED APPLICATIONS</span><span class="html-tag">&lt;/heading&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0002</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0001</span>"</span>&gt;</span><span>This application is a Continuation of International Patent Application No. PCT/CN2021/081931, filed on Mar. 19, 2021, the entire contents of each of which are hereby incorporated by references.</span><span class="html-tag">&lt;/p&gt;</span></div><span>
</span><div class="line"><span class="comment html-comment">&lt;?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?&gt;</span></div><span>
</span><div class="line"><span class="comment html-comment">&lt;?summary-of-invention description="Summary of Invention" end="lead"?&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;heading<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">h-0002</span>"</span><span class="html-attribute"> <span class="html-attribute-name">level</span>="<span class="html-attribute-value">1</span>"</span>&gt;</span><span>TECHNOLOGY FIELD</span><span class="html-tag">&lt;/heading&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0003</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0002</span>"</span>&gt;</span><span>The present disclosure relates to a technical field of wearable devices, and in particular, to a motion monitoring method and system.</span><span class="html-tag">&lt;/p&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;heading<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">h-0003</span>"</span><span class="html-attribute"> <span class="html-attribute-name">level</span>="<span class="html-attribute-value">1</span>"</span>&gt;</span><span>BACKGROUND</span><span class="html-tag">&lt;/heading&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0004</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0003</span>"</span>&gt;</span><span>With people concerned about scientific exercise and physical health, motion monitoring devices are developing tremendously. At present, the motion monitoring devices mainly monitor some of the physiological parameter information (e.g., heart rate, body temperature, step frequency, blood oxygen, etc.) of a user during motion, but cannot accurately monitor user's movement and provide feedback on the movement. In practical scenarios, a process of monitoring and feeding the users' movement back often requires the participation of live professionals. For example, the user in the fitness scenario can only correct their movement under the guidance of a fitness instructor.</span><span class="html-tag">&lt;/p&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0005</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0004</span>"</span>&gt;</span><span>Therefore, it is desirable to provide a motion monitoring device that can guide a person's motion and thereby helping the user achieve more scientifically exact exercises.</span><span class="html-tag">&lt;/p&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;heading<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">h-0004</span>"</span><span class="html-attribute"> <span class="html-attribute-name">level</span>="<span class="html-attribute-value">1</span>"</span>&gt;</span><span>SUMMARY</span><span class="html-tag">&lt;/heading&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0006</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0005</span>"</span>&gt;</span><span>According to the embodiments of the present disclosure, a motion monitoring method is provided, including: obtaining a movement signal of a user during motion, the movement signal including at least an electromyographic signal or an attitude signal; and monitoring, at least based on feature information corresponding to the electromyographic signal or feature information corresponding to the attitude signal, a movement of the user during motion.</span><span class="html-tag">&lt;/p&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0007</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0006</span>"</span>&gt;</span><span>In some embodiments, the monitoring, at least based on feature information corresponding to the electromyographic signal or feature information corresponding to the attitude signal, a movement of the user during motion: segmenting, based on the feature information corresponding to the electromyographic signal or the feature information corresponding to the attitude signal, the movement signal; and monitoring, based on at least one segment of the movement signal, the movement of the user during motion.</span><span class="html-tag">&lt;/p&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0008</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0007</span>"</span>&gt;</span><span>In some embodiments, the feature information corresponding to the electromyographic signal includes at least frequency information or amplitude information, and the feature information corresponding to the attitude signal includes at least one of an angular velocity direction, an angular velocity value, an acceleration of an angular velocity, an angle, displacement information, and stress.</span><span class="html-tag">&lt;/p&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0009</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0008</span>"</span>&gt;</span><span>In some embodiments, the segmenting, based on the feature information corresponding to the electromyographic signal or the feature information corresponding to the attitude signal, the movement signal includes: determining, based on a time domain window of the electromyographic signal or the attitude signal, at least one target feature point from the time domain window according to a preset condition; and segmenting, based on the at least one target feature point, the movement signal.</span><span class="html-tag">&lt;/p&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0010</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0009</span>"</span>&gt;</span><span>In some embodiments, the at least one target feature point includes one of a movement start point, a movement middle point, and a movement end point.</span><span class="html-tag">&lt;/p&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0011</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0010</span>"</span>&gt;</span><span>In some embodiments, the preset condition includes a change in the angular velocity direction corresponding to the attitude signal, the angular velocity corresponding to the attitude signal being greater than or equal to an angular velocity threshold, a changed value of the angular velocity value corresponding to the attitude signal being an extreme value, the angle corresponding to the attitude signal reaching an angular threshold, and the amplitude information corresponding to the electromyographic signal being greater than or equal to one or more electromyographic thresholds.</span><span class="html-tag">&lt;/p&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0012</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0011</span>"</span>&gt;</span><span>In some embodiments, the preset condition further includes the acceleration of the angular velocity corresponding to the attitude signal being continuously greater than or equal to an acceleration threshold of the angular velocity for a first specific time range.</span><span class="html-tag">&lt;/p&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0013</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0012</span>"</span>&gt;</span><span>In some embodiments, the preset condition further includes an amplitude corresponding to the electromyographic signal being continuously greater than the one or more electromyographic thresholds for a second specific time range.</span><span class="html-tag">&lt;/p&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0014</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0013</span>"</span>&gt;</span><span>In some embodiments, the monitoring, at least based on feature information corresponding to the electromyographic signal or feature information corresponding to an attitude signal, a movement of the user during motion includes: pre-processing the electromyographic signal in a frequency domain or a time domain; obtaining, based on the pre-processed electromyographic signal, the feature information corresponding to the electromyographic signal; and monitoring, according to the feature information corresponding to the electromyographic signal or the feature information corresponding to the attitude signal, the movement of the user during motion.</span><span class="html-tag">&lt;/p&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0015</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0014</span>"</span>&gt;</span><span>In some embodiments, the pre-processing of the electromyographic signal in a frequency domain or a time domain includes: filtering the electromyographic signal to select components of the electromyographic signal in a specific frequency range in the frequency domain.</span><span class="html-tag">&lt;/p&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0016</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0015</span>"</span>&gt;</span><span>In some embodiments, the pre-processing of the electromyographic signal in a frequency domain or a time domain includes: performing a signal correction process on the electromyographic signal in the time domain.</span><span class="html-tag">&lt;/p&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0017</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0016</span>"</span>&gt;</span><span>In some embodiments, the performing a signal correction processing on the electromyographic signal in the time domain includes: determining a singularity in the electromyographic signal, wherein the singularity corresponds to an abrupt signal of the electromyographic signal; and performing the signal correction processing on the singularity in the electromyographic signal.</span><span class="html-tag">&lt;/p&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0018</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0017</span>"</span>&gt;</span><span>In some embodiments, the performing the signal correction processing on the singularity in the electromyographic signal includes removing the singularity, or correcting the singularity according to a signal around the singularity.</span><span class="html-tag">&lt;/p&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0019</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0018</span>"</span>&gt;</span><span>In some embodiments, the singularity includes a burr signal, the determining the singularity in the electromyographic signal includes: selecting, based on the time domain window of the electromyographic signal, different time windows from the time domain window of the electromyographic signal, wherein the different time windows respectively cover different time ranges; and determining, based on the feature information corresponding to the electromyographic signal in the different time windows, the burr signal.</span><span class="html-tag">&lt;/p&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0020</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0019</span>"</span>&gt;</span><span>In some embodiments, the method further includes determining, based on the attitude signal, the feature information corresponding to the attitude signal, wherein the attitude signal includes coordinate information in at least one original coordinate system; determining, based on the attitude signal, the feature information corresponding to the attitude signal includes: obtaining a target coordinate system and a conversion relationship between the target coordinate system and the at least one original coordinate system; converting, based on the conversion relationship, the coordinate information in the at least one original coordinate system to coordinate information in the target coordinate system; and determining, based on the coordinate information in the target coordinate system, the feature information corresponding to the attitude signal.</span><span class="html-tag">&lt;/p&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0021</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0020</span>"</span>&gt;</span><span>In some embodiments, the attitude signal includes coordinate information generated by at least two sensors, the at least two sensors are located at different motion parts of the user and correspond to different original coordinate systems, the determining, based on the attitude signal, the feature information corresponding to the attitude signal includes: determining feature information corresponding to each of the at least two sensors based on the conversion relationship between different original coordinate systems and the target coordinate system; and determining, based on the feature information respectively corresponding to the at least two sensors, a relative motion between the motion parts of the user.</span><span class="html-tag">&lt;/p&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0022</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0021</span>"</span>&gt;</span><span>In some embodiments, the conversion relationship between the at least one original coordinate system and the target coordinate system is obtained by a calibration process, the calibration process includes: constructing a specific coordinate system, the specific coordinate system being related to an orientation of the user during the calibration process; obtaining first coordinate information of the at least one original coordinate system when the user is in a first pose; obtaining second coordinate information of the at least one original coordinate system when the user is in a second pose; and determining the conversion relationship between the at least one original coordinate system and the specific coordinate system according to the first coordinate information, the second coordinate information, and the specific coordinate system.</span><span class="html-tag">&lt;/p&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0023</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0022</span>"</span>&gt;</span><span>In some embodiments, the calibration process further includes: obtaining a conversion relationship between the specific coordinate system and the target coordinate system; and determining, according to the conversion relationship between the at least one original coordinate system and the specific coordinate system as well as the conversion relationship between the specific coordinate system and target coordinate system, the conversion relationship between the at least one original coordinate system and the target coordinate system.</span><span class="html-tag">&lt;/p&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0024</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0023</span>"</span>&gt;</span><span>In some embodiments, the target coordinate system changes as the user's orientation changes.</span><span class="html-tag">&lt;/p&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0025</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0024</span>"</span>&gt;</span><span>According to another aspect of the present disclosure, a method of training a movement recognition model is provided, including: obtaining sample information, the sample information including a movement signal of a user during motion, the movement signal including at least feature information corresponding to an electromyographic signal and feature information corresponding to an attitude signal; and training, based on the sample information, the movement recognition model.</span><span class="html-tag">&lt;/p&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0026</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0025</span>"</span>&gt;</span><span>According to another aspect of the present disclosure, a motion monitoring and feedback method is provided, including: obtaining a movement signal of a user during motion, wherein the movement signal includes at least an electromyographic signal and an attitude signal; and monitoring, based on feature information corresponding to the electromyographic signal and feature information corresponding to the attitude signal, a movement of a user by a movement recognition model, and providing, based on an output of the movement recognition model, a movement feedback.</span><span class="html-tag">&lt;/p&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0027</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0026</span>"</span>&gt;</span><span>In some embodiments, the movement recognition model includes a trained machine learning model or a preset model.</span><span class="html-tag">&lt;/p&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0028</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0027</span>"</span>&gt;</span><span>In some embodiments, the movement feedback includes at least one of sending a prompt message, stimulating a movement part of the user, and outputting a motion record of the user during motion.</span><span class="html-tag">&lt;/p&gt;</span></div><span>
</span><div class="line"><span class="comment html-comment">&lt;?summary-of-invention description="Summary of Invention" end="tail"?&gt;</span></div><span>
</span><div class="line"><span class="comment html-comment">&lt;?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?&gt;</span></div><span>
</span><div class="folder" id="folder89"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;description-of-drawings&gt;</span></div><div class="opened"><span>
</span><div class="line"><span class="html-tag">&lt;heading<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">h-0005</span>"</span><span class="html-attribute"> <span class="html-attribute-name">level</span>="<span class="html-attribute-value">1</span>"</span>&gt;</span><span>BRIEF DESCRIPTION OF THE DRAWINGS</span><span class="html-tag">&lt;/heading&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0029</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0028</span>"</span>&gt;</span><span>The present disclosure is further illustrated in terms of exemplary embodiments, and these exemplary embodiments are described in detail with reference to the drawings. These embodiments are not limiting. In these embodiments, the same number indicates the same structure, wherein:</span><span class="html-tag">&lt;/p&gt;</span></div><span>
</span><div class="folder" id="folder90"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0030</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0029</span>"</span>&gt;</span></div><div class="opened"><div class="folder" id="folder91"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1</span><span class="html-tag">&lt;/b&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span> is a schematic diagram illustrating an application scenario of a motion monitoring system according to some embodiments of the present disclosure;</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder92"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0031</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0030</span>"</span>&gt;</span></div><div class="opened"><div class="folder" id="folder93"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>2</span><span class="html-tag">&lt;/b&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span> is a schematic diagram illustrating an exemplary hardware and/or software of a wearable device according to some embodiments of the present disclosure;</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder94"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0032</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0031</span>"</span>&gt;</span></div><div class="opened"><div class="folder" id="folder95"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>3</span><span class="html-tag">&lt;/b&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span> is a schematic diagram illustrating an exemplary hardware and/or software of a computing device according to some embodiments of the present disclosure;</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder96"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0033</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0032</span>"</span>&gt;</span></div><div class="opened"><div class="folder" id="folder97"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>4</span><span class="html-tag">&lt;/b&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span> is a structure diagram of an exemplary wearable device according to some embodiments of the present disclosure;</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder98"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0034</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0033</span>"</span>&gt;</span></div><div class="opened"><div class="folder" id="folder99"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>5</span><span class="html-tag">&lt;/b&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span> is a flowchart of an exemplary motion monitoring method according to some embodiments of the present disclosure;</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder100"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0035</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0034</span>"</span>&gt;</span></div><div class="opened"><div class="folder" id="folder101"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>6</span><span class="html-tag">&lt;/b&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span> is a flowchart of an exemplary process for monitoring a movement of user motion according to some embodiments of the present disclosure;</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder102"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0036</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0035</span>"</span>&gt;</span></div><div class="opened"><div class="folder" id="folder103"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>7</span><span class="html-tag">&lt;/b&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span> is a flowchart of an exemplary process for segmenting a movement signal according to some embodiments of the present disclosure;</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder104"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0037</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0036</span>"</span>&gt;</span></div><div class="opened"><div class="folder" id="folder105"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>8</span><span class="html-tag">&lt;/b&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span> is a diagram illustrating exemplary normalized results of segmenting a movement according to some embodiments of the present disclosure;</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder106"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0038</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0037</span>"</span>&gt;</span></div><div class="opened"><div class="folder" id="folder107"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>9</span><span class="html-tag">&lt;/b&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span> is a flowchart of an exemplary process for pre-processing an electromyographic signal according to some embodiments of the present disclosure;</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder108"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0039</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0038</span>"</span>&gt;</span></div><div class="opened"><div class="folder" id="folder109"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>10</span><span class="html-tag">&lt;/b&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span> is a flow chart illustrating an exemplary burr signal according to some embodiments of the present disclosure;</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder110"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0040</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0039</span>"</span>&gt;</span></div><div class="opened"><div class="folder" id="folder111"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>11</span><span class="html-tag">&lt;/b&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span> is a flowchart of an exemplary process for determining feature information corresponding to an attitude signal according to some embodiments of the present disclosure;</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder112"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0041</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0040</span>"</span>&gt;</span></div><div class="opened"><div class="folder" id="folder113"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>12</span><span class="html-tag">&lt;/b&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span> is a flowchart of an exemplary process for determining relative motion between different motion parts of a user according to some embodiments of the present disclosure;</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder114"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0042</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0041</span>"</span>&gt;</span></div><div class="opened"><div class="folder" id="folder115"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>13</span><span class="html-tag">&lt;/b&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span> is a flowchart of an exemplary process for determining a conversion relationship between an original coordinate system to a particular coordinate system according to some embodiments of the present disclosure;</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder116"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0043</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0042</span>"</span>&gt;</span></div><div class="opened"><div class="folder" id="folder117"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>14</span><span class="html-tag">&lt;/b&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span> is a flowchart of an exemplary process for determining a conversion relationship between an original coordinate system and a target coordinate system according to some embodiments of the present disclosure;</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder118"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0044</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0043</span>"</span>&gt;</span></div><div class="opened"><div class="folder" id="folder119"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>15</span><span class="html-tag">&lt;/b&gt;</span></div><span>A</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span> is an exemplary vector coordinate diagram illustrating Euler angle data in an original coordinate system at a position of a small arm of a human body according to some embodiments of the present disclosure;</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder120"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0045</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0044</span>"</span>&gt;</span></div><div class="opened"><div class="folder" id="folder121"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>15</span><span class="html-tag">&lt;/b&gt;</span></div><span>B</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span> is an exemplary vector coordinate diagram illustrating Euler angle data in another original coordinate system for a position of a small arm of ae human body according to some embodiments of the present disclosure;</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder122"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0046</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0045</span>"</span>&gt;</span></div><div class="opened"><div class="folder" id="folder123"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>16</span><span class="html-tag">&lt;/b&gt;</span></div><span>A</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span> is an exemplary vector coordinate diagram of Euler angle data in a target coordinate system at a position of a small arm of a human body according to some embodiments of the present disclosure;</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder124"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0047</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0046</span>"</span>&gt;</span></div><div class="opened"><div class="folder" id="folder125"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>16</span><span class="html-tag">&lt;/b&gt;</span></div><span>B</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span> is an exemplary vector coordinate diagram of Euler angle data in a target coordinate system at another location of a small arm of a human body according to some embodiments of the present disclosure;</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder126"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0048</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0047</span>"</span>&gt;</span></div><div class="opened"><div class="folder" id="folder127"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>17</span><span class="html-tag">&lt;/b&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span> is an exemplary vector coordinate diagram of Euler angle data in a target coordinate system of a multi-sensor according to some embodiments of the present disclosure;</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder128"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0049</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0048</span>"</span>&gt;</span></div><div class="opened"><div class="folder" id="folder129"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>18</span><span class="html-tag">&lt;/b&gt;</span></div><span>A</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span> is a diagram illustrating exemplary results of an original angular velocity according to some embodiments of the present disclosure;</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder130"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0050</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0049</span>"</span>&gt;</span></div><div class="opened"><div class="folder" id="folder131"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>18</span><span class="html-tag">&lt;/b&gt;</span></div><span>B</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span> is a diagram illustrating exemplary results of an angular velocity after filtering processing according to some embodiments of the present disclosure;</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder132"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0051</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0050</span>"</span>&gt;</span></div><div class="opened"><div class="folder" id="folder133"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>19</span><span class="html-tag">&lt;/b&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span> is a flowchart illustrating an exemplary motion monitoring and feedback method according to some embodiments of the present disclosure; and</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder134"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0052</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0051</span>"</span>&gt;</span></div><div class="opened"><div class="folder" id="folder135"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>20</span><span class="html-tag">&lt;/b&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span> is a flowchart illustrating exemplary process for model training according to some embodiments of the present disclosure.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/description-of-drawings&gt;</span></div></div><span>
</span><div class="line"><span class="comment html-comment">&lt;?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?&gt;</span></div><span>
</span><div class="line"><span class="comment html-comment">&lt;?detailed-description description="Detailed Description" end="lead"?&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;heading<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">h-0006</span>"</span><span class="html-attribute"> <span class="html-attribute-name">level</span>="<span class="html-attribute-value">1</span>"</span>&gt;</span><span>DETAILED DESCRIPTION</span><span class="html-tag">&lt;/heading&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0053</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0052</span>"</span>&gt;</span><span>To more clearly illustrate the technical solutions related to the embodiments of the present disclosure, a brief introduction of the drawings referred to the description of the embodiments is provided below. Obviously, the accompanying drawing in the following description is merely some examples or embodiments of the present disclosure, for those skilled in the art, the present disclosure may further be applied in other similar situations according to the drawings without any creative effort. Unless obviously obtained from the context or the context illustrates otherwise, the same numeral in the drawings refers to the same structure or operation.</span><span class="html-tag">&lt;/p&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0054</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0053</span>"</span>&gt;</span><span>It will be understood that the term “system,” “device,” “unit,” and/or “module” used herein are one method to distinguish different components, elements, parts, sections or assemblies of different levels in ascending order. However, if other words may achieve the same purpose, the words may be replaced by other expressions.</span><span class="html-tag">&lt;/p&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0055</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0054</span>"</span>&gt;</span><span>As used in the disclosure and the appended claims, the singular forms “a,” “an,” and “the” include plural referents unless the content clearly dictates otherwise. Generally speaking, the terms “comprise,” “comprises,” and/or “comprising,” “include,” “includes,” and/or “including,” only imply that the clearly identified steps and elements are included, these steps and elements may not constitute an exclusive list, and the method or device may further include other steps or elements.</span><span class="html-tag">&lt;/p&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0056</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0055</span>"</span>&gt;</span><span>Flowcharts are used throughout the present disclosure to illustrate the operations performed by the system according to embodiments of the present disclosure. It should be understood that the preceding or following operations are not necessarily performed in precise order. Instead, the individual steps may be processed in reverse order or simultaneously. Other operations may be added to these processes or a step or steps of operations may be removed from these processes.</span><span class="html-tag">&lt;/p&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0057</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0056</span>"</span>&gt;</span><span>According to the present disclosure, a motion monitoring system is provided, which may obtain a movement signal of a user during motion. The movement signal includes at least an electromyographic signal, an attitude signal, an electro-cardio graphic signal, a respiratory rate signal, and the like. The motion monitoring system may monitor a movement of the user during motion based at least on feature information corresponding to the electromyographic signal or the feature information corresponding to an attitude signal. For example, the system may determine the type of movement of the user, the number of movement, the movement quality, movement time, or information of physiological parameters of the user when performing the movement through frequency information and amplitude information corresponding to the electromyographic signal, an angular velocity, an angular velocity direction and an angular velocity value of the angular velocity, an angle, displacement information, and stress, etc. corresponding to the attitude signal. In some embodiments, the motion monitoring system may further generate feedback to a user's fitness movement according to analysis results of the user's fitness movement to provide guidance to user's fitness. For example, when the user's fitness movement is not standard, the motion monitoring system can send a prompt message to the user (e.g., a voice prompt, a vibration prompt, current stimulation, etc.). The motion monitoring system may be applied to a wearable device (e.g., clothing, a wrist guard, a helmet), a medical testing device (e.g., an electromyography tester), a fitness device, etc. The motion monitoring system may accurately monitor and provide feedback on a user's movement by obtaining the movement signal of the user during motion without professional participation, which can improve the user's fitness efficiency and reduce a cost of the user fitness.</span><span class="html-tag">&lt;/p&gt;</span></div><span>
</span><div class="folder" id="folder136"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0058</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0057</span>"</span>&gt;</span></div><div class="opened"><div class="folder" id="folder137"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1</span><span class="html-tag">&lt;/b&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span> is a schematic diagram illustrating an application scenario of a motion monitoring system according to some embodiments of the present disclosure. As shown in </span><div class="folder" id="folder138"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1</span><span class="html-tag">&lt;/b&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span>, the motion monitoring system </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>100</span><span class="html-tag">&lt;/b&gt;</span></div><span> may include a processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span>, a network </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>120</span><span class="html-tag">&lt;/b&gt;</span></div><span>, a wearable device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>130</span><span class="html-tag">&lt;/b&gt;</span></div><span>, and a mobile terminal device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>140</span><span class="html-tag">&lt;/b&gt;</span></div><span>. The motion monitoring system </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>100</span><span class="html-tag">&lt;/b&gt;</span></div><span> may obtain a movement signal (e.g., an electromyographic signal, an attitude signal, an electro-cardio signal, a respiratory rate signal, etc.) representing a movement of user motion, and may monitor and provide feedback on the movement of the user during motion according to a user's movement signal.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder139"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0059</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0058</span>"</span>&gt;</span></div><div class="opened"><span>For example, the motion monitoring system </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>100</span><span class="html-tag">&lt;/b&gt;</span></div><span> may monitor and provide feedback on the movement of the user during fitness. When the user wears the wearable device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>130</span><span class="html-tag">&lt;/b&gt;</span></div><span> for fitness, the wearable device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>130</span><span class="html-tag">&lt;/b&gt;</span></div><span> may obtain the user's movement signal. The processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span> or a mobile terminal device may receive and analyze the user's movement signal to determine whether the user's fitness movement is standard, thereby monitoring the user's movement. Specifically, the monitoring of the user's movement may include determining a type of movement, a count of movement, quality of the movement, and timing of the movement, or information about the physiological parameters of the user at the time the movement is performed. Further, the motion monitoring system </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>100</span><span class="html-tag">&lt;/b&gt;</span></div><span> may generate feedback on the user's fitness movement according to the analysis results of the user's fitness movement to provide guidance to the user.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder140"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0060</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0059</span>"</span>&gt;</span></div><div class="opened"><span>Further, for example, the motion monitoring system </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>100</span><span class="html-tag">&lt;/b&gt;</span></div><span> may monitor and provide feedback on the user's movement while running. For example, when the user wears the wearable device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>130</span><span class="html-tag">&lt;/b&gt;</span></div><span> for running exercise, the motion monitoring system </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>100</span><span class="html-tag">&lt;/b&gt;</span></div><span> may monitor whether the user's running movement is standard and whether the running time meets a health standard. When a user's running time is too long or a running movement is incorrect, the fitness device may provide motion state to the user to prompt the user to adjust the running movement or the running time.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder141"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0061</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0060</span>"</span>&gt;</span></div><div class="opened"><span>In some embodiments, the processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span> may be configured to process information and/or data related to the user's movement. For example, the processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span> may receive the movement signal of the user (e.g., an electromyographic signal, an attitude signal, an electro-cardio signal, a respiratory rate signal, etc.) and further extract the feature information corresponding to the movement signal (e.g., feature information corresponding to the electromyographic signal in the movement signal, the feature information corresponding to the attitude signal). In some embodiments, the processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span> may perform a specific signal processing, such as signal segmentation, signal pre-processing (e.g., signal correction processing, filtering processing, etc.), etc., on the electromyographic signal or the attitude signal obtained by the wearable device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>130</span><span class="html-tag">&lt;/b&gt;</span></div><span>. In some embodiments, the processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span> may further determine whether the user movement is correct based on the user's movement signal. For example, the processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span> may determine whether the user movement is correct based on the feature information corresponding to the electromyographic signal (e.g., amplitude information, frequency information, etc.). For another example, the processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span> may determine whether the user movement is correct based on the feature information corresponding to the attitude signal (e.g., an angular velocity, a direction of angular velocity, an acceleration of angular velocity, an angle, displacement information, a stress, etc.). Further, for example, the processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span> may determine whether the user movement is correct based on the feature information corresponding to the electromyographic signal and the feature information corresponding to the attitude signal. In some embodiments, the processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span> may further determine whether information of physiological parameters of the user during motion meets the health standard. In some embodiments, the processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span> may further send a corresponding instruction configured to feed the user's movement back. For example, when the user is running and the motion monitoring system </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>100</span><span class="html-tag">&lt;/b&gt;</span></div><span> monitors that the user's running time is too long, the processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span> may send the instruction to the mobile terminal device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>140</span><span class="html-tag">&lt;/b&gt;</span></div><span> to prompt the user to adjust the running time. It should be noted that the feature information corresponding to the attitude signal is not limited to above angular velocity, the direction of angular velocity, the acceleration of angular velocity, the angle, the displacement information, and the stress, etc., but can also be other feature information. For example, when an attitude sensor is a strain gauge sensor, a bending angle and a bending direction at a user's joint may be obtained by measuring the resistance in a strain gauge sensor that varies with a stretch length.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder142"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0062</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0061</span>"</span>&gt;</span></div><div class="opened"><span>In some embodiments, the processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span> may be local or remote. For example, the processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span> may access information and/or materials stored in the wearable device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>130</span><span class="html-tag">&lt;/b&gt;</span></div><span> and/or the mobile terminal device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>140</span><span class="html-tag">&lt;/b&gt;</span></div><span> through the network </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>120</span><span class="html-tag">&lt;/b&gt;</span></div><span>. In some embodiments, the processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span> may be directly connected to the wearable device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>130</span><span class="html-tag">&lt;/b&gt;</span></div><span> and/or the mobile terminal device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>140</span><span class="html-tag">&lt;/b&gt;</span></div><span> to access the information and/or materials stored therein. For example, the processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span> may be located in the wearable device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>130</span><span class="html-tag">&lt;/b&gt;</span></div><span> and implement the information interact with the mobile terminal device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>140</span><span class="html-tag">&lt;/b&gt;</span></div><span> through the network </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>120</span><span class="html-tag">&lt;/b&gt;</span></div><span>. Further, for example, the processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span> may be located in the mobile terminal device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>140</span><span class="html-tag">&lt;/b&gt;</span></div><span> and implement the information interact with the wearable device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>130</span><span class="html-tag">&lt;/b&gt;</span></div><span> through a network. In some embodiments, the processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span> may be executed on a cloud platform. For example, the cloud platform may include one of a private cloud, a public cloud, a hybrid cloud, a community cloud, a decentralized cloud, an internal cloud, or any combination thereof.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder143"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0063</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0062</span>"</span>&gt;</span></div><div class="opened"><span>In some embodiments, the processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span> may process data and/or information related to motion monitoring to perform one or more of the functions described in the present disclosure. In some embodiments, the processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span> may obtain the movement signal collected by the wearable device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>130</span><span class="html-tag">&lt;/b&gt;</span></div><span> while the user is in motion. In some embodiments, the processing device may send a control instruction to the wearable device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>130</span><span class="html-tag">&lt;/b&gt;</span></div><span> or the mobile terminal device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>140</span><span class="html-tag">&lt;/b&gt;</span></div><span>. The control instruction may control an on/off state of the wearable device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>130</span><span class="html-tag">&lt;/b&gt;</span></div><span> and its respective sensor, and also control the mobile terminal device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>140</span><span class="html-tag">&lt;/b&gt;</span></div><span> to send a prompt message. In some embodiments, processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span> may include one or more sub-processing devices (e.g., a single-core processing device or a multi-core processing device). Merely by way of example, the processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span> may include a central processing unit (CPU), an application-specific integrated circuit (ASIC), an application-specific instruction processor (ASIP), a graphic processing unit (GPU), a physics processing Unit (PPU), a digital signal processor (DSP), a field-programmable gate array (FPGA), an programmable logic device (PLD), a controller, a microcontroller unit Reduced Instruction Set Computer (RISC), and a microprocessor, etc. or any combination of the above.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder144"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0064</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0063</span>"</span>&gt;</span></div><div class="opened"><span>The network </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>120</span><span class="html-tag">&lt;/b&gt;</span></div><span> may facilitate an exchange of data and/or information in the motion monitoring system </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>100</span><span class="html-tag">&lt;/b&gt;</span></div><span>. In some embodiments, one or more components of the motion monitoring system </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>100</span><span class="html-tag">&lt;/b&gt;</span></div><span> (e.g., the processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span>, the wearable device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>130</span><span class="html-tag">&lt;/b&gt;</span></div><span>, the mobile terminal device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>140</span><span class="html-tag">&lt;/b&gt;</span></div><span>) may send the data and/or the information to other components of the motion monitoring system </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>100</span><span class="html-tag">&lt;/b&gt;</span></div><span> through network </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>120</span><span class="html-tag">&lt;/b&gt;</span></div><span>. For example, the movement signal collected by the wearable device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>130</span><span class="html-tag">&lt;/b&gt;</span></div><span> may be transmitted to the processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span> through the network </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>120</span><span class="html-tag">&lt;/b&gt;</span></div><span>. For another example, confirmation results regarding the movement signal in the processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span> may be transmitted to the mobile terminal device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>140</span><span class="html-tag">&lt;/b&gt;</span></div><span> through the network </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>120</span><span class="html-tag">&lt;/b&gt;</span></div><span>. In some embodiments, the network </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>120</span><span class="html-tag">&lt;/b&gt;</span></div><span> may be any type of a wired or wireless network. For example, the network </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>120</span><span class="html-tag">&lt;/b&gt;</span></div><span> may include a cable network, a wired network, a fiber optic network, a telecommunications network, an internal network, an inter-network, a regional network (LAN), a wide area network (WAN), a wireless regional network (WLAN), a metropolitan area network (MAN), a public switched telephone network (PSTN), a Bluetooth™ network, a ZigBee™ network, and a near field communication (NFC) network, or any combination of the above. In some embodiments, the network </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>120</span><span class="html-tag">&lt;/b&gt;</span></div><span> may include one or more network entry and exit points. For example, network </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>120</span><span class="html-tag">&lt;/b&gt;</span></div><span> may include wired or wireless network entry and exit points, such as a base station and/or inter-network exchange points </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>120</span><span class="html-tag">&lt;/b&gt;</span></div><span>-</span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1</span><span class="html-tag">&lt;/b&gt;</span></div><span>, </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>120</span><span class="html-tag">&lt;/b&gt;</span></div><span>-</span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>2</span><span class="html-tag">&lt;/b&gt;</span></div><span>, . . . , through the entry and exit points, one or more components of motion monitoring system </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>100</span><span class="html-tag">&lt;/b&gt;</span></div><span> may connect to the network </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>120</span><span class="html-tag">&lt;/b&gt;</span></div><span> to exchange the data and/or the information.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder145"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0065</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0064</span>"</span>&gt;</span></div><div class="opened"><span>The wearable device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>130</span><span class="html-tag">&lt;/b&gt;</span></div><span> is a garment or device that has a wearable function. In some embodiments, the wearable device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>130</span><span class="html-tag">&lt;/b&gt;</span></div><span> may include, but is not limited to, an upper garment device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>130</span><span class="html-tag">&lt;/b&gt;</span></div><span>-</span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1</span><span class="html-tag">&lt;/b&gt;</span></div><span>, a pant device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>130</span><span class="html-tag">&lt;/b&gt;</span></div><span>-</span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>2</span><span class="html-tag">&lt;/b&gt;</span></div><span>, a wrist guard device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>130</span><span class="html-tag">&lt;/b&gt;</span></div><span>-</span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>3</span><span class="html-tag">&lt;/b&gt;</span></div><span>, and a shoe </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>130</span><span class="html-tag">&lt;/b&gt;</span></div><span>-</span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>4</span><span class="html-tag">&lt;/b&gt;</span></div><span>, etc. In some embodiments, wearable device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>130</span><span class="html-tag">&lt;/b&gt;</span></div><span> may include a plurality of sensors. The sensors may obtain various movement signals (e.g., electromyographic signals, attitude signals, temperature information, heart rate, electro-cardio signals, etc.) from the user during motion. In some embodiments, the sensors may include, but are not limited to, one or more of an electromyographic sensor, an attitude sensor, a temperature sensor, a humidity sensor, an electro-cardio sensor, an oxygen saturation sensor, a Hall sensor, a Pico electric sensor, and a rotation sensor, etc. For example, an electromyographic sensor may be provided at a human muscle location (e.g., biceps, triceps, latissimus dorsi, trapezius, etc.) in an upper garment device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>130</span><span class="html-tag">&lt;/b&gt;</span></div><span>-</span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1</span><span class="html-tag">&lt;/b&gt;</span></div><span>, and the electromyographic sensor may fit to user's skin and collect the electromyographic signal from the user during motion. For example, the upper garment device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>130</span><span class="html-tag">&lt;/b&gt;</span></div><span>-</span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1</span><span class="html-tag">&lt;/b&gt;</span></div><span> may be provided with an electro-cardio sensor near the left pectoral muscle of the human body, and the electromyographic sensor may collect the electro-cardio signal of the user. Further, for example, the attitude sensor may be provided at a human body muscle location (e.g., gluteus maximus, lateral femoris, medial femoris, gastrocnemius, etc.) in a pants device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>130</span><span class="html-tag">&lt;/b&gt;</span></div><span>-</span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>2</span><span class="html-tag">&lt;/b&gt;</span></div><span>, and the attitude sensor may collect a user's attitude signal. In some embodiments, the wearable device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>130</span><span class="html-tag">&lt;/b&gt;</span></div><span> may further provide feedback on the user's movement. For example, if the user's movement of a body part during motion does not meet the standard, the electromyographic sensor corresponding to that part may generate a stimulation signal (e.g., a current stimulation or a strike signal) to prompt the user.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder146"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0066</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0065</span>"</span>&gt;</span></div><div class="opened"><span>It should be noted that the wearable device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>130</span><span class="html-tag">&lt;/b&gt;</span></div><span> is not limited to the upper garment device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>130</span><span class="html-tag">&lt;/b&gt;</span></div><span>-</span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1</span><span class="html-tag">&lt;/b&gt;</span></div><span>, the pants device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>130</span><span class="html-tag">&lt;/b&gt;</span></div><span>-</span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>2</span><span class="html-tag">&lt;/b&gt;</span></div><span>, a wrist guard device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>130</span><span class="html-tag">&lt;/b&gt;</span></div><span>-</span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>3</span><span class="html-tag">&lt;/b&gt;</span></div><span>, and a shoe device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>130</span><span class="html-tag">&lt;/b&gt;</span></div><span>-</span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>4</span><span class="html-tag">&lt;/b&gt;</span></div><span> shown in </span><div class="folder" id="folder147"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1</span><span class="html-tag">&lt;/b&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span>, but may further include a device that are applied to other devices that require motion monitoring, such as, for example, helmet devices, knee pads, etc., which will not be limited herein, and any device that can use the motion monitoring method contained in the disclosure is within the scope of protection of the present disclosure.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder148"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0067</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0066</span>"</span>&gt;</span></div><div class="opened"><span>In some embodiments, the mobile terminal device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>140</span><span class="html-tag">&lt;/b&gt;</span></div><span> may access information or data in the motion monitoring system </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>100</span><span class="html-tag">&lt;/b&gt;</span></div><span>. In some embodiments, the mobile terminal device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>140</span><span class="html-tag">&lt;/b&gt;</span></div><span> may receive motion data processed by the processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span>, and feed motion records back based on processed motion data. An exemplary feedback manner may include, but are not limited to, a voice prompt, an image prompts, a video display, and a text prompt, etc. In some embodiments, the user may obtain movement records during an own movement through the mobile terminal device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>140</span><span class="html-tag">&lt;/b&gt;</span></div><span>. For example, the mobile terminal device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>140</span><span class="html-tag">&lt;/b&gt;</span></div><span> may be connected to the wearable device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>130</span><span class="html-tag">&lt;/b&gt;</span></div><span> through the network </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>120</span><span class="html-tag">&lt;/b&gt;</span></div><span> (e.g., the wired connection, the wireless connection), and the user may obtain the movement records during the user's movement through the mobile terminal device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>140</span><span class="html-tag">&lt;/b&gt;</span></div><span>, which may be transmitted to the processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span> through the mobile terminal device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>140</span><span class="html-tag">&lt;/b&gt;</span></div><span>. In some embodiments, the mobile terminal device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>140</span><span class="html-tag">&lt;/b&gt;</span></div><span> may include a mobile device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>140</span><span class="html-tag">&lt;/b&gt;</span></div><span>-</span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1</span><span class="html-tag">&lt;/b&gt;</span></div><span>, a tablet </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>140</span><span class="html-tag">&lt;/b&gt;</span></div><span>-</span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>2</span><span class="html-tag">&lt;/b&gt;</span></div><span>, a laptop </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>140</span><span class="html-tag">&lt;/b&gt;</span></div><span>-</span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>3</span><span class="html-tag">&lt;/b&gt;</span></div><span>, etc., or any combination thereof. In some embodiments, mobile device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>140</span><span class="html-tag">&lt;/b&gt;</span></div><span>-</span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1</span><span class="html-tag">&lt;/b&gt;</span></div><span> may include a cell phone, a smart home device, a smart mobility device, a virtual reality device, an augmented reality device, etc., or any combination thereof. In some embodiments, the smart home device may include a control device of a smart appliance, a smart monitoring device, a smart TV, a smart camera, etc., or any combination thereof. In some embodiments, the smart mobility device may include a smart phone, a personal digital assistant (PDA), a gaming device, a navigation device, a POS device, etc., or any combination thereof. In some embodiments, a virtual reality device and/or an augmented reality device may include a virtual reality helmet, virtual reality glasses, a virtual reality eye-mask, an augmented reality helmet, an augmented reality glasses, and an augmented reality eye-mask, etc., or any combination thereof.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder149"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0068</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0067</span>"</span>&gt;</span></div><div class="opened"><span>In some embodiments, the motion monitoring system </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>100</span><span class="html-tag">&lt;/b&gt;</span></div><span> may further include a database. The database may store the information (e.g., a threshold condition of an initially set, etc.) and/or the instruction (e.g., a feedback instruction). In some embodiments, the database may store the information obtained from the wearable device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>130</span><span class="html-tag">&lt;/b&gt;</span></div><span> and/or the mobile terminal device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>140</span><span class="html-tag">&lt;/b&gt;</span></div><span>. In some embodiments, the database may store the information and/or the instruction configured for the processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span> to execute or use to perform the exemplary methods described in the present disclosure. In some embodiments, the database may include a mass storage, a removable memory, a volatile read-write memory (e.g., random access memory RAM), a read-only memory (ROM), etc., or any combination thereof. In some embodiments, the database may be implemented on a cloud platform. For example, the cloud platform may include the private cloud, the public cloud, the hybrid cloud, the community cloud, the decentralized cloud, the internal cloud, or any combination thereof.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder150"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0069</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0068</span>"</span>&gt;</span></div><div class="opened"><span>In some embodiments, the database may be connected to the network </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>120</span><span class="html-tag">&lt;/b&gt;</span></div><span> to communicate with one or more components of the motion monitoring system </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>100</span><span class="html-tag">&lt;/b&gt;</span></div><span> (e.g., the processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span>, the wearable device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>130</span><span class="html-tag">&lt;/b&gt;</span></div><span>, the mobile terminal device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>140</span><span class="html-tag">&lt;/b&gt;</span></div><span>, etc.). The one or more components of the motion monitoring system </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>100</span><span class="html-tag">&lt;/b&gt;</span></div><span> may access information or instruction stored in the database through the network </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>120</span><span class="html-tag">&lt;/b&gt;</span></div><span>. In some embodiments, the database may be directly connected or communicate with one or more components of the motion monitoring system </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>100</span><span class="html-tag">&lt;/b&gt;</span></div><span> (e.g., the processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span>, the wearable device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>130</span><span class="html-tag">&lt;/b&gt;</span></div><span>, the mobile terminal device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>140</span><span class="html-tag">&lt;/b&gt;</span></div><span>). In some embodiments, the database may be a part of the processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span>.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder151"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0070</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0069</span>"</span>&gt;</span></div><div class="opened"><div class="folder" id="folder152"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>2</span><span class="html-tag">&lt;/b&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span> is a schematic diagram illustrating an exemplary hardware and/or software of a wearable device according to some embodiments of the present disclosure. As shown in </span><div class="folder" id="folder153"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>2</span><span class="html-tag">&lt;/b&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span>, the wearable device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>130</span><span class="html-tag">&lt;/b&gt;</span></div><span> may include an obtaining module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>210</span><span class="html-tag">&lt;/b&gt;</span></div><span>, a processing module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>220</span><span class="html-tag">&lt;/b&gt;</span></div><span> (also referred to as a processor), a control module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>230</span><span class="html-tag">&lt;/b&gt;</span></div><span> (also referred to as a master, MCU, a controller), a communication module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>240</span><span class="html-tag">&lt;/b&gt;</span></div><span>, a power supply module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>250</span><span class="html-tag">&lt;/b&gt;</span></div><span>, and an input/output module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>260</span><span class="html-tag">&lt;/b&gt;</span></div><span>.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder154"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0071</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0070</span>"</span>&gt;</span></div><div class="opened"><span>The obtaining module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>210</span><span class="html-tag">&lt;/b&gt;</span></div><span> may be configured to obtain a movement signal of a user during motion. In some embodiments, the obtaining module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>210</span><span class="html-tag">&lt;/b&gt;</span></div><span> may include a sensor unit, and the sensor unit may be configured to obtain one or more movement signals while the user is in motion. In some embodiments, the sensor unit may include, but is not limited to, one or more electromyographic sensors, attitude sensors, cardiac sensors, respiration sensors, temperature sensors, humidity sensors, inertial sensors, blood oxygen saturation sensors, Hall sensors, piezoelectric sensors, and rotation sensors, and the like. In some embodiments, the movement signal may include one or more electromyographic signals, attitude signals, cardiac signals, respiratory rates, temperature signals, and humidity signals, etc. The sensor unit may be placed at different locations of the wearable device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>130</span><span class="html-tag">&lt;/b&gt;</span></div><span> according to a type of a movement signal to be obtained. For example, in some embodiments, the electromyographic sensor (also referred to as an electrode element) may be placed at a human muscle location, and the electromyographic sensor may be configured to collect the electromyographic signal of the user during motion. The electromyographic signal and its corresponding feature information (e.g., frequency information, amplitude information, etc.) may reflect a state of muscle during a user's movement. The attitude sensor may be provided at different locations on a human body (e.g., locations of the wearable device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>130</span><span class="html-tag">&lt;/b&gt;</span></div><span> corresponding to the torso, limbs, and joints), and the attitude sensor may be configured to capture the attitude signal of the user during the user's movement. The attitude signal and its corresponding feature information (e.g., angular velocity direction, angular velocity value, acceleration value of angular velocity, angle, displacement information, stress, etc.) may reflect the attitude of the user's movement. The electromyographic sensor may be set at a location on the circumferential side of the human chest, and the electromyographic sensor may be configured to collect electro cardio data of the user during motion. The respiration sensor may be arranged on a circumferential side of the body's chest, and the respiration sensor may be configured to collect respiration data (e.g., respiration rate, respiration amplitude, etc.) from the user during motion. The temperature sensor may be configured to collect temperature data (e.g., a body surface temperature) of the user during motion. The humidity sensor may be configured to collect humidity data of an external environment of the user during motion.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder155"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0072</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0071</span>"</span>&gt;</span></div><div class="opened"><span>The processing module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>220</span><span class="html-tag">&lt;/b&gt;</span></div><span> may process data from the obtaining module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>210</span><span class="html-tag">&lt;/b&gt;</span></div><span>, the control module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>230</span><span class="html-tag">&lt;/b&gt;</span></div><span>, the communication module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>240</span><span class="html-tag">&lt;/b&gt;</span></div><span>, the power supply module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>250</span><span class="html-tag">&lt;/b&gt;</span></div><span>, and/or the input/output module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>260</span><span class="html-tag">&lt;/b&gt;</span></div><span>. For example, the processing module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>220</span><span class="html-tag">&lt;/b&gt;</span></div><span> may process the movement signal of the user during a process of motion from the obtaining module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>210</span><span class="html-tag">&lt;/b&gt;</span></div><span>. In some embodiments, the processing module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>220</span><span class="html-tag">&lt;/b&gt;</span></div><span> may pre-process the movement signal (e.g., the electromyographic signal, the attitude signal) obtained by the obtaining module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>210</span><span class="html-tag">&lt;/b&gt;</span></div><span>. For example, the processing module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>220</span><span class="html-tag">&lt;/b&gt;</span></div><span> segments the electromyographic signal or the attitude signal of the user during motion. For another example, the processing module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>220</span><span class="html-tag">&lt;/b&gt;</span></div><span> may perform a pre-processing (e.g., a filtering processing, a signal correction processing) on the electromyographic signal of the user during motion to improve quality of the electromyographic signal. Further, for example, the processing module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>220</span><span class="html-tag">&lt;/b&gt;</span></div><span> may determine the feature information corresponding to the attitude signal based on a user's attitude signal during motion. In some embodiments, the processing module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>220</span><span class="html-tag">&lt;/b&gt;</span></div><span> may process an instruction or operation from an input/output module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>260</span><span class="html-tag">&lt;/b&gt;</span></div><span>. In some embodiments, processed data may be stored in a memory or a hard disk. In some embodiments, the processing module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>220</span><span class="html-tag">&lt;/b&gt;</span></div><span> may transmit its processed data to one or more components in the motion monitoring system </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>100</span><span class="html-tag">&lt;/b&gt;</span></div><span> through the communication module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>240</span><span class="html-tag">&lt;/b&gt;</span></div><span> or the network </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>120</span><span class="html-tag">&lt;/b&gt;</span></div><span>. For example, the processing module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>220</span><span class="html-tag">&lt;/b&gt;</span></div><span> may send monitoring results of the user during motion to the control module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>230</span><span class="html-tag">&lt;/b&gt;</span></div><span>, which may execute subsequent operations or instructions according to motion determination results.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder156"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0073</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0072</span>"</span>&gt;</span></div><div class="opened"><span>The control module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>230</span><span class="html-tag">&lt;/b&gt;</span></div><span> may be connected to other modules in the wearable device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>130</span><span class="html-tag">&lt;/b&gt;</span></div><span>. In some embodiments, the control module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>230</span><span class="html-tag">&lt;/b&gt;</span></div><span> may control an operation state of other modules (e.g., the communication module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>240</span><span class="html-tag">&lt;/b&gt;</span></div><span>, the power supply module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>250</span><span class="html-tag">&lt;/b&gt;</span></div><span>, the input/output module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>260</span><span class="html-tag">&lt;/b&gt;</span></div><span>) in the wearable device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>130</span><span class="html-tag">&lt;/b&gt;</span></div><span>. For example, the control module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>230</span><span class="html-tag">&lt;/b&gt;</span></div><span> may control a power supply state (e.g., a normal mode, a power saving mode), power supply time, and the like, of the power supply module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>250</span><span class="html-tag">&lt;/b&gt;</span></div><span>. When remaining power of the power supply module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>250</span><span class="html-tag">&lt;/b&gt;</span></div><span> reaches a certain threshold (e.g., 10%) or less, the control module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>230</span><span class="html-tag">&lt;/b&gt;</span></div><span> may control the power supply module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>250</span><span class="html-tag">&lt;/b&gt;</span></div><span> to enter a power saving mode or send a prompt message about replenishment of power. For another example, the control module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>230</span><span class="html-tag">&lt;/b&gt;</span></div><span> may control the input/output module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>260</span><span class="html-tag">&lt;/b&gt;</span></div><span> based on user's movement determination results, and further control the mobile terminal device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>140</span><span class="html-tag">&lt;/b&gt;</span></div><span> to send feedback results of the user's movement. When there is a problem with the user's movement (e.g., movement not meeting the standard), the control module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>230</span><span class="html-tag">&lt;/b&gt;</span></div><span> may control the input/output module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>260</span><span class="html-tag">&lt;/b&gt;</span></div><span> to control the mobile terminal device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>140</span><span class="html-tag">&lt;/b&gt;</span></div><span> to provide feedback to the user, allowing the user to understand own motion movement in real time and make some adjustments. In some embodiments, the control module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>230</span><span class="html-tag">&lt;/b&gt;</span></div><span> may also control one or more sensors or other modules in the obtaining module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>210</span><span class="html-tag">&lt;/b&gt;</span></div><span> to provide feedback to the human body. For example, when a muscle of the user is exercising too strong during motion, the control module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>230</span><span class="html-tag">&lt;/b&gt;</span></div><span> may control an electrode module at a location of the muscle to stimulate the user to prompt the user to adjust the movement in time.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder157"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0074</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0073</span>"</span>&gt;</span></div><div class="opened"><span>In some embodiments, the communication module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>240</span><span class="html-tag">&lt;/b&gt;</span></div><span> may be configured for an exchange of information or data. In some embodiments, the communication module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>240</span><span class="html-tag">&lt;/b&gt;</span></div><span> may be configured for communication between components (e.g., the obtaining module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>210</span><span class="html-tag">&lt;/b&gt;</span></div><span>, the processing module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>220</span><span class="html-tag">&lt;/b&gt;</span></div><span>, the control module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>230</span><span class="html-tag">&lt;/b&gt;</span></div><span>, the power supply module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>250</span><span class="html-tag">&lt;/b&gt;</span></div><span>, the input/output module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>260</span><span class="html-tag">&lt;/b&gt;</span></div><span>) within a wearable device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>130</span><span class="html-tag">&lt;/b&gt;</span></div><span>. For example, the obtaining module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>210</span><span class="html-tag">&lt;/b&gt;</span></div><span> may send a movement signal (e.g., the electromyographic signal, the attitude signal, etc.) to the communication module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>240</span><span class="html-tag">&lt;/b&gt;</span></div><span>, and the communication module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>240</span><span class="html-tag">&lt;/b&gt;</span></div><span> may send the movement signal to the processing module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>220</span><span class="html-tag">&lt;/b&gt;</span></div><span>. For example, the communication module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>240</span><span class="html-tag">&lt;/b&gt;</span></div><span> may send state information (e.g., a switch state) of the wearable device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>130</span><span class="html-tag">&lt;/b&gt;</span></div><span> to the processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span>, and the processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span> may monitor the wearable device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>130</span><span class="html-tag">&lt;/b&gt;</span></div><span> based on the state information. The communication module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>240</span><span class="html-tag">&lt;/b&gt;</span></div><span> may employ wired, wireless, and hybrid wired/wireless technologies. The wired technology may be based on one or more combinations of fiber optic cables such as metallic cables, hybrid cables, fiber optic cables, etc. The wireless technologies may include Bluetooth (Bluetooth™), wireless network (Wi-Fi), purple bee (ZigBee™), Near Field Communication (NFC), Radio Frequency Identification (RFID), cellular networks (including GSM, CDMA, 3G, 4G, 5G, etc.), and cellular-based Narrow Band Internet of Things (NBIoT), etc. In some embodiments, the communication module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>240</span><span class="html-tag">&lt;/b&gt;</span></div><span> may use one or more coding methods to encode transmitted information, for example, the coding methods may include phase coding, non-zeroing coding, differential Manchester coding, and the like. In some embodiments, the communication module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>240</span><span class="html-tag">&lt;/b&gt;</span></div><span> may select different transmission and encoding methods according to a type of data or a type of network to be transmitted. In some embodiments, the communication module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>240</span><span class="html-tag">&lt;/b&gt;</span></div><span> may include one or more communication interfaces for different communication methods. In some embodiments, illustrated other modules of the motion monitoring system </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>100</span><span class="html-tag">&lt;/b&gt;</span></div><span> may be dispersed on a plurality of devices, in this case, each of a plurality of other modules may each include one or more communication modules </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>240</span><span class="html-tag">&lt;/b&gt;</span></div><span> for an inter-module information transmission. In some embodiments, the communication module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>240</span><span class="html-tag">&lt;/b&gt;</span></div><span> may include a receiver and a transmitter. In other embodiments, the communication module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>240</span><span class="html-tag">&lt;/b&gt;</span></div><span> may be a transceiver.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder158"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0075</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0074</span>"</span>&gt;</span></div><div class="opened"><span>In some embodiments, the power supply module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>250</span><span class="html-tag">&lt;/b&gt;</span></div><span> may provide power to other components in the motion monitoring system </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>100</span><span class="html-tag">&lt;/b&gt;</span></div><span> (e.g., the obtaining module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>210</span><span class="html-tag">&lt;/b&gt;</span></div><span>, the processing module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>220</span><span class="html-tag">&lt;/b&gt;</span></div><span>, the control module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>230</span><span class="html-tag">&lt;/b&gt;</span></div><span>, the communication module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>240</span><span class="html-tag">&lt;/b&gt;</span></div><span>, and the input/output module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>260</span><span class="html-tag">&lt;/b&gt;</span></div><span>). The power supply module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>250</span><span class="html-tag">&lt;/b&gt;</span></div><span> may receive the control signal from the processing module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>220</span><span class="html-tag">&lt;/b&gt;</span></div><span> to control a power output of the wearable device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>130</span><span class="html-tag">&lt;/b&gt;</span></div><span>. For example, if the wearable device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>130</span><span class="html-tag">&lt;/b&gt;</span></div><span> does not receive any operation (e.g., no movement signal is detected by the obtaining module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>210</span><span class="html-tag">&lt;/b&gt;</span></div><span>) for a certain period (e.g., 1 s, 2 s, 3 s, or 4 s), the power supply module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>250</span><span class="html-tag">&lt;/b&gt;</span></div><span> may supply power to the memory merely, putting the wearable device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>130</span><span class="html-tag">&lt;/b&gt;</span></div><span> into a standby mode. For example, if the wearable device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>130</span><span class="html-tag">&lt;/b&gt;</span></div><span> does not receive any operation (e.g., no movement signal is detected by the obtaining module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>210</span><span class="html-tag">&lt;/b&gt;</span></div><span>) for a certain period (e.g., 1 s, 2 s, 3 s, or 4 s), the power supply module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>250</span><span class="html-tag">&lt;/b&gt;</span></div><span> may disconnect power to other components and the data in the motion monitoring system </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>100</span><span class="html-tag">&lt;/b&gt;</span></div><span> may be transmitted to a hard disk, putting the wearable device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>130</span><span class="html-tag">&lt;/b&gt;</span></div><span> into the standby mode or a sleeping mode. In some embodiments, the power supply module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>250</span><span class="html-tag">&lt;/b&gt;</span></div><span> may include at least one battery. The battery may include one or more combinations of a dry cell, a lead battery, a lithium battery, a solar cell, a wind energy generation battery, a mechanical energy generation battery, a thermal energy generation battery, etc. Light energy maybe converted into electrical energy by the solar battery and stored in the power supply module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>250</span><span class="html-tag">&lt;/b&gt;</span></div><span>. Wind energy may be converted into the electrical energy by the wind power generation battery and stored in the power supply module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>250</span><span class="html-tag">&lt;/b&gt;</span></div><span>. Mechanical energy may be converted into the electrical energy by the mechanical energy generation battery and stored in the power supply module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>250</span><span class="html-tag">&lt;/b&gt;</span></div><span>. The solar cell may include a silicon solar cell, a thin film solar cell, a nanocrystalline chemical solar cell, a fuel sensitized solar cell, and a plastic solar cell, etc. The solar cell may be distributed on the wearable device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>130</span><span class="html-tag">&lt;/b&gt;</span></div><span> in a form of panel. A user's body temperature may be converted into the electrical energy by the thermal power cell and stored in the power supply module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>250</span><span class="html-tag">&lt;/b&gt;</span></div><span>. In some embodiments, the processing module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>220</span><span class="html-tag">&lt;/b&gt;</span></div><span> may send the control signal to the power supply module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>250</span><span class="html-tag">&lt;/b&gt;</span></div><span> when the power supply module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>250</span><span class="html-tag">&lt;/b&gt;</span></div><span> is less than a power threshold (e.g., 10% of the total power). The control signal may include information that the power supply module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>250</span><span class="html-tag">&lt;/b&gt;</span></div><span> is low on power. In some embodiments, the power supply module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>250</span><span class="html-tag">&lt;/b&gt;</span></div><span> may include a backup power source. In some embodiments, the power supply module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>250</span><span class="html-tag">&lt;/b&gt;</span></div><span> may further include a charging interface. For example, the power supply module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>250</span><span class="html-tag">&lt;/b&gt;</span></div><span> may be temporarily charged by using an electronic device (e.g., a cell phone, a tablet computer) or a rechargeable battery carried by the user to temporarily charge the power supply module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>250</span><span class="html-tag">&lt;/b&gt;</span></div><span> in an emergency (e.g., the power supply module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>250</span><span class="html-tag">&lt;/b&gt;</span></div><span> is at zero power and an external power system is out of power).</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder159"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0076</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0075</span>"</span>&gt;</span></div><div class="opened"><span>The input/output module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>260</span><span class="html-tag">&lt;/b&gt;</span></div><span> may obtain, transmit, and send a signal. The input/output module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>260</span><span class="html-tag">&lt;/b&gt;</span></div><span> may connect or communicate with other components in the motion monitoring system </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>100</span><span class="html-tag">&lt;/b&gt;</span></div><span>. The other components in the motion monitoring system </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>100</span><span class="html-tag">&lt;/b&gt;</span></div><span> may be connected or communicated through the input/output module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>260</span><span class="html-tag">&lt;/b&gt;</span></div><span>. The input/output module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>260</span><span class="html-tag">&lt;/b&gt;</span></div><span> may be a wired USB interface, a serial communication interface, a parallel communication port, or a wireless Bluetooth, infrared-frequency identification, radio-frequency identification (RFID), WLAN Authentication and Privacy Infrastructure (WAPI), General Packet Radio Service (GPRS), Code Division Multiple Access (CDMA), or any combination thereof. In some embodiments, the input/output module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>260</span><span class="html-tag">&lt;/b&gt;</span></div><span> may be connected to the network </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>120</span><span class="html-tag">&lt;/b&gt;</span></div><span> and obtain the information through the network </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>120</span><span class="html-tag">&lt;/b&gt;</span></div><span>. For example, the input/output module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>260</span><span class="html-tag">&lt;/b&gt;</span></div><span> may obtain the movement signal from the obtaining module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>210</span><span class="html-tag">&lt;/b&gt;</span></div><span> of the user during motion and output user movement information through the network </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>120</span><span class="html-tag">&lt;/b&gt;</span></div><span> or the communication module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>240</span><span class="html-tag">&lt;/b&gt;</span></div><span>. In some embodiments, the input/output module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>260</span><span class="html-tag">&lt;/b&gt;</span></div><span> may include VCC, GND, RS-232, RS-485 (e.g., RS485-A, RS485-B), and a universal network interface, or any combination thereof. In some embodiments, the input/output module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>260</span><span class="html-tag">&lt;/b&gt;</span></div><span> may transmit obtained user motion information, through the network </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>120</span><span class="html-tag">&lt;/b&gt;</span></div><span>, to the obtaining module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>210</span><span class="html-tag">&lt;/b&gt;</span></div><span>. The encoding methods may include the phase coding, the non-zeroing system encoding, the differential Manchester encoding, etc., or any combination thereof.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder160"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0077</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0076</span>"</span>&gt;</span></div><div class="opened"><span>It should be understood that the system and its modules shown in </span><div class="folder" id="folder161"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>2</span><span class="html-tag">&lt;/b&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span> may be implemented by using a plurality of methods. For example, in some embodiments, the system and its modules may be implemented by hardware, software, or a combination of software and hardware. In particular, a hardware portion may be implemented by using dedicated logic. A software portion may be stored in memory and executed by an appropriate instruction execution system, such as a microprocessor or dedicated design hardware. Those skilled in the art may understand that the above methods and the system can be implemented by using a computer executable instruction and/or contained in a processor control code, for example, such encoding provided on a carrier medium such as a disk, CD or DVD-ROM, a programmable memory such as a read-only memory (firmware), or a data carrier such as an optical or electronic signal carrier. The system and its modules in one or more embodiments of the present disclosure may be implemented by a hardware circuit, e.g., ultra-large scale integrated circuit or gate array, a semiconductor such as a logic chip, a transistor, etc., or a programmable hardcore device such as a field programmable gate array, a programmable logic device, etc., implemented by software executed by various types of processors, or implemented by a combination of above hardware circuit and software (e.g., firmware).</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder162"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0078</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0077</span>"</span>&gt;</span></div><div class="opened"><span>It should be noted that the above description of the motion monitoring system and its modules is merely for descriptive convenience and does not limit one or more embodiments of the present disclosure within the scope of the embodiments. Understandably, for those skilled in the art, after understanding a principle of the system, they may make any combination of the modules, or to form a sub-system to connect with other modules, or to omit one or more modules thereof, without departing from this principle. For example, the obtaining module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>210</span><span class="html-tag">&lt;/b&gt;</span></div><span> and the processing module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>220</span><span class="html-tag">&lt;/b&gt;</span></div><span> may be one module that may have a function of obtaining and processing the user movement signal. Another example is that the processing module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>220</span><span class="html-tag">&lt;/b&gt;</span></div><span> may not be provided in the wearable device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>130</span><span class="html-tag">&lt;/b&gt;</span></div><span>, but integrated in the processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span>. Variations such as these are within the scope of protection of one or more embodiments of the present disclosure.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder163"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0079</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0078</span>"</span>&gt;</span></div><div class="opened"><div class="folder" id="folder164"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>3</span><span class="html-tag">&lt;/b&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span> is a schematic diagram illustrating an exemplary hardware and/or software of a computing device according to some embodiments of the present disclosure. In some embodiments, the processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span> and/or the mobile terminal device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>140</span><span class="html-tag">&lt;/b&gt;</span></div><span> may be implemented on a computing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>300</span><span class="html-tag">&lt;/b&gt;</span></div><span>. As shown in </span><div class="folder" id="folder165"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>3</span><span class="html-tag">&lt;/b&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span>, the computing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>300</span><span class="html-tag">&lt;/b&gt;</span></div><span> may include an internal communication bus </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>310</span><span class="html-tag">&lt;/b&gt;</span></div><span>, a processor </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>320</span><span class="html-tag">&lt;/b&gt;</span></div><span>, a read-only memory </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>330</span><span class="html-tag">&lt;/b&gt;</span></div><span>, a random memory </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>340</span><span class="html-tag">&lt;/b&gt;</span></div><span>, a communication port </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>350</span><span class="html-tag">&lt;/b&gt;</span></div><span>, an input/output interface </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>360</span><span class="html-tag">&lt;/b&gt;</span></div><span>, a hard disk </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>370</span><span class="html-tag">&lt;/b&gt;</span></div><span>, and a user interface </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>380</span><span class="html-tag">&lt;/b&gt;</span></div><span>.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder166"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0080</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0079</span>"</span>&gt;</span></div><div class="opened"><span>The internal communication bus </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>310</span><span class="html-tag">&lt;/b&gt;</span></div><span> may enable data communication between components in the computing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>300</span><span class="html-tag">&lt;/b&gt;</span></div><span>. For example, the processor </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>320</span><span class="html-tag">&lt;/b&gt;</span></div><span> may send data to other hardware such as a memory or the input/output interface </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>360</span><span class="html-tag">&lt;/b&gt;</span></div><span> through the internal communication bus </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>310</span><span class="html-tag">&lt;/b&gt;</span></div><span>. In some embodiments, the internal communication bus </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>310</span><span class="html-tag">&lt;/b&gt;</span></div><span> may be an industry standard architecture (ISA) bus, an extended industry standard architecture (EISA) bus, a video electronics standard architecture (VESA) bus, and a peripheral component interconnect (PCI) bus, etc. In some embodiments, the internal communication bus </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>310</span><span class="html-tag">&lt;/b&gt;</span></div><span> may be configured to connect various modules (e.g., obtaining module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>210</span><span class="html-tag">&lt;/b&gt;</span></div><span>, processing module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>220</span><span class="html-tag">&lt;/b&gt;</span></div><span>, control module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>230</span><span class="html-tag">&lt;/b&gt;</span></div><span>, communication module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>240</span><span class="html-tag">&lt;/b&gt;</span></div><span>, input and output module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>260</span><span class="html-tag">&lt;/b&gt;</span></div><span>) of the motion monitoring system </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>100</span><span class="html-tag">&lt;/b&gt;</span></div><span> shown in </span><div class="folder" id="folder167"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1</span><span class="html-tag">&lt;/b&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span>.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder168"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0081</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0080</span>"</span>&gt;</span></div><div class="opened"><span>The processor </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>320</span><span class="html-tag">&lt;/b&gt;</span></div><span> may execute a computing instruction (a program code) and perform functions of the motion monitoring system </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>100</span><span class="html-tag">&lt;/b&gt;</span></div><span> described in the present disclosure. The computing instruction may include a program, an object, a component, a data structure, process, modules, and functions (the functions refer to specific functions described in the present disclosure). For example, processor </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>320</span><span class="html-tag">&lt;/b&gt;</span></div><span> may process the obtained movement signal (e.g., the electromyographic signal, the attitude signal) of a user during motion from the wearable device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>130</span><span class="html-tag">&lt;/b&gt;</span></div><span> or/and the mobile terminal device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>140</span><span class="html-tag">&lt;/b&gt;</span></div><span> of the motion monitoring system </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>100</span><span class="html-tag">&lt;/b&gt;</span></div><span>, and monitor the movement of the user during motion based on the movement signal during motion. In some embodiments, the processor </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>320</span><span class="html-tag">&lt;/b&gt;</span></div><span> may include a microcontroller, a microprocessor, a reduced instruction set computer (RISC), an application-specific integrated circuit (ASIC), an application-specific instruction-set processor (ASIP), a central processing unit (CPU), a graphics processing unit (GPU), a physical processing unit (PPU), a microcontroller unit, a digital signal processor (DSP), a field Programmable Gate Array (FPGA), an Advanced RISC Machine (ARM), a programmable logic device, and any circuit and processor capable of performing one or more functions, or any combination thereof. For illustrative purposes only, the computing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>300</span><span class="html-tag">&lt;/b&gt;</span></div><span> in </span><div class="folder" id="folder169"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>3</span><span class="html-tag">&lt;/b&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span> depicts only one processor, but it should be noted that the computing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>300</span><span class="html-tag">&lt;/b&gt;</span></div><span> in the present disclosure may further include a plurality of processors.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder170"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0082</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0081</span>"</span>&gt;</span></div><div class="opened"><span>A memory of computing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>300</span><span class="html-tag">&lt;/b&gt;</span></div><span> (e.g., a read-only memory (ROM) </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>330</span><span class="html-tag">&lt;/b&gt;</span></div><span>, a Random Access Memory (RAM) </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>340</span><span class="html-tag">&lt;/b&gt;</span></div><span>, a hard disk </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>370</span><span class="html-tag">&lt;/b&gt;</span></div><span>, etc.) may store data/information obtained from any other components of the motion monitoring system </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>100</span><span class="html-tag">&lt;/b&gt;</span></div><span>. In some embodiments, the memory of the computing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>300</span><span class="html-tag">&lt;/b&gt;</span></div><span> may be located in the wearable device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>130</span><span class="html-tag">&lt;/b&gt;</span></div><span> or the processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span>. An exemplary ROM may include a mask ROM (MROM), a programmable ROM (PROM), an erasable programmable ROM (PEROM), an electrically erasable programmable ROM (EEPROM), a compact disk ROM (CD-ROM), and a digital versatile disk ROM, etc. An exemplary RAM may include a dynamic RAM (DRAM), a double-rate synchronous dynamic RAM (DDR SDRAM), a static RAM (SRAM), a thyristor RAM (T-RAM), and a zero-capacitor RAM (Z-RAM), etc.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder171"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0083</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0082</span>"</span>&gt;</span></div><div class="opened"><span>The input/output interface </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>360</span><span class="html-tag">&lt;/b&gt;</span></div><span> may input or output signals, data, or information. In some embodiments, the input/output interface </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>360</span><span class="html-tag">&lt;/b&gt;</span></div><span> may enable a user to interact with the motion monitoring system </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>100</span><span class="html-tag">&lt;/b&gt;</span></div><span>. For example, the input/output interface </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>360</span><span class="html-tag">&lt;/b&gt;</span></div><span> may include a communication module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>240</span><span class="html-tag">&lt;/b&gt;</span></div><span> to enable the communication function of the motion monitoring system </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>100</span><span class="html-tag">&lt;/b&gt;</span></div><span>. In some embodiments, the input/output interface </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>360</span><span class="html-tag">&lt;/b&gt;</span></div><span> may include an input device and an output device. Exemplary input devices may include a keyboard, a mouse, a touch screen, and a microphone, etc., or any combination thereof. Exemplary output devices may include a display device, a loudspeaker, a printer, a projector, etc., or any combination thereof. Example display devices may include a liquid crystal display (LCD), a light-emitting diode (LED)-based display, a flat panel display, a curved display, a television device, a cathode ray tubes (CRT), etc., or any combination thereof. The communication port </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>350</span><span class="html-tag">&lt;/b&gt;</span></div><span> may be connected to a network for data communication. Connection may be a wired connection, a wireless connection, or a combination of both. The wired connection may include a cable, a fiber optic cable, or telephone line, or any combination thereof. The wireless connection may include Bluetooth™, Wi-Fi, WiMAX, WLAN, ZigBee™, a mobile network (e.g., 3G, 4G, or 5G, etc.), or any combination thereof. In some embodiments, the communication port </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>350</span><span class="html-tag">&lt;/b&gt;</span></div><span> may be a standard port, such as RS232, RS485, etc. In some embodiments, the communication port </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>350</span><span class="html-tag">&lt;/b&gt;</span></div><span> may be a specially designed port.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder172"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0084</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0083</span>"</span>&gt;</span></div><div class="opened"><span>The hard disk </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>370</span><span class="html-tag">&lt;/b&gt;</span></div><span> may be configured to store the information and the data generated by or received from the processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span>. For example, the hard disk </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>370</span><span class="html-tag">&lt;/b&gt;</span></div><span> may store confirmation information of a user. In some embodiments, the hard disk </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>370</span><span class="html-tag">&lt;/b&gt;</span></div><span> may include a hard disk drive (HDD), a solid-state drive (SSD), or a hybrid hard disk (HHD), etc. In some embodiments, the hard disk </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>370</span><span class="html-tag">&lt;/b&gt;</span></div><span> may be provided in the processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span> or in the wearable device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>130</span><span class="html-tag">&lt;/b&gt;</span></div><span>. The user interface </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>380</span><span class="html-tag">&lt;/b&gt;</span></div><span> may enable an interact and information exchange between the computing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>300</span><span class="html-tag">&lt;/b&gt;</span></div><span> and the user. In some embodiments, the user interface </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>380</span><span class="html-tag">&lt;/b&gt;</span></div><span> may be configured to present motion recordings generated by the motion monitoring system </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>100</span><span class="html-tag">&lt;/b&gt;</span></div><span> to the user. In some embodiments, the user interface </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>380</span><span class="html-tag">&lt;/b&gt;</span></div><span> may include a physical display such as a display with speakers, an LCD display, an LED display, an OLED display, an electronic ink display (E-Ink), etc.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder173"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0085</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0084</span>"</span>&gt;</span></div><div class="opened"><div class="folder" id="folder174"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>4</span><span class="html-tag">&lt;/b&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span> is a structure diagram of an exemplary wearable device according to some embodiments of the present disclosure. To further describe the wearable device, the upper garment is illustrated as an example, as shown in </span><div class="folder" id="folder175"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>4</span><span class="html-tag">&lt;/b&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span>. The wearable device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>400</span><span class="html-tag">&lt;/b&gt;</span></div><span> may include an upper garment </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>410</span><span class="html-tag">&lt;/b&gt;</span></div><span>. The upper garment </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>410</span><span class="html-tag">&lt;/b&gt;</span></div><span> may include an upper garment substrate </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>4110</span><span class="html-tag">&lt;/b&gt;</span></div><span>, at least one upper garment processing module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>4120</span><span class="html-tag">&lt;/b&gt;</span></div><span>, at least one upper garment feedback module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>4130</span><span class="html-tag">&lt;/b&gt;</span></div><span>, at least one upper garment obtaining module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>4140</span><span class="html-tag">&lt;/b&gt;</span></div><span>, etc. The upper garment substrate </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>4110</span><span class="html-tag">&lt;/b&gt;</span></div><span> may refer to clothe worn on an upper body of a human body. In some embodiments, the upper garment substrate </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>4110</span><span class="html-tag">&lt;/b&gt;</span></div><span> may include a short sleeve T-shirt, a long sleeve T-shirt, a shirt, and a jacket, etc. The at least one upper garment processing module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>4120</span><span class="html-tag">&lt;/b&gt;</span></div><span>, the at least one upper garment obtaining module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>4140</span><span class="html-tag">&lt;/b&gt;</span></div><span> may be located in areas of the upper garment substrate </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>4110</span><span class="html-tag">&lt;/b&gt;</span></div><span> that fit to different parts of the human body. The at least one upper garment feedback module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>4130</span><span class="html-tag">&lt;/b&gt;</span></div><span> may be located at any location on the upper garment substrate </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>4110</span><span class="html-tag">&lt;/b&gt;</span></div><span>, and the at least one upper garment feedback module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>4130</span><span class="html-tag">&lt;/b&gt;</span></div><span> may be configured to provide feedback on information about a user's upper body movement state. Exemplary feedback manners may include, but are not limited to, voice prompts, text prompts, pressure prompts, electrical stimulation, etc. In some embodiments, the at least one upper garment obtaining module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>4140</span><span class="html-tag">&lt;/b&gt;</span></div><span> may include, but is not limited to, one or more of an attitude sensor, an electro-cardio sensor, an electromyographic sensor, a temperature sensor, a humidity sensor, an inertial sensor, an acid-base sensor, an acoustic transducer, and etc. The sensor(s) in the upper garment obtaining module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>4140</span><span class="html-tag">&lt;/b&gt;</span></div><span> may be placed at different locations on user's body according to a signal to be measured. For example, when the attitude sensor is configured to obtain the attitude signal of a user during motion, the attitude sensor can be placed in the upper garment substrate </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>4110</span><span class="html-tag">&lt;/b&gt;</span></div><span> at a location corresponding to the human torso, arms, and joints. For another example, when the electromyographic sensor is configured to obtain Electromyographic signal of the user during motion, the Electromyographic sensor may be located near the muscles to be measured. In some embodiments, the attitude sensor may include, but is not limited to, an acceleration triaxial sensor, an angular velocity tri-axial sensor, a magnetic sensor, etc., or any combination thereof. For example, an attitude sensor may include an acceleration triaxial sensor, an angular velocity triaxial sensor. In some embodiments, an attitude sensor may further include a strain gauge sensor. A strain gauge sensor may be a sensor based on strain generated by deformation of an object to be measured caused by a force. In some embodiments, the strain gauge sensor may include, but is not limited to, one or more of a strain-gauge force sensor, a strain-gauge pressure sensor, a strain-gauge torque sensor, a strain-gauge displacement sensor, a strain-gauge acceleration sensor, etc. For example, the strain gauge sensor may be arranged at a joint location of the user, and a bending angle and a bending direction at the user's joint can be obtained based on the resistance in the strain gauge sensor that varies with a stretch length at the joint. It should be understood that the upper garment </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>410</span><span class="html-tag">&lt;/b&gt;</span></div><span> may include other modules, such as a power supply module, a communication module, an input/output module, and etc., in addition to the upper garment substrate </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>4110</span><span class="html-tag">&lt;/b&gt;</span></div><span>, the upper garment processing module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>4120</span><span class="html-tag">&lt;/b&gt;</span></div><span>, the upper garment feedback module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>4130</span><span class="html-tag">&lt;/b&gt;</span></div><span>, and the upper garment obtaining module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>4140</span><span class="html-tag">&lt;/b&gt;</span></div><span> described above. The upper garment processing module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>4120</span><span class="html-tag">&lt;/b&gt;</span></div><span> is similar to the processing module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>220</span><span class="html-tag">&lt;/b&gt;</span></div><span> shown in </span><div class="folder" id="folder176"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>2</span><span class="html-tag">&lt;/b&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span>, and the upper garment obtaining module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>4140</span><span class="html-tag">&lt;/b&gt;</span></div><span> is similar to the obtaining module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>210</span><span class="html-tag">&lt;/b&gt;</span></div><span> shown in </span><div class="folder" id="folder177"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>2</span><span class="html-tag">&lt;/b&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span>. Specific descriptions regarding various modules in the upper garment </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>410</span><span class="html-tag">&lt;/b&gt;</span></div><span> may be found in </span><div class="folder" id="folder178"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>2</span><span class="html-tag">&lt;/b&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span> and its relevant descriptions of the present disclosure, which will not be repeated herein.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder179"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0086</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0085</span>"</span>&gt;</span></div><div class="opened"><div class="folder" id="folder180"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>5</span><span class="html-tag">&lt;/b&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span> is a flowchart illustrating an exemplary motion monitoring method according to some embodiments of the present disclosure. As shown in </span><div class="folder" id="folder181"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>5</span><span class="html-tag">&lt;/b&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span>, process </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>500</span><span class="html-tag">&lt;/b&gt;</span></div><span> may include the following steps.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder182"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0087</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0086</span>"</span>&gt;</span></div><div class="opened"><span>In step </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>510</span><span class="html-tag">&lt;/b&gt;</span></div><span>, obtaining a movement signal of a user during motion.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder183"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0088</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0087</span>"</span>&gt;</span></div><div class="opened"><span>In some embodiments, the step </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>510</span><span class="html-tag">&lt;/b&gt;</span></div><span> may be performed by the obtaining module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>210</span><span class="html-tag">&lt;/b&gt;</span></div><span>. The movement signal refers to human body parameter information of the user during motion. In some embodiments, the human body parameter information may include, but is not limited to, one or more of an electromyographic signal, an attitude signal, an electro-cardio signal, a temperature signal, a humidity signal, a blood oxygen concentration, and a respiration rate, etc. In some embodiments, an electromyographic sensor in the obtaining module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>210</span><span class="html-tag">&lt;/b&gt;</span></div><span> may collect the electromyographic signal of the user during motion. For example, when the user performs a seated chest press, the electromyographic sensors in a wearable device corresponding to human pectoral muscles, latissimus dorsi, etc. may obtain the electromyographic signals of corresponding muscle positions of the user. For another example, when a user performs a deep squat, the electromyographic sensors in the wearable device corresponding to gluteus maximus and quadriceps can collect the electromyographic signals of the corresponding muscle positions. For another example, when the user is running, the electromyographic sensors in the wearable device corresponding to a gastrocnemius muscle and other positions can obtain the electromyographic signals of the corresponding muscle positions. In some embodiments, the attitude sensor in the obtaining module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>210</span><span class="html-tag">&lt;/b&gt;</span></div><span> may obtain an attitude signal of the user during motion. For example, when the user performs a barbell bench press, the attitude sensor in the wearable device corresponding to the human triceps, etc., can obtain the attitude signal of the triceps, etc. For example, when the user performs a dumbbell flyover, the attitude sensor set at a position such as a human deltoid muscle may obtain the attitude signal of the corresponding position. In some embodiments, a plurality of attitude sensors may obtain attitude signals of a plurality of portions of the user during motion, and the attitude signals of a plurality of portions may reflect a relative movement between different parts of the body. For example, an attitude signal at an arm and an attitude signal at a torso can reflect a movement condition of the arm relative to the torso. In some embodiments, the attitude signal is associated with a type of the attitude sensor. For example, when the attitude sensor is an angular velocity tri-axis sensor, an obtained attitude signal is angular velocity information. For another example, when the attitude sensor is the angular velocity tri-axis sensor and an acceleration tri-axis sensor, the obtained attitude signal is the angular velocity information and acceleration information. For example, when the attitude sensor is a strain gauge sensor, the strain gauge sensor can be arranged at a user's joint position, by measuring the resistance in the strain gauge sensor that varies with the stretch length, the obtained attitude signal may be displacement information, stress, etc., and a bending angle and a bending direction at the user's joint may be represented through these attitude signals. It is important to note that the parameter information configured to reflect the relative motion of the user's body may be feature information corresponding to the attitude signal, which can be obtained by using different types of attitude sensors according to the type of the feature information.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="line"><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0089</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0088</span>"</span>&gt;</span><span>In some embodiments, the movement signal may include the electromyographic signal and an attitude signal of a particular part of the user's body. The electromyographic signal and the attitude signal can reflect a movement state of the particular part of the user's body from different angles. In simple terms, the attitude signal of a specific part of the user's body can reflect the type of movement, movement amplitude, movement frequency, etc. of the specific part. The electromyographic signal may reflect a muscle state of the particular part during motion. In some embodiments, by measuring the electromyographic signal and/or the attitude signal of the same body part, whether the movement of that part is standard can be better assessed.</span><span class="html-tag">&lt;/p&gt;</span></div><span>
</span><div class="folder" id="folder184"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0090</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0089</span>"</span>&gt;</span></div><div class="opened"><span>In step </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>520</span><span class="html-tag">&lt;/b&gt;</span></div><span>, monitoring the movement of the user during motion based at least on feature information corresponding to the electromyographic signal or feature information corresponding to the attitude signal.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder185"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0091</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0090</span>"</span>&gt;</span></div><div class="opened"><span>In some embodiments, the step </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>520</span><span class="html-tag">&lt;/b&gt;</span></div><span> may be performed by the processing module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>220</span><span class="html-tag">&lt;/b&gt;</span></div><span> and/or the processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span>. In some embodiments, the feature information corresponding to the electromyographic signal may include, but is not limited to, one or more of frequency information, amplitude information, etc. The feature information corresponding to the attitude signal is parameter information configured to represent the relative motion of the user's body. In some embodiments, the feature information corresponding to the attitude signal may include, but is not limited to, one or more of an angular velocity direction, an angular velocity value, an acceleration value of angular velocity, etc. In some embodiments, the feature information corresponding to the attitude signal may further include an angle, displacement information (e.g., a stretch length in a strain gauge sensor), stress, etc. For example, when the attitude sensor is a strain gauge sensor, the strain gauge sensor may be set at the user's joint position, and by measuring the resistance in the strain gauge sensor that varies with the stretch length, the obtained attitude signal may be displacement information, stress, etc., which may represent the bending angle and the bending direction at the user's joint. In some embodiments, the processing module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>220</span><span class="html-tag">&lt;/b&gt;</span></div><span> and/or the processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span> may extract the feature information corresponding to the electromyographic signal (e.g., frequency information, amplitude information) or the feature information corresponding to the attitude signal (e.g., the angular velocity direction, the angular velocity value, the acceleration value of angular velocity, the angle, the displacement information, the stress, etc.), and monitor the movement of the user during motion based on the feature information corresponding to the electromyographic signal or the feature information corresponding to the attitude signal. The monitoring of the movement during motion includes user's movement-related information. In some embodiments, movement-related information may include one or more of a movement type, number of movements, a movement quality (e.g., whether the movement meets a standard), a movement time, etc. The movement type is a fitness movement performed by the user during motion. In some embodiments, the movement type may include, but is not limited to, one or more of seated chest presses, deep squats, hard pulls, plank supports, running, swimming, etc. The number of movements refers to the number of times the user performs the movement during motion. For example, if the user performs 10 seated chest clamps during motion, 10 is the number of movements. The movement quality refers to the standard degree of the fitness movement performed by the user related to a standard fitness movement. For example, when the user performs a deep squat movement, the processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span> may determine a movement type of the user based on the feature information corresponding to the movement signal (the electromyographic signal and the attitude signal) of a particular specific muscle location (gluteus maximus, quadriceps, etc.) and determine the movement quality of the user during performing the deep squat movement based on the movement signal. The movement time is the time corresponding to one or more movement types of the user or the total time of the movement process. Detailed descriptions of monitoring the movement of the user during motion based on the feature information corresponding to the electromyographic signal and/or the feature information corresponding to the attitude signal may be found in </span><div class="folder" id="folder186"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>6</span><span class="html-tag">&lt;/b&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span> and its relevant descriptions of the present disclosure.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder187"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0092</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0091</span>"</span>&gt;</span></div><div class="opened"><span>In some embodiments, the processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span> may use one or more movement recognition models to recognize and monitor the movement of the user during motion. For example, the processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span> may input the feature information corresponding to the electromyographic signal and/or the feature information corresponding to the attitude signal into a movement recognition model, and the movement recognition model outputs information related to the user's movement. In some embodiments, the movement recognition model may include different types of movement recognition models, for example, a model configured to recognize the movement type of the user, or a model configured to identify movement quality of the user, etc.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder188"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0093</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0092</span>"</span>&gt;</span></div><div class="opened"><span>It should be noted that the above description regarding process </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>500</span><span class="html-tag">&lt;/b&gt;</span></div><span> is for exemplary and illustrative purpose only, and does not limit the scope of application of the present disclosure. For those skilled in the art, various amendments and changes can be made to the process </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>500</span><span class="html-tag">&lt;/b&gt;</span></div><span> under the guidance of the present disclosure. However, these amendments and changes remain within the scope of the present disclosure. For example, extraction of the feature information corresponding to the electromyographic signal or the feature information corresponding to the attitude signal in step </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>520</span><span class="html-tag">&lt;/b&gt;</span></div><span> may be performed through the processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span>, or in some embodiments, by processing module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>220</span><span class="html-tag">&lt;/b&gt;</span></div><span>. For example, the user's movement signal is not limited to the above electromyographic signal, attitude signal, electro-cardio signal, temperature signal, humidity signal, blood oxygen concentration, respiration rate, but may also include other human physiological parameter signal, and the physiological parameter signals involved in human movement can be all considered as the movement signal in the embodiments of the present disclosure.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder189"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0094</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0093</span>"</span>&gt;</span></div><div class="opened"><div class="folder" id="folder190"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>6</span><span class="html-tag">&lt;/b&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span> is a flowchart of an exemplary process for monitoring a movement of a user during motion according to some embodiments of the present disclosure. As shown in </span><div class="folder" id="folder191"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>6</span><span class="html-tag">&lt;/b&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span>, process </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>600</span><span class="html-tag">&lt;/b&gt;</span></div><span> may include the following steps.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder192"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0095</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0094</span>"</span>&gt;</span></div><div class="opened"><span>In step </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>610</span><span class="html-tag">&lt;/b&gt;</span></div><span>, segmenting, based on the feature information corresponding to the electromyographic signal or the feature information corresponding to the attitude signal, the movement signal.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder193"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0096</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0095</span>"</span>&gt;</span></div><div class="opened"><span>In some embodiments, the step may be performed by the processing module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>220</span><span class="html-tag">&lt;/b&gt;</span></div><span> and/or the processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span>. The process of obtaining the movement signal (e.g., the electromyographic signal, the attitude signal) of the user during motion is continuous, and a movement of the user during motion may be a combination of a plurality of sets of movement or a combination of different movement types. To analyze each movement of the user during motion, the processing module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>220</span><span class="html-tag">&lt;/b&gt;</span></div><span> may segment the movement signal of the user based on the feature information corresponding to the electromyographic signal or the feature information corresponding to the attitude signal. The segmenting the movement signal of the user herein refers to dividing the movement signal into signal segments having same or different durations, or extract one or more signal segments having a specific duration from the movement signal. In some embodiments, each segment of the movement signal may correspond to one or more complete movement of the user. For example, when a user performs a deep squat, the user's movement from a standing position to a squat position and then getting up to return to the standing position can be considered as completing the deep squat, and the movement signal collected by the obtaining module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>210</span><span class="html-tag">&lt;/b&gt;</span></div><span> during this process can be considered as one segment (or one cycle) of the movement signal, after which the movement signal collected by the obtaining module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>210</span><span class="html-tag">&lt;/b&gt;</span></div><span> from the next deep squat completed by the user can be considered as another segment of the movement signal. In some embodiments, each movement signal may also correspond to a portion of the user's movement, where a portion of the movement may be understood as a portion of a complete movement. For example, when a user performs a deep squat, the user's movement from a standing position to a squat position may be considered as one segment of the movement, and getting up to return to the standing position may be considered as another segment of the movement. A change in each movement of the user during motion may cause the electromyographic signal and the attitude signal of a corresponding body part to change. For example, when the user performs a squat, the electromyographic signal and the attitude signal of the muscles in the corresponding parts of the user's body (e.g., arms, legs, hips, abdomen) fluctuate less when the user stands; when the user squats from the standing position, the electromyographic signal and the attitude signal of the muscles in the corresponding parts of the user's body fluctuate more, e.g., amplitude information corresponding to signals of different frequencies of the electromyographic signal becomes greater, or an angular velocity value, a direction of angular velocity, an acceleration value of angular velocity, an angle, displacement information, stress, etc. of the attitude signal may also change. When the user gets up from a squatting state to a standing state, the amplitude information corresponding to the electromyographic signal and the angular velocity value, the direction of angular velocity, the acceleration value of angular velocity, the angle, the displacement information, and the stress corresponding to the attitude signal may change again. Based on this situation, the processing module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>220</span><span class="html-tag">&lt;/b&gt;</span></div><span> may segment, based on the feature information corresponding to the electromyographic signal or the feature information corresponding to the attitude signal, the movement signal. Detailed descriptions of segmenting the movement signal based on the feature information corresponding to the electromyographic signal or the feature information corresponding to the attitude signal may be found in </span><div class="folder" id="folder194"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>7</span><span class="html-tag">&lt;/b&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span> and </span><div class="folder" id="folder195"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>8</span><span class="html-tag">&lt;/b&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span> of the present disclosure and their related descriptions.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder196"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0097</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0096</span>"</span>&gt;</span></div><div class="opened"><span>In step </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>620</span><span class="html-tag">&lt;/b&gt;</span></div><span>, monitoring, based on at least one segment of the movement signal, the movement of the user during motion.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder197"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0098</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0097</span>"</span>&gt;</span></div><div class="opened"><span>The step may be performed by processing module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>220</span><span class="html-tag">&lt;/b&gt;</span></div><span> and/or processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span>. In some embodiments, monitoring of the movement of the user based on at least one segment of the movement signal may include matching the at least one segment of the movement signal with at least one segment of a preset movement signal to determine the movement type of the user. The at least one segment of the preset movement signal is standard movement signals corresponding to different movements that are preset in a database. In some embodiments, a movement type of the user during motion may be determined by determining a matching degree of the at least one segment of the movement signal and the at least one segment of the preset movement signal. Further, the movement type of the user may be determined by determining whether the matching degree of the movement signal and the preset movement signal is within a first matching threshold range (e.g., greater than 80%). If so, the movement type of the user during motion is determined based on the movement type corresponding to the preset movement signal. In some embodiments, monitoring the movement of the user during motion based on the at least one segment of the movement signal may further include determining the movement type of the user during motion by matching the feature information corresponding to the at least one segment of the electromyographic signal and feature information corresponding to an electromyographic signal of the at least one segment of the preset movement signal. For example, match degree(s) between one or more feature information (e.g., frequency information, amplitude information) of the segment of the electromyographic signal and the one or more feature information of the segment of the preset movement signal may be calculated respectively, and a determination is made as to whether a weighted matching degree of the one or more feature information or an average matching degree of the one or more feature information is within a first matching threshold. If so, the movement type of the user during motion is determined based on the movement type corresponding to the preset movement signal. In some embodiments, monitoring the movement of the user during motion based on the at least one segment of the movement signal may further include determining the movement type of the user during motion by matching the feature information corresponding to the at least one segment of the attitude signal with the feature information corresponding to the attitude signal of the at least one segment of the preset movement signal. For example, the matching degree of the one or more feature information (e.g., the angular velocity value, the angular velocity direction and the acceleration value of the angular velocity, the angle, the displacement information, the stress, etc.) of one segment of the attitude signal and the one or more feature information of one segment of the preset movement signal are calculated respectively to determine whether the weighted matching degree or the average matching degree of the one or more feature information is within the first matching threshold. If so, the movement type of the user is determined according to preset a movement type corresponding to the preset movement signal. In some embodiments, monitoring the movement of the user during motion based on the at least one segment of the movement signal may further include determining the movement type of the user during motion by matching the feature information corresponding to the electromyographic signal and the feature information corresponding to the attitude signal of the at least one segment of the movement signal and the feature information corresponding to the electromyographic signal and the feature information corresponding to the attitude signal of the at least one segment of the preset movement signal.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="line"><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0099</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0098</span>"</span>&gt;</span><span>In some embodiments, monitoring the movement of the user during motion based on the at least one segment of the movement signal may include determining the movement quality of the user by matching the at least one segment of the movement signal with the at least one segment of the preset movement signal. Further, if a matching degree of the movement signal and the preset movement signal is within a second matching threshold range (e.g., greater than 90%), the movement quality of the user during motion meets the standard. In some embodiments, determining the movement of the user during motion based on the movement signal of the at least one segment may include determining the movement quality of the user during motion by matching the one or more feature information of the movement signal of the at least one segment with the one or more feature information of the at least one segment of the preset movement signal. It should be noted that a segment of the movement signal may be a movement signal of a complete movement or a movement signal of a partial of a complete movement. In some embodiments, for a complex complete movement, there may be different ways of force generation at different stages of the complete movement, that is, there may be different movement signals at the different stages of the movement, and the user movement can be monitored in real time, and thus, the accuracy of the monitored movement signal at the different stages of the complete movement can be improved.</span><span class="html-tag">&lt;/p&gt;</span></div><span>
</span><div class="folder" id="folder198"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0100</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0099</span>"</span>&gt;</span></div><div class="opened"><span>It should be noted that the above description of the process </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>600</span><span class="html-tag">&lt;/b&gt;</span></div><span> is for example and illustration purposes only and does not limit the scope of application of the present disclosure. For those skilled in the art, various amendments and changes can be made to process </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>600</span><span class="html-tag">&lt;/b&gt;</span></div><span> under the guidance of the present disclosure. However, these amendments and changes remain within the scope of the present disclosure. For example, in some embodiments, the user's movement may also be determined through a movement recognition model or a manually preset model.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder199"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0101</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0100</span>"</span>&gt;</span></div><div class="opened"><div class="folder" id="folder200"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>7</span><span class="html-tag">&lt;/b&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span> is a flowchart of an exemplary process for segmenting a movement signal according to some embodiments of the present disclosure. As shown in </span><div class="folder" id="folder201"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>7</span><span class="html-tag">&lt;/b&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span>, process </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>700</span><span class="html-tag">&lt;/b&gt;</span></div><span> may include the following steps.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder202"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0102</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0101</span>"</span>&gt;</span></div><div class="opened"><span>In step </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>710</span><span class="html-tag">&lt;/b&gt;</span></div><span>, determining, based on a time domain window of the electromyographic signal or the attitude signal, at least one target feature point from within the time domain window according to a preset condition.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder203"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0103</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0102</span>"</span>&gt;</span></div><div class="opened"><span>In some embodiments, the step may be performed by the processing module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>220</span><span class="html-tag">&lt;/b&gt;</span></div><span> and/or the processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span>. The time domain window of the electromyographic signal includes an electromyographic signal over a range of time, and the time domain window of the attitude signal includes an attitude signal over a same range of time. A target feature point refers to a signal of the movement signal with a target feature, which may represent a stage of the user's movement. For example, when a user performs a seated chest press, at the beginning, the user's arms are extended outward horizontally, begin to rotate internally, come together, and finally return to the extended state again in the horizontal direction, this process is a complete seated chest press movement. When the user performs a seated chest press movement, the feature information corresponding to the electromyographic signal or the attitude signal is different in each stage. By analyzing the feature information corresponding to the electromyographic signal (e.g., amplitude information, frequency information) or the feature information corresponding to the attitude signal (e.g., the angular velocity value, the direction of angular velocity, the acceleration value of angular velocity, the angle, the displacement information, the stress, etc.), the target feature point corresponding to a stage of the user's movement may be determined. In some embodiments, one or more target feature points may be determined from the time domain window based on the preset condition. In some embodiments, the preset condition may include one or more of a change in the direction of the angular velocity corresponding to the attitude signal, the angular velocity corresponding to the attitude signal being greater than or equal to an angular velocity threshold, the angle corresponding to the attitude signal reaching an angular threshold, the change of the angular velocity value corresponding to the attitude signal being the extreme value, and the amplitude information corresponding to the electromyographic signal being greater than or equal to an electromyographic threshold. In some embodiments, the target feature points at the different stages of a movement may correspond to different preset conditions. For example, in the seated chest press, a preset condition for a target feature point when the user's arms are horizontally extended outward and then start to internally rotate is different from a preset condition for a target feature point when the arms are brought together. In some embodiments, the target feature points of different movements may correspond to different preset conditions. For example, the chest press movement and bent-over movement are different, and the preset conditions regarding the respective preset target feature points in these two movements are also different. Exemplary descriptions of the preset condition may refer to the description of a movement start point, a movement middle point and a movement end point in the present disclosure.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="line"><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0104</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0103</span>"</span>&gt;</span><span>In other embodiments, the at least one target feature point may be determined, based on the both time domain windows of the electromyographic signal and the attitude signal, from the time domain windows according to the preset condition. The time domain windows of the electromyographic signal and the attitude signal both include the electromyographic signal and the attitude signal over a range of time. The time of the electromyographic signal corresponds to the time of the attitude signal. For example, a time point of the electromyographic signal when the user starts to move is the same as a time point of the attitude signal when the user starts to move. The target feature point here may be determined by combining the feature information corresponding to the electromyographic signal (e.g., the amplitude information) and the feature information corresponding to the attitude signal (e.g., the angular velocity value, the direction of angular velocity, the acceleration value of angular velocity, the angle, etc.).</span><span class="html-tag">&lt;/p&gt;</span></div><span>
</span><div class="folder" id="folder204"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0105</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0104</span>"</span>&gt;</span></div><div class="opened"><span>In step </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>720</span><span class="html-tag">&lt;/b&gt;</span></div><span>, segmenting, based on the at least one target feature point, the movement signal.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder205"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0106</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0105</span>"</span>&gt;</span></div><div class="opened"><span>In some embodiments, the step </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>720</span><span class="html-tag">&lt;/b&gt;</span></div><span> may be performed by the processing module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>220</span><span class="html-tag">&lt;/b&gt;</span></div><span> and/or the processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span>. In some embodiments, the target feature point in the electromyographic signal or the attitude signal may be one or more, and the movement signal may be divided into multiple segments by one or more target feature points. For example, when there is a target feature point in the electromyographic signal, the target feature point may divide the electromyographic signal into two segments, where the two segments may include the electromyographic signal before the target feature point and the electromyographic signal after the target feature point. Alternatively, the processing module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>220</span><span class="html-tag">&lt;/b&gt;</span></div><span> and/or the processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span> may extract the electromyographic signal for a certain time range around the target feature point as a segment of the electromyographic signal. For another example, when the electromyographic signal has a plurality of target feature points (e.g., n-target feature points, and the first target feature point is not a beginning of the time domain window and the n</span><div class="line"><span class="html-tag">&lt;sup&gt;</span><span>th </span><span class="html-tag">&lt;/sup&gt;</span></div><span>target feature point is not an end of the time domain window), the electromyographic signal may be divided into (n+1) segments based on the n target feature points. For another example, when the electromyographic signal has the plurality of target feature points (e.g., n-target feature points, and the first target feature point is the beginning of the time domain window and the n</span><div class="line"><span class="html-tag">&lt;sup&gt;</span><span>th </span><span class="html-tag">&lt;/sup&gt;</span></div><span>target feature point is not the end of the time domain window), the electromyographic signal may be divided into n segments based on the n target feature points. As a further example, when the electromyographic signal has the plurality of target feature points (e.g., n-target feature points, and the first target feature point is the beginning of the time domain window and the n</span><div class="line"><span class="html-tag">&lt;sup&gt;</span><span>th </span><span class="html-tag">&lt;/sup&gt;</span></div><span>target feature point is the end of the time domain window), the electromyographic signal may be divided into (n−1) segments based on the n target feature points. It should be noted that the movement stage corresponding to the target feature point may include one or more types, and a plurality of movement stages corresponding to the target feature point may be used as a benchmark for segmenting the movement signal. For example, the movement stage corresponding to the target feature point may include the movement start point and the movement end point, with the movement start point preceding the movement end point, and the movement signal here between the movement start point and a next movement start point may be considered as a segment of the movement signal.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="line"><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0107</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0106</span>"</span>&gt;</span><span>In some embodiments, the target feature point may include one or more of the movement start point, the movement middle point, or the movement end point.</span><span class="html-tag">&lt;/p&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0108</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0107</span>"</span>&gt;</span><span>To describe the segmentation of the movement signal, take the target feature point including all of the movement start point, the movement middle point and the movement end point as an exemplary illustration. The movement start point may be considered as a start point of a user movement cycle. In some embodiments, different movements may correspond to the different preset conditions. For example, in the seated chest press, the preset condition may be that the direction of the angular velocity of the movement after the movement start point changes relative to the direction of the angular velocity of the movement before the movement start point, or that the value of the angular velocity at the movement start point is approximately 0 and the acceleration value of the angular velocity at the movement start point is greater than 0. In other words, when the user performs the seated chest press, the movement starting point may be set to the point when the arms are extended outward horizontally and start to internally rotate. For another example, in a bent-over movement, the preset condition may be that the angle of arm lift is greater than or equal to an angle threshold. Specifically, when the user performs a bent-over movement, the angle of arm lift when the user's arm is horizontal is 0°, the angle of arm lift when the arm is down is negative, and the angle of arm lift when the arm is up is positive. When the user's arm is raised from the horizontal position, the arm is raised at an angle greater than 0. The point in time when the angle of the arm lift reaches the angle threshold may be considered as the movement start point. The angle threshold may be −70° to −20°, or as a preference, the angle threshold may be −50° to −25°. In some embodiments, to further ensure the accuracy of a selected movement start point, the preset condition may also include that the angular velocity of the arm within a specific range of time after the movement start point may be greater than or equal to an angular velocity threshold. The angular velocity threshold may range from 5°/s˜50°/s. According to preference of example, the angular velocity threshold may range from 10°/s˜30°/s. For example, when a user performs a bent-over movement, the angular velocity of the arm is continuously greater than the angular velocity threshold for a specific time range (e.g., 0.05 s, 0.1 s, 0.5 s) after an angular threshold is reached and the user's arm is continuously raised upward. In some embodiments, if the angular velocity of the selected movement start point according to the preset condition is less than the angular velocity threshold within a specific range of time, the preset condition continues until a movement start point is determined.</span><span class="html-tag">&lt;/p&gt;</span></div><span>
</span><div class="folder" id="folder206"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0109</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0108</span>"</span>&gt;</span></div><div class="opened"><span>In some embodiments, the movement middle point may be a point within one movement cycle from the start point. For example, when the user performs the seated chest press, a start point of the movement may be set to the time when the arms extend outward horizontally and begin to internally rotate, and the time when the arms come together may be used as a movement middle point of the user. In some embodiments, the preset condition may be that a direction of the angular velocity at the point in time after the movement middle point changes relative to a direction of the angular velocity at the point in time before the movement middle point, and an angular velocity value at the movement middle point is approximately zero, wherein the direction of the angular velocity at the movement middle point is opposite to the direction of the angular velocity at the movement start point. In some embodiments, to improve the accuracy of the selection of the movement middle point, a change of the angular velocity (acceleration of angular velocity) in a first specific time range after the movement middle point (e.g., 0.05 s, 0.1 s, 0.5 s) may be greater than an acceleration threshold of angular velocity (e.g., 0.05 rad/s). In some implementations, the amplitude information in the electromyographic signal corresponding to the movement middle point is greater than the electromyographic threshold while the movement middle point satisfies the preset condition described above. Since the different movements correspond to different electromyographic signals, the electromyographic threshold is related to the user movement and the target electromyographic signal. In the seated chest press, the electromyographic signal at the pectoral muscle is the target electromyographic signal. In some embodiments, the position corresponding to the middle point of the movement (also may be called as “middle position”) may be approximated as a maximum point of muscle force, where the electromyographic signal may have a relatively great value. It should be noted that the electromyographic signal at the part of the user's body when the user performs the movement during motion is substantially higher than the electromyographic signal at the part of the user's body when the user does not perform the movement during motion (when the muscle in the particular part may be considered as a resting state). For example, an amplitude of the electromyographic signal at the part of the user's body when the user's movement reaches the middle position is 10 times higher than that in the resting state. In addition, the relationship between the amplitude of the electromyographic signal at the part of the user when the movement position reaches the middle position (the movement middle point) and the amplitude of the electromyographic signal in the resting state may be different according to the different movement types performed by the user, and the relationship between the two may be adapted according to the actual movement. In some embodiments, to improve the accuracy of the selection of the movement middle point, the amplitude corresponding to a second specific time range after the movement middle point (e.g., 0.05 s, 0.1 s, 0.5 s) may be continuously greater than the electromyographic threshold. In some embodiments, in addition to the above preset condition (e.g., the angular velocity and an amplitude condition of the electromyographic signal), a Euler angle (also referred to as angle) of the movement middle point and the start position satisfies a certain condition preset to determine the movement middle point. For example, in the seated chest press, the Euler angle at the movement middle point relative to the movement start point may be greater than one or more Euler angle thresholds (also known as angle thresholds). For example, with a front-to-back direction of the human body as an X-axis, a left-right direction of the human body as a Y-axis, and a height direction of the human body as a Z-axis, an Euler angle changed in the X and Y directions may be less than 25°, and the Euler angle changed in the Z direction may be greater than 40° (the movement of the seated chest press is mainly related to the rotation at the Z-axis direction, the above parameters are only reference examples). In some embodiments, the electromyographic thresholds and/or the Euler angle thresholds may be stored in advance in the memory or hard drive of the wearable device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>130</span><span class="html-tag">&lt;/b&gt;</span></div><span>, or in the processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span>, or calculated based on an actual condition and adjusted in real time.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder207"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0110</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0109</span>"</span>&gt;</span></div><div class="opened"><span>In some embodiments, the processing module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>220</span><span class="html-tag">&lt;/b&gt;</span></div><span> may determine, based on the time domain window of the electromyographic signal or the attitude signal, the movement middle point from a time domain window at a time point after the movement start point according to a preset condition. In some implementations, after the movement middle point is determined, whether there are other time points that meet the preset condition within the time range from the movement start point to the movement middle point may be re-verified, and if so, a movement start point closest to the movement middle point may be selected as the best movement start point. In some embodiments, if the difference between the time of the movement middle point and the time of the movement start point is greater than a specific time threshold (e.g., ½ or ⅔ of a movement cycle), the movement middle point is invalid, and the movement start point and movement middle point are re-determined based on preset condition.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder208"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0111</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0110</span>"</span>&gt;</span></div><div class="opened"><span>In some embodiments, the movement end point may be a time point that is within one movement cycle from the movement start point and after the movement middle point. For example, the movement end point may be set to as a point that is one movement cycle from the movement start point, and the movement end point herein may be considered the end of a movement cycle of the user. For example, when the user performs the seated chest press, the movement start point may be set as a time point when the arms extend horizontally to the left and right and start internal rotation, the time point when the arms close together may be the movement middle point of the user, and the time point when the arms return to the extended state again from the horizontal direction may correspond to the movement end point of the user. In some embodiments, the preset condition may be that a changed angular velocity value corresponding to the attitude signal is an extreme value. In some embodiments, to prevent jitter misjudgment, the change in Euler angle should exceed a certain Euler angle threshold, e.g., 20°, in the time range from the movement middle point to the movement end point. In some embodiments, the processing module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>220</span><span class="html-tag">&lt;/b&gt;</span></div><span> may determine the movement end point from the time domain window after the movement middle point based on the time domain windows of the electromyographic signal and the attitude signal according to the preset condition. In some embodiments, if the difference between the time of the movement end point and the time of the movement middle point is greater than a specific time threshold (e.g., ½ of a movement cycle), the movement start point and the movement middle point are invalid, and the movement start point, movement middle point, and movement end point are re-determined based on the preset condition.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder209"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0112</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0111</span>"</span>&gt;</span></div><div class="opened"><span>In some embodiments, at least one set of the movement start point, the movement middle point, and the movement end point in the movement signal may be repeatedly determined, and the movement signal may be segmented based on the at least one set of the movement start point, the movement middle point, and the movement end point as the target feature points. The step may be performed by the processing module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>220</span><span class="html-tag">&lt;/b&gt;</span></div><span> and/or the processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span>. It should be noted that segmentation of the movement signal is not limited to be based on the above movement start point, movement middle point and movement end point, but may also include other time points. For example, for the seated chest press, 5 time points may be selected according to the above steps, a first time point may be a movement start point, a second time point may be a moment of the maximum angular velocity of the internal rotation, a third time point may be the movement middle point, a fourth time point may be the moment of the maximum angular velocity of external rotation, a fifth time point may be the moment when the arms return to extend left and right, and the angular velocity is 0, that is, the movement end point. In this example, compared to the movement start point, movement middle point and movement end point in the above steps, the second time point is added as a ¼ marker point of the movement cycle, the movement end point described in the above embodiments is used as the fourth time point for marking the ¾ position of the movement cycle, and the fifth time point is added as an end point of the complete movement. For the seated chest press, more time points are used here, and a recognition of the movement quality may be done based on the signal of the first ¾ of the movement cycle (i.e., the recognition of the movement quality for a single cycle does not depend on a complete analysis of the signal of a whole cycle), which can complete the monitoring and feedback of the user's movement without the end of a current cycle. At same time, all signals of the process of the whole movement may be completely recorded to be easily uploaded to the cloud or the mobile terminal device, thus more methods may be adopted to monitor the user's movement. For more complex movement, the cycle of the movement may be quite long, and the stages for the movement have different force pattern. In some embodiments, the above method of determining each time point may be adopted to divide the movement into multiple stages, and the signal for each stage may be recognized and fed back separately to improve timeliness of feedback of the user's movement.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="line"><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0113</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0112</span>"</span>&gt;</span><span>It should be noted that the above segmentation and monitoring of the movement signal based on the movement start point, movement middle point and movement end point as a set of target feature point is only an exemplary illustration. In some embodiments, the user's movement signal may also be segmented and monitored based on any one or more of the movement start point, the movement middle point and the movement end point as the target feature point. For example, the movement signal may be segmented and monitored by using the movement start point as the target feature point. For another example, the movement start point and the movement end point may be used as a set of target feature points to segment and monitor the movement signal, and other time point or time ranges that can be used as the target feature point are within the scope of protection of the present disclosure.</span><span class="html-tag">&lt;/p&gt;</span></div><span>
</span><div class="folder" id="folder210"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0114</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0113</span>"</span>&gt;</span></div><div class="opened"><span>It should be noted that the above description of the process </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>700</span><span class="html-tag">&lt;/b&gt;</span></div><span> is for example and illustration purposes only and does not limit the scope of application of the present disclosure. For those skilled in the art, various amendments and changes can be made to the process </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>700</span><span class="html-tag">&lt;/b&gt;</span></div><span> under the guidance of the present disclosure. However, these amendments and changes remain within the scope of the present disclosure. For example, step </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>710</span><span class="html-tag">&lt;/b&gt;</span></div><span> and step </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>720</span><span class="html-tag">&lt;/b&gt;</span></div><span> may be performed simultaneously in the processing module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>220</span><span class="html-tag">&lt;/b&gt;</span></div><span>. For another example, step </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>710</span><span class="html-tag">&lt;/b&gt;</span></div><span> and step </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>720</span><span class="html-tag">&lt;/b&gt;</span></div><span> may be performed simultaneously in the processing module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>220</span><span class="html-tag">&lt;/b&gt;</span></div><span> and the processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span>, respectively.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder211"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0115</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0114</span>"</span>&gt;</span></div><div class="opened"><div class="folder" id="folder212"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>8</span><span class="html-tag">&lt;/b&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span> is a diagram illustrating exemplary movement signal segmentation according to some embodiments of the present disclosure. A horizontal coordinate in </span><div class="folder" id="folder213"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>8</span><span class="html-tag">&lt;/b&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span> may indicate a motion time of a user, and a vertical coordinate may indicate amplitude information of an electromyographic signal of a muscle part (e.g., pectoralis major) during seated chest press. Also included in </span><div class="folder" id="folder214"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>8</span><span class="html-tag">&lt;/b&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span> are an angular velocity curve and a Euler angle curve corresponding to an attitude signal of the wrist position of the user during motion. The angular velocity curve is configured to represent a velocity change of the user during motion and the Euler angle curve is configured to represent a position situation of a user's body part during motion. As shown in </span><div class="folder" id="folder215"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>8</span><span class="html-tag">&lt;/b&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span>, point A</span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1</span><span class="html-tag">&lt;/b&gt;</span></div><span> is determined as the movement start point according to the preset condition. Specifically, a direction of the angular velocity at a time point after the user's movement start point A</span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1</span><span class="html-tag">&lt;/b&gt;</span></div><span> changes relative to the direction of the angular velocity at a time point before the movement start point A</span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1</span><span class="html-tag">&lt;/b&gt;</span></div><span>. Further, the angular velocity value at the movement start point A</span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1</span><span class="html-tag">&lt;/b&gt;</span></div><span> is approximately 0, and an acceleration value of the angular velocity at the movement start point A</span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1</span><span class="html-tag">&lt;/b&gt;</span></div><span> is greater than 0.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder216"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0116</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0115</span>"</span>&gt;</span></div><div class="opened"><span>Refer to </span><div class="folder" id="folder217"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>8</span><span class="html-tag">&lt;/b&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span>, point B</span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1</span><span class="html-tag">&lt;/b&gt;</span></div><span> is determined as the movement middle point according to the preset condition. Specifically, the direction of the angular velocity at the time point after the user's movement middle point B</span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1</span><span class="html-tag">&lt;/b&gt;</span></div><span> changes relative to the direction of the angular velocity at the time point before the movement middle point B</span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1</span><span class="html-tag">&lt;/b&gt;</span></div><span>, and the angular velocity value at the movement middle point B</span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1</span><span class="html-tag">&lt;/b&gt;</span></div><span> is approximately 0. The direction of the angular velocity at the movement middle point B</span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1</span><span class="html-tag">&lt;/b&gt;</span></div><span> is opposite to the direction of the angular velocity at the movement start point A</span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1</span><span class="html-tag">&lt;/b&gt;</span></div><span>. In addition, the amplitude of the electromyographic signal (shown as the “electromyographic signal” in </span><div class="folder" id="folder218"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>8</span><span class="html-tag">&lt;/b&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span>) corresponding to the movement middle point B</span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1</span><span class="html-tag">&lt;/b&gt;</span></div><span> is greater than the electromyographic threshold.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder219"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0117</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0116</span>"</span>&gt;</span></div><div class="opened"><span>Continue to refer to </span><div class="folder" id="folder220"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>8</span><span class="html-tag">&lt;/b&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span>, point C</span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1</span><span class="html-tag">&lt;/b&gt;</span></div><span> is determined as the movement end point according to the preset condition. Specifically, a changed angular velocity value at the movement end point C</span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1</span><span class="html-tag">&lt;/b&gt;</span></div><span> is the extreme value from the movement start point A</span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1</span><span class="html-tag">&lt;/b&gt;</span></div><span> to the movement end point C</span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1</span><span class="html-tag">&lt;/b&gt;</span></div><span>. In some embodiments, the process </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>700</span><span class="html-tag">&lt;/b&gt;</span></div><span> may complete the movement segmentation shown in </span><div class="folder" id="folder221"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>8</span><span class="html-tag">&lt;/b&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span>, such that the movement signal from the movement start point A</span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1</span><span class="html-tag">&lt;/b&gt;</span></div><span> to the movement end point C</span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1</span><span class="html-tag">&lt;/b&gt;</span></div><span> shown in </span><div class="folder" id="folder222"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>8</span><span class="html-tag">&lt;/b&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span> may be considered as a segment of the motion.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder223"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0118</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0117</span>"</span>&gt;</span></div><div class="opened"><span>It is noted that in some embodiments, if a time interval between the movement middle point and the movement start point is greater than a specific time threshold (e.g., ½ of a movement cycle), the processing module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>220</span><span class="html-tag">&lt;/b&gt;</span></div><span> may re-determine the movement start point to improve the accuracy of the movement segmentation. The specific time threshold here may be stored in the memory or the hard drive of the wearable device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>130</span><span class="html-tag">&lt;/b&gt;</span></div><span>, or in the processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span>, or calculated or adjusted based on the actual situation of the user during motion. For example, if the time interval between the movement start point A</span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1</span><span class="html-tag">&lt;/b&gt;</span></div><span> and the movement middle point B</span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1</span><span class="html-tag">&lt;/b&gt;</span></div><span> in </span><div class="folder" id="folder224"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>8</span><span class="html-tag">&lt;/b&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span> is greater than a specific time threshold, the processing module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>220</span><span class="html-tag">&lt;/b&gt;</span></div><span> may re-determine the movement start point, thereby improving the accuracy of the movement segmentation. In addition, the segmentation of the movement signal is not limited to be based on the above movement start point A</span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1</span><span class="html-tag">&lt;/b&gt;</span></div><span>, movement middle point B</span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1</span><span class="html-tag">&lt;/b&gt;</span></div><span> and movement end point C</span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1</span><span class="html-tag">&lt;/b&gt;</span></div><span>, but may also include other time points, and selection of the time points may be made according to complexity of the movement.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder225"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0119</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0118</span>"</span>&gt;</span></div><div class="opened"><span>When obtaining the user's movement signal, other physiological parameter information of the user (e.g., a heart rate signal), external condition such as a relative movement of the obtaining module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>210</span><span class="html-tag">&lt;/b&gt;</span></div><span> and the human body during motion or compression of the obtaining module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>210</span><span class="html-tag">&lt;/b&gt;</span></div><span> may affect the quality of the movement signal, for example, resulting in an abrupt change in the electromyographic signal, thereby affecting the monitoring of the movement. For ease of description, an abrupt electromyographic signal may be described by using a singularity, and an exemplary singularity may include a burr signal, a discontinuous signal, etc. In some embodiments, monitoring the movement of the user during motion based at least on the feature information corresponding to the electromyographic signal or the feature information corresponding to the attitude signal may further include: pre-processing the electromyographic signal in a frequency domain or a time domain, obtaining, based on the pre-processed electromyographic signal, the feature information corresponding to the electromyographic signal, and monitoring, based on the feature information corresponding to the electromyographic signal or the feature information corresponding to the attitude signal, the movement of the user during motion. In some embodiments, pre-processing the electromyographic signal in the frequency domain or the time domain may include filtering the electromyographic signal in the frequency domain to select or retain components of the electromyographic signal in a particular frequency range in the frequency domain. In some embodiments, the obtaining module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>210</span><span class="html-tag">&lt;/b&gt;</span></div><span> may obtain an electromyographic signal in a frequency range of 1 Hz-1000 Hz, filter the electromyographic signal and select an electromyographic signal in a specific frequency range (e.g., 30 Hz-150 Hz) for subsequent processing. In some embodiments, the specific frequency range may be 10 Hz-500 Hz. According to preference of example, the specific frequency range may be 15 Hz-300 Hz or 30 Hz-150 Hz. In some embodiments, a filtering process may include a low-pass filter processing. In some embodiments, the low-pass filter may include an LC passive filter, an RC passive filter, an RC active filter, a passive filter composed of special elements. In some embodiments, the passive filter composed of the special elements may include one or more of a piezoelectric ceramic filter, a crystal filter, and an acoustic surface filter. It should be noted that the specific frequency range is not limited to the above range, but may also be other ranges, which may be selected according to the actual situation. More descriptions of monitoring, according to the feature information corresponding to the electromyographic signal or the feature information corresponding to the attitude signal, the movement of the user during motion may be found in </span><div class="folder" id="folder226"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>5</span><span class="html-tag">&lt;/b&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span>, </span><div class="folder" id="folder227"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>6</span><span class="html-tag">&lt;/b&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span> of the present disclosure and their relevant descriptions.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="line"><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0120</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0119</span>"</span>&gt;</span><span>In some embodiments, pre-processing the electromyographic signal in the frequency domain or the time domain may further include signal correction processing of the electromyographic signal in the time domain. The signal correction processing refers to a correction to the singularity (e.g., the burr signal, the discontinuous signal, etc.) in the electromyographic signal. In some embodiments, the signal correction processing of the electromyographic signal in the time domain may include determining the singularity in the electromyographic signal, i.e., determining the abrupt signal in the electromyographic signal. The singularity may be a sudden change in the amplitude of an electromyographic signal within a certain moment, causing a discontinuity in the signal. For another example, the electromyographic signal is morphologically smooth and there is no abrupt change in the amplitude of the electromyographic signal, but there is the abrupt change in the first-order differential of the electromyographic signal, and the first-order differential is discontinuous. In some embodiments, the method of determining the singularity in the electromyographic signal may include, but is not limited to, one or more of Fourier transform, wavelet transform, fractal dimension, etc. In some embodiments, the signal correction processing of the electromyographic signal in the time domain may include removing the singularity in the electromyographic signal, for example, removing signals within a period of time at and near the singularity. Alternatively, the signal correction processing of the electromyographic signal in the time domain may include correcting the singularity of the electromyographic signal according to the feature information of the electromyographic signal in the specific time range, such as adjusting the amplitude of the singularity based on the signals around the singularity. In some embodiments, the feature information of the electromyographic signal may include the amplitude information, the statistic information of the amplitude information, etc. The statistic information of amplitude information (also known as amplitude entropy) refers to a distribution of the amplitude information of the electromyographic signal in the time domain. In some embodiments, after a location (e.g., the time point) of the singularity in the electromyographic signal is determined through a signal processing algorithm (e.g., the Fourier transform, the wavelet transform, the fractal dimension), the singularity may be corrected based on the electromyographic signal in the specific time range before or after the location of the singularity. For example, when the singularity is an abrupt trough, the electromyographic signal at the abrupt trough can be supplemented based on the feature information (e.g., the amplitude information, the statistic information of the amplitude information) of the electromyographic signal in a specific time range (e.g., 5 ms-60 ms) before or after the abrupt trough.</span><span class="html-tag">&lt;/p&gt;</span></div><span>
</span><div class="folder" id="folder228"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0121</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0120</span>"</span>&gt;</span></div><div class="opened"><span>Exemplary illustration with the singularity as the burr signal, </span><div class="folder" id="folder229"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>9</span><span class="html-tag">&lt;/b&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span> is a flowchart of an exemplary process for pre-processing an electromyographic signal according to some embodiments of the present disclosure. As shown in </span><div class="folder" id="folder230"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>9</span><span class="html-tag">&lt;/b&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span>, the process </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>900</span><span class="html-tag">&lt;/b&gt;</span></div><span> may include:</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder231"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0122</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0121</span>"</span>&gt;</span></div><div class="opened"><span>Step </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>910</span><span class="html-tag">&lt;/b&gt;</span></div><span>, selecting, based on the time domain window of the electromyographic signal, different time windows from the time domain window of the electromyographic signal, wherein the different time windows respectively cover different time ranges.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder232"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0123</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0122</span>"</span>&gt;</span></div><div class="opened"><span>In some embodiments, the step may be performed by the processing module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>220</span><span class="html-tag">&lt;/b&gt;</span></div><span> and/or the processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span>. In some embodiments, the different windows may include at least one specific window. A specific window is a window with a specific time length selected from the time domain window. For example, a time length of the specific window may be 100 ms when the time length of the time domain window of the electromyographic signal is 3 s. In some embodiments, a specific window may include a plurality of different time windows. Merely as way of exemplary illustration, the specific window may include a first time window and a second time window, and the first time window may refer to a window corresponding to a partial time length of the specific window, for example, when the time length of the specific window is 100 ms, the time length of the first time window may be 80 ms. The second time window may be another window corresponding to the partial time length of the specific window. For example, when the specific window is 100 ms, the second time window may be 20 ms. In some embodiments, the first time window and the second time window may be consecutive time windows within a same specific window. In some embodiments, the first time window and the second time window may also be two discrete or overlapping time windows within the same specific window. For example, when the time length of the specific window is 100 ms, the time length of the first time window may be 80 ms and the time length of the second time window may be 25 ms, in which case the second time window is overlapped with the first time window in 5 ms. In some embodiments, the processing module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>220</span><span class="html-tag">&lt;/b&gt;</span></div><span> may slide and update the specific window sequentially from an initially time point of the time domain window of the electromyographic signal according to the specific time length based on the time domain window of the electromyographic signal, and may continue to divide an updated specific window into the first time window and the second time window. The specific time length mentioned here may be less than 1 s, 2 s, 3 s, etc. For example, the processing module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>220</span><span class="html-tag">&lt;/b&gt;</span></div><span> may select a specific window of a specific time length of 100 ms and divide that specific window into a first time window of 80 ms and a second time window of 20 ms. Further, the specific window may be updated by sliding along the time direction. A sliding distance here may be a time length of the second time window (e.g., 20 ms) or other suitable time lengths, e.g., 30 ms, 40 ms, etc.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder233"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0124</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0123</span>"</span>&gt;</span></div><div class="opened"><span>Step </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>920</span><span class="html-tag">&lt;/b&gt;</span></div><span>, determining, based on the feature information corresponding to the electromyographic signal in the different time windows, the burr signal.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder234"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0125</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0124</span>"</span>&gt;</span></div><div class="opened"><span>In some embodiments, the step may be performed by the processing module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>220</span><span class="html-tag">&lt;/b&gt;</span></div><span> and/or the processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span>. In some embodiments, the feature information corresponding to the electromyographic signal may include at least one of the amplitude information, the statistic information of the amplitude information. In some embodiments, the processing module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>220</span><span class="html-tag">&lt;/b&gt;</span></div><span> may obtain the amplitude information or the statistic information of the amplitude information corresponding to the electromyographic signal in different time windows (e.g., the first time window, the second time window) to determine the location of the burr signal. Detailed descriptions of determining, based on the feature information corresponding to the electromyographic signal in different time windows, the location of the burr signal may be found in </span><div class="folder" id="folder235"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>10</span><span class="html-tag">&lt;/b&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span> and its relevant descriptions.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder236"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0126</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0125</span>"</span>&gt;</span></div><div class="opened"><span>It should be noted that the above description of the process </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>900</span><span class="html-tag">&lt;/b&gt;</span></div><span> is for example and illustration purposes only and does not limit the scope of application of the present disclosure. For those skilled in the art, various amendments and changes can be made to process </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>900</span><span class="html-tag">&lt;/b&gt;</span></div><span> under the guidance of the present disclosure. For example, the specific window is not limited to include the first time window and the second time window described above, but may also include other time windows, for example, a third time window, a fourth time window, etc. In addition, the specific range of moments before or after the position of the burr signal may be adapted according to the length of the burr signal, which will not be further limited herein. However, these amendments and changes remain within the scope of the present disclosure.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder237"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0127</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0126</span>"</span>&gt;</span></div><div class="opened"><div class="folder" id="folder238"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>10</span><span class="html-tag">&lt;/b&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span> is a flow chart illustrating an exemplary process for determining a burr signal according to some embodiments of the present disclosure.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder239"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0128</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0127</span>"</span>&gt;</span></div><div class="opened"><span>Step </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1010</span><span class="html-tag">&lt;/b&gt;</span></div><span>, determining first amplitude information corresponding to the electromyographic signal within the first time window and second amplitude information corresponding to the electromyographic signal within the second time window.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder240"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0129</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0128</span>"</span>&gt;</span></div><div class="opened"><span>In some embodiments, the step may be performed by the processing module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>220</span><span class="html-tag">&lt;/b&gt;</span></div><span> and/or the processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span>. In some embodiments, the processing module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>220</span><span class="html-tag">&lt;/b&gt;</span></div><span> may select the time length of the first time window and the second time window and extract the first amplitude information corresponding to the electromyographic signal during the time length of the first time window and the second amplitude information corresponding to the electromyographic signal during the time length of the second time window. In some embodiments, the first amplitude information may include an average amplitude of the electromyographic signal during the first time window, and the second amplitude information may include the average amplitude of the electromyographic signal during the second time window. For example, the processing module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>220</span><span class="html-tag">&lt;/b&gt;</span></div><span> may select a time length of a first time window as 80 ms and extract the first amplitude information corresponding to the electromyographic signal within the first time window, and the processing module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>220</span><span class="html-tag">&lt;/b&gt;</span></div><span> may select a time length of a second time window as 20 ms and extract the second amplitude information corresponding to the electromyographic signal within the second time window.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="line"><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0130</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0129</span>"</span>&gt;</span><span>In some embodiments, a selection of the time length of the first time window and the time length of the second time window is related to the shortest burr signal length and amount of computation of the system. In some embodiments, the time length of the first time window and the time length of the second time window may be selected according to the feature of the burr signal. The time length of an electro-cardio burr signal is 40 ms-100 ms, the time interval between two burr signals in the electro-cardio signal may be about 1 s, a peak point of the burr signal is basically symmetrical on both sides, an amplitude distribution of the burr signal is relatively even on both sides, etc. In some embodiments, when the burr signal is the electro-cardio signal, a time length less than the length of the burr signal, e.g., half the length of the burr signal, may be selected as the time length of the second time window, and the time length of the first time window may be greater than (e.g., four times) the time length of the second time window. In some embodiments, the time length of the first time window may be within a range of an interval (about 1 s) between burr signals minus the time length of the second time window. It should also be noted that the above selected time length of the first time window and the time length of the second time window are not limited to the above description, as long as a sum of the time length of the second time window and the time length of the first time window is less than time intervals of adjacent two burr signals, or the time length of the second time window is less than the single burr signal length, or an amplitude of the electromyographic signal within the second time window and an amplitude of the electromyographic signal the first time window may be discriminated.</span><span class="html-tag">&lt;/p&gt;</span></div><span>
</span><div class="folder" id="folder241"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0131</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0130</span>"</span>&gt;</span></div><div class="opened"><span>Step </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1020</span><span class="html-tag">&lt;/b&gt;</span></div><span>, judging whether a ratio of the second amplitude information to the first amplitude information is greater than a threshold.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder242"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0132</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0131</span>"</span>&gt;</span></div><div class="opened"><span>In some embodiments, the step may be performed by the processing module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>220</span><span class="html-tag">&lt;/b&gt;</span></div><span> and/or the processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span>. In some embodiments, the processing module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>220</span><span class="html-tag">&lt;/b&gt;</span></div><span> may determine whether the ratio of the second amplitude information corresponding to the electromyographic signal in the second time window to the first amplitude information corresponding to the electromyographic signal in the first time window is greater than the threshold. The threshold here may be stored in the memory or the hard drive of the wearable device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>130</span><span class="html-tag">&lt;/b&gt;</span></div><span>, or in the processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span>, or adjusted according to the actual situation. In some embodiments, the step </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1020</span><span class="html-tag">&lt;/b&gt;</span></div><span> may proceed to step </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1030</span><span class="html-tag">&lt;/b&gt;</span></div><span> if the processing module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>220</span><span class="html-tag">&lt;/b&gt;</span></div><span> judges that the ratio of the second amplitude information to the first amplitude information is greater than the threshold. In other embodiments, if the processing module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>220</span><span class="html-tag">&lt;/b&gt;</span></div><span> determines that the ratio of the second amplitude information to the first amplitude information is not greater than the threshold, step </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1020</span><span class="html-tag">&lt;/b&gt;</span></div><span> may proceed to step </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1040</span><span class="html-tag">&lt;/b&gt;</span></div><span>.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder243"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0133</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0132</span>"</span>&gt;</span></div><div class="opened"><span>Step </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1030</span><span class="html-tag">&lt;/b&gt;</span></div><span>, performing a signal correction processing on the electromyographic signal within the second time window.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder244"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0134</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0133</span>"</span>&gt;</span></div><div class="opened"><span>In some embodiments, the step may be performed by the processing module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>220</span><span class="html-tag">&lt;/b&gt;</span></div><span> and/or the processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span>. In some embodiments, the processing module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>220</span><span class="html-tag">&lt;/b&gt;</span></div><span> may perform the signal correction processing on the electromyographic signal within the second time window based on the comparison result of the ratio of the second amplitude information to the first amplitude information and the threshold in step </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1020</span><span class="html-tag">&lt;/b&gt;</span></div><span>. For example, in some embodiments, if the ratio of the second amplitude information to the first amplitude information is greater than the threshold, then the electromyographic signal in the second time window corresponding to the second amplitude information is a burr signal. In some embodiments, processing the electromyographic signal within the second time window may include performing signal correction processing on the electromyographic signal within the second time window based on the electromyographic signal within a specific time range before or after the second time window. In some embodiments, the signal correction processing of the electromyographic signal within the second time window may include, but is not limited to, padding, interpolation, etc. In some embodiments, the specific time range herein may be 5 ms-60 ms. According to preference of example, the specific time range may be 10 ms-50 ms or 20 ms-40 ms. It should be noted that the specific time range is not limited to the above range, for example, the specific time range may be greater than 60 ms, less than 5 ms, or other ranges. In practical application scenarios, the specific time range may be adapted based on the duration of the burr signal.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder245"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0135</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0134</span>"</span>&gt;</span></div><div class="opened"><span>In step </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1040</span><span class="html-tag">&lt;/b&gt;</span></div><span>, retaining an electromyographic signal within the second time window.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder246"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0136</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0135</span>"</span>&gt;</span></div><div class="opened"><span>In some embodiments, the step may be performed by the processing module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>220</span><span class="html-tag">&lt;/b&gt;</span></div><span> and/or the processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span>. In some embodiments, the processing module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>220</span><span class="html-tag">&lt;/b&gt;</span></div><span> may perform retention on the electromyographic signal within the second time window according to the comparison result of the ratio of the second amplitude information to the first amplitude information and the threshold in step </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1020</span><span class="html-tag">&lt;/b&gt;</span></div><span>. For example, in some embodiments, the ratio of the second amplitude information to the first amplitude information is not greater than the threshold, then the electromyographic signal within the second time window corresponding to the second amplitude information is a normal electromyographic signal, and the normal electromyographic signal may be retained, i.e., the electromyographic signal within the second time window is retained.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder247"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0137</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0136</span>"</span>&gt;</span></div><div class="opened"><span>It should be noted that the amplitude of the electromyographic signal is gradually increasing since electrical charges gradually accumulates during muscular exertion, so that the amplitude of the electromyographic signal within two adjacent time windows (e.g., the first time window and the second time window) does not change abruptly in the absence of a burr signal. In some embodiments, whether there is the burr signal in the electromyographic signal may be determined and the burr signal may be removed based on the process </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1000</span><span class="html-tag">&lt;/b&gt;</span></div><span> to realize a real-time processing of the burr signal, thereby enabling the wearable device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>130</span><span class="html-tag">&lt;/b&gt;</span></div><span> or the mobile terminal device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>140</span><span class="html-tag">&lt;/b&gt;</span></div><span> to provide a real-time feedback of the motion state to the user, and helping the user to perform motion more scientifically.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="line"><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0138</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0137</span>"</span>&gt;</span><span>In some embodiments, the time length corresponding to the first time window may be greater than the time length corresponding to the second time window. In some embodiments, a specific time length corresponding to a specific window may be less than 1 s. In some embodiments, the ratio of the time length corresponding to the first time window to the time length corresponding to the second time window may be greater than 2. In some embodiments, the time length corresponding to the first time window, the time length corresponding to the second time window, and the specific time length corresponding to the specific window are selected to ensure that the shortest burr signal (e.g., 40 ms) can be removed, and the system has a high signal-to-noise ratio, calculation volume of the system can be decreased, repeated calculation of the system can be avoided, the time complexity can be reduced, thereby improving calculation efficiency and calculation accuracy of the system.</span><span class="html-tag">&lt;/p&gt;</span></div><span>
</span><div class="folder" id="folder248"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0139</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0138</span>"</span>&gt;</span></div><div class="opened"><span>It should be noted that the above description of the process </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1000</span><span class="html-tag">&lt;/b&gt;</span></div><span> is for example and illustration purposes only, and does not limit the scope of application of the present disclosure. For those skilled in the art, various amendments and changes may be made to process </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1000</span><span class="html-tag">&lt;/b&gt;</span></div><span> under the guidance of the present disclosure. For example, the above process </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1000</span><span class="html-tag">&lt;/b&gt;</span></div><span> is only an example where the singularity is the burr signal, and when the singularity is a trough signal, each of the above steps (e.g., step </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1010</span><span class="html-tag">&lt;/b&gt;</span></div><span>, step </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1020</span><span class="html-tag">&lt;/b&gt;</span></div><span>, step </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1030</span><span class="html-tag">&lt;/b&gt;</span></div><span>, etc.) and the technical schemes may be adjusted or other methods may be used to perform signal correction processing. However, these amendments and changes remain within the scope of the present disclosure.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="line"><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0140</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0139</span>"</span>&gt;</span><span>In some embodiments, the signal correction processing on the singularity of the electromyographic signal may further be performed by the other methods, e.g., a high-pass method, a low-pass method, a band-pass method, a wavelet transform reconstruction method, etc. In some embodiments, for an application scenario where a low-frequency signal is not sensitive, a 100 Hz high-pass filter may be used for a removal of the burr signal. In some embodiments, in addition to the signal correction processing of the electromyographic signal, the other methods of the signal processing of the electromyographic signal, such as a filtering processing, a signal amplification, a phase adjustment, etc., may also be performed. In some embodiments, the electromyographic signal of the user collected by the electromyographic sensor may be converted into a digital electromyographic signal by an analog-to-digital converter (ADC), and the converted digital electromyographic signal may be subjected to a filtering process, which can filter out an industrial frequency signal and its harmonic signal, etc. In some embodiments, the processing of the electromyographic signal may further include removing motion artifacts of the user. The motion artifacts here refer to signal noise generated by a relative movement of the muscles at the position to be measured relative to the electromyographic module during an obtaining process of the electromyographic signal while the user in motion.</span><span class="html-tag">&lt;/p&gt;</span></div><span>
</span><div class="folder" id="folder249"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0141</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0140</span>"</span>&gt;</span></div><div class="opened"><span>In some embodiments, the attitude signal may be obtained by the attitude sensor on the wearable device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>130</span><span class="html-tag">&lt;/b&gt;</span></div><span>. The attitude sensor on the wearable device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>130</span><span class="html-tag">&lt;/b&gt;</span></div><span> may be distributed on the limb areas (e.g., arms, legs, etc.), the trunk areas (e.g., chest, abdomen, back, waist, etc.), and the head, etc. The attitude sensor enables the collection of the attitude signal from other parts of the body such as limb parts and trunk parts. In some embodiments, the attitude sensor may be a sensor of an Attitude and heading reference system (AHRS) with an attitude fusion algorithm. The attitude fusion algorithm may fuse data from a nine-axis inertial measurement unit (IMU) with a three-axis acceleration sensor, a three-axis angular velocity sensor, and a three-axis geomagnetic sensor into Euler angles or quaternions to obtain the attitude signal of the user's body part where the attitude sensor is located. In some embodiments, the processing module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>220</span><span class="html-tag">&lt;/b&gt;</span></div><span> and/or the processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span> may determine the feature information corresponding to the attitude based on the attitude signal. In some embodiments, the feature information corresponding to the attitude signal may include, but is not limited to, the angular velocity value, the direction of angular velocity, the acceleration value of angular velocity, etc. In some embodiments, the attitude sensor may be a strain sensor, and the strain sensor may obtain a bending direction and bending angle at the user's joints, thereby obtaining the attitude signal during the user's motion. For example, the strain sensor may be set at the knee joint of the user, and when the user is in motion, the user's body part acts on the strain sensor, and the bending direction and the bending angle at the knee joint of the user may be calculated based on the change in resistance or length of the strain sensor, thereby obtaining the attitude signal of the user's leg. In some embodiments, the attitude sensor may also include a fiber optic sensor, and the attitude signal may be represented by a change in direction after bending of a fiber from the fiber optic sensor. In some embodiments, the attitude sensor may also be a magnetic flux sensor, and the attitude signal may be represented by transformation of the magnetic flux. It should be noted that the type of attitude sensor is not limited to the above sensors, but can also be other sensors, the sensors that can obtain the user's attitude signal are within the scope of the attitude sensor of the present disclosure.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder250"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0142</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0141</span>"</span>&gt;</span></div><div class="opened"><div class="folder" id="folder251"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>11</span><span class="html-tag">&lt;/b&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span> is a flowchart of an exemplary process for determining feature information corresponding to an attitude signal according to some embodiments of the present disclosure. As shown in </span><div class="folder" id="folder252"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>11</span><span class="html-tag">&lt;/b&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span>, the process </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1100</span><span class="html-tag">&lt;/b&gt;</span></div><span> may include:</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder253"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0143</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0142</span>"</span>&gt;</span></div><div class="opened"><span>Step </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1110</span><span class="html-tag">&lt;/b&gt;</span></div><span>, obtaining a target coordinate system and a conversion relationship between the target coordinate system and at least one original coordinate system.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder254"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0144</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0143</span>"</span>&gt;</span></div><div class="opened"><span>In some embodiments, the step may be performed by the processing module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>220</span><span class="html-tag">&lt;/b&gt;</span></div><span> and/or the processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span>. In some embodiments, the original coordinate system is a coordinate system corresponding to the attitude sensor set on the human body. When the user uses the wearable device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>130</span><span class="html-tag">&lt;/b&gt;</span></div><span>, each attitude sensor on the wearable device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>130</span><span class="html-tag">&lt;/b&gt;</span></div><span> is distributed on different parts of the human body, so that installation angles of the attitude sensors are different, and the attitude sensors in different parts use their own coordinate systems as the original coordinate systems, so the attitude sensors in different parts have different original coordinate systems. In some embodiments, an obtained attitude signal of the each attitude sensor may be represented in its corresponding original coordinate system. By transforming the attitude signal in different original coordinate systems into a same coordinate system (e.g., the target coordinate system), it is easy to determine relative motion between different parts of the human body. In some embodiments, the target coordinate system refers to a human coordinate system established based on the human body. For example, a length direction of the human torso (i.e., a direction perpendicular to a transverse plane of the body) can be used as the Z-axis, an anterior-posterior direction of the human torso (i.e., the direction perpendicular to the coronal plane of the body) as the X-axis, and the left-right direction of the human torso (i.e., the direction perpendicular to the sagittal plane of the body) as the Y-axis in the target coordinate system. In some embodiments, there is a conversion relationship between the target coordinate system and the original coordinate system by which the coordinate information in the original coordinate system can be converted to the coordinate information in the target coordinate system. In some embodiments, the conversion relationship may be expressed as one or more rotation matrices. More descriptions of determining the conversion relationship between the target coordinate system and the original coordinate system may be found in </span><div class="folder" id="folder255"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>13</span><span class="html-tag">&lt;/b&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span> of the present disclosure and its relevant descriptions.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder256"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0145</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0144</span>"</span>&gt;</span></div><div class="opened"><span>Step </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1120</span><span class="html-tag">&lt;/b&gt;</span></div><span>, converting, based on the conversion relationship, the coordinate information in the at least one original coordinate system to the coordinate information in the target coordinate system.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder257"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0146</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0145</span>"</span>&gt;</span></div><div class="opened"><span>In some embodiments, the step may be performed by the processing module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>220</span><span class="html-tag">&lt;/b&gt;</span></div><span> and/or the processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span>. The coordinate information in the original coordinate system is three-dimensional coordinate information in the original coordinate system. The coordinate information in the target coordinate system is the three-dimensional coordinate information in the target coordinate system. Merely as way of exemplary illustration, the coordinate information v</span><div class="line"><span class="html-tag">&lt;sub&gt;</span><span>1 </span><span class="html-tag">&lt;/sub&gt;</span></div><span>in the original coordinate system may be converted to the coordinate information v</span><div class="line"><span class="html-tag">&lt;sub&gt;</span><span>2 </span><span class="html-tag">&lt;/sub&gt;</span></div><span>in the target coordinate system according to the conversion relationship. Specifically, a conversion between the coordinate information v</span><div class="line"><span class="html-tag">&lt;sub&gt;</span><span>1 </span><span class="html-tag">&lt;/sub&gt;</span></div><span>and the coordinate information v</span><div class="line"><span class="html-tag">&lt;sub&gt;</span><span>2 </span><span class="html-tag">&lt;/sub&gt;</span></div><span>may be performed by using a rotation matrix, the rotation matrix here can be understood as the conversion relationship between the original coordinate system and the target coordinate system. Specifically, the coordinate information v</span><div class="line"><span class="html-tag">&lt;sub&gt;</span><span>1 </span><span class="html-tag">&lt;/sub&gt;</span></div><span>in the original coordinate system may be converted to coordinate information v</span><div class="line"><span class="html-tag">&lt;sub&gt;</span><span>1</span><span class="html-tag">&lt;/sub&gt;</span></div><span>−1 by a first rotation matrix, the coordinate information v</span><div class="line"><span class="html-tag">&lt;sub&gt;</span><span>1</span><span class="html-tag">&lt;/sub&gt;</span></div><span>−1 may be converted to coordinate information v</span><div class="line"><span class="html-tag">&lt;sub&gt;</span><span>1</span><span class="html-tag">&lt;/sub&gt;</span></div><span>−2 by a second rotation matrix, and the coordinate information v</span><div class="line"><span class="html-tag">&lt;sub&gt;</span><span>1</span><span class="html-tag">&lt;/sub&gt;</span></div><span>−2 may be converted to coordinate information v</span><div class="line"><span class="html-tag">&lt;sub&gt;</span><span>1</span><span class="html-tag">&lt;/sub&gt;</span></div><span>−3 by a third rotation matrix. The coordinate information v</span><div class="line"><span class="html-tag">&lt;sub&gt;</span><span>1</span><span class="html-tag">&lt;/sub&gt;</span></div><span>−3 is the coordinate information v</span><div class="line"><span class="html-tag">&lt;sub&gt;</span><span>2 </span><span class="html-tag">&lt;/sub&gt;</span></div><span>in the target coordinate system. It should be noted that the rotation matrices are not limited to the above first rotation matrix, the second rotation matrix and the third rotation matrix, but may also include fewer or more rotation matrices. In some alternative embodiments, the rotation matrix may be a rotation matrix or a combination of a plurality of rotation matrices.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder258"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0147</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0146</span>"</span>&gt;</span></div><div class="opened"><span>Step </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1130</span><span class="html-tag">&lt;/b&gt;</span></div><span>, determining, based on the coordinate information in the target coordinate system, the feature information corresponding to the attitude signal.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder259"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0148</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0147</span>"</span>&gt;</span></div><div class="opened"><span>In some embodiments, the step may be performed by the processing module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>220</span><span class="html-tag">&lt;/b&gt;</span></div><span> and/or the processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span>. In some embodiments, determining, based on the coordinate information in the target coordinate system, the feature information corresponding to the attitude signal comprises determining based on a plurality of coordinate information in the target coordinate system of the user during motion, the feature information corresponding to the attitude signal of the user. For example, when the user performs a seated chest press, the user's arm may correspond to the first coordinate information in the target coordinate system when the user's arm is held forward, and the user's arm can correspond to the second coordinate information in the target coordinate system when the user's arm is opened in a same plane as the torso. Based on the first coordinate information and the second coordinate information, the feature information (for example, the angular velocity, the angular velocity direction, and the acceleration value of the angular velocity) corresponding to the attitude signal may be calculated.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder260"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0149</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0148</span>"</span>&gt;</span></div><div class="opened"><span>It should be noted that the above description of the process </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1100</span><span class="html-tag">&lt;/b&gt;</span></div><span> is for example and illustration purposes only and does not limit the scope of application of the present disclosure. For those skilled in the art, various amendments and changes can be made to process </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1100</span><span class="html-tag">&lt;/b&gt;</span></div><span> under the guidance of the present disclosure. However, these amendments and changes remain within the scope of the present disclosure.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder261"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0150</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0149</span>"</span>&gt;</span></div><div class="opened"><span>In some embodiments, the relative motion between different motion parts of the user's body may be determined by the feature information corresponding to the attitude sensors located at the different motion parts of the user's body. For example, by using the feature information corresponding to the attitude sensor at the user's arm and the feature information corresponding to the attitude sensor at the user's torso, the relative motion between the user's arm and torso during motion can be determined. </span><div class="folder" id="folder262"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>12</span><span class="html-tag">&lt;/b&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span> is a flowchart of an exemplary process for determining relative motion between the different motion parts of the user according to some embodiments of the present disclosure. As shown in </span><div class="folder" id="folder263"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>12</span><span class="html-tag">&lt;/b&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span>, the process </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1200</span><span class="html-tag">&lt;/b&gt;</span></div><span> may include:</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder264"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0151</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0150</span>"</span>&gt;</span></div><div class="opened"><span>Step </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1210</span><span class="html-tag">&lt;/b&gt;</span></div><span>, determining, based on the conversion relationships between the different original coordinate systems and the target coordinate system, the feature information corresponding to at least two sensors respectively.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder265"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0152</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0151</span>"</span>&gt;</span></div><div class="opened"><span>In some embodiments, the step may be performed by the processing module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>220</span><span class="html-tag">&lt;/b&gt;</span></div><span> and/or the processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span>. In some embodiments, different sensors have different conversion relationships between the original coordinate systems corresponding to the sensors and the target coordinate system due to the different installation positions at the human body. In some embodiments, the processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span> may convert the coordinate information in the original coordinate systems corresponding to the sensors of different parts of the user (e.g., small arm, large arm, torso, etc.) to the coordinate information in the target coordinate system, respectively, so that the feature information corresponding to at least two sensors can be determined respectively. More descriptions of the conversion of the coordinate information in the original coordinate system to coordinate information in the target coordinate system may be found elsewhere in the present disclosure, e.g., </span><div class="folder" id="folder266"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>11</span><span class="html-tag">&lt;/b&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span>, which will not be repeated herein.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder267"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0153</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0152</span>"</span>&gt;</span></div><div class="opened"><span>Step </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1220</span><span class="html-tag">&lt;/b&gt;</span></div><span>, determining, based on the feature information corresponding to the at least two sensors respectively, the relative motion between the different motion parts.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder268"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0154</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0153</span>"</span>&gt;</span></div><div class="opened"><span>In some embodiments, the step may be performed by the processing module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>220</span><span class="html-tag">&lt;/b&gt;</span></div><span> and/or the processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span>. In some embodiments, a motion part may refer to a limb on the human body that can move independently, for example, a small arm, a large arm, a small leg, a thigh, etc. Merely as way of exemplary illustration, when the user performs an arm lifting dumbbell, the coordinate information in the target coordinate system corresponding to the sensor set at the small arm part and the coordinate information in the target coordinate system corresponding to the sensor set at the large arm part are combined to determine the relative motion between the small arm and the large arm of the user, thereby determining the arm lifting dumbbell movement of the user.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="line"><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0155</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0154</span>"</span>&gt;</span><span>In some embodiments, a same motion part of the user may be arranged with a plurality of sensors of the same or different types, and the coordinate information in the original coordinate systems corresponding to a plurality of sensors of same or different types may be converted to the coordinate information in the target coordinate system, respectively. For example, a plurality of sensors of the same or different types can be arranged at different locations of the user's small arm part, and a plurality of coordinates in the target coordinate system corresponding to a plurality of sensors of the same or different types may simultaneously represent the movement of the user's small arm part. For example, the coordinate information in the target coordinate systems corresponding to a plurality of sensors of the same type can be averaged, thereby improving the accuracy of the coordinate information of the motion parts during the user's motion. For example, the coordinate information in the target coordinate system can be obtained by performing a fusion algorithm (e.g., Kalman filtering, etc.) on the coordinate information in coordinate systems corresponding to a plurality of the different types of sensors.</span><span class="html-tag">&lt;/p&gt;</span></div><span>
</span><div class="folder" id="folder269"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0156</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0155</span>"</span>&gt;</span></div><div class="opened"><span>It should be noted that the above description of the process </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1100</span><span class="html-tag">&lt;/b&gt;</span></div><span> is for example and illustration purposes only and does not limit the scope of application of the present disclosure. For those skilled in the art, various amendments and changes can be made to process </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1100</span><span class="html-tag">&lt;/b&gt;</span></div><span> under the guidance of the present disclosure. However, these amendments and changes remain within the scope of the present disclosure.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder270"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0157</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0156</span>"</span>&gt;</span></div><div class="opened"><div class="folder" id="folder271"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>13</span><span class="html-tag">&lt;/b&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span> is a flowchart of an exemplary process for determining a conversion relationship between an original coordinate system to a specific coordinate system according to some embodiments of the present disclosure. In some embodiments, the process of determining the conversion relationship between the original coordinate system to a specific coordinate system may also be called a calibration process. As shown in </span><div class="folder" id="folder272"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>13</span><span class="html-tag">&lt;/b&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span>, the process </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1300</span><span class="html-tag">&lt;/b&gt;</span></div><span> may include:</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder273"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0158</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0157</span>"</span>&gt;</span></div><div class="opened"><span>Step </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1310</span><span class="html-tag">&lt;/b&gt;</span></div><span>, constructing the specific coordinate system.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder274"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0159</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0158</span>"</span>&gt;</span></div><div class="opened"><span>In some embodiments, the step may be performed by the processing module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>220</span><span class="html-tag">&lt;/b&gt;</span></div><span> and/or the processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span>. In some embodiments, the conversion relationship between at least one original coordinate system and the target coordinate system may be obtained by the calibration process. The specific coordinate system is a reference coordinate system configured to determine the conversion relationship between the original coordinate system and the target coordinate system during the calibration process. In some embodiments, a constructed specific coordinate system may have the length direction of the torso when the human body is standing as the Z-axis, the front-to-back direction of the human body as the X-axis, and the left-to-right direction of the human torso as the Y-axis. In some embodiments, the specific coordinate system is related to the orientation of the user during the calibration process. For example, if the user's body is facing a fixed direction (e.g., north) during the calibration process, the direction in front of the body (north) is the X-axis.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder275"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0160</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0159</span>"</span>&gt;</span></div><div class="opened"><span>Step </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1320</span><span class="html-tag">&lt;/b&gt;</span></div><span>, obtaining the first coordinate information in the at least one original coordinate system when the user is in a first pose.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder276"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0161</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0160</span>"</span>&gt;</span></div><div class="opened"><span>In some embodiments, the step may be performed by the obtaining module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>210</span><span class="html-tag">&lt;/b&gt;</span></div><span>. The first pose may be a pose that the user approximately remains standing. The obtaining module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>210</span><span class="html-tag">&lt;/b&gt;</span></div><span> (e.g., the sensor) may obtain the first coordinate information in the original coordinate system based on the user's first pose.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder277"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0162</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0161</span>"</span>&gt;</span></div><div class="opened"><span>Step </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1330</span><span class="html-tag">&lt;/b&gt;</span></div><span>, obtaining the second coordinate information in the at least one original coordinate system when the user is in a second pose.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder278"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0163</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0162</span>"</span>&gt;</span></div><div class="opened"><span>In some embodiments, the step may be performed by the obtaining module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>210</span><span class="html-tag">&lt;/b&gt;</span></div><span>. The second pose may be a pose that the user's body part (e.g., arm) where the sensor is located is tilted forward. In some embodiments, the obtaining module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>210</span><span class="html-tag">&lt;/b&gt;</span></div><span> (e.g., the sensor) may obtain the second coordinate information in the original coordinate system based on the user's second pose (e.g., a forward leaning pose).</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder279"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0164</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0163</span>"</span>&gt;</span></div><div class="opened"><span>Step </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1340</span><span class="html-tag">&lt;/b&gt;</span></div><span>, determining, according to the first coordinate information, the second coordinate information, and the specific coordinate system, the relationship between the at least one original coordinate system and the specific coordinate system.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder280"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0165</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0164</span>"</span>&gt;</span></div><div class="opened"><span>In some embodiments, the step may be performed by the processing module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>220</span><span class="html-tag">&lt;/b&gt;</span></div><span> and/or processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span>. In some embodiments, the first rotation matrix may be determined through the first coordinate information corresponding to the first pose. In the first pose, since the Euler angle in a X and Y direction of the specific coordinate system in a ZYX rotation order are 0, and the Euler angle in the X and Y direction of the original coordinate system is not necessarily 0, then the first rotation matrix is the rotation matrix obtained by reversing the original coordinate system around the X-axis and then around the Y-axis. In some embodiments, the second rotation matrix may be determined through the second coordinate information of the second pose (e.g., the body part where the sensor is located is tilted forward). Specifically, in the second pose, it is known that the Euler angle of the specific coordinate system in a Y and Z</span><div class="line"><span class="html-tag">&lt;sub&gt;</span><span>3 </span><span class="html-tag">&lt;/sub&gt;</span></div><span>direction is 0 under the ZYZ rotation order, and the Euler angle of the original coordinate system in a Y and Z</span><div class="line"><span class="html-tag">&lt;sub&gt;</span><span>3 </span><span class="html-tag">&lt;/sub&gt;</span></div><span>direction is not necessarily 0, then the second rotation matrix is the rotation matrix obtained by reversing the original coordinate system around the Y direction and then around the Z</span><div class="line"><span class="html-tag">&lt;sub&gt;</span><span>3 </span><span class="html-tag">&lt;/sub&gt;</span></div><span>direction. The conversion relationship between the original coordinate system and the specific coordinate system may be determined through the above first rotation matrix and second rotation matrix. In some embodiments, when there are a plurality of original coordinate systems (sensors), the above method may be configured to determine the conversion relationship between each original coordinate system and the specific coordinate system.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="line"><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0166</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0165</span>"</span>&gt;</span><span>It should be noted that the above first pose is not limited to an approximately standing pose, and the second pose is not limited to the pose that the user's body part (e.g., arm) where the sensor is located is tilted forward, the first and second poses herein may be approximated as being stationary during the calibration process. In some embodiments, the first pose and/or the second pose may also be a dynamic pose during the calibration process. For example, the user's walking attitude is a relatively fixed attitude, the angle and angular velocity of the arms, legs and feet during walking can be extracted to recognize the movement, such as forward stride, forward arm swing and the like, and the user's forward walking attitude can be used as the second pose in the calibration process. In some embodiments, the second pose is not limited to one movement, but a plurality of movements can also be extracted as the second pose. For example, the coordinate information of a plurality of movements may be fused to obtain a more accurate rotation matrix.</span><span class="html-tag">&lt;/p&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0167</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0166</span>"</span>&gt;</span><span>In some embodiments, the rotation matrix may be dynamically corrected during the calibration process by using some signal processing algorithms (e.g., using Kalman filtering algorithm) to obtain a better transformation matrix throughout the calibration process.</span><span class="html-tag">&lt;/p&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0168</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0167</span>"</span>&gt;</span><span>In some embodiments, machine learning algorithms, or other algorithms may be configured for automatic recognition of some specific movements to update the rotation matrix in real time. For example, if the machine learning algorithm recognizes that a current user is walking, or standing, the calibration process is automatically started. In this case, the wearable device does not need an explicit calibration process anymore, and the rotation matrix is dynamically updated when the user uses the wearable device.</span><span class="html-tag">&lt;/p&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0169</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0168</span>"</span>&gt;</span><span>In some embodiments, the installation position of the attitude sensor may be relatively fixed and a rotation matrix may be preset, which can make the recognition process of the specific movement more accurate. Further, the rotation matrix continues to be corrected as the user using the wearable device, so that an obtained rotation matrix is closer to the real situation.</span><span class="html-tag">&lt;/p&gt;</span></div><span>
</span><div class="folder" id="folder281"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0170</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0169</span>"</span>&gt;</span></div><div class="opened"><span>It should be noted that the above description of the process </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1300</span><span class="html-tag">&lt;/b&gt;</span></div><span> is for example and illustration purposes only, and does not limit the scope of application of the present disclosure. For those skilled in the art, various amendments and changes can be made to process </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1300</span><span class="html-tag">&lt;/b&gt;</span></div><span> under the guidance of the present disclosure. However, these amendments and changes remain within the scope of the present disclosure.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder282"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0171</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0170</span>"</span>&gt;</span></div><div class="opened"><div class="folder" id="folder283"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>14</span><span class="html-tag">&lt;/b&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span> is a flowchart of an exemplary process for determining a conversion relationship between an original coordinate system and a target coordinate system according to some embodiments of the present disclosure. As shown in </span><div class="folder" id="folder284"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>14</span><span class="html-tag">&lt;/b&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span>, the process </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1400</span><span class="html-tag">&lt;/b&gt;</span></div><span> may include:</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder285"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0172</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0171</span>"</span>&gt;</span></div><div class="opened"><span>Step </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1410</span><span class="html-tag">&lt;/b&gt;</span></div><span>, obtaining the conversion relationship between the specific coordinate system and the target coordinate system.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder286"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0173</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0172</span>"</span>&gt;</span></div><div class="opened"><span>In some embodiments, the step may be performed by the processing module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>220</span><span class="html-tag">&lt;/b&gt;</span></div><span> and/or the processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span>. Both the specific coordinate system and the target coordinate system take the length direction of the human torso as the Z-axis, so that through the conversion relationship between the X-axis of the specific coordinate system and the X-axis of the target coordinate system and the conversion relationship between the Y-axis of the specific coordinate system and the Y-axis of the target coordinate system, the conversion relationship between the specific coordinate relationship and the target coordinate system can be obtained. The principle of obtaining the conversion relationship between the specific coordinate relationship and the target coordinate system may be found in </span><div class="folder" id="folder287"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>13</span><span class="html-tag">&lt;/b&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span> and its relevant descriptions.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="line"><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0174</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0173</span>"</span>&gt;</span><span>In some embodiments, the specific coordinate system may take the length direction of the human torso as the Z-axis and a front-to-back direction of the human body as a calibrated X-axis. Since the front-to-back direction of the user's body changes during motion (e.g., a turning movement) and cannot be fixed in the calibrated coordinate system, it is necessary to determine the coordinate system that can rotate with the body, i.e., the target coordinate system. In some embodiments, the target coordinate system may change as the user's orientation changes, with the X-axis of the target coordinate system always being directly in front of the human torso.</span><span class="html-tag">&lt;/p&gt;</span></div><span>
</span><div class="folder" id="folder288"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0175</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0174</span>"</span>&gt;</span></div><div class="opened"><span>Step </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1420</span><span class="html-tag">&lt;/b&gt;</span></div><span>, determining, according to the conversion relationship between the at least one original coordinate system and the specific coordinate system, and the conversion relationship between the specific coordinate system and the target coordinate system, the conversion relationship between the at least one original coordinate system and the target coordinate system.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder289"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0176</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0175</span>"</span>&gt;</span></div><div class="opened"><span>In some embodiments, the step may be performed by the processing module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>220</span><span class="html-tag">&lt;/b&gt;</span></div><span> and/or the processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span>. In some embodiments, the processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span> may determine the conversion relationship between the at least one original coordinate system and the target coordinate system according to the conversion relationship between the at least one original coordinate system and the specific coordinate system determined in the process </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1300</span><span class="html-tag">&lt;/b&gt;</span></div><span> and the conversion relationship between the specific coordinate system and the target coordinate system determined in step </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1410</span><span class="html-tag">&lt;/b&gt;</span></div><span>, such that the coordinate information in the original coordinate system may be converted to the target coordinate information in the target coordinate system.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder290"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0177</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0176</span>"</span>&gt;</span></div><div class="opened"><span>It should be noted that the above description of the process </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1400</span><span class="html-tag">&lt;/b&gt;</span></div><span> is for example and illustration purposes only and does not limit the scope of application of the present disclosure. For those skilled in the art, various amendments and changes can be made to the process </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1400</span><span class="html-tag">&lt;/b&gt;</span></div><span> under the guidance of the present disclosure. However, these amendments and changes remain within the scope of the present disclosure.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder291"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0178</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0177</span>"</span>&gt;</span></div><div class="opened"><span>In some embodiments, the position of the attitude sensors set on the wearable device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>130</span><span class="html-tag">&lt;/b&gt;</span></div><span> may change and/or the attitude sensors may be installed at different angles on the human body, so that the user performs the same motion, the attitude data returned by the attitude sensors may have a relatively big difference.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder292"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0179</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0178</span>"</span>&gt;</span></div><div class="opened"><div class="folder" id="folder293"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>15</span><span class="html-tag">&lt;/b&gt;</span></div><span>A</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span> is an exemplary vector coordinate diagram illustrating Euler angle data in an original coordinate system at a position of a small arm of a human body according to some embodiments of the present disclosure. A boxed part may represent the Euler angle data (the coordinate information) in the original coordinate system corresponding to the position of the small arm at the time the user does the same movement. As shown in </span><div class="folder" id="folder294"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>15</span><span class="html-tag">&lt;/b&gt;</span></div><span>A</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span>, the results of the Euler angle vector in the Z-axis direction (shown as “Z” in </span><div class="folder" id="folder295"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>15</span><span class="html-tag">&lt;/b&gt;</span></div><span>A</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span>) in the boxed part are approximately in the range of −180° to (−80°). The results of the Euler angle vector in the Y-axis direction (shown as “Y” in </span><div class="folder" id="folder296"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>15</span><span class="html-tag">&lt;/b&gt;</span></div><span>A</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span>) fluctuate approximately around 0°, and the results of the Euler angle vector in the X-axis direction (shown as “X” in </span><div class="folder" id="folder297"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>15</span><span class="html-tag">&lt;/b&gt;</span></div><span>A</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span>) fluctuate approximately around −80°. A fluctuation range here may be 20°.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder298"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0180</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0179</span>"</span>&gt;</span></div><div class="opened"><div class="folder" id="folder299"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>15</span><span class="html-tag">&lt;/b&gt;</span></div><span>B</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span> is an exemplary vector coordinate diagram illustrating Euler angle data in another original coordinate system at a position of a small arm of a human body according to some embodiments of the present disclosure. The boxed part may represent the Euler angle data in the original coordinate system corresponding to the other position of the small arm when the user performs the same movement (the same movement as shown in </span><div class="folder" id="folder300"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>15</span><span class="html-tag">&lt;/b&gt;</span></div><span>A</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span>). As shown in </span><div class="folder" id="folder301"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>15</span><span class="html-tag">&lt;/b&gt;</span></div><span>B</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span>, the results of the Euler angle vector in the Z-axis direction (shown as “Z′” in </span><div class="folder" id="folder302"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>15</span><span class="html-tag">&lt;/b&gt;</span></div><span>B</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span>) in the boxed section are approximately in a range of −180° to 180°. The results of the Euler angle vector in the Y-axis direction (shown as “Y′” in </span><div class="folder" id="folder303"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>15</span><span class="html-tag">&lt;/b&gt;</span></div><span>B</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span>) fluctuate approximately around 0°. And the results of the Euler angle vector in the X-axis direction (shown as “X′” in </span><div class="folder" id="folder304"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>15</span><span class="html-tag">&lt;/b&gt;</span></div><span>B</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span>) fluctuate approximately around −150°. The fluctuation range here may be 20°.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder305"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0181</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0180</span>"</span>&gt;</span></div><div class="opened"><span>The Euler angle data shown in </span><div class="folder" id="folder306"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>15</span><span class="html-tag">&lt;/b&gt;</span></div><span>A</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span> and </span><div class="folder" id="folder307"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>15</span><span class="html-tag">&lt;/b&gt;</span></div><span>B</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span> are the Euler angle data (coordinate information) respectively obtained in the original coordinate system when the user performs the same movement at different positions of the human small arm (which can also be interpreted as different installation angles of the attitude sensor at the human small arm position). Comparing </span><div class="folder" id="folder308"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>15</span><span class="html-tag">&lt;/b&gt;</span></div><span>A</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span> with </span><div class="folder" id="folder309"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>15</span><span class="html-tag">&lt;/b&gt;</span></div><span>B</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span>, it can be seen that the when the user does the same movement, the angles at which the attitude sensor is installed on the human body are different, causing difference in the Euler angle data in the original coordinate system returned by the attitude sensor. For example, the results of the Euler angle vector in the Z-axis direction in </span><div class="folder" id="folder310"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>15</span><span class="html-tag">&lt;/b&gt;</span></div><span>A</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span> are approximately in the range of −180°-(−80°), and the results of the Euler angle vector in the Z-axis direction in </span><div class="folder" id="folder311"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>15</span><span class="html-tag">&lt;/b&gt;</span></div><span>B</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span> are approximately in the range of −180°-180°, which are quite different from each other.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder312"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0182</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0181</span>"</span>&gt;</span></div><div class="opened"><span>In some embodiments, the Euler angle data in the original coordinate system corresponding to sensors with different installation angles may be converted to the Euler angle data in the target coordinate system, thereby facilitating analysis of the attitude signal of the sensors at different positions. Merely as way of exemplary illustration, a line where the left arm is located can be abstracted as a unit vector pointing from the elbow to the wrist, which is a coordinate value in the target coordinate system. The target coordinate system here includes the axis pointing to the rear of the body as the X-axis, the axis pointing to the right side of the body as the Y-axis, and the axis pointing to the top of the body as the Z-axis, which conforms to the right-handed coordinate system. For example, a coordinate value [−1, 0, 0] in the target coordinate system indicates that the arm is held forward flat. A coordinate value [0, −1, 0] of the target coordinate system indicates that the arm is held flat to the left. </span><div class="folder" id="folder313"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>16</span><span class="html-tag">&lt;/b&gt;</span></div><span>A</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span> is a curve obtained based on the vector coordinates in the target coordinate system converted from the Euler angle data of the small arm in the original coordinates in </span><div class="folder" id="folder314"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>15</span><span class="html-tag">&lt;/b&gt;</span></div><span>A</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span>. The boxed portion can represent the Euler angle data in the target coordinate system at the position of the small arm when the user performs the movement. As shown in </span><div class="folder" id="folder315"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>16</span><span class="html-tag">&lt;/b&gt;</span></div><span>A</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span>, a small arm vector [x, y, z] in the boxed portion moves reciprocally between the first position and the second position, where a first position is [0.2, −0.9, −0.38] and the second position is [0.1, −0.95, −0.3]. It should be noted that for each reciprocal movement of the small arm, there will be a small deviation between the first position and the second position.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder316"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0183</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0182</span>"</span>&gt;</span></div><div class="opened"><div class="folder" id="folder317"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>16</span><span class="html-tag">&lt;/b&gt;</span></div><span>B</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span> is an exemplary vector coordinate diagram of Euler angle data in a target coordinate system at another location of a small arm of a human body according to some embodiments of the present disclosure. </span><div class="folder" id="folder318"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>16</span><span class="html-tag">&lt;/b&gt;</span></div><span>B</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span> is a curve obtained based on the vector coordinates in the target coordinate system converted from Euler angle data of the small arm in the original coordinates in </span><div class="folder" id="folder319"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>15</span><span class="html-tag">&lt;/b&gt;</span></div><span>B</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span>. The boxed part may represent the Euler angle data in the target coordinate system at another location of the small arm when the user performs the same movement (the same movement as the movement shown in </span><div class="folder" id="folder320"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>16</span><span class="html-tag">&lt;/b&gt;</span></div><span>A</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span>). As shown in </span><div class="folder" id="folder321"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>16</span><span class="html-tag">&lt;/b&gt;</span></div><span>B</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span>, a small arm vector [x, y, z] similarly reciprocates between the first position and the second position, where a first position is [0.2, −0.9, −0.38] and a second position is [0.1, −0.95, −0.3].</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder322"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0184</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0183</span>"</span>&gt;</span></div><div class="opened"><span>Combining </span><div class="folder" id="folder323"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>15</span><span class="html-tag">&lt;/b&gt;</span></div><span>A</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span> to </span><div class="folder" id="folder324"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>16</span><span class="html-tag">&lt;/b&gt;</span></div><span>B</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span>, it can be seen from </span><div class="folder" id="folder325"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIGS. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>15</span><span class="html-tag">&lt;/b&gt;</span></div><span>A and </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>15</span><span class="html-tag">&lt;/b&gt;</span></div><span>B</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span> that the Euler angles in the original coordinate system have a great difference in the range of values and fluctuation forms due to the different installation positions of the two attitude sensors. After converting the coordinate information of the original coordinate system corresponding to the two attitude sensors to the vector coordinates corresponding to the target coordinate system (e.g., the vector coordinates in </span><div class="folder" id="folder326"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIGS. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>16</span><span class="html-tag">&lt;/b&gt;</span></div><span>A and </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>16</span><span class="html-tag">&lt;/b&gt;</span></div><span>B</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span>) respectively, two approximately same vector coordinates may be obtained. That is to say, the method may ensure the feature information corresponding to the attitude signal to be independent of the sensor installation position. Specifically, in </span><div class="folder" id="folder327"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>16</span><span class="html-tag">&lt;/b&gt;</span></div><span>A</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span> and </span><div class="folder" id="folder328"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>16</span><span class="html-tag">&lt;/b&gt;</span></div><span>B</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span>, it can be seen that the two attitude sensors are installed in different positions on the small arm, and after the above coordinate conversion, the same vector coordinates are obtained, i.e., during the process of the seated chest press, they can represent the process of switching back and forth between the two states, state </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1</span><span class="html-tag">&lt;/b&gt;</span></div><span> (arm held flat to the right) and state </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>2</span><span class="html-tag">&lt;/b&gt;</span></div><span> (arm held flat to the front).</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder329"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0185</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0184</span>"</span>&gt;</span></div><div class="opened"><div class="folder" id="folder330"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>17</span><span class="html-tag">&lt;/b&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span> is an exemplary vector coordinate diagram of a limb vector in a target coordinate system according to some embodiments of the present disclosure. As shown in </span><div class="folder" id="folder331"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>17</span><span class="html-tag">&lt;/b&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span>, the vector coordinates of the attitude sensors in the target coordinate system at the positions of the left small arm (</span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>17</span><span class="html-tag">&lt;/b&gt;</span></div><span>-</span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1</span><span class="html-tag">&lt;/b&gt;</span></div><span>), right small arm (</span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>17</span><span class="html-tag">&lt;/b&gt;</span></div><span>-</span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>2</span><span class="html-tag">&lt;/b&gt;</span></div><span>), left large arm (</span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>17</span><span class="html-tag">&lt;/b&gt;</span></div><span>-</span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>3</span><span class="html-tag">&lt;/b&gt;</span></div><span>), right large arm (</span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>17</span><span class="html-tag">&lt;/b&gt;</span></div><span>-</span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>4</span><span class="html-tag">&lt;/b&gt;</span></div><span>), and torso (</span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>17</span><span class="html-tag">&lt;/b&gt;</span></div><span>-</span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>5</span><span class="html-tag">&lt;/b&gt;</span></div><span>) of the human body can be represented from top to bottom, respectively. The vector coordinates of each position (e.g., </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>17</span><span class="html-tag">&lt;/b&gt;</span></div><span>-</span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1</span><span class="html-tag">&lt;/b&gt;</span></div><span>, </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>17</span><span class="html-tag">&lt;/b&gt;</span></div><span>-</span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>2</span><span class="html-tag">&lt;/b&gt;</span></div><span>, </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>17</span><span class="html-tag">&lt;/b&gt;</span></div><span>-</span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>3</span><span class="html-tag">&lt;/b&gt;</span></div><span>, </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>17</span><span class="html-tag">&lt;/b&gt;</span></div><span>-</span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>4</span><span class="html-tag">&lt;/b&gt;</span></div><span>, </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>17</span><span class="html-tag">&lt;/b&gt;</span></div><span>-</span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>5</span><span class="html-tag">&lt;/b&gt;</span></div><span>) in the target coordinate system of human during motion are illustrated in </span><div class="folder" id="folder332"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>17</span><span class="html-tag">&lt;/b&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span>. The first </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>4200</span><span class="html-tag">&lt;/b&gt;</span></div><span> points in </span><div class="folder" id="folder333"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>17</span><span class="html-tag">&lt;/b&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span> correspond to the calibration movements needed to calibrate the limbs, such as standing, torso forward, arm forward, arm side planks, etc. To use the first </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>4200</span><span class="html-tag">&lt;/b&gt;</span></div><span> points corresponding to the calibration movements to calibrate, raw data collected by the attitude sensors may be converted to the Euler angles in the target coordinate system. To facilitate performing analysis on the data, the coordinate vector of the arm vector in the target coordinate system may be further converted. The target coordinate system here is pointing to the front of the torso as the X-axis, to the left of the torso as the Y-axis, and to the top of the torso as the Z-axis. The reciprocal movements in </span><div class="folder" id="folder334"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>17</span><span class="html-tag">&lt;/b&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span> are, from left to right, movement </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1</span><span class="html-tag">&lt;/b&gt;</span></div><span>, movement </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>2</span><span class="html-tag">&lt;/b&gt;</span></div><span>, movement </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>3</span><span class="html-tag">&lt;/b&gt;</span></div><span>, movement </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>4</span><span class="html-tag">&lt;/b&gt;</span></div><span>, movement </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>5</span><span class="html-tag">&lt;/b&gt;</span></div><span>, and movement </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>6</span><span class="html-tag">&lt;/b&gt;</span></div><span>: seated chest press, high pull-down, seated chest thrust, seated shoulder thrust, barbell dip head curl, and seated chest press, respectively. As can be seen in </span><div class="folder" id="folder335"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>17</span><span class="html-tag">&lt;/b&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span>, different movements have different movement patterns, which can be clearly recognized by using the limb vectors. At the same time, the same movement also has good repeatability, for example, the movement </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1</span><span class="html-tag">&lt;/b&gt;</span></div><span> and the movement </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>6</span><span class="html-tag">&lt;/b&gt;</span></div><span> both represent the seated chest press, and the curves of these two movements have the good repeatability.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder336"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0186</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0185</span>"</span>&gt;</span></div><div class="opened"><span>In some embodiments, the attitude data (e.g., the Euler angles, the angular velocities, etc.) directly output in the original coordinate system may be converted to the attitude data in the target coordinate system by the processes </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1300</span><span class="html-tag">&lt;/b&gt;</span></div><span> and </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1400</span><span class="html-tag">&lt;/b&gt;</span></div><span>, so that highly consistent attitude data (e.g., Euler angles, angular velocities, limb vector coordinates, etc.) can be obtained.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder337"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0187</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0186</span>"</span>&gt;</span></div><div class="opened"><div class="folder" id="folder338"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>18</span><span class="html-tag">&lt;/b&gt;</span></div><span>A</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span> is a diagram illustrating an exemplary coordinate vector of an original angular velocity according to some embodiments of the present disclosure. The original angular velocity may be understood as the conversion of the Euler angle data in the original coordinate systems corresponding to the sensors with different installation angles to the Euler angle data in the target coordinate system. In some embodiments, factors such as jitter during user movement may affect the results of the angular velocity in the attitude data. As shown in </span><div class="folder" id="folder339"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>18</span><span class="html-tag">&lt;/b&gt;</span></div><span>A</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span>, the original angular velocity shows a more obvious unsmooth curve in its vector coordinate curve under an influence of jitter, etc. For example, a presence of an abrupt signal in the vector coordinate curve of the original angular velocity makes the vector coordinate curve of the original angular velocity unsmooth. In some embodiments, a jittered angular velocity needs to be corrected to obtain a smooth vector coordinate curve because of an effect of jitter, etc. on the angular velocity results. In some embodiments, the original angular velocity may be filtered by using a 1 Hz-3 Hz low-pass filtering method. </span><div class="folder" id="folder340"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>18</span><span class="html-tag">&lt;/b&gt;</span></div><span>B</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span> is an exemplary diagram illustrating results of an angular velocity after filtering processing according to some embodiments of the present disclosure. As shown in </span><div class="folder" id="folder341"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>18</span><span class="html-tag">&lt;/b&gt;</span></div><span>B</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span>, performing a low-pass filtering from 1 Hz to 3 Hz on the original angular velocity may eliminate the effect of jitter and other effects on the angular velocity (e.g., abrupt signals), so that the vector coordinate curve corresponding to the angular velocity is displayed smoother. In some embodiments, performing the low-pass filtering from 1 Hz to 3 Hz on the angular velocity may effectively prevent the effects of jitter, etc. on the attitude data (e.g., the Euler angles, the angular velocity, etc.), which makes it easier to follow the process of segmenting the signal. In some embodiments, the filtering process may also filter out an industrial frequency signal and its harmonic wave signal, burr signal, etc. from the movement signal. It should be noted that low-pass filtering at 1 Hz-3 Hz introduces time delay, which makes a movement point of the attitude signal and a movement point of a real electromyographic signal misaligned in time. Therefore, the time delay generated during the low-pass filtering process is subtracted from the vector coordinate curve after the low-pass filtering processing to ensure synchronization of the attitude signal and the electromyographic signal in time. In some embodiments, the time delay is associated with a center frequency of the filter, and when the attitude signal and the electromyographic signal are processed with different filters, and the time delay is adapted according to the center frequency of the filter. In some embodiments, since the angular range of the Euler angle is [−180°, +180° ], an obtained Euler angle may have a change of −180° to +180° or +180° to −180° when an actual Euler angle is not in this angular range. For example, when the angle is −181°, the Euler angle changes to 179°. In the practical application the angle change can affect the calculation of the angle difference, and it is necessary to correct the angle change first.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder342"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0188</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0187</span>"</span>&gt;</span></div><div class="opened"><span>In some embodiments, a movement recognition model may also be configured to analyze the user's movement signal or the feature information corresponding to the movement signal to recognize the user's movement. In some embodiments, the movement recognition model includes a trained machine learning model configured to recognize the user's movement. In some embodiments, the movement recognition model may include one or more machine learning models. In some embodiments, the movement recognition model may include, but is not limited to, one or more of a machine learning model that classifies the user's movement signal, a machine learning model that recognizes the movement quality of the user, a machine learning model that recognizes the number of the user's movements, and a machine learning model that recognizes a fatigue index of the user performing the movement. In some embodiments, the machine learning model may include one or more of a linear classification model (LR), a support vector machine model (SVM), a plain Bayesian model (NB), a K-nearest neighbor model (KNN), a decision tree model (DT), ae random forest/a gradient boosting decision tree (RF/GDBT, etc.), etc. More descriptions regarding the movement recognition model may be found elsewhere in the present disclosure, such as </span><div class="folder" id="folder343"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>20</span><span class="html-tag">&lt;/b&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span> and its relevant descriptions.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder344"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0189</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0188</span>"</span>&gt;</span></div><div class="opened"><div class="folder" id="folder345"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>19</span><span class="html-tag">&lt;/b&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span> is a flowchart illustrating an exemplary motion monitoring and feedback method according to some embodiments of the present disclosure. As shown in </span><div class="folder" id="folder346"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>19</span><span class="html-tag">&lt;/b&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span>, the process </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1900</span><span class="html-tag">&lt;/b&gt;</span></div><span> may include:</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder347"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0190</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0189</span>"</span>&gt;</span></div><div class="opened"><span>Step </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1910</span><span class="html-tag">&lt;/b&gt;</span></div><span>, obtaining the movement signal of the user during motion.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder348"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0191</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0190</span>"</span>&gt;</span></div><div class="opened"><span>In some embodiments, the step may be performed by the obtaining module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>210</span><span class="html-tag">&lt;/b&gt;</span></div><span>. In some embodiments, the movement signal includes at least the feature information corresponding to the electromyographic signal and the feature information corresponding to the attitude signal. The movement signal refers to human body parameter information of the user during motion. In some embodiments, the human body parameter information may include, but is not limited to, one or more of the electromyographic signals, the attitude signals, the heart rate signals, the temperature signals, the humidity signals, the blood oxygen concentration, etc. In some embodiments, the movement signal may include at least the electromyographic signal and the attitude signal. In some embodiments, the electromyographic sensor in the obtaining module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>210</span><span class="html-tag">&lt;/b&gt;</span></div><span> may collect the electromyographic signal of the user during motion, and the attitude sensor in the obtaining module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>210</span><span class="html-tag">&lt;/b&gt;</span></div><span> may collect the attitude signal of the user during motion.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder349"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0192</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0191</span>"</span>&gt;</span></div><div class="opened"><span>Step </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1920</span><span class="html-tag">&lt;/b&gt;</span></div><span>, monitoring, based on the movement signal, the user's movement during motion through the movement recognition model, and giving, based on the output of the movement recognition model, the movement feedback.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder350"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0193</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0192</span>"</span>&gt;</span></div><div class="opened"><span>In some embodiments, the step may be performed by the processing module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>220</span><span class="html-tag">&lt;/b&gt;</span></div><span> and/or the processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span>. In some embodiments, the output of the movement recognition model may include, but is not limited to, one or more of the movement type, the movement quality, the number of movements, a fatigue index, etc. For example, the movement recognition model may recognize the user's movement type as the seated chest press based on the movement signal. For another example, one machine learning model of the movement recognition model may first recognize the user's movement type as the seated chest press based on the movement signal, and another machine learning model of the movement recognition model may output the movement quality of the user's movement as a standard movement or an incorrect movement according to the movement signal (e.g., amplitude information of the electromyographic signal, the frequency information, and/or the angular velocity, the angular velocity direction, and the acceleration value of angular velocity of the attitude signal). In some embodiments, the movement feedback may include sending the prompt message. In some embodiments, the prompt message may include, but is not limited to, the voice prompt, the message prompt, the image prompt, the video prompt, etc. For example, if the output result of the movement recognition model is the incorrect movement, the processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span> may control the wearable device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>130</span><span class="html-tag">&lt;/b&gt;</span></div><span> or the mobile terminal device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>140</span><span class="html-tag">&lt;/b&gt;</span></div><span> to send a voice prompt (e.g., a message such as “nonstandard movement”) to the user to remind the user to adjust the fitness movement in a timely manner. For another example, if the output of the movement recognition model is the standard movement, the wearable device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>130</span><span class="html-tag">&lt;/b&gt;</span></div><span> or the mobile terminal device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>140</span><span class="html-tag">&lt;/b&gt;</span></div><span> may not send a prompt message, or send a prompt message like “standard movement”. In some embodiments, the motion feedback may also include the wearable device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>130</span><span class="html-tag">&lt;/b&gt;</span></div><span> stimulating the corresponding movement part of the user. For example, the components of the wearable device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>130</span><span class="html-tag">&lt;/b&gt;</span></div><span> stimulate the corresponding parts of the user's movements through a vibration feedback, an electrical stimulation feedback, a pressure feedback, etc. For example, the output results of the movement recognition model are the incorrect movement, and the processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span> may control the components of the wearable device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>130</span><span class="html-tag">&lt;/b&gt;</span></div><span> to stimulate the corresponding parts of the user's movement. In some embodiments, the movement feedback may also include outputting a motion record of the user during motion. The motion record here may refer to one or more of the user's movement type, exercise duration, number of movements, movement quality, fatigue index, physiological parameter information during motion, etc. Descriptions regarding the movement recognition model may be found elsewhere in the present disclosure and will not be repeated herein.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder351"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0194</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0193</span>"</span>&gt;</span></div><div class="opened"><span>It should be noted that the above description of the process </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1900</span><span class="html-tag">&lt;/b&gt;</span></div><span> is for example and illustration purposes only and does not limit the scope of application of the present disclosure. For those skilled in the art, various amendments and changes can be made to process </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1900</span><span class="html-tag">&lt;/b&gt;</span></div><span> under the guidance of the present disclosure. However, these amendments and changes remain within the scope of the present disclosure.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder352"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0195</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0194</span>"</span>&gt;</span></div><div class="opened"><div class="folder" id="folder353"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;figref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">DRAWINGS</span>"</span>&gt;</span></div><div class="opened"><span>FIG. </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>20</span><span class="html-tag">&lt;/b&gt;</span></div></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/figref&gt;</span></div></div><span> is a flowchart illustrating an exemplary process for model training according to some embodiments of the present disclosure.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder354"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0196</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0195</span>"</span>&gt;</span></div><div class="opened"><span>In step </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>2010</span><span class="html-tag">&lt;/b&gt;</span></div><span>, obtaining the sample information.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder355"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0197</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0196</span>"</span>&gt;</span></div><div class="opened"><span>In some embodiments, the step may be performed by the obtaining module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>210</span><span class="html-tag">&lt;/b&gt;</span></div><span>. In some embodiments, the sample information may include the movement signal of professionals (e.g., fitness trainers) and/or non-professionals during motion. For example, the sample information may include the electromyographic signals and/or the attitude signals generated by the professionals and/or the non-professionals while performing the same movement type (e.g., the seated chest press). In some embodiments, the electromyographic signal and/or attitude signal in the sample information may undergo the segmentation processing of the process </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>700</span><span class="html-tag">&lt;/b&gt;</span></div><span>, the burr processing of the process </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>900</span><span class="html-tag">&lt;/b&gt;</span></div><span>, and the conversion processing of the process </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1300</span><span class="html-tag">&lt;/b&gt;</span></div><span>, etc., to form at least one segment of the electromyographic signal and/or the attitude signal. The at least one segment of the electromyographic signal and/or the attitude signal may be used as the input of the machine learning model to train the machine learning model. In some embodiments, the feature information corresponding to the at least one segment of the electromyographic signal and/or the feature information corresponding to the attitude signal may also be used as the input of the machine learning model to train the machine learning model. For example, the frequency information and the amplitude information of the electromyographic signal can be used as the input of the machine learning model. For another example, the angular velocity of the attitude signal and the angular velocity direction/the acceleration value of the angular velocity can be used as the input of the machine learning model. For another example, the movement start point, the movement middle point and the movement end point signal can be used as the inputs to the machine learning model. In some embodiments, the sample information may be obtained from the storage device of the processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span>. In some embodiments, the sample information may be obtained from the obtaining module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>210</span><span class="html-tag">&lt;/b&gt;</span></div><span>.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder356"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0198</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0197</span>"</span>&gt;</span></div><div class="opened"><span>In step </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>2020</span><span class="html-tag">&lt;/b&gt;</span></div><span>, training the movement recognition model.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder357"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0199</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0198</span>"</span>&gt;</span></div><div class="opened"><span>The step may be performed by the processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span>. In some embodiments, the movement recognition model may include one or more machine learning models. For example, the movement recognition model may include, but is not limited to, one or more of the machine learning model that classifies the user's movement signal, the machine learning model that recognizes the movement quality of the user, the machine learning model that recognizes the number of user's movement, and the machine learning model that recognizes the fatigue level of the user performing the movement. In some embodiments, the machine learning model may include one or more of the linear classification model (LR), the support vector machine model (SVM), the Native Bayesian model (NB), the K-nearest neighbor model (KNN), the decision tree model (DT), the random forest/the gradient boosting decision tree (RF/GDBT, etc.), etc.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder358"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0200</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0199</span>"</span>&gt;</span></div><div class="opened"><span>In some embodiments, training of the machine learning model may include obtaining the sample information. In some embodiments, the sample information may include the movement signal of the professionals (e.g., fitness trainers) and/or non-professionals during motion. For example, the sample information may include electromyographic signal and/or postural signal generated by professionals and/or the non-professionals while performing the same movement type (e.g., the seated chest press). In some embodiments, the electromyographic signal and/or the attitude signal in the sample information may undergo the segmentation processing of the process </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>700</span><span class="html-tag">&lt;/b&gt;</span></div><span>, the burr processing of the process </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>900</span><span class="html-tag">&lt;/b&gt;</span></div><span>, and the conversion processing of the process </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1300</span><span class="html-tag">&lt;/b&gt;</span></div><span>, etc., to generate at least one segment of the electromyographic signal and/or the attitude signal. The at least one segment of the electromyographic signal and/or the attitude signal may be used as the input to the machine learning model to train the machine learning model. In some embodiments, the feature information corresponding to the at least one segment of the electromyographic signal and/or the feature information corresponding to the attitude signal may also be used as the input of the machine learning model to train the machine learning model. For example, the frequency information and the amplitude information of the electromyographic signal can be used as the input of the machine learning model. For another example, the angular velocity of the attitude signal and the angular velocity direction/acceleration value of the velocity angle can be used as the input of the machine learning model. For another example, the signal corresponding to the movement start point, the movement middle point, and/or the movement end point signal (including the electromyographic signal and/or the attitude signal) can be used as the input of the machine learning model.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="line"><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0201</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0200</span>"</span>&gt;</span><span>In some embodiments, when training a machine learning model for recognizing the user's movement type, the sample information from the different movement types (per segment of the electromyographic signal or/and the attitude signal) may be labelled and processed. For example, the sample information from the electromyographic signal and/or the attitude signal generated by the user performing a seated chest press may be marked as “1”, where “1” is configured to represent the “seated chest press”. The sample information from the electromyographic signal and/or the attitude signal generated when the user performs the bicep lifting maybe marked as “2”, where “2” is configured to represent the “bicep lifting”. The different movement types correspond to the different feature information (e.g., the frequency information, the amplitude information) of electromyographic signals, and feature information (e.g., angular velocity, angular velocity direction, angular velocity value of angular velocity) of attitude signals. Labeled sample information (e.g., feature information corresponding to electromyographic signal and/or attitude signal in the sample information) is used as the input of the machine learning model to train the machine learning model, so that the movement recognition model configured to recognize the user's movement type may be obtained, and by inputting the movement signal in the machine learning model, a corresponding movement type may be output.</span><span class="html-tag">&lt;/p&gt;</span></div><span>
</span><div class="folder" id="folder359"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0202</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0201</span>"</span>&gt;</span></div><div class="opened"><span>In some embodiments, the movement recognition model may further include the machine learning model for determining the quality of the user's movement. The sample information here may include both the standard movement signal (also known as a positive sample) and a non-standard movement signal (also known as negative samples). The standard movement signal may include the movement signal generated by the professional performing the standard movement. For example, the movement signal generated by a professional performing the standard seated chest press is the standard movement signal. The non-standard movement signal may include the movement signal generated by the user performing the non-standard movement (e.g., an incorrect movement). In some embodiments, the electromyographic signal and/or the attitude signal in the sample information may undergo the segmentation processing of the process </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>700</span><span class="html-tag">&lt;/b&gt;</span></div><span>, the burr processing of the process </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>900</span><span class="html-tag">&lt;/b&gt;</span></div><span>, and the conversion processing of the process </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1300</span><span class="html-tag">&lt;/b&gt;</span></div><span>, etc., to generate at least one segment of the electromyographic signal and/or the attitude signal. The at least one segment of the electromyographic signal and/or the attitude signal may be used as the input of the machine learning model to train the machine learning model. In some embodiments, the positive and negative samples of the sample information (per segment of the electromyographic signal or/the attitude signal) may be tagged. For example, a positive sample is marked as “1” and a negative sample is marked as “0”. The “1” here is configured to represent the user's movement as a standard movement, and the “0” here is configured to represent the user's movement as a wrong movement. The trained machine learning model may output different labels based on the input sample information (e.g., the positive sample, the negative sample). It should be noted that the movement recognition model may include one or more machine learning models for analyzing and recognizing the quality of the user movement, and different machine learning models may analyze and recognize the sample information from the different movement types, respectively.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder360"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0203</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0202</span>"</span>&gt;</span></div><div class="opened"><span>In some embodiments, the movement recognition model may also include a model that recognizes the number of movements of the user's fitness motion. For example, the movement signal (e.g., the electromyographic signal and/or the attitude signal) in the sample information is segmented by the process </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>700</span><span class="html-tag">&lt;/b&gt;</span></div><span> to obtain at least one set of a movement start point, a movement middle point, and a movement end point, and each set of the movement start point, the movement middle point, and the movement end point is marked, for example, the movement start point is marked as 1, the movement middle point is marked as 2, and the movement end point is marked as 3, and the marks are used as the input to the machine learning model, and a set of consecutive “1”, “2” and “3” are input to the machine learning model to output one movement. For example, three consecutive sets of “1”, “2”, and “3” are input into a machine learning model to output three movements.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder361"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0204</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0203</span>"</span>&gt;</span></div><div class="opened"><span>In some embodiments, the movement recognition model may also include a machine learning model for identifying a user's fatigue index. The sample information here may also include signals of other physiological parameters such as the electro-cardio signals, the respiratory rates, the temperature signals, the humidity signals, etc. For example, different frequency ranges of the electro-cardio signal can be used as the input data for the machine learning model, with electro-cardio signal in the range of 60 beats/min-100 beats/min marked as “1” (normal) and less than 60 beats/min or more than 100 beats/min marked as “2” (abnormal). In some embodiments, a further segmentation can be performed and different indices can be labeled as the input data based on the user's electro-cardio signal frequency, and the trained machine learning model can output a corresponding fatigue index according to the frequency of the electro-cardio signal. In some embodiments, the machine learning model may also be trained in conjunction with the physiological parameter signal such as the respiratory rate and the temperature signal. In some embodiments, the sample information may be obtained from the storage device of processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span>. In some embodiments, the sample information may be obtained from the obtaining module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>210</span><span class="html-tag">&lt;/b&gt;</span></div><span>. It should be noted that the movement recognition model can be any one of the above machine learning models or a combination of a plurality of above machine learning models, or include other machine learning models, which can be selected according to the actual situation. In addition, a training input to the machine learning model is not limited to one segment (one cycle) of the movement signal, but can also be part of a segment of the movement signal, or a plurality of segments of the movement signal, etc.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder362"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0205</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0204</span>"</span>&gt;</span></div><div class="opened"><span>Step </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>2030</span><span class="html-tag">&lt;/b&gt;</span></div><span>, extracting the movement recognition model.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder363"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0206</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0205</span>"</span>&gt;</span></div><div class="opened"><span>In some embodiments, the step may be performed by the processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span>. In some embodiments, the processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span> and/or the processing module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>220</span><span class="html-tag">&lt;/b&gt;</span></div><span> may extract the movement recognition model. In some embodiments, the movement recognition model may be stored to the processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span>, the processing module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>220</span><span class="html-tag">&lt;/b&gt;</span></div><span>, or the mobile terminal.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder364"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0207</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0206</span>"</span>&gt;</span></div><div class="opened"><span>Step </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>2040</span><span class="html-tag">&lt;/b&gt;</span></div><span>, obtaining the user's movement signal.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder365"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0208</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0207</span>"</span>&gt;</span></div><div class="opened"><span>In some embodiments, the step may be performed by the obtaining module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>210</span><span class="html-tag">&lt;/b&gt;</span></div><span>. For example, in some embodiments, the electromyographic sensor in the obtaining module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>210</span><span class="html-tag">&lt;/b&gt;</span></div><span> may obtain the electromyographic signal of the user, and the attitude sensor in the obtaining module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>210</span><span class="html-tag">&lt;/b&gt;</span></div><span> may obtain the attitude signal of the user. In some embodiments, the user movement signal may also include other physiological parameter signals such as the electro-cardio signal, the respiration signal, the temperature signal, the humidity signal, etc. of the user during motion. In some embodiments, the obtained movement signal (e.g., the electromyographic signal and/or the attitude signal) may be subjected to the segmentation processing of the process </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>700</span><span class="html-tag">&lt;/b&gt;</span></div><span>, the burr processing of process the </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>900</span><span class="html-tag">&lt;/b&gt;</span></div><span>, and the conversion processing of the process </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1300</span><span class="html-tag">&lt;/b&gt;</span></div><span>, etc., to form at least one segment of the electromyographic signal and/or the attitude signal.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder366"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0209</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0208</span>"</span>&gt;</span></div><div class="opened"><span>Step </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>2050</span><span class="html-tag">&lt;/b&gt;</span></div><span>, judging, based on the user's movement signal, the movement through the movement recognition model.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder367"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0210</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0209</span>"</span>&gt;</span></div><div class="opened"><span>The step may be performed by the processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span> and/or the processing module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>220</span><span class="html-tag">&lt;/b&gt;</span></div><span>. In some embodiments, the processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span> and/or the processing module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>220</span><span class="html-tag">&lt;/b&gt;</span></div><span> may determine the user movement based on the movement recognition model. In some embodiments, the trained movement recognition model may include one or more machine learning models. In some embodiments, the movement recognition model may include, but is not limited to, one or more of the machine learning model that classifies the user's movement signal, the machine learning model that recognizes the movement of the user, the machine learning model that recognizes the number of user's movement, and the machine learning model that recognizes the fatigue index of the user performing the movements. The different machine learning models may have different recognition effects. For example, a machine learning model for classifying the movement signal may use the user's movement signal as input data and output the corresponding movement type. For example, a machine learning model that recognizes the quality of the user's movement can use the user's movement signal as input data and output the movement quality (e.g., standard movement, wrong movement). For example, the machine learning model that recognizes the fatigue index of a user performing a movement can use the user's movement signal (e.g., the electro-cardio signal frequency) as the input data and output the user's fatigue index. In some embodiments, the user's movement signal and the judgment results (output) of the machine learning model may also be used as the sample information of training the movement recognition model to optimize relevant parameters of the movement recognition model. It should be noted that the movement recognition model is not limited to the trained machine learning model described above, but can also be a preset model, e.g., a manually predefined conditional judgment algorithm or add an artificially added parameter (e.g., confidence level) to the trained machine learning model, etc.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder368"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0211</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0210</span>"</span>&gt;</span></div><div class="opened"><span>Step </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>2060</span><span class="html-tag">&lt;/b&gt;</span></div><span>, providing, based on the judgment results, feedback for the user's movement.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder369"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0212</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0211</span>"</span>&gt;</span></div><div class="opened"><span>In some embodiments, the step may be performed by the wearable device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>130</span><span class="html-tag">&lt;/b&gt;</span></div><span> and/or the mobile terminal device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>140</span><span class="html-tag">&lt;/b&gt;</span></div><span>. Further, the processing device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>110</span><span class="html-tag">&lt;/b&gt;</span></div><span> and/or the processing module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>220</span><span class="html-tag">&lt;/b&gt;</span></div><span> sends a feedback instruction to the wearable device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>130</span><span class="html-tag">&lt;/b&gt;</span></div><span> and/or the mobile terminal device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>140</span><span class="html-tag">&lt;/b&gt;</span></div><span> based on the judgment results of the user's movement, and the wearable device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>130</span><span class="html-tag">&lt;/b&gt;</span></div><span> and/or the mobile terminal device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>140</span><span class="html-tag">&lt;/b&gt;</span></div><span> provides the feedback to the user based on the feedback instruction. In some embodiments, the feedback may include sending prompt messages (e.g., text information, picture information, video information, voice information, indicator information, etc.) and/or stimulating the user's body when performing the movement (in a form of electrical stimulation, vibration, pressure changes, heat change, etc.). For example, when a user performs a sit-up movement, the user's movement signal is monitored and it is determined that the user is exerting too much force on the oblique muscles during motion (i.e., a user's head and neck movement are not standard), in which case the input/output module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>260</span><span class="html-tag">&lt;/b&gt;</span></div><span> (e.g., a vibration prompter) in the wearable device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>130</span><span class="html-tag">&lt;/b&gt;</span></div><span> and the mobile terminal device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>140</span><span class="html-tag">&lt;/b&gt;</span></div><span> (e.g., a smartwatch, smartphone etc.) provide a corresponding feedback (e.g., perform the vibration on the user's body part, send the voice prompt, etc.) to prompt the user to adjust the force-exerting part of body in time. In some embodiments, during the user's movement, by monitoring the movement signal during the user's movement and determining the movement type, the movement quality, and the number of the user's movements during motion, the mobile terminal device </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>140</span><span class="html-tag">&lt;/b&gt;</span></div><span> can output the corresponding movement record so that the user can understand its motion situation during motion.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="line"><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0213</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0212</span>"</span>&gt;</span><span>In some embodiments, when the feedback is given to the user, the feedback may be matched to user perception. For example, if the user's movement is not standard, the user can know that the movement is not standard based on the vibration stimulation in the area corresponding to the user's movement, and the vibration stimulation is in an acceptable range of the user. Further, a matching model may be constructed based on user's movement signal and the user perception to find the best balance between the user perception and a real feedback.</span><span class="html-tag">&lt;/p&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0214</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0213</span>"</span>&gt;</span><span>In some embodiments, the movement recognition model may further be trained based on the user's movement signals. In some embodiments, training the movement recognition model according to the user's movement signal may include evaluating the user's movement signal to determine a confidence level of the user's movement signal. The confidence level may indicate the quality of the user's movement signal. For example, the higher the confidence level, the better the quality of the user's movement signal. In some embodiments, evaluation of the user's movement signal may be performed at the stages of the movement signal obtaining, pre-processing, segmentation, and/or recognition.</span><span class="html-tag">&lt;/p&gt;</span></div><span>
</span><div class="folder" id="folder370"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0215</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0214</span>"</span>&gt;</span></div><div class="opened"><span>In some embodiments, training the movement recognition model according to the user's movement signal may further include determining whether the confidence level is greater than a confidence level threshold (e.g., </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>80</span><span class="html-tag">&lt;/b&gt;</span></div><span>), and if the confidence level is greater than or equal to the confidence level threshold, the movement recognition model is trained by using the user's movement signal corresponding to that confidence level as sample data. If the confidence level is less than the confidence level threshold, the user's movement signal corresponding to the confidence level is not used as sample data to train the movement recognition model. In some embodiments, the confidence level may include, but is not limited to, a confidence level at any of the stages of the movement signal obtaining, the movement signal pre-processing, movement signal segmentation, or the movement signal recognition. For example, the confidence level of the movement signal collected by the obtaining module </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>210</span><span class="html-tag">&lt;/b&gt;</span></div><span> is used as a judgment criterion. In some embodiments, the confidence level may further be a combined confidence level at any of the above stages. The combined confidence level may be obtained by averaging or weighting the confidence levels of the stages, etc. In some embodiments, the movement recognition model according to the user's movement signal may be trained in real time, periodically (e.g., a day, a week, a month, etc.), or when a certain data size is met.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="folder" id="folder371"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0216</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0215</span>"</span>&gt;</span></div><div class="opened"><span>It should be noted that the above description of the process </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1700</span><span class="html-tag">&lt;/b&gt;</span></div><span> is merely provided for the purpose of illustration, and is not intended to limit the scope of the present disclosure. For those skilled in the art, various of amendments and changes may be made to the process </span><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1700</span><span class="html-tag">&lt;/b&gt;</span></div><span> under the guidance of the present disclosure. However, these amendments and changes remain within the scope of this disclosure.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/p&gt;</span></div></div><span>
</span><div class="line"><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0217</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0216</span>"</span>&gt;</span><span>The basic concepts have been described. Obviously, for those skilled in the art, the detailed disclosure may be only an example and does not constitute a limitation to the present disclosure. Although not explicitly stated here, those skilled in the art may make various modifications, improvements, and amendments to the present disclosure. These alterations, improvements, and modifications are intended to be suggested by this disclosure, and are within the spirit and scope of the exemplary embodiments of this disclosure.</span><span class="html-tag">&lt;/p&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0218</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0217</span>"</span>&gt;</span><span>Moreover, certain terminology has been used to describe embodiments of the present disclosure. For example, the terms “one embodiment,” “an embodiment,” and/or “some embodiments” mean that a particular feature, structure or characteristic described in connection with the embodiment is included in at least one embodiment of the present disclosure. Therefore, it is emphasized and should be appreciated that two or more references to “an embodiment” or “one embodiment” or “an alternative embodiment” in various parts of the present disclosure are not necessarily all referring to the same embodiment. In addition, some features, structures, or features in the present disclosure of one or more embodiments may be appropriately combined.</span><span class="html-tag">&lt;/p&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0219</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0218</span>"</span>&gt;</span><span>In addition, those skilled in the art can understand that various aspects of the present disclosure can be illustrated and described through several patentable categories or situations, including any new and useful processes, machines, products, or combinations of materials, or any new and useful improvements. Accordingly, all aspects of the present disclosure may be performed entirely by hardware, may be performed entirely by software (including firmware, resident software, microcode, etc.), or may be performed by a combination of hardware and software. The above hardware or software can be referred to as “data block”, “module”, “engine”, “unit”, “component” or “system”. In addition, aspects of the present disclosure may appear as a computer product located in one or more computer-readable media, the product including computer-readable program code.</span><span class="html-tag">&lt;/p&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0220</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0219</span>"</span>&gt;</span><span>The computer storage medium may include a propagation data signal containing a computer program encoding, such as on a baseband or as part of a carrier. The propagation signal may have a variety of expressions, including electromagnetic form, optical form, or suitable combination form. The computer storage medium can be any computer-readable medium other than the computer-readable storage medium, which can be used to perform systems, devices, or devices to implement communication, propagating, or devices by connecting to an instruction. The program code located on the computer storage medium may be propagated through any suitable medium, including radio, cable, fiber optic cable, RF, or similar media, or any combination of the foregoing.</span><span class="html-tag">&lt;/p&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0221</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0220</span>"</span>&gt;</span><span>Computer program code for carrying out operations for aspects of the present disclosure may be written in any combination of one or more programming languages, including an object-oriented programming language such as Java, Scala, Smalltalk, Eiffel, JADE, Emerald, C++, C #, VB.NET, Python or the like, conventional procedural programming languages, such as the “C” programming language, Visual Basic, Fortran 2003, Perl, COBOL 2002, PHP, ABAP, dynamic programming languages such as Python, Ruby, and Groovy, or other programming languages. The program code may execute entirely on the user's computer, partly on the user's computer, as a stand-alone software package, partly on the user's computer, partly on a remote computer, or entirely on the remote computer or server. In the case of subsequent cases, the remote computer can be connected to the user computer through any network, such as a local area network (LAN) or a wide area network (WAN), or connected to an external computer (e.g., through the Internet), or in the cloud computing environment, or as a service Use Software, SaaS.</span><span class="html-tag">&lt;/p&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0222</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0221</span>"</span>&gt;</span><span>Moreover, unless otherwise specified in the claims, the sequence of the processing elements and sequences of the present disclosure, the use of digital letters, or other names are not used to define the order of the application flow and methods. Although the above disclosure discusses through various examples what is currently considered to be a variety of useful embodiments of the disclosure, it is to be understood that such detail is solely for that purpose and that the appended claims are not limited to the disclosed embodiments, but, on the contrary, are intended to cover modifications and equivalent arrangements that are within the spirit and scope of the disclosed embodiments. For example, although the implementation of various components described above may be embodied in a hardware device, it may also be implemented as a software-only solution, e.g., an installation on an existing server or mobile device.</span><span class="html-tag">&lt;/p&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0223</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0222</span>"</span>&gt;</span><span>Similarly, it should be appreciated that in the foregoing description of embodiments of the present disclosure, various features are sometimes grouped together in a single embodiment, figure, or description thereof for the purpose of streamlining the disclosure and aiding in the understanding of one or more of the various embodiments. However, this disclosure does not mean that the present disclosure object requires more features than the features mentioned in the claims. Rather, claimed subject matter may lie in less than all features of a single foregoing disclosed embodiment.</span><span class="html-tag">&lt;/p&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0224</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0223</span>"</span>&gt;</span><span>In some embodiments, numbers expressing quantities of ingredients, properties, and so forth, configured to describe and claim certain embodiments of the application are to be understood as being modified in some instances by the term “about,” “approximate,” or “substantially”. Unless otherwise stated, “approximately”, “approximately” or “substantially” indicates that the number is allowed to vary by ±20%. Correspondingly, in some embodiments, the value parameters used in the present disclosure and claims are approximate values. The approximate values may be changed according to the characteristics of individual embodiments. In some embodiments, the numerical parameters should be construed in light of the number of reported significant digits and by applying ordinary rounding techniques. Although the numerical domains and parameters used in the present application are used to confirm the range of ranges, the settings of this type are as accurate in the feasible range within the feasible range in the specific embodiments.</span><span class="html-tag">&lt;/p&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0225</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0224</span>"</span>&gt;</span><span>For each patent, patent application, patent application publication, and other materials cited in the present disclosure, such as articles, books, specifications, publications, documents, etc., the entire contents are hereby incorporated by reference into the present disclosure. Except for application history documents that are inconsistent with or conflict with the contents of the present disclosure, the documents with the most limited scope of the claims of the present disclosure (current or later appended to the present disclosure) are also excluded. It should be noted that if the description, definition, and/or terms used in the appended application of the present disclosure are inconsistent or conflicting with the content described in the present disclosure, the use of the description, definition, and/or terms of the present disclosure shall prevail.</span><span class="html-tag">&lt;/p&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;p<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">p-0226</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">0225</span>"</span>&gt;</span><span>At last, it should be understood that the embodiments described in the present disclosure are merely illustrative of the principles of the embodiments of the present disclosure. Other modifications that may be employed may be within the scope of the present disclosure. Thus, by way of example, but not of limitation, alternative configurations of the embodiments of the present disclosure may be utilized in accordance with the teachings herein. Accordingly, the embodiments of the present disclosure are not limited to that precisely as shown and described.</span><span class="html-tag">&lt;/p&gt;</span></div><span>
</span><div class="line"><span class="comment html-comment">&lt;?detailed-description description="Detailed Description" end="tail"?&gt;</span></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/description&gt;</span></div></div><span>
</span><div class="folder" id="folder372"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;claims<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">claims</span>"</span>&gt;</span></div><div class="opened"><span>
</span><div class="folder" id="folder373"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;claim<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">CLM-00001</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">00001</span>"</span>&gt;</span></div><div class="opened"><span>
</span><div class="folder" id="folder374"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;claim-text&gt;</span></div><div class="opened"><div class="line"><span class="html-tag">&lt;b&gt;</span><span>1</span><span class="html-tag">&lt;/b&gt;</span></div><span>. A motion monitoring method, comprising:
</span><div class="line"><span class="html-tag">&lt;claim-text&gt;</span><span>obtaining a movement signal of a user during motion, the movement signal comprising at least an electromyographic signal or an attitude signal; and</span><span class="html-tag">&lt;/claim-text&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;claim-text&gt;</span><span>monitoring, at least based on feature information corresponding to the electromyographic signal or feature information corresponding to the attitude signal, a movement of the user during motion, wherein the feature information corresponding to the electromyographic signal includes at least frequency information or amplitude information, and the feature information corresponding to the attitude signal includes at least one of an angular velocity direction, an angular velocity value, an acceleration of an angular velocity, an angle, displacement information, and stress.</span><span class="html-tag">&lt;/claim-text&gt;</span></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/claim-text&gt;</span></div></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/claim&gt;</span></div></div><span>
</span><div class="folder" id="folder375"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;claim<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">CLM-00002</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">00002</span>"</span>&gt;</span></div><div class="opened"><span>
</span><div class="folder" id="folder376"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;claim-text&gt;</span></div><div class="opened"><div class="line"><span class="html-tag">&lt;b&gt;</span><span>2</span><span class="html-tag">&lt;/b&gt;</span></div><span>. The motion monitoring method of </span><div class="line"><span class="html-tag">&lt;claim-ref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">CLM-00001</span>"</span>&gt;</span><span>claim 1</span><span class="html-tag">&lt;/claim-ref&gt;</span></div><span>, comprising:
</span><div class="line"><span class="html-tag">&lt;claim-text&gt;</span><span>segmenting, based on the feature information corresponding to the electromyographic signal or the feature information corresponding to the attitude signal, the movement signal; and</span><span class="html-tag">&lt;/claim-text&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;claim-text&gt;</span><span>monitoring, based on at least one segment of the movement signal, the movement of the user during motion.</span><span class="html-tag">&lt;/claim-text&gt;</span></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/claim-text&gt;</span></div></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/claim&gt;</span></div></div><span>
</span><div class="folder" id="folder377"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;claim<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">CLM-00003</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">00003</span>"</span>&gt;</span></div><div class="opened"><span>
</span><div class="folder" id="folder378"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;claim-text&gt;</span></div><div class="opened"><div class="line"><span class="html-tag">&lt;b&gt;</span><span>3</span><span class="html-tag">&lt;/b&gt;</span></div><span>. (canceled)</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/claim-text&gt;</span></div></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/claim&gt;</span></div></div><span>
</span><div class="folder" id="folder379"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;claim<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">CLM-00004</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">00004</span>"</span>&gt;</span></div><div class="opened"><span>
</span><div class="folder" id="folder380"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;claim-text&gt;</span></div><div class="opened"><div class="line"><span class="html-tag">&lt;b&gt;</span><span>4</span><span class="html-tag">&lt;/b&gt;</span></div><span>. The motion monitoring method of </span><div class="line"><span class="html-tag">&lt;claim-ref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">CLM-00003</span>"</span>&gt;</span><span>claim 3</span><span class="html-tag">&lt;/claim-ref&gt;</span></div><span>, wherein the segmenting, based on the feature information corresponding to the electromyographic signal or the feature information corresponding to the attitude signal, the movement signal includes:
</span><div class="line"><span class="html-tag">&lt;claim-text&gt;</span><span>determining, based on a time domain window of the electromyographic signal or the attitude signal, at least one target feature point from the time domain window according to a preset condition; and</span><span class="html-tag">&lt;/claim-text&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;claim-text&gt;</span><span>segmenting, based on the at least one target feature point, the movement signal.</span><span class="html-tag">&lt;/claim-text&gt;</span></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/claim-text&gt;</span></div></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/claim&gt;</span></div></div><span>
</span><div class="folder" id="folder381"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;claim<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">CLM-00005</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">00005</span>"</span>&gt;</span></div><div class="opened"><span>
</span><div class="folder" id="folder382"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;claim-text&gt;</span></div><div class="opened"><div class="line"><span class="html-tag">&lt;b&gt;</span><span>5</span><span class="html-tag">&lt;/b&gt;</span></div><span>. The motion monitoring method of </span><div class="line"><span class="html-tag">&lt;claim-ref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">CLM-00004</span>"</span>&gt;</span><span>claim 4</span><span class="html-tag">&lt;/claim-ref&gt;</span></div><span>, wherein the at least one target feature point includes one of a movement start point, a movement middle point, and a movement end point.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/claim-text&gt;</span></div></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/claim&gt;</span></div></div><span>
</span><div class="folder" id="folder383"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;claim<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">CLM-00006</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">00006</span>"</span>&gt;</span></div><div class="opened"><span>
</span><div class="folder" id="folder384"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;claim-text&gt;</span></div><div class="opened"><div class="line"><span class="html-tag">&lt;b&gt;</span><span>6</span><span class="html-tag">&lt;/b&gt;</span></div><span>. The motion monitoring method of </span><div class="line"><span class="html-tag">&lt;claim-ref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">CLM-00005</span>"</span>&gt;</span><span>claim 5</span><span class="html-tag">&lt;/claim-ref&gt;</span></div><span>, wherein the preset condition includes one or more of a change in the angular velocity direction corresponding to the attitude signal; the angular velocity corresponding to the attitude signal being greater than or equal to an angular velocity threshold; a changed value of the angular velocity value corresponding to the attitude signal being an extreme value; the angle corresponding to the attitude signal reaching an angular threshold; and the amplitude information corresponding to the electromyographic signal being greater than or equal to one or more electromyographic thresholds.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/claim-text&gt;</span></div></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/claim&gt;</span></div></div><span>
</span><div class="folder" id="folder385"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;claim<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">CLM-00007</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">00007</span>"</span>&gt;</span></div><div class="opened"><span>
</span><div class="folder" id="folder386"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;claim-text&gt;</span></div><div class="opened"><div class="line"><span class="html-tag">&lt;b&gt;</span><span>7</span><span class="html-tag">&lt;/b&gt;</span></div><span>. The motion monitoring method of </span><div class="line"><span class="html-tag">&lt;claim-ref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">CLM-00006</span>"</span>&gt;</span><span>claim 6</span><span class="html-tag">&lt;/claim-ref&gt;</span></div><span>, wherein the preset condition further includes the acceleration of the angular velocity corresponding to the attitude signal being continuously greater than or equal to an acceleration threshold of the angular velocity for a first specific time range.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/claim-text&gt;</span></div></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/claim&gt;</span></div></div><span>
</span><div class="folder" id="folder387"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;claim<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">CLM-00008</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">00008</span>"</span>&gt;</span></div><div class="opened"><span>
</span><div class="folder" id="folder388"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;claim-text&gt;</span></div><div class="opened"><div class="line"><span class="html-tag">&lt;b&gt;</span><span>8</span><span class="html-tag">&lt;/b&gt;</span></div><span>. The motion monitoring method of </span><div class="line"><span class="html-tag">&lt;claim-ref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">CLM-00006</span>"</span>&gt;</span><span>claim 6</span><span class="html-tag">&lt;/claim-ref&gt;</span></div><span>, wherein the preset condition further includes an amplitude corresponding to the electromyographic signal being continuously greater than the one or more electromyographic thresholds for a second specific time range.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/claim-text&gt;</span></div></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/claim&gt;</span></div></div><span>
</span><div class="folder" id="folder389"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;claim<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">CLM-00009</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">00009</span>"</span>&gt;</span></div><div class="opened"><span>
</span><div class="folder" id="folder390"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;claim-text&gt;</span></div><div class="opened"><div class="line"><span class="html-tag">&lt;b&gt;</span><span>9</span><span class="html-tag">&lt;/b&gt;</span></div><span>. The motion monitoring method of </span><div class="line"><span class="html-tag">&lt;claim-ref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">CLM-00001</span>"</span>&gt;</span><span>claim 1</span><span class="html-tag">&lt;/claim-ref&gt;</span></div><span>, wherein the monitoring, at least based on feature information corresponding to the electromyographic signal or feature information corresponding to an attitude signal, a movement of the user during motion comprises:
</span><div class="line"><span class="html-tag">&lt;claim-text&gt;</span><span>pre-processing the electromyographic signal in a frequency domain or a time domain;</span><span class="html-tag">&lt;/claim-text&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;claim-text&gt;</span><span>obtaining, based on the pre-processed electromyographic signal, the feature information corresponding to the electromyographic signal; and</span><span class="html-tag">&lt;/claim-text&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;claim-text&gt;</span><span>monitoring, according to the feature information corresponding to the electromyographic signal or the feature information corresponding to the attitude signal, the movement of the user during motion.</span><span class="html-tag">&lt;/claim-text&gt;</span></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/claim-text&gt;</span></div></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/claim&gt;</span></div></div><span>
</span><div class="folder" id="folder391"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;claim<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">CLM-00010</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">00010</span>"</span>&gt;</span></div><div class="opened"><span>
</span><div class="folder" id="folder392"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;claim-text&gt;</span></div><div class="opened"><div class="line"><span class="html-tag">&lt;b&gt;</span><span>10</span><span class="html-tag">&lt;/b&gt;</span></div><span>. The motion monitoring method of </span><div class="line"><span class="html-tag">&lt;claim-ref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">CLM-00009</span>"</span>&gt;</span><span>claim 9</span><span class="html-tag">&lt;/claim-ref&gt;</span></div><span>, wherein the pre-processing the electromyographic signal in a frequency domain or a time domain includes:
</span><div class="line"><span class="html-tag">&lt;claim-text&gt;</span><span>filtering the electromyographic signal to select components of the electromyographic signal in a specific frequency range in the frequency domain.</span><span class="html-tag">&lt;/claim-text&gt;</span></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/claim-text&gt;</span></div></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/claim&gt;</span></div></div><span>
</span><div class="folder" id="folder393"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;claim<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">CLM-00011</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">00011</span>"</span>&gt;</span></div><div class="opened"><span>
</span><div class="folder" id="folder394"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;claim-text&gt;</span></div><div class="opened"><div class="line"><span class="html-tag">&lt;b&gt;</span><span>11</span><span class="html-tag">&lt;/b&gt;</span></div><span>. The motion monitoring method of </span><div class="line"><span class="html-tag">&lt;claim-ref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">CLM-00009</span>"</span>&gt;</span><span>claim 9</span><span class="html-tag">&lt;/claim-ref&gt;</span></div><span>, wherein the pre-processing the electromyographic signal in a frequency domain or a time domain includes:
</span><div class="line"><span class="html-tag">&lt;claim-text&gt;</span><span>performing a signal correction processing on the electromyographic signal in the time domain.</span><span class="html-tag">&lt;/claim-text&gt;</span></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/claim-text&gt;</span></div></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/claim&gt;</span></div></div><span>
</span><div class="folder" id="folder395"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;claim<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">CLM-00012</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">00012</span>"</span>&gt;</span></div><div class="opened"><span>
</span><div class="folder" id="folder396"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;claim-text&gt;</span></div><div class="opened"><div class="line"><span class="html-tag">&lt;b&gt;</span><span>12</span><span class="html-tag">&lt;/b&gt;</span></div><span>. The motion monitoring method of </span><div class="line"><span class="html-tag">&lt;claim-ref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">CLM-00011</span>"</span>&gt;</span><span>claim 11</span><span class="html-tag">&lt;/claim-ref&gt;</span></div><span>, wherein the performing a signal correction processing on the electromyographic signal in the time domain includes:
</span><div class="line"><span class="html-tag">&lt;claim-text&gt;</span><span>determining a singularity in the electromyographic signal, wherein the singularity corresponds to an abrupt signal of the electromyographic signal; and</span><span class="html-tag">&lt;/claim-text&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;claim-text&gt;</span><span>performing the signal correction processing on the singularity in the electromyographic signal.</span><span class="html-tag">&lt;/claim-text&gt;</span></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/claim-text&gt;</span></div></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/claim&gt;</span></div></div><span>
</span><div class="folder" id="folder397"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;claim<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">CLM-00013</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">00013</span>"</span>&gt;</span></div><div class="opened"><span>
</span><div class="folder" id="folder398"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;claim-text&gt;</span></div><div class="opened"><div class="line"><span class="html-tag">&lt;b&gt;</span><span>13</span><span class="html-tag">&lt;/b&gt;</span></div><span>. The motion monitoring method of </span><div class="line"><span class="html-tag">&lt;claim-ref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">CLM-00012</span>"</span>&gt;</span><span>claim 12</span><span class="html-tag">&lt;/claim-ref&gt;</span></div><span>, wherein the performing the signal correction processing on the singularity in the electromyographic signal includes removing the singularity or performing the signal correction processing on the singularity according to a signal around the singularity includes:
</span><div class="line"><span class="html-tag">&lt;claim-text&gt;</span><span>removing the singularity, or correcting the singularity according to a signal around the singularity.</span><span class="html-tag">&lt;/claim-text&gt;</span></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/claim-text&gt;</span></div></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/claim&gt;</span></div></div><span>
</span><div class="folder" id="folder399"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;claim<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">CLM-00014</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">00014</span>"</span>&gt;</span></div><div class="opened"><span>
</span><div class="folder" id="folder400"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;claim-text&gt;</span></div><div class="opened"><div class="line"><span class="html-tag">&lt;b&gt;</span><span>14</span><span class="html-tag">&lt;/b&gt;</span></div><span>. The motion monitoring method of </span><div class="line"><span class="html-tag">&lt;claim-ref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">CLM-00012</span>"</span>&gt;</span><span>claim 12</span><span class="html-tag">&lt;/claim-ref&gt;</span></div><span>, wherein the singularity includes a burr signal, the determining the singularity in the electromyographic signal includes:
</span><div class="line"><span class="html-tag">&lt;claim-text&gt;</span><span>selecting, based on the time domain window of the electromyographic signal, different time windows from the time domain window of the electromyographic signal, wherein the different time windows respectively cover different time ranges; and</span><span class="html-tag">&lt;/claim-text&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;claim-text&gt;</span><span>determining, based on the feature information corresponding to the electromyographic signal in the different time windows, the burr signal.</span><span class="html-tag">&lt;/claim-text&gt;</span></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/claim-text&gt;</span></div></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/claim&gt;</span></div></div><span>
</span><div class="folder" id="folder401"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;claim<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">CLM-00015</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">00015</span>"</span>&gt;</span></div><div class="opened"><span>
</span><div class="folder" id="folder402"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;claim-text&gt;</span></div><div class="opened"><div class="line"><span class="html-tag">&lt;b&gt;</span><span>15</span><span class="html-tag">&lt;/b&gt;</span></div><span>. The motion monitoring method of </span><div class="line"><span class="html-tag">&lt;claim-ref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">CLM-00001</span>"</span>&gt;</span><span>claim 1</span><span class="html-tag">&lt;/claim-ref&gt;</span></div><span>, further comprising determining, based on the attitude signal, the feature information corresponding to the attitude signal, wherein the attitude signal comprises coordinate information in at least one original coordinate system; and
</span><div class="line"><span class="html-tag">&lt;claim-text&gt;</span><span>determining, based on the attitude signal, the feature information corresponding to the attitude signal comprises:</span><span class="html-tag">&lt;/claim-text&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;claim-text&gt;</span><span>obtaining a target coordinate system and a conversion relationship between the target coordinate system and the at least one original coordinate system;</span><span class="html-tag">&lt;/claim-text&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;claim-text&gt;</span><span>converting, based on the conversion relationship, the coordinate information in the at least one original coordinate system to coordinate information in the target coordinate system; and</span><span class="html-tag">&lt;/claim-text&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;claim-text&gt;</span><span>determining, based on the coordinate information in the target coordinate system, the feature information corresponding to the attitude signal.</span><span class="html-tag">&lt;/claim-text&gt;</span></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/claim-text&gt;</span></div></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/claim&gt;</span></div></div><span>
</span><div class="folder" id="folder403"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;claim<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">CLM-00016</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">00016</span>"</span>&gt;</span></div><div class="opened"><span>
</span><div class="folder" id="folder404"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;claim-text&gt;</span></div><div class="opened"><div class="line"><span class="html-tag">&lt;b&gt;</span><span>16</span><span class="html-tag">&lt;/b&gt;</span></div><span>. The motion monitoring method of </span><div class="line"><span class="html-tag">&lt;claim-ref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">CLM-00015</span>"</span>&gt;</span><span>claim 15</span><span class="html-tag">&lt;/claim-ref&gt;</span></div><span>, wherein the attitude signal includes coordinate information generated by at least two sensors, the at least two sensors are located at different motion parts of the user and correspond to different original coordinate systems, the determining, based on the attitude signal, the feature information corresponding to the attitude signal includes:
</span><div class="line"><span class="html-tag">&lt;claim-text&gt;</span><span>determining feature information corresponding to each of the at least two sensors based on the conversion relationship between different original coordinate systems and the target coordinate system; and</span><span class="html-tag">&lt;/claim-text&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;claim-text&gt;</span><span>determining, based on the feature information respectively corresponding to the at least two sensors, a relative motion between the motion parts of the user.</span><span class="html-tag">&lt;/claim-text&gt;</span></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/claim-text&gt;</span></div></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/claim&gt;</span></div></div><span>
</span><div class="folder" id="folder405"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;claim<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">CLM-00017</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">00017</span>"</span>&gt;</span></div><div class="opened"><span>
</span><div class="folder" id="folder406"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;claim-text&gt;</span></div><div class="opened"><div class="line"><span class="html-tag">&lt;b&gt;</span><span>17</span><span class="html-tag">&lt;/b&gt;</span></div><span>. The motion monitoring method of </span><div class="line"><span class="html-tag">&lt;claim-ref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">CLM-00015</span>"</span>&gt;</span><span>claim 15</span><span class="html-tag">&lt;/claim-ref&gt;</span></div><span>, wherein the conversion relationship between the at least one original coordinate system and the target coordinate system is obtained by a calibration process including:
</span><div class="line"><span class="html-tag">&lt;claim-text&gt;</span><span>constructing a specific coordinate system, the specific coordinate system being related to an orientation of the user during the calibration process;</span><span class="html-tag">&lt;/claim-text&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;claim-text&gt;</span><span>obtaining first coordinate information of the at least one original coordinate system when the user is in a first pose;</span><span class="html-tag">&lt;/claim-text&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;claim-text&gt;</span><span>obtaining second coordinate information of the at least one original coordinate system when the user is in a second pose; and</span><span class="html-tag">&lt;/claim-text&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;claim-text&gt;</span><span>determining the conversion relationship between the at least one original coordinate system and the specific coordinate system according to the first coordinate information, the second coordinate information, and the specific coordinate system.</span><span class="html-tag">&lt;/claim-text&gt;</span></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/claim-text&gt;</span></div></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/claim&gt;</span></div></div><span>
</span><div class="folder" id="folder407"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;claim<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">CLM-00018</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">00018</span>"</span>&gt;</span></div><div class="opened"><span>
</span><div class="folder" id="folder408"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;claim-text&gt;</span></div><div class="opened"><div class="line"><span class="html-tag">&lt;b&gt;</span><span>18</span><span class="html-tag">&lt;/b&gt;</span></div><span>. The motion monitoring method of </span><div class="line"><span class="html-tag">&lt;claim-ref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">CLM-00017</span>"</span>&gt;</span><span>claim 17</span><span class="html-tag">&lt;/claim-ref&gt;</span></div><span>, where the calibration process further includes:
</span><div class="line"><span class="html-tag">&lt;claim-text&gt;</span><span>obtaining a conversion relationship between the specific coordinate system and the target coordinate system; and</span><span class="html-tag">&lt;/claim-text&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;claim-text&gt;</span><span>determining, according to the conversion relationship between the at least one original coordinate system and the specific coordinate system as well as the conversion relationship between the specific coordinate system and target coordinate system, the conversion relationship between the at least one original coordinate system and the target coordinate system.</span><span class="html-tag">&lt;/claim-text&gt;</span></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/claim-text&gt;</span></div></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/claim&gt;</span></div></div><span>
</span><div class="folder" id="folder409"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;claim<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">CLM-00019</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">00019</span>"</span>&gt;</span></div><div class="opened"><span>
</span><div class="folder" id="folder410"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;claim-text&gt;</span></div><div class="opened"><div class="line"><span class="html-tag">&lt;b&gt;</span><span>19</span><span class="html-tag">&lt;/b&gt;</span></div><span>. The motion monitoring method of </span><div class="line"><span class="html-tag">&lt;claim-ref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">CLM-00015</span>"</span>&gt;</span><span>claim 15</span><span class="html-tag">&lt;/claim-ref&gt;</span></div><span>, wherein the target coordinate system changes as the user's orientation changes.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/claim-text&gt;</span></div></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/claim&gt;</span></div></div><span>
</span><div class="folder" id="folder411"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;claim<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">CLM-00020</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">00020</span>"</span>&gt;</span></div><div class="opened"><span>
</span><div class="folder" id="folder412"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;claim-text&gt;</span></div><div class="opened"><div class="line"><span class="html-tag">&lt;b&gt;</span><span>20</span><span class="html-tag">&lt;/b&gt;</span></div><span>. (canceled)</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/claim-text&gt;</span></div></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/claim&gt;</span></div></div><span>
</span><div class="folder" id="folder413"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;claim<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">CLM-00021</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">00021</span>"</span>&gt;</span></div><div class="opened"><span>
</span><div class="folder" id="folder414"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;claim-text&gt;</span></div><div class="opened"><div class="line"><span class="html-tag">&lt;b&gt;</span><span>21</span><span class="html-tag">&lt;/b&gt;</span></div><span>. A motion monitoring and feedback method, comprising:
</span><div class="line"><span class="html-tag">&lt;claim-text&gt;</span><span>obtaining movement signal of a user during motion, wherein the movement signal includes at least an electromyographic signal and an attitude signal; and</span><span class="html-tag">&lt;/claim-text&gt;</span></div><span>
</span><div class="line"><span class="html-tag">&lt;claim-text&gt;</span><span>monitoring, based on feature information corresponding to the electromyographic signal and feature information corresponding to the attitude signal, a movement of a user by a movement recognition model, and providing, based on an output of the movement recognition model, a movement feedback.</span><span class="html-tag">&lt;/claim-text&gt;</span></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/claim-text&gt;</span></div></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/claim&gt;</span></div></div><span>
</span><div class="folder" id="folder415"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;claim<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">CLM-00022</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">00022</span>"</span>&gt;</span></div><div class="opened"><span>
</span><div class="folder" id="folder416"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;claim-text&gt;</span></div><div class="opened"><div class="line"><span class="html-tag">&lt;b&gt;</span><span>22</span><span class="html-tag">&lt;/b&gt;</span></div><span>. (canceled)</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/claim-text&gt;</span></div></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/claim&gt;</span></div></div><span>
</span><div class="folder" id="folder417"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;claim<span class="html-attribute"> <span class="html-attribute-name">id</span>="<span class="html-attribute-value">CLM-00023</span>"</span><span class="html-attribute"> <span class="html-attribute-name">num</span>="<span class="html-attribute-value">00023</span>"</span>&gt;</span></div><div class="opened"><span>
</span><div class="folder" id="folder418"><div class="line"><span class="folder-button fold"></span><span class="html-tag">&lt;claim-text&gt;</span></div><div class="opened"><div class="line"><span class="html-tag">&lt;b&gt;</span><span>23</span><span class="html-tag">&lt;/b&gt;</span></div><span>. The motion monitoring and feedback method of </span><div class="line"><span class="html-tag">&lt;claim-ref<span class="html-attribute"> <span class="html-attribute-name">idref</span>="<span class="html-attribute-value">CLM-00021</span>"</span>&gt;</span><span>claim 21</span><span class="html-tag">&lt;/claim-ref&gt;</span></div><span>, wherein the movement feedback includes at least one of sending a prompt message, stimulating a movement part of the user, and outputting a motion record of the user during motion.</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/claim-text&gt;</span></div></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/claim&gt;</span></div></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/claims&gt;</span></div></div><span>
</span></div><span class="folded hidden">...</span><div class="line"><span class="html-tag">&lt;/us-patent-application&gt;</span></div></div></div></body></html>