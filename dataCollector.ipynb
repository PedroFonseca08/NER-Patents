{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collector (Patentes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando bibliotecas\n",
    "\n",
    "Bibliotecas que serão utilizadas no decorrer da aplicação. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.common.exceptions import NoSuchElementException, ElementNotInteractableException\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variáveis Globais\n",
    "\n",
    "Definindo os parâmetros para a extração de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variáveis globais para coletar dados do Google Patents\n",
    "htmls_folder = \"htmlsGooglePatents\"\n",
    "page_numbers = 2\n",
    "url_google_patents = 'https://patents.google.com/?q=(\"Smart+mobility\")&country=US&language=ENGLISH&type=PATENT&num=100'\n",
    "patentsHTML_folder = 'patentsHTML'\n",
    "patentsXML_folder = 'patentsXML'\n",
    "db_name = \"NER-Patents-DB\"\n",
    "db_collection = \"patents\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### URL referente ao filtro das patentes\n",
    "\n",
    "Utilizando o webdriver(chrome) da bilbioteca selenium para acessar ao link referente ao Google Patents com um filtro específico, além de ser possível delimitar o filtro, também é possível delimitar a quantidade de páginas que serão baixadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "service = Service()\n",
    "options = webdriver.ChromeOptions()\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "\n",
    "driver.get(url_google_patents)\n",
    "\n",
    "for i in range(page_numbers):\n",
    "\n",
    "    time.sleep(3)\n",
    "    \n",
    "    html = driver.page_source\n",
    "\n",
    "    file_name = 'paginaPatentes' + time.strftime(\"%Y%m%d_%H%M%S\") + '.html'\n",
    "    file_path = os.path.join(htmls_folder, file_name)\n",
    "\n",
    "    with open(file_path, 'w', encoding='utf-8') as file:\n",
    "        file.write(html)\n",
    "\n",
    "    next_link = None\n",
    "    try:\n",
    "        next_link = driver.find_element(By.XPATH, '/html/body/search-app/search-results/search-ui/div/div/div/div/div/div[1]/div[6]/search-paging/state-modifier[3]/a/paper-icon-button/iron-icon')\n",
    "    except NoSuchElementException:\n",
    "        break\n",
    "\n",
    "    if next_link and next_link.is_displayed() and next_link.is_enabled():\n",
    "        try:\n",
    "            next_link.click()\n",
    "        except ElementNotInteractableException:\n",
    "            print(\"Elemento de próxima página não está interagível.\")\n",
    "            break\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coletando HTML e PDF de cada patente\n",
    "\n",
    "Utilazando o BeautifulSoup para conseguir extrair os HTMLs de cada patente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_names = []\n",
    "\n",
    "i = 0\n",
    "for filename in os.listdir(htmls_folder):\n",
    "    if filename.endswith('.html'):\n",
    "        filepath = os.path.join(htmls_folder, filename)\n",
    "        with open(filepath, 'r', encoding='utf-8') as file:\n",
    "            html_content = file.read()\n",
    "        \n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "        \n",
    "        spans = soup.find_all('span', {'data-proto': 'OPEN_PATENT_PDF'})\n",
    "        \n",
    "        for span in spans:\n",
    "            files_names.append(span.text.strip())\n",
    "            patent_filename = files_names[i] + '.html'\n",
    "            patent_html_path = os.path.join(patentsHTML_folder, patent_filename)\n",
    "            if not os.path.exists(patent_html_path):              \n",
    "                patent_link = 'https://patents.google.com/patent/' + span.text.strip()\n",
    "                patent_html_response = requests.get(patent_link)\n",
    "                if patent_html_response.status_code == 200:\n",
    "                    patent_html_content = patent_html_response.text\n",
    "                    with open(patent_html_path, 'w', encoding='utf-8') as patent_html_file:\n",
    "                        patent_html_file.write(patent_html_content)\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coletando dados das patenes\n",
    "Os dados coletados dos HTMLs (título e número da aplicação) serão utilizados para o web scrapling da plataforma WIPO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "patent_application_numbers = []\n",
    "patent_application_pattern = r\"US(\\d+)/(\\d+),(\\d+)\"\n",
    "\n",
    "for filename in os.listdir(patentsHTML_folder):\n",
    "\n",
    "    if filename.endswith('.html'):\n",
    "\n",
    "        html_path = os.path.join(patentsHTML_folder, filename)\n",
    "        \n",
    "        with open(html_path, 'r', encoding='utf-8') as file:\n",
    "            html_file = file.read()\n",
    "\n",
    "        soup = BeautifulSoup(html_file, 'html.parser')\n",
    "\n",
    "        patent_application_find = soup.find('dd', itemprop='applicationNumber')\n",
    "        patent_application = patent_application_find.get_text().strip()\n",
    "        patent_number_match = re.match(patent_application_pattern, patent_application)\n",
    "\n",
    "        patent_title_find = soup.find('span', itemprop='title')\n",
    "        patent_title = patent_title_find.get_text().strip()\n",
    "\n",
    "        if patent_number_match:\n",
    "            patent_application_number = patent_number_match.group(1) + patent_number_match.group(2) + patent_number_match.group(3)\n",
    "            patent_application_numbers.append((filename, patent_title , patent_application_number))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web Scrapling na plataforma WIPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_wipo = 'https://patentscope.wipo.int/search/en/search.jsf'\n",
    "\n",
    "service = Service()\n",
    "options = webdriver.ChromeOptions()\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "for patent in patent_application_numbers:\n",
    "    \n",
    "    filename_xml = patent[0].replace(\".html\", \".xml\")\n",
    "    xml_path = os.path.join(patentsXML_folder, filename_xml)\n",
    "\n",
    "    if not os.path.exists(xml_path):\n",
    "        driver.get(url_wipo)\n",
    "        time.sleep(10)\n",
    "\n",
    "        input_element = driver.find_element(By.XPATH, '/html/body/div[2]/div[5]/div/div[2]/form/div/div[1]/div[2]/div/div/div[1]/div[1]/input')\n",
    "        input_element.send_keys(\"EN_TI:(\\\"\" + patent[1] + \"\\\") AND AN:(\"+ patent[2] +\")\")\n",
    "\n",
    "        button_element = driver.find_element(By.XPATH, '/html/body/div[2]/div[5]/div/div[2]/form/div/div[1]/div[2]/div/div/div[1]/div[2]/button')\n",
    "        button_element.click()\n",
    "        time.sleep(10)\n",
    "\n",
    "        document_element = driver.find_element(By.LINK_TEXT, 'Documents')\n",
    "        document_element.click()\n",
    "        time.sleep(5)\n",
    "\n",
    "        link_element = driver.find_element(By.LINK_TEXT, 'XML')\n",
    "        link_url = link_element.get_attribute('href')\n",
    "\n",
    "        driver.get(link_url)\n",
    "        page_content = driver.page_source\n",
    "\n",
    "        xml_path = os.path.join(patentsXML_folder, filename_xml)\n",
    "        with open(xml_path, 'w', encoding='utf-8') as file:\n",
    "            file.write(page_content)\n",
    "        time.sleep(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classe Pantete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "class Patent:\n",
    "    def __init__(self):\n",
    "        self.patent_title = None\n",
    "        self.patent_number = None\n",
    "        self.date_of_patent = None\n",
    "        self.date_filed = None\n",
    "        self.applicants = []\n",
    "        self.inventors = []\n",
    "        self.assignees = []\n",
    "        self.classifications = []\n",
    "        self.agents = []\n",
    "        self.abstract = None\n",
    "        self.claims = []\n",
    "\n",
    "    def convert_dated(self, date_str):\n",
    "        date_obj = datetime.strptime(date_str, '%Y%m%d')\n",
    "\n",
    "        return (date_obj.strftime('%d/%m/%Y'))\n",
    "\n",
    "\n",
    "    def extract_info(self, element):\n",
    "        orgname = element.find('orgname')\n",
    "        last_name = element.find('last-name')\n",
    "        first_name = element.find('first-name')\n",
    "        city = element.find('city')\n",
    "        state = element.find('state')\n",
    "        country = element.find('country')\n",
    "\n",
    "        orgname = orgname.text if orgname else None\n",
    "        last_name = last_name.text if last_name else None\n",
    "        first_name = first_name.text if first_name else None\n",
    "        city = city.text if city else None\n",
    "        state = state.text if state else None\n",
    "        country = country.text if country else None\n",
    "\n",
    "        return orgname, last_name, first_name, city, state, country\n",
    "\n",
    "    def process_elements(self, elements, type):\n",
    "        for element in elements:\n",
    "            orgname, last_name, first_name, city, state, country = self.extract_info(element)\n",
    "            \n",
    "            if orgname is not None:\n",
    "                name = orgname\n",
    "            else:\n",
    "                name = first_name + \" \" + last_name\n",
    "\n",
    "            if type == 'INV':\n",
    "                self.add_inventor(name, city, state, country)        \n",
    "            elif type == 'ASS':\n",
    "                self.add_assignee(name, city, state, country)  \n",
    "            elif type == 'APP':\n",
    "                self.add_applicant(name, city, state, country)  \n",
    "\n",
    "    def extract_data_xml(self, xml_content, filename):\n",
    "\n",
    "        soup = BeautifulSoup(xml_content, 'html.parser')\n",
    "        \n",
    "        self.patent_title = soup.find('invention-title').text\n",
    "\n",
    "        self.patent_number = os.path.splitext(filename)[0]\n",
    "        \n",
    "        date_patent_find = soup.find('document-id')\n",
    "        self.date_of_patent = self.convert_dated(date_patent_find.find('date').text)\n",
    "\n",
    "        date_filed_find = soup.find('application-reference')\n",
    "        self.date_filed = self.convert_dated(date_filed_find.find('date').text)\n",
    "\n",
    "        inventors = soup.find_all('inventor')\n",
    "        self.process_elements(inventors, 'INV')\n",
    "\n",
    "        assignees = soup.find_all('assignee')\n",
    "        self.process_elements(assignees, 'ASS')\n",
    "\n",
    "        applicants = soup.find_all('us-applicant')\n",
    "        self.process_elements(applicants, 'APP')\n",
    "        \n",
    "        classifications = soup.find_all('classification-ipcr')\n",
    "\n",
    "        for classification in classifications:\n",
    "            section = classification.find('section').text if classification.find('section') else None\n",
    "            class_ = classification.find('class').text if classification.find('class') else None\n",
    "            subclass = classification.find('subclass').text if classification.find('subclass') else None\n",
    "            main_group = classification.find('main-group').text if classification.find('main-group') else None\n",
    "            subgroup = classification.find('subgroup').text if classification.find('subgroup') else None\n",
    "\n",
    "            classification_str = f\"{section}{class_}{subclass}{main_group}/{subgroup}\"\n",
    "            self.classifications.append(classification_str)\n",
    "\n",
    "        agents = soup.find_all('agent')\n",
    "\n",
    "        for agent in agents:\n",
    "            orgname = agent.find('orgname').text if agent.find('orgname') else None\n",
    "            last_name = agent.find('last-name').text if agent.find('last-name') else None\n",
    "            first_name = agent.find('first-name').text if agent.find('first-name') else None\n",
    "\n",
    "            if orgname is not None:\n",
    "                self.agents.append(orgname)\n",
    "            elif first_name is not None and last_name is not None:\n",
    "                self.agents.append(first_name + \" \" + last_name)\n",
    "\n",
    "        self.abstract = soup.find('abstract').text\n",
    "\n",
    "        claims = soup.find_all('claim')\n",
    "\n",
    "        for claim in claims:\n",
    "            claim_text = claim.find('claim-text').text\n",
    "            self.claims.append(claim_text)\n",
    "    \n",
    "    def add_applicant(self, name, city, state, country):\n",
    "        self.applicants.append({\n",
    "            \"name\": name,\n",
    "            \"city\": city,\n",
    "            \"state\": state,\n",
    "            \"country\": country\n",
    "        })\n",
    "\n",
    "    def add_inventor(self, name, city, state, country):\n",
    "        self.inventors.append({\n",
    "            \"name\": name,\n",
    "            \"city\": city,\n",
    "            \"state\": state,\n",
    "            \"country\": country\n",
    "        })\n",
    "\n",
    "    def add_assignee(self, name, city, state, country):\n",
    "        self.assignees.append({\n",
    "            \"name\": name,\n",
    "            \"city\": city,\n",
    "            \"state\": state,\n",
    "            \"country\": country\n",
    "        })\n",
    "    \n",
    "    def print_patent_info(self):\n",
    "        print(\"Patent Title:\", self.patent_title)\n",
    "        print(\"Patent Number:\", self.patent_number)\n",
    "        print(\"Date Filed:\", self.date_filed)\n",
    "        print(\"Date of Patent:\", self.date_of_patent)\n",
    "        print(\"Applicants:\")\n",
    "        for applicant in self.applicants:\n",
    "            print(applicant)\n",
    "        print(\"Inventors:\")\n",
    "        for inventor in self.inventors:\n",
    "            print(inventor)\n",
    "        print(\"Assignees:\")\n",
    "        for assignee in self.assignees:\n",
    "            print(assignee)\n",
    "        print(\"Classifications:\", self.classifications)\n",
    "        print(\"Agents:\", self.agents)\n",
    "        print(\"Abstract:\", self.abstract)\n",
    "        print(\"Claims:\")\n",
    "        print(self.claims)\n",
    "            \n",
    "    def to_document(self):\n",
    "        document = {\n",
    "            \"patent_title\": self.patent_title,\n",
    "            \"patent_number\": self.patent_number,\n",
    "            \"date_of_patent\": self.date_of_patent,\n",
    "            \"date_filed\": self.date_filed,\n",
    "            \"applicants\": self.applicants,\n",
    "            \"inventors\": self.inventors,\n",
    "            \"assignees\": self.assignees,\n",
    "            \"classifications\": self.classifications,\n",
    "            \"agents\": self.agents,\n",
    "            \"abstract\": self.abstract,\n",
    "            \"claims\": self.claims,\n",
    "        }\n",
    "        \n",
    "        return document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coletando dados do XML\n",
    "\n",
    "Armazenando os dados presentes no XML em uma lista da classe patentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "patents = []\n",
    "for filename in os.listdir(patentsXML_folder):\n",
    "    filepath = os.path.join(patentsXML_folder, filename)\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        xml_file = file.read() \n",
    "        \n",
    "        patent = Patent()\n",
    "        patent.extract_data_xml(xml_file, filename)\n",
    "        patents.append(patent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Banco de Dados\n",
    "\n",
    "Criação e inserção das patentes no banco de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "\n",
    "connection_string = \"mongodb://localhost:27017/\"\n",
    "try:\n",
    "    client = pymongo.MongoClient(connection_string)\n",
    "    db = client[db_name]\n",
    "    collection = db[db_collection]\n",
    "except pymongo.errors.ConnectionFailure as e:\n",
    "    print(\"Falha na conexão com o MongoDB:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "for patent in patents:\n",
    "    new_document = patent.to_document()\n",
    "    result = collection.insert_one(new_document)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
